{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug interaction prediction in *E. coli*\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Compound class stratified validation](#classlockout)\n",
    "* [Choose thresholds for interactions](#threshclass)\n",
    "* [Precision-recall and ROC curves](#pr)\n",
    "* [Probability calibration](#calib)\n",
    "* [Predictions on the test set](#test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "sys.path.append('..')\n",
    "import base.chemgen_utils as utl\n",
    "import MLmod.predictor as prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "It has been previously shown that drug interactions can be predicted in bacteria using chemogenomic data. Here we use random forest classifier on single-compound chemical genetics data in *E. coli* to predict antagonisms, synergies and additive combinations. \n",
    "\n",
    "We encode our input predictor matrix as follows: \n",
    "+ For each combination load single-compound profiles. Each profile has dimensions `(1 x genes)` and the following possible gene states {-1,0,+1}. Negative drug-gene interaction (-1) implies increased sensitivity in that gene deletion, while positive gene state (+1) indicates decreased sensitivity in that mutant\n",
    "+ Combination profiles are generaeted based on superposition of individual drug profiles and may take on the following gene states {-2, -1, 0, +1, +2, +/-}\n",
    "+ We then use one-hot encoding scheme (\"dummy variable encoding\") before passing the predictor matrix `X` to the classifier\n",
    "\n",
    "We furthermore subset the data so that only those genes are included that are significantly enriched in antagonisms and synergies based on chi-squared test. This gene list is `interaction-genes-Ecoli`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugleg_fname = \"../data/chemicals/legend_gramnegpos.txt\"\n",
    "gene_subset = '../data/interaction-genes-Ecoli'\n",
    "gene_subset = pd.read_csv(gene_subset, header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chemgen = pd.read_csv('../data/chemgenetics/nichols_signed.csv', index_col=0)\n",
    "X_chemgen = X_chemgen.iloc[:,np.where(np.isin(X_chemgen.columns, gene_subset))[0]]\n",
    "targets = pd.read_csv(\"../data/chemgenetics/nichols_y.csv\")\n",
    "combs = targets['comb'].values\n",
    "y = targets['type'].values\n",
    "\n",
    "X_df = pd.DataFrame([utl.get_comb_feat_signed(X_chemgen, c) for c in combs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using `OneVsRestClassifier`, we convert our categorical response variable `y` (\"synergy\" ,\"antagonism\", \"none\") into a `n x 3` binary array using `label_binarize` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs rest classification\n",
    "y[y=='none'] = 0\n",
    "y[y=='antagonism']=1\n",
    "y[y=='synergy']=2\n",
    "\n",
    "y=y.astype('int')\n",
    "y = label_binarize(y, classes=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode combination profiles using one-hot encoding scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = pd.get_dummies(X_df.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot.iloc[:6,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least 5 combinations with that variable set\n",
    "X_onehot = X_onehot.loc[:,(X_onehot.sum(axis=0) > 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed grid search to find the best parameters for the `RandomForestClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'n_estimators': 300,\n",
    " 'min_samples_split': 6,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_depth': None,\n",
    " 'class_weight': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classlockout\"></a> \n",
    "## Compound Class Stratified Validation\n",
    "In order to assess the generalization error we stratified the data by compound class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugclasses = pd.read_csv(drugleg_fname, sep='\\t')\n",
    "druglegend = drugclasses.loc[:,['Drug', 'Class']]\n",
    "\n",
    "comb_drugs = pd.DataFrame(np.array([utl.split_vec(i) for i in combs]),\n",
    "                          columns=['d1', 'd2'])\n",
    "comb_drugs = utl.add_class(strain=comb_drugs,\n",
    "                           druglegend=druglegend)\n",
    "# an array with all drug class labels\n",
    "class_arr = np.unique(np.union1d(pd.unique(comb_drugs.class1),\n",
    "                                 pd.unique(comb_drugs.class2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_drugs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each cross-validation iteration we withhold the data of a certain drug class and test the trained model on the withheld combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = prd.MultiClassPredictions(X=X_onehot.to_numpy(), y=y,\n",
    "                                   combs=combs,\n",
    "                                  **param_dict,\n",
    "                                   clf='randomforest',\n",
    "                                   top = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.crossval_drugclass(class_arr=class_arr, leg_class=comb_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pr.save_topfeat(outdir='../data/chemgenetics/', \n",
    "                fname=\"topfeat-multiclass-Nichols-signed\",\n",
    "                    featname=X_onehot.columns.values)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df = (pd.concat({k: pd.DataFrame(v.values(),\n",
    "                                   index=['AUCROC_none',\n",
    "                                          'AUCROC_antag',\n",
    "                                          'AUCROC_syn']).T \\\n",
    "                   for k,v in pr.auc.items()}).\n",
    "         reset_index().rename(columns={\"level_0\": \"cvfold\"}).\n",
    "         drop(columns=[\"level_1\"]))\n",
    "\n",
    "ap_df = (pd.concat({k: pd.DataFrame(v.values(),\n",
    "                           index=['AP_none',\n",
    "                                  'AP_antag',\n",
    "                                  'AP_syn']).T \\\n",
    "           for k,v in pr.avprec.items()}).\n",
    " reset_index().rename(columns={\"level_0\": \"cvfold\"}).\n",
    " drop(columns=[\"level_1\"]))\n",
    "\n",
    "metrics = pd.merge(auc_df, ap_df, on='cvfold', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows the cross-validation results sorted by average precision for antagonism prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics.\n",
    " sort_values('AP_antag', ascending=False).\n",
    " reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for synergy prediction - arrange the table by average precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics.\n",
    " sort_values('AP_syn', ascending=False).\n",
    " reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the most important genetic features and rank them by the number of cross-validation folds in which these appeared as top 30 features based on the splitting criterion (Gini impurity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvars = (pd.concat(pr.topfeat).\n",
    "                   reset_index().\n",
    "                   rename(columns={\"level_0\": \"cvfold\"}).\n",
    "                   drop(columns=['level_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featname=X_onehot.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvars = (topvars.assign(feature=featname[topvars.feat]).\n",
    "           drop(columns=['feat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top genes for antagonism prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(topvars[topvars.type == 'antagonism'].\n",
    " groupby('feature').agg('count').\n",
    " query('cvfold > 1').\n",
    " sort_values('cvfold', ascending=False).iloc[:30,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top genes for synergy prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(topvars[topvars.type == 'synergy'].\n",
    " groupby('feature').agg('count').\n",
    " query('cvfold > 1').\n",
    " sort_values('cvfold', ascending=False).iloc[:30,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"threshclass\"></a> \n",
    "## Choose Thresholds for Antagonisms and Synergies\n",
    "The 'probability' score $p_{RF}$ output by random forests does not correspond to the probability of being a synergy or antagonism, i.e. \n",
    "$$p_{RF}(c=C|X) \\neq P(c=C|X)$$\n",
    "\n",
    "By construction random forests do not approximate class probabilities (unlike logistic regression e.g.) and due to class imbalance (80% additive combinations, 10% synergies, 10% antagonisms) almost all combinations are predicted to be neutral if one takes \n",
    "$$ \\hat{C} = \\mathrm{argmax} (p_{RF}(c|X)) $$\n",
    "\n",
    "Since we are using `OneVsRestClassifier` however, we have technically 3 different binary classifiers, one for each combination type. We can use precision-recall characteristics in cross-validation folds to find thresholds for $p_{RF}(c=\\mathrm{antagonism}|X)$ and $p_{RF}(c=\\mathrm{synergy}|X)$.\n",
    "\n",
    "In each cross-validation fold select thresholds such that precision > 0.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose prob score cutoff such that precision > 0.6\n",
    "prec_thresh = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "TP_df = list()\n",
    "for cl in pr.predicted.keys():\n",
    "    # print(cl)\n",
    "    ycl = y[np.isin(combs, pr.predicted[cl]['comb'].values)]\n",
    "    gt = pd.DataFrame(ycl, columns=['none', 'antagonism', 'synergy'])\n",
    "    gt['comb'] = combs[np.isin(combs, pr.predicted[cl]['comb'].values)]\n",
    "    pred_df = pd.merge(left=pr.predicted[cl], right=gt, how='inner', on='comb')\n",
    "    \n",
    "    precision, recall, thresh = precision_recall_curve(pred_df['antagonism'].values,\n",
    "                                                        pred_df['prob_ant'].values)\n",
    "    if np.any(precision > prec_thresh):\n",
    "        # maximum recall\n",
    "        rmax = np.max(recall[precision > prec_thresh])\n",
    "        # maximum precision\n",
    "        pmax = np.max(precision[recall == rmax])\n",
    "        # index with maximum recall and precision > prec_thresh\n",
    "        idx = np.where(np.logical_and(precision == pmax, recall == rmax))[0][0]\n",
    "        # corresponding threshold\n",
    "        antag_thresh = thresh[idx] if idx < len(thresh) else thresh[-1]\n",
    "        antag_tp = pred_df[(pred_df.prob_ant > antag_thresh) == pred_df.antagonism]\n",
    "        antag_tp = antag_tp[antag_tp.antagonism == 1]\n",
    "        antag_tp['thresh'] = antag_thresh\n",
    "        antag_tp['precision'] = pmax\n",
    "        antag_tp['recall'] = rmax\n",
    "        antag_tp['cvfold'] = cl\n",
    "        TP_df.append(antag_tp)\n",
    "    \n",
    "    precision, recall, thresh = precision_recall_curve(pred_df['synergy'].values,\n",
    "                                                        pred_df['prob_syn'].values)\n",
    "    if np.any(precision > prec_thresh):\n",
    "        # maximum recall\n",
    "        rmax = np.max(recall[precision > prec_thresh])\n",
    "        # maximum precision\n",
    "        pmax = np.max(precision[recall == rmax])\n",
    "        # index with maximum recall and precision > prec_thresh\n",
    "        idx = np.where(np.logical_and(precision == pmax, recall == rmax))[0][0]\n",
    "        # corresponding threshold\n",
    "        syn_thresh = thresh[idx] if idx < len(thresh) else thresh[-1]\n",
    "\n",
    "        syn_tp = pred_df[(pred_df.prob_syn > syn_thresh) == pred_df.synergy]\n",
    "        syn_tp = syn_tp[syn_tp.synergy == 1]\n",
    "        syn_tp['thresh'] = syn_thresh\n",
    "        syn_tp['precision'] = pmax\n",
    "        syn_tp['recall'] = rmax\n",
    "        syn_tp['cvfold'] = cl\n",
    "        TP_df.append(syn_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_df = pd.concat(TP_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds to call antagonisms in cross-validation folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(TP_df[TP_df['antagonism']==1]['thresh'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in most cases we end up with precision greater than 0.6 if we take a cutoff between 0.25-0.4. This already suggests  that $p_{RF}$ cannot be interpreted as probability $P(C|X)$ as we will see again in [Probability calibration](#calib) section. We can take the median as a cutoff for calling antagonisms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antag_thresh = np.median(np.unique(TP_df[TP_df['antagonism']==1]['thresh'].values))\n",
    "antag_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds to call synergies in cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(TP_df[TP_df['synergy']==1]['thresh'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we achieve precision greater than 0.6 if we take relatively loose cutoffs between 0.16-0.35. We'll take the median as our threshold for calling synergies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_thresh = np.median(np.unique(TP_df[TP_df['synergy']==1]['thresh'].values))\n",
    "syn_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TP_df.to_csv('Nichols-true-positives-CVfold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pr\"></a> \n",
    "## Plot Precision-Recall and ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.auc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_classes = ['DNA_gyrase', 'RNA_polymerase', 'aminoglycoside',\n",
    "                'beta-lactam', 'chloramphenicol', 'folic_acid_biosynthesis',\n",
    "               'human_drug', 'macrolide', 'multiple', 'other_DNA',\n",
    "               'other_cell_wall', 'oxidative_stress', 'tRNA',\n",
    "               'tetracycline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'normal',\n",
    "        'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.recall[cl][1], pr.precision[cl][1], lw=2, alpha=0.75,\n",
    "         label='%s (AP = %0.2f)' % (cl, pr.avprec[cl][1]))\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#plt.title(title)\n",
    "#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={\"size\": 13})\n",
    "plt.legend([], frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-antagonism-vs-rest.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6, 6)\n",
    "fig_leg = plt.figure(figsize=figsize)\n",
    "ax_leg = fig_leg.add_subplot(111)\n",
    "# add the legend from the previous axes\n",
    "ax_leg.legend(*ax.get_legend_handles_labels(), loc='center', frameon=False)\n",
    "# hide the axes frame and the x/y labels\n",
    "ax_leg.axis('off')\n",
    "#fig_leg.savefig('Ecoli-legend-antag.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.recall[cl][2], pr.precision[cl][2], lw=2, alpha=0.75,\n",
    "         label='%s (AP = %0.2f)' % (cl, pr.avprec[cl][2]))\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.legend([], frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-synergy-vs-rest.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6, 6)\n",
    "fig_leg = plt.figure(figsize=figsize)\n",
    "ax_leg = fig_leg.add_subplot(111)\n",
    "# add the legend from the previous axes\n",
    "ax_leg.legend(*ax.get_legend_handles_labels(), loc='center', frameon=False)\n",
    "# hide the axes frame and the x/y labels\n",
    "ax_leg.axis('off')\n",
    "#fig_leg.savefig('Ecoli-legend-synergy.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add only mean average precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = (pd.concat(pr.predicted).\n",
    "                  reset_index().\n",
    "                  rename(columns={\"level_0\": \"cvfold\"}).\n",
    "                  drop(columns=['level_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt = targets.loc[:, ['comb', 'type']]\n",
    "y_gt['syn'] = 0\n",
    "y_gt['ant'] = 0\n",
    "y_gt.loc[y_gt.type == 1,'ant'] = 1\n",
    "y_gt.loc[y_gt.type == 2,'syn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vs_true = pd.merge(preds_, y_gt, on='comb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vs_true = pred_vs_true[np.isin(pred_vs_true.cvfold, drug_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "prec_micro, recall_micro, _ = precision_recall_curve(pred_vs_true['ant'].values,\n",
    "                                                    pred_vs_true['prob_ant'].values)\n",
    "ap_micro = average_precision_score(pred_vs_true['ant'].values,\n",
    "                                   pred_vs_true['prob_ant'].values,\n",
    "                                   average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.recall[cl][1], pr.precision[cl][1],\n",
    "             color='grey', lw=1.5, alpha=0.6)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "plt.plot(recall_micro, prec_micro,\n",
    "        label='Aggregated (AP = {0:0.2f})'\n",
    "               ''.format(ap_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "#ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#plt.title(title)\n",
    "plt.legend(handles=handles, loc='upper right', prop={\"size\": 13},\n",
    "          frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-antagonism-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "prec_micro, recall_micro, _ = precision_recall_curve(pred_vs_true['syn'].values,\n",
    "                                                    pred_vs_true['prob_syn'].values)\n",
    "ap_micro = average_precision_score(pred_vs_true['syn'].values,\n",
    "                                   pred_vs_true['prob_syn'].values,\n",
    "                                   average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.recall[cl][2], pr.precision[cl][2],\n",
    "            color='grey', lw=1.5, alpha=0.6)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot(recall_micro, prec_micro,\n",
    "        label='Aggregated (AP = {0:0.2f})'\n",
    "               ''.format(ap_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.ylim([-0.02, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#plt.title(title)\n",
    "plt.legend(handles=handles, loc='upper right',\n",
    "           prop={\"size\": 13},\n",
    "            #bbox_to_anchor=(1.2,0.8),\n",
    "          frameon=False)\n",
    "#plt.legend([], frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-synergy-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.fpr[cl][1], pr.tpr[cl][1], lw=2, alpha=0.7,\n",
    "             label='{0} (area = {1:0.2f})'\n",
    "             ''.format(cl, pr.auc[cl][1]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.legend([], frameon=False)\n",
    "#plt.savefig('Ecoli-ROC-antagonism-vs-rest.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6, 6)\n",
    "fig_leg = plt.figure(figsize=figsize)\n",
    "ax_leg = fig_leg.add_subplot(111)\n",
    "# add the legend from the previous axes\n",
    "ax_leg.legend(*ax.get_legend_handles_labels(), loc='center', frameon=False)\n",
    "# hide the axes frame and the x/y labels\n",
    "ax_leg.axis('off')\n",
    "#fig_leg.savefig('Ecoli-ROC-legend-antag.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curves for synergy vs rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.fpr[cl][2], pr.tpr[cl][2], lw=2, alpha=0.7,\n",
    "             label='{0} (area = {1:0.2f})'\n",
    "             ''.format(cl, pr.auc[cl][2]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.legend([], frameon=False)\n",
    "#plt.savefig('Ecoli-ROC-synergy-vs-rest.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6, 6)\n",
    "fig_leg = plt.figure(figsize=figsize)\n",
    "ax_leg = fig_leg.add_subplot(111)\n",
    "# add the legend from the previous axes\n",
    "ax_leg.legend(*ax.get_legend_handles_labels(), loc='center', frameon=False)\n",
    "# hide the axes frame and the x/y labels\n",
    "ax_leg.axis('off')\n",
    "#fig_leg.savefig('Ecoli-ROC-legend-syn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_micro, tpr_micro, _ = roc_curve(pred_vs_true['ant'].values,\n",
    "                                                    pred_vs_true['prob_ant'].values)\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.fpr[cl][1], pr.tpr[cl][1],\n",
    "             color='grey', lw=1.5, alpha=0.6)\n",
    "plt.plot(fpr_micro, tpr_micro,\n",
    "        label='Aggregated (AUCROC = {0:0.2f})'\n",
    "               ''.format(roc_auc_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.legend(handles=handles, loc='lower right', prop={\"size\": 13},\n",
    "          frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-ROC-antagonism-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_micro, tpr_micro, _ = roc_curve(pred_vs_true['syn'].values,\n",
    "                                                    pred_vs_true['prob_syn'].values)\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "for cl in drug_classes:\n",
    "    plt.plot(pr.fpr[cl][2], pr.tpr[cl][2],\n",
    "             color='grey', lw=1.5, alpha=0.6)\n",
    "plt.plot(fpr_micro, tpr_micro,\n",
    "        label='Aggregated (AUCROC = {0:0.2f})'\n",
    "               ''.format(roc_auc_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "#ax.xaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.legend(handles=handles, loc='lower right', prop={\"size\": 13},\n",
    "          frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-ROC-synergy-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot average precision (AP) vs interaction rate for each cross-validation fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "# for antagonism predictions\n",
    "for cl in drug_classes:\n",
    "    ycl = y[np.isin(combs, pr.predicted[cl]['comb'].values)].argmax(axis=1)\n",
    "    antag_rate = np.sum(ycl == 1) / ycl.size\n",
    "    plt.scatter(antag_rate, pr.avprec[cl][1], marker='o', \n",
    "             label=cl, s=50)\n",
    "    plt.xlim((0,0.8))\n",
    "    plt.ylim((0,0.8))\n",
    "plt.plot([0.01, 1], [0.01, 1], 'k--', lw=1)\n",
    "plt.xlabel('Proportion of antagonisms')\n",
    "plt.ylabel('Average precision')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-AP-antag-vs-rate.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "# for antagonism predictions\n",
    "for cl in drug_classes:\n",
    "    ycl = y[np.isin(combs, pr.predicted[cl]['comb'].values)].argmax(axis=1)\n",
    "    syn_rate = np.sum(ycl == 2) / ycl.size\n",
    "    plt.scatter(syn_rate, pr.avprec[cl][2], marker='o', \n",
    "             label=cl, s=50)\n",
    "    plt.xlim((0,0.8))\n",
    "    plt.ylim((0,0.8))\n",
    "plt.plot([0.01, 1], [0.01, 1], 'k--', lw=1)\n",
    "plt.xlabel('Proportion of synergies')\n",
    "plt.ylabel('Average precision')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-AP-syn-vs-rate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"calib\"></a> \n",
    "## Probability calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(bootstrap=True,\n",
    "                                                max_features='sqrt',\n",
    "                                                **param_dict,\n",
    "                                                random_state=2305,\n",
    "                                              n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_onehot, y, test_size=0.2,\n",
    "                                                    random_state=2305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_ = clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot precision-recall for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "thresh = dict()\n",
    "average_precision = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val[:, i], probas_[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    precision[i], recall[i], thresh[i] = precision_recall_curve(y_val[:, i],\n",
    "                                                        probas_[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val[:, i], probas_[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "class_names = ['none', 'antagonism', 'synergy']\n",
    "colors = cycle(['#808080','#FFCC33', '#009999'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y_ = f_score * x / (2 * x - f_score)\n",
    "    plt.plot(x[y_ >= 0], y_[y_ >= 0], color='gray', alpha=0.2,\n",
    "             label='iso-F1 curves')\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y_[45] + 0.02))\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label='Precision-recall of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "fraction_of_positives = dict()\n",
    "mean_predicted_value = dict()\n",
    "for i in range(n_classes):\n",
    "    proba_val = clf.predict_proba(X_val)[:, i]\n",
    "    fraction_of_positives[i], mean_predicted_value[i] = calibration_curve(y_val[:,i],\n",
    "                                                                proba_val,\n",
    "                                                                n_bins=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predicted_value[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "plt.plot(mean_predicted_value[0], fraction_of_positives[0], 's-', label='none')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot(mean_predicted_value[1], fraction_of_positives[1], 's-', label='antagonism')\n",
    "plt.plot(mean_predicted_value[2], fraction_of_positives[2], 's-', label='synergy')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Uncalibrated probabilities')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_of_positives = dict()\n",
    "mean_predicted_value = dict()\n",
    "for i in range(n_classes):\n",
    "    #proba_val = clf.predict_proba(X_val)[:, i]\n",
    "    clf_calib = CalibratedClassifierCV(clf.estimators_[i], cv=5, method='sigmoid')\n",
    "    proba_val = clf_calib.fit(X_train, y_train[:,i]).predict_proba(X_val)[:,1]\n",
    "    fraction_of_positives[i], mean_predicted_value[i] = calibration_curve(y_val[:,i],\n",
    "                                                                proba_val,\n",
    "                                                                n_bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "plt.plot(mean_predicted_value[0], fraction_of_positives[0], 's-', label='none')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot(mean_predicted_value[1], fraction_of_positives[1], 's-', label='antagonism')\n",
    "plt.plot(mean_predicted_value[2], fraction_of_positives[2], 's-', label='synergy')\n",
    "plt.title('Calibrated probabilities')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow calibrated probabilities are worse than the \"uncalibrated\" ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test\"></a> \n",
    "## Generate Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs = pd.read_csv('../data/chemgenetics/nichols_testset_signed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs = X_drugs.iloc[:,np.where(np.isin(X_drugs.columns, gene_subset))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drugs = X_drugs.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "combs_test = list(itertools.combinations(test_drugs, 2))\n",
    "combs_test = np.array([i[0]+\"_\"+i[1] for i in combs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame([utl.get_comb_feat_signed(X_drugs, c) for c in combs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[:10,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad some columns (as some are all zeros in the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pad = np.setdiff1d(X_onehot.columns, X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_pad:\n",
    "    X_test[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.loc[:,np.isin(X_test.columns, X_onehot.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[X_onehot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(X_test.columns == X_onehot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without probability calibration\n",
    "y_test_proba = clf.fit(X_onehot, y).predict_proba(X_test)\n",
    "antag = combs_test[y_test_proba[:,1] > antag_thresh]\n",
    "syn = combs_test[y_test_proba[:,2] > syn_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setdiff1d(antag, syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setdiff1d(syn, antag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.intersect1d(antag, syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr = pd.DataFrame(y_test_proba, index=combs_test,\n",
    "             columns=['none', 'antag', 'synergy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr.to_csv('nichols_test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr.sort_values('antag', ascending=False).iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr.sort_values('synergy', ascending=False).iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=6)\n",
    "\n",
    "# with calibration\n",
    "probs = dict()\n",
    "for i in range(n_classes):\n",
    "    clf_calib = CalibratedClassifierCV(clf.estimators_[i], cv=skf, method='isotonic')\n",
    "    probs[i] = clf_calib.fit(X_onehot, y[:,i]).predict_proba(X_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
