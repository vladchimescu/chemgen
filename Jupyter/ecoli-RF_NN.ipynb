{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug interaction prediction in *E. coli*\n",
    "*Author: Vladislav Kim*\n",
    "* [Introduction](#intro)\n",
    "* [Compound class stratified validation](#classlockout)\n",
    "* [Choose thresholds for interactions](#threshclass)\n",
    "* [Precision-recall and ROC curves](#pr)\n",
    "* [Probability calibration](#calib)\n",
    "* [Predictions on the test set](#test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "sys.path.append('..')\n",
    "import base.chemgen_utils as utl\n",
    "import MLmod.predictor_modified as prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a> \n",
    "## Introduction\n",
    "It has been previously shown that drug interactions can be predicted in bacteria using chemogenomic data. Here we use random forest classifier on single-compound chemical genetics data in *E. coli* to predict antagonisms, synergies and additive combinations. \n",
    "\n",
    "We encode our input predictor matrix as follows: \n",
    "+ For each combination load single-compound profiles. Each profile has dimensions `(1 x genes)` and the following possible gene states {-1,0,+1}. Negative drug-gene interaction (-1) implies increased sensitivity in that gene deletion, while positive gene state (+1) indicates decreased sensitivity in that mutant\n",
    "+ Combination profiles are generaeted based on superposition of individual drug profiles and may take on the following gene states {-2, -1, 0, +1, +2, +/-}\n",
    "+ We then use one-hot encoding scheme (\"dummy variable encoding\") before passing the predictor matrix `X` to the classifier\n",
    "\n",
    "We furthermore subset the data so that only those genes are included that are significantly enriched in antagonisms and synergies based on chi-squared test. This gene list is `interaction-genes-Ecoli`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugleg_fname = \"../data/chemicals/legend_gramnegpos.txt\"\n",
    "gene_subset = '../data/interaction-genes-Ecoli'\n",
    "gene_subset = pd.read_csv(gene_subset, header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chemgen = pd.read_csv('../data/chemgenetics/nichols_signed.csv', index_col=0)\n",
    "X_chemgen = X_chemgen.iloc[:,np.where(np.isin(X_chemgen.columns, gene_subset))[0]]\n",
    "targets = pd.read_csv(\"../data/chemgenetics/nichols_y.csv\")\n",
    "combs = targets['comb'].values\n",
    "y = targets['type'].values\n",
    "\n",
    "X_df = pd.DataFrame([utl.get_comb_feat_signed(X_chemgen, c) for c in combs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using `OneVsRestClassifier`, we convert our categorical response variable `y` (\"synergy\" ,\"antagonism\", \"none\") into a `n x 3` binary array using `label_binarize` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs rest classification\n",
    "y[y=='none'] = 0\n",
    "y[y=='antagonism']=1\n",
    "y[y=='synergy']=2\n",
    "\n",
    "y=y.astype('int')\n",
    "y = label_binarize(y, classes=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode combination profiles using one-hot encoding scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = pd.get_dummies(X_df.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACRA_-2</th>\n",
       "      <th>ACRA_-1</th>\n",
       "      <th>ACRA_0</th>\n",
       "      <th>ACRA_1</th>\n",
       "      <th>ACRA_2</th>\n",
       "      <th>ACRA_3</th>\n",
       "      <th>ACRB_-2</th>\n",
       "      <th>ACRB_-1</th>\n",
       "      <th>ACRB_0</th>\n",
       "      <th>ACRB_1</th>\n",
       "      <th>ACRB_2</th>\n",
       "      <th>ACRB_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACRA_-2  ACRA_-1  ACRA_0  ACRA_1  ACRA_2  ACRA_3  ACRB_-2  ACRB_-1  ACRB_0  \\\n",
       "0        0        0       1       0       0       0        0        0       0   \n",
       "1        0        1       0       0       0       0        0        0       0   \n",
       "2        0        0       1       0       0       0        0        0       0   \n",
       "3        0        1       0       0       0       0        0        0       0   \n",
       "4        0        1       0       0       0       0        0        0       0   \n",
       "5        0        0       1       0       0       0        0        0       0   \n",
       "\n",
       "   ACRB_1  ACRB_2  ACRB_3  \n",
       "0       1       0       0  \n",
       "1       0       0       1  \n",
       "2       1       0       0  \n",
       "3       0       0       1  \n",
       "4       0       0       1  \n",
       "5       1       0       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_onehot.iloc[:6,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at least 5 combinations with that variable set\n",
    "X_onehot = X_onehot.loc[:,(X_onehot.sum(axis=0) > 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We performed grid search to find the best parameters for the `RandomForestClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters when sorted by meanAP_syn, meanAP_antag\n",
    "#param_dict = {'n_estimators': 200,\n",
    "# 'min_samples_split': 6,\n",
    "# 'min_samples_leaf': 2,\n",
    "# 'max_depth': None,\n",
    "# 'class_weight': {0: 1, 1: 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters neural network\n",
    "param_dict = {'layers': 3,\n",
    "'dropout': 0.2,\n",
    "'epochs': 200,\n",
    "'steps': 32,\n",
    "'learning_rate_deep': 0.001,\n",
    "'nodes': 32,\n",
    "'class_weight': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classlockout\"></a> \n",
    "## Cross Validation\n",
    "In order to assess the generalization error we generate 20 cross-validation folds by withholding 15 randomly chosen compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import KFold, RepeatedKFold\\n\\nkf = RepeatedKFold(n_splits=10, n_repeats=2, random_state=1401)\\nsplits = kf.split(X=X_onehot.to_numpy(),y=y)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import KFold, RepeatedKFold\n",
    "\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=2, random_state=1401)\n",
    "splits = kf.split(X=X_onehot.to_numpy(),y=y)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val(drugs, combs, n_holdout=15):\n",
    "    val_drugs = np.random.choice(drugs, size=n_holdout)\n",
    "    \n",
    "    combs_val = list(itertools.combinations(val_drugs, 2))\n",
    "    combs_val = [sorted(i) for i in combs_val]\n",
    "    combs_val = np.array([i[0]+\"_\"+i[1] for i in combs_val])\n",
    "    combs_val = np.intersect1d(combs_val, combs)\n",
    "    combs_train = np.setdiff1d(combs, combs_val)\n",
    "    \n",
    "    assert((combs_train.shape[0] + combs_val.shape[0]) == combs.shape[0])\n",
    "    train = np.where(np.isin(combs, combs_train))[0]\n",
    "    val = np.where(np.isin(combs, combs_val))[0]\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1601)\n",
    "# drugs in the chemical genetics dataset of E. coli\n",
    "drugs = np.unique(X_chemgen.index)\n",
    "# generate CV folds by withholding 15 randomly chosen drugs\n",
    "splits = [generate_train_val(drugs, combs) for i in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each cross-validation iteration we withhold a random subset of drugs $(n=15)$ and test the trained model on the withheld combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = prd.MultiClassPredictions(X=X_onehot.to_numpy(), y=y,\n",
    "                                   combs=combs,\n",
    "                                  **param_dict,\n",
    "                                   clf='neural_network',\n",
    "                                   top = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 1: 102\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8087 - accuracy: 0.6153\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6621\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.6806\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6411\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.7404\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7415\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7230\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.7329\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7728\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7599\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7799\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8195\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.8015\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8043\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8182\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8567\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8243\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8349\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8471\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8387\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8472\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8645\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8699\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8881\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.3018 - accuracy: 0.8614\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8832\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8763\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8755\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8757\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.8935\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.8962\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9083\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.9188\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9140\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.9152\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9049\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9131\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9156\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9172\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9087\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.8811\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9031\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.9137\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 0.9104\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9208\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9330\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.9280\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9352\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.9269\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9301\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9135\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9205\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1296 - accuracy: 0.9496\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1612 - accuracy: 0.9242\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1298 - accuracy: 0.9415\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1273 - accuracy: 0.9432\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1737 - accuracy: 0.9224\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1191 - accuracy: 0.9555\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.1859 - accuracy: 0.9223\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1479 - accuracy: 0.9392\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.1585 - accuracy: 0.9330\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1701 - accuracy: 0.9166\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.1463 - accuracy: 0.9499\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1171 - accuracy: 0.9538\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.1316 - accuracy: 0.9505\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1057 - accuracy: 0.9599\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1004 - accuracy: 0.9623\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1215 - accuracy: 0.9530\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1735 - accuracy: 0.9269\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1209 - accuracy: 0.9562\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1727 - accuracy: 0.9225\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1037 - accuracy: 0.9535\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1196 - accuracy: 0.9456\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1073 - accuracy: 0.9501\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9397\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9549\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9610\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1389 - accuracy: 0.9447\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1166 - accuracy: 0.9498\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9708\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9322\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9451\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9445\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9614\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9578\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9571\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9551\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9626\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9474\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9703\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9722\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9635\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0799 - accuracy: 0.9656\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0920 - accuracy: 0.9630\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0939 - accuracy: 0.9565\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0912 - accuracy: 0.9588\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0818 - accuracy: 0.9750\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0757 - accuracy: 0.9688\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0896 - accuracy: 0.9664\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9456\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.9654\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9576\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9643\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9728\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9513\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9427\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9494\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9539\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9590\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9179\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9647\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9638\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9519\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9691\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9540\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9537\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9570\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9639\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9625\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0835 - accuracy: 0.9542\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1259 - accuracy: 0.9398\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0830 - accuracy: 0.9577\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0816 - accuracy: 0.9550\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0864 - accuracy: 0.9610\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1157 - accuracy: 0.9406\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1167 - accuracy: 0.9457\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1056 - accuracy: 0.9516\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1193 - accuracy: 0.9489\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0528 - accuracy: 0.9788\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0849 - accuracy: 0.9659\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0705 - accuracy: 0.9706\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0529 - accuracy: 0.9676\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1071 - accuracy: 0.9622\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9519\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9655\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9487\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9474\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9792\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0757 - accuracy: 0.9659\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9494\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9653\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0703 - accuracy: 0.9619\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0588 - accuracy: 0.9722\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0712 - accuracy: 0.9694\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0653 - accuracy: 0.9780\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0428 - accuracy: 0.9856\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0562 - accuracy: 0.9734\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0629 - accuracy: 0.9701\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0830 - accuracy: 0.9660\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0748 - accuracy: 0.9735\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1095 - accuracy: 0.9451\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0642 - accuracy: 0.9688\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9719\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0532 - accuracy: 0.9762\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0640 - accuracy: 0.9749\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0682 - accuracy: 0.9741\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0603 - accuracy: 0.9785\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0545 - accuracy: 0.9743\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9793\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9794\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9720\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9820\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9611\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9783\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9745\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0591 - accuracy: 0.9750\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9711\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9569\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9364\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1063 - accuracy: 0.9512\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0554 - accuracy: 0.9774\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9721\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9709\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9633\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9478\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9643\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9675\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9719\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9705\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9637\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9712\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9719\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9507\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9520\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9523\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9545\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9733\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9677\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9737\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9673\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0813 - accuracy: 0.9595\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0619 - accuracy: 0.9717\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0497 - accuracy: 0.9695\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0660 - accuracy: 0.9665\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0939 - accuracy: 0.9568\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0548 - accuracy: 0.9741\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0416 - accuracy: 0.9777\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0547 - accuracy: 0.9650\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0875 - accuracy: 0.9660\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0603 - accuracy: 0.9791\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.7916 - accuracy: 0.6098\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.5077 - accuracy: 0.8165\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.4522 - accuracy: 0.8254\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.4358 - accuracy: 0.8199\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.4262 - accuracy: 0.8034\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.3651 - accuracy: 0.8423\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.3507 - accuracy: 0.8488\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.3404 - accuracy: 0.8321\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.3489 - accuracy: 0.8334\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.3249 - accuracy: 0.8578\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2827 - accuracy: 0.8534\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.3116 - accuracy: 0.8518\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.3153 - accuracy: 0.8407\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.2839 - accuracy: 0.8576\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.2768 - accuracy: 0.8724\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.2750 - accuracy: 0.8778\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.2567 - accuracy: 0.8933\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.2254 - accuracy: 0.8975\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2365 - accuracy: 0.9047\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.9045\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.8999\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.9082\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9039\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9413\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.8986\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9131\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9396\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.9241\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.9216\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9469\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9362\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9353\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1482 - accuracy: 0.9397\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9524\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1350 - accuracy: 0.9532\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1594 - accuracy: 0.9263\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.2026 - accuracy: 0.9125\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1248 - accuracy: 0.9548\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1398 - accuracy: 0.9454\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1082 - accuracy: 0.9629\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1162 - accuracy: 0.9551\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.1183 - accuracy: 0.9484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1200 - accuracy: 0.9540\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1031 - accuracy: 0.9532\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0962 - accuracy: 0.9659\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1040 - accuracy: 0.9515\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0780 - accuracy: 0.9724\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1321 - accuracy: 0.9420\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1233 - accuracy: 0.9431\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0970 - accuracy: 0.9637\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0941 - accuracy: 0.9673\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1143 - accuracy: 0.9569\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0776 - accuracy: 0.9699\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1116 - accuracy: 0.9492\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1270 - accuracy: 0.9511\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1204 - accuracy: 0.9397\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1251 - accuracy: 0.9433\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1195 - accuracy: 0.9422\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0782 - accuracy: 0.9693\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0856 - accuracy: 0.9680\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0929 - accuracy: 0.9589\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0777 - accuracy: 0.9624\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0601 - accuracy: 0.9833\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0765 - accuracy: 0.9739\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0779 - accuracy: 0.9661\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0574 - accuracy: 0.9774\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0613 - accuracy: 0.9795\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0541 - accuracy: 0.9788\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0757 - accuracy: 0.9712\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0881 - accuracy: 0.9667\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0581 - accuracy: 0.9795\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9607\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9574\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9703\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9707\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9644\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9689\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9663\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9669\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9650\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9788\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9748\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9880\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9736\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9662\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9709\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9634\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9822\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9569\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9737\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0558 - accuracy: 0.9756\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.1161 - accuracy: 0.9646\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1303 - accuracy: 0.9414\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0941 - accuracy: 0.9505\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0833 - accuracy: 0.9606\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0672 - accuracy: 0.9757\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0380 - accuracy: 0.9862\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0567 - accuracy: 0.9762\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0605 - accuracy: 0.9770\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0680 - accuracy: 0.9703\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0619 - accuracy: 0.9754\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0673 - accuracy: 0.9785\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0635 - accuracy: 0.9727\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0410 - accuracy: 0.9888\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0540 - accuracy: 0.9766\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0527 - accuracy: 0.9855\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0630 - accuracy: 0.9736\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0574 - accuracy: 0.9783\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.0322 - accuracy: 0.9942\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0433 - accuracy: 0.9846\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0399 - accuracy: 0.9889\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0917 - accuracy: 0.9594\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0849 - accuracy: 0.9651\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0814 - accuracy: 0.9672\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0758 - accuracy: 0.9725\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0537 - accuracy: 0.9794\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0279 - accuracy: 0.9933\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0383 - accuracy: 0.9891\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0579 - accuracy: 0.9781\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0662 - accuracy: 0.9741\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0602 - accuracy: 0.9747\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0469 - accuracy: 0.9825\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 867us/step - loss: 0.0392 - accuracy: 0.9847\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0431 - accuracy: 0.9844\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0403 - accuracy: 0.9901\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0284 - accuracy: 0.9895\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0331 - accuracy: 0.9847\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0770 - accuracy: 0.9682\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0804 - accuracy: 0.9635\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0398 - accuracy: 0.9881\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0577 - accuracy: 0.9769\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0692 - accuracy: 0.9776\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0488 - accuracy: 0.9858\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0892 - accuracy: 0.9715\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0346 - accuracy: 0.9856\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0770 - accuracy: 0.9732\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0948 - accuracy: 0.9568\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0737 - accuracy: 0.9622\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0417 - accuracy: 0.9873\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0322 - accuracy: 0.9929\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0395 - accuracy: 0.9895\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0488 - accuracy: 0.9799\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0577 - accuracy: 0.9767\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0766 - accuracy: 0.9764\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0339 - accuracy: 0.9898\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0402 - accuracy: 0.9911\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0318 - accuracy: 0.9926\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0352 - accuracy: 0.9924\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0132 - accuracy: 0.9982\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0309 - accuracy: 0.9918\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0348 - accuracy: 0.9910\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0418 - accuracy: 0.9854\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0651 - accuracy: 0.9694\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0499 - accuracy: 0.9800\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0485 - accuracy: 0.9864\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0497 - accuracy: 0.9805\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0630 - accuracy: 0.9728\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0679 - accuracy: 0.9746\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0497 - accuracy: 0.9800\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0928 - accuracy: 0.9552\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0680 - accuracy: 0.9668\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0405 - accuracy: 0.9905\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0408 - accuracy: 0.9806\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0252 - accuracy: 0.9944\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0423 - accuracy: 0.9863\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0364 - accuracy: 0.9894\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0159 - accuracy: 0.9947\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0269 - accuracy: 0.9935\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1261 - accuracy: 0.9542\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0740 - accuracy: 0.9751\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0856 - accuracy: 0.9739\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0698 - accuracy: 0.9740\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.1358 - accuracy: 0.9427\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0663 - accuracy: 0.9835\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0682 - accuracy: 0.9806\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0384 - accuracy: 0.9888\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0328 - accuracy: 0.9941\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0206 - accuracy: 0.9970\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0381 - accuracy: 0.9866\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0414 - accuracy: 0.9834\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0373 - accuracy: 0.9897\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0244 - accuracy: 0.9910\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0214 - accuracy: 0.9975\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0553 - accuracy: 0.9828\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0452 - accuracy: 0.9856\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0497 - accuracy: 0.9862\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0532 - accuracy: 0.9846\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0329 - accuracy: 0.9903\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0465 - accuracy: 0.9851\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0384 - accuracy: 0.9878\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0213 - accuracy: 0.9955\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0441 - accuracy: 0.9848\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0333 - accuracy: 0.9892\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0423 - accuracy: 0.9893\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0237 - accuracy: 0.9942\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0222 - accuracy: 0.9939\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0424 - accuracy: 0.9830\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0705 - accuracy: 0.9746\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0348 - accuracy: 0.9900\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0308 - accuracy: 0.9877\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8085 - accuracy: 0.6623\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8674\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8692\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8574\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8650\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8708\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8677\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8567\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8648\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8663\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8648\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8447\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8582\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8681\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8717\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.8943\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.8927\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.8901\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.2395 - accuracy: 0.8948\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.2280 - accuracy: 0.9143\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.2267 - accuracy: 0.9131\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.2055 - accuracy: 0.9204\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1806 - accuracy: 0.9279\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1957 - accuracy: 0.9246\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1791 - accuracy: 0.9201\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1654 - accuracy: 0.9377\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9469\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1527 - accuracy: 0.9425\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9487\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9457\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9480\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9436\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9573\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9578\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9668\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9566\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9586\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9744\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9728\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9449\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9384\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9746\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9606\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9638\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9566\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9677\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9732\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0774 - accuracy: 0.9721\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0827 - accuracy: 0.9669\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0551 - accuracy: 0.9765\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1122 - accuracy: 0.9550\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0998 - accuracy: 0.9559\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9610\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0894 - accuracy: 0.9609\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1062 - accuracy: 0.9594\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9675\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9770\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9821\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9878\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9819\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9706\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9696\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9757\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0780 - accuracy: 0.9705\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9666\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9713\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0797 - accuracy: 0.9705\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0836 - accuracy: 0.9678\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9767\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9747\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9708\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9833\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9706\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9700\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9661\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9850\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9774\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9853\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9729\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9532\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9621\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9754\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9652\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9808\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0609 - accuracy: 0.9781\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9772\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0496 - accuracy: 0.9802\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0427 - accuracy: 0.9849\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0856 - accuracy: 0.9665\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0879 - accuracy: 0.9693\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0880 - accuracy: 0.9591\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0693 - accuracy: 0.9708\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0617 - accuracy: 0.9758\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0438 - accuracy: 0.9829\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0542 - accuracy: 0.9774\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0450 - accuracy: 0.9789\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0672 - accuracy: 0.9773\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0300 - accuracy: 0.9917\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0366 - accuracy: 0.9889\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0427 - accuracy: 0.9831\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0304 - accuracy: 0.9903\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0382 - accuracy: 0.9835\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0359 - accuracy: 0.9905\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0273 - accuracy: 0.9869\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9858\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9860\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0417 - accuracy: 0.9839\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0293 - accuracy: 0.9916\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0415 - accuracy: 0.9829\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0284 - accuracy: 0.9887\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0476 - accuracy: 0.9765\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0373 - accuracy: 0.9864\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0402 - accuracy: 0.9846\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9841\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9823\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9853\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9791\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9809\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9909\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0287 - accuracy: 0.9925\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9780\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9870\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9902\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9776\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9871\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9836\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9794\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9899\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9898\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0474 - accuracy: 0.9833\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9943\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0287 - accuracy: 0.9926\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0301 - accuracy: 0.9878\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0268 - accuracy: 0.9923\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0465 - accuracy: 0.9812\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0552 - accuracy: 0.9748\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0594 - accuracy: 0.9734\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9768\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9768\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0322 - accuracy: 0.9866\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0464 - accuracy: 0.9838\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9923\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9932\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0208 - accuracy: 0.9899\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0433 - accuracy: 0.9800\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0285 - accuracy: 0.9895\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9903\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0312 - accuracy: 0.9922\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0465 - accuracy: 0.9802\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0297 - accuracy: 0.9964\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0350 - accuracy: 0.9853\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0232 - accuracy: 0.9940\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0519 - accuracy: 0.9776\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9853\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9898\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9955\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9864\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0313 - accuracy: 0.9866\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9927\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0430 - accuracy: 0.9865\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 987us/step - loss: 0.0112 - accuracy: 0.9982\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0194 - accuracy: 0.9923\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0234 - accuracy: 0.9917\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9926\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9814\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9906\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9821\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9888\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9757\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9915\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9807\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9995\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9905\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9877\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0335 - accuracy: 0.9842\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0482 - accuracy: 0.9879\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9808\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0261 - accuracy: 0.9889\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0362 - accuracy: 0.9874\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9885\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9842\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0288 - accuracy: 0.9918\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0258 - accuracy: 0.9902\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9891\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9843\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0346 - accuracy: 0.9891\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9933\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0316 - accuracy: 0.9861\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0256 - accuracy: 0.9900\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0598 - accuracy: 0.9834\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0211 - accuracy: 0.9904\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0247 - accuracy: 0.9912\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0319 - accuracy: 0.9866\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0663 - accuracy: 0.9725\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0209 - accuracy: 0.9919\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0219 - accuracy: 0.9934\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0377 - accuracy: 0.9904\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0114 - accuracy: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 2: 65\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8619 - accuracy: 0.5860\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.6662\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.7360\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.7072\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.7210\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.7066\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.5434 - accuracy: 0.7367\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5473 - accuracy: 0.7229\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7197\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.7230\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7525\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7442\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7349\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7912\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7751\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7767\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7909\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8226\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.8049\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.4004 - accuracy: 0.8215\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.3830 - accuracy: 0.8375\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8352\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8379\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8537\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.3511 - accuracy: 0.8513\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.3376 - accuracy: 0.8435\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.3565 - accuracy: 0.8497\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.3148 - accuracy: 0.8838\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.8786\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2741 - accuracy: 0.8802\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8555\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.2693 - accuracy: 0.8741\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.3081 - accuracy: 0.8578\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.3299 - accuracy: 0.8360\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2543 - accuracy: 0.8843\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.2558 - accuracy: 0.8925\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.2624 - accuracy: 0.8793\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9067\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9136\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2406 - accuracy: 0.9026\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2477 - accuracy: 0.8911\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.8782\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.2812 - accuracy: 0.8784\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.8898\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9036\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.2073 - accuracy: 0.9139\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9045\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.2356 - accuracy: 0.8917\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9203\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9102\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.8804\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1869 - accuracy: 0.9120\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9088\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9202\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9253\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.9007\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.2079 - accuracy: 0.9042\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.9394\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9198\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9303\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9299\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9329\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9500\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1369 - accuracy: 0.9450\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1294 - accuracy: 0.9457\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9458\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9399\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1520 - accuracy: 0.9358\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9425\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1785 - accuracy: 0.9147\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1732 - accuracy: 0.9123\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9392\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1389 - accuracy: 0.9439\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1156 - accuracy: 0.9493\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1535 - accuracy: 0.9224\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9295\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9641\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9428\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9495\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9551\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1221 - accuracy: 0.9544\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9492\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9535\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9340\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1423 - accuracy: 0.9332\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9553\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1124 - accuracy: 0.9554\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9606\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1595 - accuracy: 0.9317\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9546\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9338\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9579\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1452 - accuracy: 0.9364\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9130\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1185 - accuracy: 0.9567\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9679\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1049 - accuracy: 0.9551\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9653\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9294\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9581\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9768\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1143 - accuracy: 0.9557\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9647\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9543\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9595\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9148\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9573\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1300 - accuracy: 0.9411\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1231 - accuracy: 0.9541\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1214 - accuracy: 0.9486\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9516\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9626\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9622\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9771\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9792\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0915 - accuracy: 0.9570\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0793 - accuracy: 0.9704\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0890 - accuracy: 0.9660\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9734\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9700\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0749 - accuracy: 0.9771\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9668\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0798 - accuracy: 0.9698\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9700\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0601 - accuracy: 0.9752\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9737\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9723\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9353\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9479\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9569\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9734\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9751\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9760\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0940 - accuracy: 0.9587\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9565\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1178 - accuracy: 0.9439\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9656\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9518\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1389 - accuracy: 0.9410\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9524\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9489\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1220 - accuracy: 0.9443\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9732\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9793\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0621 - accuracy: 0.9733\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9829\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9789\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9657\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9333\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9483\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1225 - accuracy: 0.9498\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0873 - accuracy: 0.9658\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9723\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9634\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0876 - accuracy: 0.9678\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0784 - accuracy: 0.9725\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0684 - accuracy: 0.9724\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0794 - accuracy: 0.9699\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0710 - accuracy: 0.9729\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9821\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9845\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 971us/step - loss: 0.0736 - accuracy: 0.9739\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9729\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9729\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9606\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9671\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9662\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1523 - accuracy: 0.9394\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9642\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9670\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9563\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9730\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9537\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9554\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9825\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9787\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9827\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9802\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9755\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9640\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.9484\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9761\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9590\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9833\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9808\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9855\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9832\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0593 - accuracy: 0.9813\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0491 - accuracy: 0.9788\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9633\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9765\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9769\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9672\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9780\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9905\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0679 - accuracy: 0.9727\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9903\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9848\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9835\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9343\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.7537 - accuracy: 0.6782\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.5203 - accuracy: 0.8114\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.8329\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8271\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8474\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.3754 - accuracy: 0.8584\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8518\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8275\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8290\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8728\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8436\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8658\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8628\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8585\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.8836\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9001\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2602 - accuracy: 0.8775\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.8897\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2367 - accuracy: 0.8933\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8806\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.9033\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9016\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1998 - accuracy: 0.9037\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1928 - accuracy: 0.9204\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9133\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1746 - accuracy: 0.9297\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1810 - accuracy: 0.9246\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1507 - accuracy: 0.9380\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9213\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1821 - accuracy: 0.9198\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1778 - accuracy: 0.9209\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.9268\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1435 - accuracy: 0.9418\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1216 - accuracy: 0.9501\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1470 - accuracy: 0.9280\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1495 - accuracy: 0.9284\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1825 - accuracy: 0.9192\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9351\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9598\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9583\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0989 - accuracy: 0.9712\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9558\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9291\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1430 - accuracy: 0.9330\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9649\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9414\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9560\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0751 - accuracy: 0.9711\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1132 - accuracy: 0.9539\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9624\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9594\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9600\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1376 - accuracy: 0.9490\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9396\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9590\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9733\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9698\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9458\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9566\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9521\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9547\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9592\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9360\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9433\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0810 - accuracy: 0.9669\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9731\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9740\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9658\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9632\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9802\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9765\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9639\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9792\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9754\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0710 - accuracy: 0.9734\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0562 - accuracy: 0.9803\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0996 - accuracy: 0.9567\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9627\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9644\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9755\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0449 - accuracy: 0.9868\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9876\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0463 - accuracy: 0.9843\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9815\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0483 - accuracy: 0.9823\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9704\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0675 - accuracy: 0.9721\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9698\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9652\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9654\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9482\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9869\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9744\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9795\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9748\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0487 - accuracy: 0.9859\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9812\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0613 - accuracy: 0.9777\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9671\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0714 - accuracy: 0.9745\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9524\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9345\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9457\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9778\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9856\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9762\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9855\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0635 - accuracy: 0.9709\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9693\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9656\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9756\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9838\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9686\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9735\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9703\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9569\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9731\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9799\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9789\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9830\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9840\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0477 - accuracy: 0.9803\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0491 - accuracy: 0.9844\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 997us/step - loss: 0.0649 - accuracy: 0.9761\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0401 - accuracy: 0.9856\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9737\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0565 - accuracy: 0.9805\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0428 - accuracy: 0.9793\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9870\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9822\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0602 - accuracy: 0.9812\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9812\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9877\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9618\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9925\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0545 - accuracy: 0.9760\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0358 - accuracy: 0.9893\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9780\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9922\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9838\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9799\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9805\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0448 - accuracy: 0.9827\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0821 - accuracy: 0.9713\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9890\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9897\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9878\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9955\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9879\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0514 - accuracy: 0.9822\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9887\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9728\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9771\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0195 - accuracy: 0.9946\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0631 - accuracy: 0.9801\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9844\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9716\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9794\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9839\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0353 - accuracy: 0.9914\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9870\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9862\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0341 - accuracy: 0.9882\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9845\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9643\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9816\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9865\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0553 - accuracy: 0.9815\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9941\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9852\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9962\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0460 - accuracy: 0.9843\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9906\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9961\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9883\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9906\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9946\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9868\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9955\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0187 - accuracy: 0.9949\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9949\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9869\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9880\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9870\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9842\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9737\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9639\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9633\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9912\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9921\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9899\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9842\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9895\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9951\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9878\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9923\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9815\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9808\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9841\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 1ms/step - loss: 0.7918 - accuracy: 0.6566\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.8565\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8731\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8819\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.9013\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.3647 - accuracy: 0.8692\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8733\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8722\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8692\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8737\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.3612 - accuracy: 0.8665\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.3037 - accuracy: 0.8724\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.3037 - accuracy: 0.8827\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8787\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.2796 - accuracy: 0.8852\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2598 - accuracy: 0.9062\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.2656 - accuracy: 0.8949\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.2744 - accuracy: 0.8957\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9165\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.9292\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.2016 - accuracy: 0.9307\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9336\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9349\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9211\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9258\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9151\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9415\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1331 - accuracy: 0.9520\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1640 - accuracy: 0.9386\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1470 - accuracy: 0.9442\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.9458\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9364\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9555\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1129 - accuracy: 0.9636\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9617\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9580\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1485 - accuracy: 0.9419\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1112 - accuracy: 0.9542\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1082 - accuracy: 0.9552\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1253 - accuracy: 0.9492\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1281 - accuracy: 0.9513\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9515\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9558\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9591\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9571\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9565\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9545\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9552\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9717\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9564\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9523\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9619\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9651\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9711\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9615\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9664\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1046 - accuracy: 0.9584\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9577\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0799 - accuracy: 0.9699\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9674\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0478 - accuracy: 0.9801\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9679\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1689 - accuracy: 0.9234\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1087 - accuracy: 0.9565\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9740\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0510 - accuracy: 0.9804\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9726\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9853\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9766\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9791\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9798\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9900\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9849\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9741\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9578\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9800\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9781\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9761\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9899\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9858\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9799\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9827\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9793\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9830\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9819\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9809\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9914\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9826\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9832\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9755\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9797\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9835\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9845\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9844\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9873\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9765\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9766\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9790\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9736\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9780\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9772\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9923\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9955\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9855\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9883\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9682\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9760\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9837\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9875\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9852\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9770\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9710\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9519\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9928\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9955\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9906\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9966\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9919\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9819\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9813\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9710\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9859\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0322 - accuracy: 0.9848\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9925\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0210 - accuracy: 0.9955\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9800\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0183 - accuracy: 0.9909\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9929\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9870\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9928\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9886\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9873\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9776\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9859\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9923\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9917\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9884\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9808\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9796\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0329 - accuracy: 0.9851\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9892\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9888\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9840\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0263 - accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0161 - accuracy: 0.9948\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9898\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0579 - accuracy: 0.9729\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0574 - accuracy: 0.9722\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0591 - accuracy: 0.9828\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9850\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0532 - accuracy: 0.9847\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0315 - accuracy: 0.9898\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0245 - accuracy: 0.9928\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9894\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0178 - accuracy: 0.9962\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9890\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9753\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9941\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9936\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9896\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0244 - accuracy: 0.9933\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0242 - accuracy: 0.9907\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0225 - accuracy: 0.9921\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9958\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0171 - accuracy: 0.9913\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9922\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9897\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0283 - accuracy: 0.9901\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0427 - accuracy: 0.9819\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9881\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0142 - accuracy: 0.9951\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0288 - accuracy: 0.9909\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9920\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9964\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9870\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0075 - accuracy: 0.9999\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0420 - accuracy: 0.9865\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9893\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9900\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9854\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9881\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9877\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9861\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9959\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9892\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9932\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9896\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9800\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9842\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9769\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0329 - accuracy: 0.9920\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9927\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9885\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9961\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9968\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9876\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9913\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 3: 91\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.8750 - accuracy: 0.6126\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.6500 - accuracy: 0.7000\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.6751\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.6861\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.5744 - accuracy: 0.7266\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7353\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7429\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7466\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7574\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7544\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7658\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.4756 - accuracy: 0.7572\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.4342 - accuracy: 0.8072\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.4709 - accuracy: 0.7994\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.4525 - accuracy: 0.7782\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8177\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7973\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8168\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8355\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7948\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8239\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8099\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8384\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8251\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8274\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.7998\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8641\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8569\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8535\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8585\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.8690\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8824\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8794\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.8889\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8776\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8715\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.8832\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.2710 - accuracy: 0.8731\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.2206 - accuracy: 0.9038\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.2467 - accuracy: 0.8970\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.2347 - accuracy: 0.9008\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.2456 - accuracy: 0.9075\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.2456 - accuracy: 0.8908\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.2357 - accuracy: 0.8878\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.2198 - accuracy: 0.8954\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1914 - accuracy: 0.9283\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.2738 - accuracy: 0.8595\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.2721 - accuracy: 0.8851\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.2336 - accuracy: 0.9049\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2137 - accuracy: 0.9050\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.2067 - accuracy: 0.8985\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1768 - accuracy: 0.9349\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1693 - accuracy: 0.9230\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.2021 - accuracy: 0.9130\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1763 - accuracy: 0.9323\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1701 - accuracy: 0.9286\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2091 - accuracy: 0.9203\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1626 - accuracy: 0.9180\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1895 - accuracy: 0.9085\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.2144 - accuracy: 0.9061\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2439 - accuracy: 0.8971\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.2372 - accuracy: 0.8903\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.2267 - accuracy: 0.8811\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.2391 - accuracy: 0.8826\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.2394 - accuracy: 0.8804\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1946 - accuracy: 0.9131\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1647 - accuracy: 0.9373\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1707 - accuracy: 0.9419\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2262 - accuracy: 0.8892\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1713 - accuracy: 0.9397\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1983 - accuracy: 0.9158\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1688 - accuracy: 0.9191\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1643 - accuracy: 0.9253\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1889 - accuracy: 0.9173\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1724 - accuracy: 0.8934\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1653 - accuracy: 0.9305\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1829 - accuracy: 0.9293\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1256 - accuracy: 0.9416\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1492 - accuracy: 0.9424\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1632 - accuracy: 0.9360\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 866us/step - loss: 0.1520 - accuracy: 0.9433\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1423 - accuracy: 0.9332\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1097 - accuracy: 0.9628\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1895 - accuracy: 0.9150\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1736 - accuracy: 0.9296\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1545 - accuracy: 0.9245\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1159 - accuracy: 0.9546\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1664 - accuracy: 0.9330\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1347 - accuracy: 0.9341\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1209 - accuracy: 0.9353\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1647 - accuracy: 0.9195\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1449 - accuracy: 0.9166\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1926 - accuracy: 0.8747\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1535 - accuracy: 0.9222\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1514 - accuracy: 0.9119\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1469 - accuracy: 0.9229\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1437 - accuracy: 0.9307\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1441 - accuracy: 0.9410\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1398 - accuracy: 0.9174\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1213 - accuracy: 0.9387\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1910 - accuracy: 0.9043\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1658 - accuracy: 0.9276\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1358 - accuracy: 0.9413\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1491 - accuracy: 0.9284\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1265 - accuracy: 0.9266\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1290 - accuracy: 0.9431\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1176 - accuracy: 0.9327\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1343 - accuracy: 0.9207\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1347 - accuracy: 0.9260\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1302 - accuracy: 0.9273\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1441 - accuracy: 0.9267\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1511 - accuracy: 0.9177\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1321 - accuracy: 0.9377\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1388 - accuracy: 0.9318\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.1744 - accuracy: 0.9121\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1606 - accuracy: 0.9290\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9273\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1476 - accuracy: 0.9174\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1295 - accuracy: 0.9243\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1598 - accuracy: 0.8944\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.8975\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1117 - accuracy: 0.9464\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1288 - accuracy: 0.9410\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1136 - accuracy: 0.9259\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1398 - accuracy: 0.9351\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1547 - accuracy: 0.9255\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.1217 - accuracy: 0.9524\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1203 - accuracy: 0.9368\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1574 - accuracy: 0.9089\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9454\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1331 - accuracy: 0.9351\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1432 - accuracy: 0.9363\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1199 - accuracy: 0.9384\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1227 - accuracy: 0.9476\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9237\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1588 - accuracy: 0.9053\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1504 - accuracy: 0.9160\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1296 - accuracy: 0.9168\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1317 - accuracy: 0.9204\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1133 - accuracy: 0.9513\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1161 - accuracy: 0.9571\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1038 - accuracy: 0.9540\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0975 - accuracy: 0.9542\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1225 - accuracy: 0.9488\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1356 - accuracy: 0.9460\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0796 - accuracy: 0.9598\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0936 - accuracy: 0.9489\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1538 - accuracy: 0.9121\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1277 - accuracy: 0.9436\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.1103 - accuracy: 0.9447\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1177 - accuracy: 0.9345\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1214 - accuracy: 0.9335\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0995 - accuracy: 0.9627\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1163 - accuracy: 0.9406\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1097 - accuracy: 0.9522\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1240 - accuracy: 0.9382\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0867 - accuracy: 0.9618\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1186 - accuracy: 0.9328\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1299 - accuracy: 0.9277\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 838us/step - loss: 0.0936 - accuracy: 0.9553\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1614 - accuracy: 0.9291\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0940 - accuracy: 0.9504\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1036 - accuracy: 0.9429\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1166 - accuracy: 0.9400\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1322 - accuracy: 0.9204\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9361\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1215 - accuracy: 0.9386\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1140 - accuracy: 0.9429\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1001 - accuracy: 0.9467\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1166 - accuracy: 0.9490\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1055 - accuracy: 0.9413\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0973 - accuracy: 0.9557\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1159 - accuracy: 0.9316\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0892 - accuracy: 0.9570\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0954 - accuracy: 0.9617\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1130 - accuracy: 0.9405\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1210 - accuracy: 0.9335\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1258 - accuracy: 0.9442\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1076 - accuracy: 0.9591\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1179 - accuracy: 0.9427\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1226 - accuracy: 0.9405\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0954 - accuracy: 0.9501\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0805 - accuracy: 0.9533\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0713 - accuracy: 0.9623\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9618\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1014 - accuracy: 0.9394\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1009 - accuracy: 0.9420\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0840 - accuracy: 0.9488\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0983 - accuracy: 0.9465\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1051 - accuracy: 0.9447\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.1148 - accuracy: 0.9555\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1034 - accuracy: 0.9448\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1216 - accuracy: 0.9307\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1293 - accuracy: 0.9228\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1027 - accuracy: 0.9458\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1002 - accuracy: 0.9543\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1099 - accuracy: 0.9319\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1097 - accuracy: 0.9293\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1040 - accuracy: 0.9472\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1407 - accuracy: 0.9198\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.6141 - accuracy: 0.8363\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.4805 - accuracy: 0.8323\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8184\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8449\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.3876 - accuracy: 0.8318\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.3771 - accuracy: 0.8321\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.3676 - accuracy: 0.8382\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.3312 - accuracy: 0.8565\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.3156 - accuracy: 0.8593\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.3370 - accuracy: 0.8599\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.3205 - accuracy: 0.8406\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.3161 - accuracy: 0.8574\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.3089 - accuracy: 0.8625\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.2653 - accuracy: 0.8795\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.8646\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8868\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.8838\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.2276 - accuracy: 0.8898\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.2324 - accuracy: 0.9021\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.2527 - accuracy: 0.8913\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1975 - accuracy: 0.9101\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2331 - accuracy: 0.8879\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1920 - accuracy: 0.9214\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.2033 - accuracy: 0.9188\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.1779 - accuracy: 0.9345\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2108 - accuracy: 0.9060\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1582 - accuracy: 0.9308\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1892 - accuracy: 0.9215\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1951 - accuracy: 0.9120\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1541 - accuracy: 0.9408\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1608 - accuracy: 0.9350\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1560 - accuracy: 0.9372\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1966 - accuracy: 0.9123\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1431 - accuracy: 0.9392\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1525 - accuracy: 0.9457\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1235 - accuracy: 0.9488\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1394 - accuracy: 0.9446\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1478 - accuracy: 0.9246\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1365 - accuracy: 0.9466\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 888us/step - loss: 0.1282 - accuracy: 0.9525\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1012 - accuracy: 0.9663\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1122 - accuracy: 0.9613\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1245 - accuracy: 0.9483\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1016 - accuracy: 0.9537\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1024 - accuracy: 0.9652\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1040 - accuracy: 0.9618\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0787 - accuracy: 0.9761\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0892 - accuracy: 0.9683\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0855 - accuracy: 0.9688\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0983 - accuracy: 0.9617\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0819 - accuracy: 0.9720\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1281 - accuracy: 0.9406\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0877 - accuracy: 0.9693\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1134 - accuracy: 0.9510\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0711 - accuracy: 0.9773\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0662 - accuracy: 0.9771\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0658 - accuracy: 0.9698\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9761\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0643 - accuracy: 0.9763\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0729 - accuracy: 0.9710\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0727 - accuracy: 0.9685\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0959 - accuracy: 0.9630\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1307 - accuracy: 0.9435\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1183 - accuracy: 0.9535\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0943 - accuracy: 0.9636\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.1026 - accuracy: 0.9607\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0640 - accuracy: 0.9730\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0604 - accuracy: 0.9781\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0856 - accuracy: 0.9647\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0663 - accuracy: 0.9779\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0516 - accuracy: 0.9791\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0585 - accuracy: 0.9799\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0694 - accuracy: 0.9806\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0849 - accuracy: 0.9605\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1170 - accuracy: 0.9512\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0791 - accuracy: 0.9724\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0549 - accuracy: 0.9787\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0529 - accuracy: 0.9839\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0514 - accuracy: 0.9835\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0566 - accuracy: 0.9784\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0441 - accuracy: 0.9854\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0493 - accuracy: 0.9820\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0435 - accuracy: 0.9866\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0397 - accuracy: 0.9881\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0448 - accuracy: 0.9884\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0226 - accuracy: 0.9955\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0508 - accuracy: 0.9802\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0245 - accuracy: 0.9935\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0313 - accuracy: 0.9925\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0495 - accuracy: 0.9881\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0671 - accuracy: 0.9714\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0982 - accuracy: 0.9602\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0753 - accuracy: 0.9701\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0558 - accuracy: 0.9740\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0291 - accuracy: 0.9924\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0615 - accuracy: 0.9758\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0424 - accuracy: 0.9885\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0484 - accuracy: 0.9809\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0618 - accuracy: 0.9758\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0285 - accuracy: 0.9947\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0349 - accuracy: 0.9865\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0533 - accuracy: 0.9800\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0551 - accuracy: 0.9761\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0427 - accuracy: 0.9887\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0502 - accuracy: 0.9828\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9894\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0709 - accuracy: 0.9786\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0478 - accuracy: 0.9832\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9848\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0526 - accuracy: 0.9789\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0516 - accuracy: 0.9813\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0310 - accuracy: 0.9927\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0353 - accuracy: 0.9904\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0558 - accuracy: 0.9721\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0406 - accuracy: 0.9863\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0624 - accuracy: 0.9807\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0470 - accuracy: 0.9815\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0569 - accuracy: 0.9772\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 861us/step - loss: 0.0503 - accuracy: 0.9814\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0585 - accuracy: 0.9785\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0384 - accuracy: 0.9877\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0223 - accuracy: 0.9932\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0673 - accuracy: 0.9751\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1062 - accuracy: 0.9619\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0532 - accuracy: 0.9798\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0314 - accuracy: 0.9901\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0259 - accuracy: 0.9943\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0293 - accuracy: 0.9872\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0637 - accuracy: 0.9776\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0567 - accuracy: 0.9758\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0693 - accuracy: 0.9760\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0367 - accuracy: 0.9859\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0325 - accuracy: 0.9883\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0221 - accuracy: 0.9960\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0294 - accuracy: 0.9917\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0764 - accuracy: 0.9735\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0760 - accuracy: 0.9736\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0557 - accuracy: 0.9797\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0268 - accuracy: 0.9907\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0341 - accuracy: 0.9877\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0370 - accuracy: 0.9819\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0220 - accuracy: 0.9906\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0352 - accuracy: 0.9881\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0199 - accuracy: 0.9948\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0179 - accuracy: 0.9946\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0287 - accuracy: 0.9895\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0279 - accuracy: 0.9927\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0184 - accuracy: 0.9960\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0211 - accuracy: 0.9956\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0247 - accuracy: 0.9910\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0376 - accuracy: 0.9828\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0473 - accuracy: 0.9842\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0569 - accuracy: 0.9852\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0487 - accuracy: 0.9890\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0476 - accuracy: 0.9871\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9623\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0365 - accuracy: 0.9877\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0549 - accuracy: 0.9750\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0384 - accuracy: 0.9829\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0358 - accuracy: 0.9954\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0710 - accuracy: 0.9666\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0329 - accuracy: 0.9902\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0288 - accuracy: 0.9915\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0501 - accuracy: 0.9769\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0466 - accuracy: 0.9872\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0597 - accuracy: 0.9801\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0439 - accuracy: 0.9836\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0342 - accuracy: 0.9874\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0144 - accuracy: 0.9964\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0249 - accuracy: 0.9935\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0139 - accuracy: 0.9979\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9884\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0525 - accuracy: 0.9819\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0302 - accuracy: 0.9915\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0449 - accuracy: 0.9856\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9938\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9840\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0196 - accuracy: 0.9965\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0294 - accuracy: 0.9874\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9875\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0155 - accuracy: 0.9914\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0522 - accuracy: 0.9830\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0632 - accuracy: 0.9739\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0775 - accuracy: 0.9689\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0559 - accuracy: 0.9792\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0700 - accuracy: 0.9733\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0880 - accuracy: 0.9575\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0567 - accuracy: 0.9819\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0567 - accuracy: 0.9787\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0514 - accuracy: 0.9813\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0337 - accuracy: 0.9900\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0315 - accuracy: 0.9919\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0276 - accuracy: 0.9945\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0460 - accuracy: 0.9859\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0301 - accuracy: 0.9889\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0340 - accuracy: 0.9915\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 945us/step - loss: 0.0730 - accuracy: 0.9673\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0822 - accuracy: 0.9592\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.7775\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.3837 - accuracy: 0.8827\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8646\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.3394 - accuracy: 0.8935\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.3560 - accuracy: 0.9003\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3734 - accuracy: 0.8698\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.3238 - accuracy: 0.8884\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.3513 - accuracy: 0.8716\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.3289 - accuracy: 0.8770\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.2907 - accuracy: 0.8992\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.2836 - accuracy: 0.8963\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.2614 - accuracy: 0.8883\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.2763 - accuracy: 0.8983\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.2639 - accuracy: 0.8807\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.2451 - accuracy: 0.8959\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.2556 - accuracy: 0.8709\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2539 - accuracy: 0.8907\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2098 - accuracy: 0.9007\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.2418 - accuracy: 0.9307\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.2228 - accuracy: 0.9102\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.2397 - accuracy: 0.9093\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.2251 - accuracy: 0.9011\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1942 - accuracy: 0.9251\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.2009 - accuracy: 0.9196\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1898 - accuracy: 0.9321\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1988 - accuracy: 0.9235\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1767 - accuracy: 0.9333\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1304 - accuracy: 0.9596\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1422 - accuracy: 0.9499\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1507 - accuracy: 0.9422\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9482\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.9632\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1050 - accuracy: 0.9651\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1204 - accuracy: 0.9529\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1266 - accuracy: 0.9499\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9381\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1910 - accuracy: 0.9290\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9474\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9702\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1032 - accuracy: 0.9639\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9667\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9610\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9549\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1002 - accuracy: 0.9669\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0809 - accuracy: 0.9761\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9557\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1258 - accuracy: 0.9479\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9623\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0450 - accuracy: 0.9865\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9681\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0891 - accuracy: 0.9639\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1253 - accuracy: 0.9561\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0772 - accuracy: 0.9748\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1333 - accuracy: 0.9471\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0729 - accuracy: 0.9761\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0772 - accuracy: 0.9730\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0915 - accuracy: 0.9632\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0845 - accuracy: 0.9663\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0852 - accuracy: 0.9679\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0882 - accuracy: 0.9696\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1050 - accuracy: 0.9561\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0638 - accuracy: 0.9835\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0934 - accuracy: 0.9601\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0805 - accuracy: 0.9645\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0608 - accuracy: 0.9734\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0607 - accuracy: 0.9833\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0752 - accuracy: 0.9673\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0743 - accuracy: 0.9681\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0844 - accuracy: 0.9676\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0570 - accuracy: 0.9820\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0926 - accuracy: 0.9684\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0540 - accuracy: 0.9804\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0587 - accuracy: 0.9814\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0664 - accuracy: 0.9790\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0547 - accuracy: 0.9826\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0369 - accuracy: 0.9885\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0507 - accuracy: 0.9796\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0482 - accuracy: 0.9842\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 862us/step - loss: 0.0635 - accuracy: 0.9793\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1070 - accuracy: 0.9608\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0785 - accuracy: 0.9753\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0711 - accuracy: 0.9753\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0703 - accuracy: 0.9692\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0561 - accuracy: 0.9829\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0861 - accuracy: 0.9655\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0923 - accuracy: 0.9673\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0881 - accuracy: 0.9654\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0721 - accuracy: 0.9738\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0736 - accuracy: 0.9722\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0433 - accuracy: 0.9881\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0597 - accuracy: 0.9814\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0478 - accuracy: 0.9878\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0737 - accuracy: 0.9766\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0361 - accuracy: 0.9916\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0459 - accuracy: 0.9861\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0521 - accuracy: 0.9794\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0703 - accuracy: 0.9733\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0667 - accuracy: 0.9799\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0621 - accuracy: 0.9732\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0593 - accuracy: 0.9731\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0664 - accuracy: 0.9767\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0462 - accuracy: 0.9848\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0408 - accuracy: 0.9888\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0478 - accuracy: 0.9869\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0588 - accuracy: 0.9771\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0671 - accuracy: 0.9783\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0765 - accuracy: 0.9775\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0423 - accuracy: 0.9896\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.0491 - accuracy: 0.9844\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0337 - accuracy: 0.9884\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0380 - accuracy: 0.9914\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0505 - accuracy: 0.9827\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0685 - accuracy: 0.9717\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0411 - accuracy: 0.9854\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0493 - accuracy: 0.9844\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0413 - accuracy: 0.9867\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0401 - accuracy: 0.9881\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0438 - accuracy: 0.9858\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0437 - accuracy: 0.9829\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0541 - accuracy: 0.9857\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0632 - accuracy: 0.9807\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0603 - accuracy: 0.9785\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0509 - accuracy: 0.9808\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0854 - accuracy: 0.9720\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0471 - accuracy: 0.9864\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0557 - accuracy: 0.9782\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0459 - accuracy: 0.9860\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0538 - accuracy: 0.9796\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0602 - accuracy: 0.9802\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0569 - accuracy: 0.9806\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0597 - accuracy: 0.9780\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0453 - accuracy: 0.9829\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0404 - accuracy: 0.9858\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0462 - accuracy: 0.9819\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0203 - accuracy: 0.9945\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0588 - accuracy: 0.9806\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0453 - accuracy: 0.9876\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0355 - accuracy: 0.9861\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0526 - accuracy: 0.9834\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1033 - accuracy: 0.9688\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1025 - accuracy: 0.9600\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0841 - accuracy: 0.9641\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0479 - accuracy: 0.9837\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0303 - accuracy: 0.9941\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0380 - accuracy: 0.9878\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0308 - accuracy: 0.9945\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0384 - accuracy: 0.9853\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0394 - accuracy: 0.9890\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0326 - accuracy: 0.9898\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0571 - accuracy: 0.9807\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0290 - accuracy: 0.9946\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0139 - accuracy: 0.9983\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0395 - accuracy: 0.9887\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0467 - accuracy: 0.9880\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0277 - accuracy: 0.9923\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0616 - accuracy: 0.9783\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 973us/step - loss: 0.0621 - accuracy: 0.9771\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0880 - accuracy: 0.9620\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0499 - accuracy: 0.9781\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0623 - accuracy: 0.9726\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0478 - accuracy: 0.9858\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0607 - accuracy: 0.9805\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0537 - accuracy: 0.9798\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0287 - accuracy: 0.9948\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0524 - accuracy: 0.9852\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0485 - accuracy: 0.9853\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0427 - accuracy: 0.9876\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0478 - accuracy: 0.9861\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0288 - accuracy: 0.9911\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0193 - accuracy: 0.9963\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0194 - accuracy: 0.9964\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0580 - accuracy: 0.9854\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9900\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0635 - accuracy: 0.9795\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0272 - accuracy: 0.9917\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0491 - accuracy: 0.9861\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0395 - accuracy: 0.9854\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0479 - accuracy: 0.9872\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0352 - accuracy: 0.9904\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0734 - accuracy: 0.9686\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0704 - accuracy: 0.9722\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0551 - accuracy: 0.9796\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0633 - accuracy: 0.9792\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9933\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0365 - accuracy: 0.9889\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0491 - accuracy: 0.9840\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0579 - accuracy: 0.9776\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0551 - accuracy: 0.9824\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0761 - accuracy: 0.9766\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0196 - accuracy: 0.9968\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0297 - accuracy: 0.9886\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0526 - accuracy: 0.9800\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0340 - accuracy: 0.9887\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0593 - accuracy: 0.9806\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0372 - accuracy: 0.9888\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0555 - accuracy: 0.9797\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0277 - accuracy: 0.9923\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0377 - accuracy: 0.9903\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0360 - accuracy: 0.9899\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c78c0eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73ed8af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73f6bb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 4: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.7778 - accuracy: 0.6595\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.7196\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.5814 - accuracy: 0.7081\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7418\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.5130 - accuracy: 0.7466\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.5188 - accuracy: 0.7495\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.5025 - accuracy: 0.7603\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.5137 - accuracy: 0.7450\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.5056 - accuracy: 0.7423\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.4680 - accuracy: 0.7985\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.4549 - accuracy: 0.8015\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.4578 - accuracy: 0.7921\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.4241 - accuracy: 0.7960\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.4258 - accuracy: 0.8032\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.4370 - accuracy: 0.8034\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.3730 - accuracy: 0.8476\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.4402 - accuracy: 0.8019\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.3713 - accuracy: 0.8325\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.3879 - accuracy: 0.8238\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.3828 - accuracy: 0.8519\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.3515 - accuracy: 0.8526\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.3551 - accuracy: 0.8502\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.3245 - accuracy: 0.8562\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.8748\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.2974 - accuracy: 0.8721\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.3012 - accuracy: 0.8798\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2832 - accuracy: 0.8794\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.9014\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.2915 - accuracy: 0.8783\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2386 - accuracy: 0.9024\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.2419 - accuracy: 0.8992\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2395 - accuracy: 0.8769\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.2724 - accuracy: 0.8711\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.2053 - accuracy: 0.9192\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.2091 - accuracy: 0.9133\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1904 - accuracy: 0.9288\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.9010\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.8939\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.2201 - accuracy: 0.8989\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9224\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.2236 - accuracy: 0.9004\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.9077\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.2478 - accuracy: 0.9005\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2289 - accuracy: 0.9100\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1833 - accuracy: 0.9204\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.2006 - accuracy: 0.9327\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1979 - accuracy: 0.9163\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2225 - accuracy: 0.8971\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9063\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.2429 - accuracy: 0.8931\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1969 - accuracy: 0.9224\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1936 - accuracy: 0.9103\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.2052 - accuracy: 0.9054\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1732 - accuracy: 0.9261\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1785 - accuracy: 0.9197\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.1476 - accuracy: 0.9374\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1902 - accuracy: 0.9083\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1945 - accuracy: 0.9203\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1362 - accuracy: 0.9438\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1605 - accuracy: 0.9356\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1783 - accuracy: 0.9242\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1405 - accuracy: 0.9344\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1297 - accuracy: 0.9272\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1364 - accuracy: 0.9395\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1080 - accuracy: 0.9536\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1253 - accuracy: 0.9585\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1808 - accuracy: 0.9144\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.2076 - accuracy: 0.8954\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9341\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9422\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1233 - accuracy: 0.9433\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1195 - accuracy: 0.9292\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1171 - accuracy: 0.9363\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1327 - accuracy: 0.9386\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9187\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1661 - accuracy: 0.9189\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1499 - accuracy: 0.9336\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1392 - accuracy: 0.9287\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1279 - accuracy: 0.9433\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1405 - accuracy: 0.9314\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 874us/step - loss: 0.1467 - accuracy: 0.9468\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1141 - accuracy: 0.9516\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1423 - accuracy: 0.9468\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1556 - accuracy: 0.9225\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1176 - accuracy: 0.9524\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1239 - accuracy: 0.9523\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1286 - accuracy: 0.9326\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1235 - accuracy: 0.9434\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1505 - accuracy: 0.9341\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1417 - accuracy: 0.9415\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1202 - accuracy: 0.9444\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1255 - accuracy: 0.9494\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.2074 - accuracy: 0.9022\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.1825 - accuracy: 0.9104\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1497 - accuracy: 0.9353\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0942 - accuracy: 0.9613\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1183 - accuracy: 0.9548\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1283 - accuracy: 0.9495\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1161 - accuracy: 0.9502\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1122 - accuracy: 0.9573\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0797 - accuracy: 0.9752\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1083 - accuracy: 0.9542\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1443 - accuracy: 0.9386\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1067 - accuracy: 0.9520\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1017 - accuracy: 0.9641\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1185 - accuracy: 0.9521\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1923 - accuracy: 0.9290\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1417 - accuracy: 0.9526\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0814 - accuracy: 0.9685\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1136 - accuracy: 0.9549\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0793 - accuracy: 0.9741\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1277 - accuracy: 0.9570\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1255 - accuracy: 0.9499\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0956 - accuracy: 0.9678\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0889 - accuracy: 0.9652\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0791 - accuracy: 0.9711\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0725 - accuracy: 0.9728\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0956 - accuracy: 0.9624\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1000 - accuracy: 0.9633\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1076 - accuracy: 0.9513\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1414 - accuracy: 0.9373\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1130 - accuracy: 0.9475\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1093 - accuracy: 0.9516\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0853 - accuracy: 0.9680\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0892 - accuracy: 0.9571\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0796 - accuracy: 0.9682\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0833 - accuracy: 0.9663\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0554 - accuracy: 0.9783\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1009 - accuracy: 0.9602\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0929 - accuracy: 0.9589\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0856 - accuracy: 0.9605\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0690 - accuracy: 0.9780\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0876 - accuracy: 0.9569\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0786 - accuracy: 0.9687\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1033 - accuracy: 0.9500\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0655 - accuracy: 0.9704\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.1221 - accuracy: 0.9542\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0492 - accuracy: 0.9882\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0687 - accuracy: 0.9721\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0710 - accuracy: 0.9684\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0951 - accuracy: 0.9635\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1011 - accuracy: 0.9657\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0834 - accuracy: 0.9719\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0997 - accuracy: 0.9517\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0929 - accuracy: 0.9644\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0949 - accuracy: 0.9626\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1680 - accuracy: 0.9337\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0665 - accuracy: 0.9729\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0718 - accuracy: 0.9716\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0662 - accuracy: 0.9761\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0735 - accuracy: 0.9702\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0479 - accuracy: 0.9883\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0966 - accuracy: 0.9665\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0387 - accuracy: 0.9852\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0671 - accuracy: 0.9784\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9671\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0511 - accuracy: 0.9821\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0663 - accuracy: 0.9729\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0599 - accuracy: 0.9752\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 940us/step - loss: 0.0879 - accuracy: 0.9664\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0655 - accuracy: 0.9727\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0814 - accuracy: 0.9743\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0561 - accuracy: 0.9770\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0578 - accuracy: 0.9852\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9653\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9733\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0751 - accuracy: 0.9643\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0788 - accuracy: 0.9658\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9550\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0762 - accuracy: 0.9606\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0570 - accuracy: 0.9786\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1315 - accuracy: 0.9501\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0769 - accuracy: 0.9608\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0936 - accuracy: 0.9600\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0915 - accuracy: 0.9607\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0664 - accuracy: 0.9757\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0951 - accuracy: 0.9528\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9710\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0597 - accuracy: 0.9809\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0935 - accuracy: 0.9570\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1182 - accuracy: 0.9595\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9594\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9761\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0878 - accuracy: 0.9608\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0928 - accuracy: 0.9629\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0902 - accuracy: 0.9731\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0691 - accuracy: 0.9710\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0658 - accuracy: 0.9660\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0785 - accuracy: 0.9648\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0902 - accuracy: 0.9542\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0649 - accuracy: 0.9664\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0964 - accuracy: 0.9616\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0640 - accuracy: 0.9660\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0770 - accuracy: 0.9682\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0721 - accuracy: 0.9807\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0963 - accuracy: 0.9590\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0565 - accuracy: 0.9804\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9758\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9776\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0880 - accuracy: 0.9674\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.6569 - accuracy: 0.7966\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.4489 - accuracy: 0.8420\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.4466 - accuracy: 0.8317\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.4191 - accuracy: 0.8250\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.3832 - accuracy: 0.8386\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.3732 - accuracy: 0.8400\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.3814 - accuracy: 0.8281\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.3676 - accuracy: 0.8273\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.3707 - accuracy: 0.8254\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.3192 - accuracy: 0.8456\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.3308 - accuracy: 0.8379\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.2961 - accuracy: 0.8647\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.3340 - accuracy: 0.8590\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8497\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2864 - accuracy: 0.8755\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.3000 - accuracy: 0.8621\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.2769 - accuracy: 0.8582\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.2554 - accuracy: 0.8904\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.2353 - accuracy: 0.8987\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.2450 - accuracy: 0.8814\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.3256 - accuracy: 0.8419\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.2334 - accuracy: 0.9078\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.2255 - accuracy: 0.8955\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.2434 - accuracy: 0.8890\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.2128 - accuracy: 0.9097\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.2327 - accuracy: 0.8867\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.2153 - accuracy: 0.9038\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1876 - accuracy: 0.9279\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1875 - accuracy: 0.9200\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1849 - accuracy: 0.9290\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9324\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1500 - accuracy: 0.9541\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1783 - accuracy: 0.9241\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1700 - accuracy: 0.9261\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1439 - accuracy: 0.9449\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1578 - accuracy: 0.9409\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9578\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1582 - accuracy: 0.9164\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1536 - accuracy: 0.9334\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 966us/step - loss: 0.1392 - accuracy: 0.9429\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1043 - accuracy: 0.9683\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1450 - accuracy: 0.9299\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1456 - accuracy: 0.9366\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1263 - accuracy: 0.9410\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1043 - accuracy: 0.9554\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1136 - accuracy: 0.9548\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1208 - accuracy: 0.9462\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1185 - accuracy: 0.9519\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1279 - accuracy: 0.9404\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0944 - accuracy: 0.9583\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0837 - accuracy: 0.9631\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0995 - accuracy: 0.9635\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9423\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0986 - accuracy: 0.9580\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1026 - accuracy: 0.9639\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9604\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0862 - accuracy: 0.9633\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0904 - accuracy: 0.9707\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0771 - accuracy: 0.9749\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0933 - accuracy: 0.9637\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9704\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9667\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0853 - accuracy: 0.9686\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0734 - accuracy: 0.9679\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9738\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0723 - accuracy: 0.9750\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0661 - accuracy: 0.9759\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0580 - accuracy: 0.9804\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1136 - accuracy: 0.9543\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0911 - accuracy: 0.9644\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9554\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9672\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1062 - accuracy: 0.9551\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0861 - accuracy: 0.9706\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0797 - accuracy: 0.9669\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0516 - accuracy: 0.9840\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0489 - accuracy: 0.9825\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0366 - accuracy: 0.9894\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0498 - accuracy: 0.9818\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0416 - accuracy: 0.9881\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0403 - accuracy: 0.9877\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0704 - accuracy: 0.9709\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0928 - accuracy: 0.9707\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9712\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0591 - accuracy: 0.9777\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9818\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0456 - accuracy: 0.9801\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9697\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0844 - accuracy: 0.9692\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9727\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0459 - accuracy: 0.9844\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9762\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0820 - accuracy: 0.9635\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0644 - accuracy: 0.9770\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9740\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0299 - accuracy: 0.9928\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9739\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0361 - accuracy: 0.9882\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9844\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0386 - accuracy: 0.9931\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0873 - accuracy: 0.9680\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0368 - accuracy: 0.9880\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0825 - accuracy: 0.9677\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0955 - accuracy: 0.9603\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9769\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9645\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9601\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9790\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9779\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9711\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0835 - accuracy: 0.9660\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9638\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9711\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9663\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9683\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9804\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9889\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9844\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9819\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9908\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9851\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9916\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9881\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9631\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0511 - accuracy: 0.9838\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0463 - accuracy: 0.9857\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0447 - accuracy: 0.9883\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9904\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9897\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0277 - accuracy: 0.9917\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0169 - accuracy: 0.9964\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9875\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9851\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0278 - accuracy: 0.9937\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0183 - accuracy: 0.9947\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0221 - accuracy: 0.9937\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0223 - accuracy: 0.9939\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0368 - accuracy: 0.9832\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0473 - accuracy: 0.9884\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0895 - accuracy: 0.9673\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0475 - accuracy: 0.9872\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0844 - accuracy: 0.9682\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0705 - accuracy: 0.9649\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0483 - accuracy: 0.9860\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0489 - accuracy: 0.9797\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0290 - accuracy: 0.9905\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0264 - accuracy: 0.9925\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0323 - accuracy: 0.9902\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0205 - accuracy: 0.9971\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0327 - accuracy: 0.9859\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0261 - accuracy: 0.9951\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0194 - accuracy: 0.9939\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0548 - accuracy: 0.9788\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0562 - accuracy: 0.9800\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.1568 - accuracy: 0.9463\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0908 - accuracy: 0.9649\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0843 - accuracy: 0.9737\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0730 - accuracy: 0.9793\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0425 - accuracy: 0.9837\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0473 - accuracy: 0.9880\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0300 - accuracy: 0.9926\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0286 - accuracy: 0.9903\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.0244 - accuracy: 0.9956\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0228 - accuracy: 0.9914\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0450 - accuracy: 0.9875\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0524 - accuracy: 0.9826\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0511 - accuracy: 0.9815\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0301 - accuracy: 0.9949\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0358 - accuracy: 0.9875\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0595 - accuracy: 0.9796\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0737 - accuracy: 0.9750\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0465 - accuracy: 0.9852\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0485 - accuracy: 0.9851\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0419 - accuracy: 0.9865\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0497 - accuracy: 0.9781\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0404 - accuracy: 0.9870\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0684 - accuracy: 0.9769\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0547 - accuracy: 0.9858\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0473 - accuracy: 0.9860\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0308 - accuracy: 0.9878\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0170 - accuracy: 0.9965\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0555 - accuracy: 0.9821\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0368 - accuracy: 0.9857\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0579 - accuracy: 0.9795\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0334 - accuracy: 0.9865\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0204 - accuracy: 0.9955\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0234 - accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0298 - accuracy: 0.9918\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0593 - accuracy: 0.9781\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0547 - accuracy: 0.9846\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0503 - accuracy: 0.9827\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0552 - accuracy: 0.9848\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0413 - accuracy: 0.9867\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0357 - accuracy: 0.9852\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0218 - accuracy: 0.9941\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0339 - accuracy: 0.9864\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 821us/step - loss: 0.0319 - accuracy: 0.9906\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0434 - accuracy: 0.9838\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9739 - accuracy: 0.4768 \n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.4569 - accuracy: 0.8689\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.4094 - accuracy: 0.8803\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.3523 - accuracy: 0.8823\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.3702 - accuracy: 0.8787\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.3125 - accuracy: 0.9110\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.3641 - accuracy: 0.8838\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.3281 - accuracy: 0.8954\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.3089 - accuracy: 0.8974\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.3491 - accuracy: 0.8672\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.2880 - accuracy: 0.8967\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.2907 - accuracy: 0.8958\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2805 - accuracy: 0.8987\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.2669 - accuracy: 0.8932\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.2766 - accuracy: 0.8952\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.2947 - accuracy: 0.8877\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.2556 - accuracy: 0.9064\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.2594 - accuracy: 0.9011\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.2396 - accuracy: 0.8998\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.2255 - accuracy: 0.9253\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.2229 - accuracy: 0.9140\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.2242 - accuracy: 0.9084\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.2134 - accuracy: 0.9127\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.2226 - accuracy: 0.9094\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.2380 - accuracy: 0.9154\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.2916 - accuracy: 0.9086\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.2126 - accuracy: 0.9169\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1962 - accuracy: 0.9234\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.2075 - accuracy: 0.9294\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.1795 - accuracy: 0.9325\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.2044 - accuracy: 0.9224\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1593 - accuracy: 0.9384\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.1309 - accuracy: 0.9541\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1342 - accuracy: 0.9408\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1413 - accuracy: 0.9394\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1528 - accuracy: 0.9462\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.1226 - accuracy: 0.9459\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1570 - accuracy: 0.9258\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.1594 - accuracy: 0.9416\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.1054 - accuracy: 0.9617\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1126 - accuracy: 0.9488\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.1250 - accuracy: 0.9444\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.1363 - accuracy: 0.9440\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1532 - accuracy: 0.9449\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1088 - accuracy: 0.9551\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1170 - accuracy: 0.9519\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9528\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1400 - accuracy: 0.9322\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9539\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1083 - accuracy: 0.9597\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1251 - accuracy: 0.9534\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9564\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1089 - accuracy: 0.9622\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1060 - accuracy: 0.9600\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0996 - accuracy: 0.9602\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0692 - accuracy: 0.9669\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0962 - accuracy: 0.9577\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0747 - accuracy: 0.9700\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0777 - accuracy: 0.9738\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0802 - accuracy: 0.9608\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0696 - accuracy: 0.9757\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0766 - accuracy: 0.9667\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0739 - accuracy: 0.9730\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0546 - accuracy: 0.9777\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1018 - accuracy: 0.9570\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0645 - accuracy: 0.9806\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0900 - accuracy: 0.9612\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0857 - accuracy: 0.9608\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9657\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0858 - accuracy: 0.9695\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0665 - accuracy: 0.9745\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0680 - accuracy: 0.9828\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0884 - accuracy: 0.9666\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1046 - accuracy: 0.9554\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0606 - accuracy: 0.9775\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9739\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0525 - accuracy: 0.9810\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0809 - accuracy: 0.9653\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 974us/step - loss: 0.0855 - accuracy: 0.9522\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9799\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9771\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0906 - accuracy: 0.9606\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0869 - accuracy: 0.9672\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0677 - accuracy: 0.9753\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0826 - accuracy: 0.9659\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0765 - accuracy: 0.9741\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9603\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0694 - accuracy: 0.9716\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9695\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0727 - accuracy: 0.9689\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0681 - accuracy: 0.9736\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0536 - accuracy: 0.9825\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9513\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0626 - accuracy: 0.9754\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0926 - accuracy: 0.9467\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9599\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0971 - accuracy: 0.9556\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0693 - accuracy: 0.9742\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0892 - accuracy: 0.9767\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0650 - accuracy: 0.9686\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0529 - accuracy: 0.9775\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0557 - accuracy: 0.9824\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0720 - accuracy: 0.9716\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0570 - accuracy: 0.9789\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0531 - accuracy: 0.9818\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0611 - accuracy: 0.9711\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0731 - accuracy: 0.9651\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0669 - accuracy: 0.9696\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0649 - accuracy: 0.9726\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0587 - accuracy: 0.9784\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0495 - accuracy: 0.9893\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0538 - accuracy: 0.9760\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0509 - accuracy: 0.9854\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0653 - accuracy: 0.9695\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0922 - accuracy: 0.9558\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0550 - accuracy: 0.9779\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0659 - accuracy: 0.9698\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0954 - accuracy: 0.9602\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1067 - accuracy: 0.9434\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0858 - accuracy: 0.9769\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0703 - accuracy: 0.9723\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0481 - accuracy: 0.9845\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0501 - accuracy: 0.9769\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0643 - accuracy: 0.9720\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0548 - accuracy: 0.9782\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0611 - accuracy: 0.9745\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0706 - accuracy: 0.9744\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0464 - accuracy: 0.9823\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9858\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9829\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0611 - accuracy: 0.9649\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0346 - accuracy: 0.9900\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0492 - accuracy: 0.9808\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0468 - accuracy: 0.9848\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0568 - accuracy: 0.9717\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0718 - accuracy: 0.9732\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0421 - accuracy: 0.9827\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0551 - accuracy: 0.9783\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0474 - accuracy: 0.9812\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0492 - accuracy: 0.9830\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0457 - accuracy: 0.9871\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0359 - accuracy: 0.9907\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0288 - accuracy: 0.9938\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0367 - accuracy: 0.9918\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0694 - accuracy: 0.9790\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0525 - accuracy: 0.9805\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0465 - accuracy: 0.9816\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0481 - accuracy: 0.9832\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0331 - accuracy: 0.9917\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0314 - accuracy: 0.9908\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0602 - accuracy: 0.9785\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0477 - accuracy: 0.9808\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0209 - accuracy: 0.9967\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0432 - accuracy: 0.9831\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0410 - accuracy: 0.9888\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0314 - accuracy: 0.9890\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0403 - accuracy: 0.9853\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0533 - accuracy: 0.9772\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9802\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0772 - accuracy: 0.9742\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0543 - accuracy: 0.9773\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9884\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0381 - accuracy: 0.9916\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0304 - accuracy: 0.9901\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0557 - accuracy: 0.9781\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9597\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0479 - accuracy: 0.9843\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0400 - accuracy: 0.9827\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9821\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0523 - accuracy: 0.9795\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0523 - accuracy: 0.9826\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0416 - accuracy: 0.9861\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0908 - accuracy: 0.9704\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0516 - accuracy: 0.9841\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9768\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9823\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9686\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0392 - accuracy: 0.9865\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0316 - accuracy: 0.9845\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0411 - accuracy: 0.9842\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0356 - accuracy: 0.9904\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9820\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0298 - accuracy: 0.9893\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0385 - accuracy: 0.9859\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0329 - accuracy: 0.9910\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0925 - accuracy: 0.9657\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0539 - accuracy: 0.9776\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0651 - accuracy: 0.9708\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0796 - accuracy: 0.9641\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0454 - accuracy: 0.9794\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0318 - accuracy: 0.9894\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0401 - accuracy: 0.9842\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0283 - accuracy: 0.9892\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0235 - accuracy: 0.9927\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0398 - accuracy: 0.9871\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0249 - accuracy: 0.9911\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0309 - accuracy: 0.9860\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9915\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9952\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9876\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c797998b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7a595ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7974f3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 5: 78\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9303 - accuracy: 0.5378\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.7249 - accuracy: 0.6769\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.6492 - accuracy: 0.6966\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.6096 - accuracy: 0.6885\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.5963 - accuracy: 0.7084\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.5829 - accuracy: 0.6878\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.5578 - accuracy: 0.6939\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.5498 - accuracy: 0.7515\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.5441 - accuracy: 0.7415\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.5790 - accuracy: 0.7249\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.5400 - accuracy: 0.7554\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.5253 - accuracy: 0.7485\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7522\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.4903 - accuracy: 0.7692\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.4682 - accuracy: 0.7839\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7718\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.4459 - accuracy: 0.8031\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.4382 - accuracy: 0.7921\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.4379 - accuracy: 0.8002\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.4423 - accuracy: 0.8134\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.4048 - accuracy: 0.8172\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.4160 - accuracy: 0.8035\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.3812 - accuracy: 0.8291\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.3775 - accuracy: 0.8539\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.3692 - accuracy: 0.8443\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8472\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.3502 - accuracy: 0.8464\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.3604 - accuracy: 0.8385\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.3679 - accuracy: 0.8567\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8055\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.3648 - accuracy: 0.8312\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.3215 - accuracy: 0.8635\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.3159 - accuracy: 0.8615\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.3254 - accuracy: 0.8411\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.3069 - accuracy: 0.8722\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.2829 - accuracy: 0.8705\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.3029 - accuracy: 0.8780\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.8657\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.2889 - accuracy: 0.8957\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.2914 - accuracy: 0.8684\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.2541 - accuracy: 0.8954\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.2534 - accuracy: 0.8919\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.2681 - accuracy: 0.8605\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.2393 - accuracy: 0.9135\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8508\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.3194 - accuracy: 0.8565\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.2492 - accuracy: 0.8987\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.2107 - accuracy: 0.9027\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.2282 - accuracy: 0.8985\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.2391 - accuracy: 0.8983\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.2670 - accuracy: 0.8714\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.2452 - accuracy: 0.8978\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.2365 - accuracy: 0.9166\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.2490 - accuracy: 0.9018\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.2407 - accuracy: 0.8959\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2146 - accuracy: 0.9051\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.2238 - accuracy: 0.8846\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.2043 - accuracy: 0.9111\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1916 - accuracy: 0.9168\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.2019 - accuracy: 0.9088\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1898 - accuracy: 0.9145\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1587 - accuracy: 0.9272\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1682 - accuracy: 0.9150\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1813 - accuracy: 0.9240\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.2012 - accuracy: 0.9041\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1787 - accuracy: 0.9197\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1666 - accuracy: 0.9114\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1979 - accuracy: 0.8891\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.2213 - accuracy: 0.9037\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1489 - accuracy: 0.9202\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1414 - accuracy: 0.9339\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1788 - accuracy: 0.9115\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.2064 - accuracy: 0.9077\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.2146 - accuracy: 0.9067\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1673 - accuracy: 0.9355\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1696 - accuracy: 0.9249\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1862 - accuracy: 0.9145\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1822 - accuracy: 0.9142\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1740 - accuracy: 0.9165\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.2145 - accuracy: 0.8658\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 912us/step - loss: 0.1740 - accuracy: 0.9025\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1588 - accuracy: 0.9158\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1538 - accuracy: 0.9362\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1742 - accuracy: 0.9147\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1728 - accuracy: 0.9154\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.9125\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1423 - accuracy: 0.9376\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1199 - accuracy: 0.9485\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.8824\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1959 - accuracy: 0.9001\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1464 - accuracy: 0.9267\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1603 - accuracy: 0.9144\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1699 - accuracy: 0.9065\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9053\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2000 - accuracy: 0.8987\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1878 - accuracy: 0.8943\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1576 - accuracy: 0.9154\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1838 - accuracy: 0.9205\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1807 - accuracy: 0.9026\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1553 - accuracy: 0.9240\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1442 - accuracy: 0.9233\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1371 - accuracy: 0.9342\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1207 - accuracy: 0.9474\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1201 - accuracy: 0.9339\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1362 - accuracy: 0.9323\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1165 - accuracy: 0.9441\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1691 - accuracy: 0.9189\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1376 - accuracy: 0.9419\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1501 - accuracy: 0.9348\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9324\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1365 - accuracy: 0.9276\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1529 - accuracy: 0.9281\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1327 - accuracy: 0.9345\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1549 - accuracy: 0.9090\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1412 - accuracy: 0.9245\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1425 - accuracy: 0.9362\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1811 - accuracy: 0.8883\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.9072\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1441 - accuracy: 0.9107\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1389 - accuracy: 0.9292\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1409 - accuracy: 0.9279\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.8957\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1484 - accuracy: 0.9276\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9323\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9386\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1385 - accuracy: 0.9170\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1455 - accuracy: 0.9406\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9252\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0872 - accuracy: 0.9700\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9317\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1534 - accuracy: 0.9234\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9178\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9428\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9446\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1337 - accuracy: 0.9454\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1245 - accuracy: 0.9376\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1147 - accuracy: 0.9419\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9277\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1140 - accuracy: 0.9546\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1179 - accuracy: 0.9406\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1366 - accuracy: 0.9117\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9020\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1081 - accuracy: 0.9402\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1037 - accuracy: 0.9486\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1450 - accuracy: 0.9204\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9091\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9336\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.9400\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1430 - accuracy: 0.9168\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1394 - accuracy: 0.9181\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1637 - accuracy: 0.9166\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1308 - accuracy: 0.9311\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.8569\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1671 - accuracy: 0.9184\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1521 - accuracy: 0.9105\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9136\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1376 - accuracy: 0.9141\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1208 - accuracy: 0.9502\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0909 - accuracy: 0.9506\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1405 - accuracy: 0.9412\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 922us/step - loss: 0.1463 - accuracy: 0.9186\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0972 - accuracy: 0.9517\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9428\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1031 - accuracy: 0.9557\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1151 - accuracy: 0.9506\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9579\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9446\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9461\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9279\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9443\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9447\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1172 - accuracy: 0.9513\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9494\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9458\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9483\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9263\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9573\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9617\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9356\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9530\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9460\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9415\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9473\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9375\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1416 - accuracy: 0.9123\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9569\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1321 - accuracy: 0.9419\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1094 - accuracy: 0.9435\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1031 - accuracy: 0.9483\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0984 - accuracy: 0.9617\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9458\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1216 - accuracy: 0.9454\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1088 - accuracy: 0.9419\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1075 - accuracy: 0.9415\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1366 - accuracy: 0.9352\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9225\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.9457\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9320\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0973 - accuracy: 0.9558\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9673\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.7798 - accuracy: 0.6261\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.5574 - accuracy: 0.8106\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.4634 - accuracy: 0.8258\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.4452 - accuracy: 0.8124\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.4071 - accuracy: 0.8471\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.4111 - accuracy: 0.8365\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8515\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.3476 - accuracy: 0.8462\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.3665 - accuracy: 0.8449\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.3731 - accuracy: 0.8402\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.3531 - accuracy: 0.8512\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8528\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8795\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.3405 - accuracy: 0.8455\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.8920\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.2789 - accuracy: 0.8909\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.3097 - accuracy: 0.8641\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.2630 - accuracy: 0.8818\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2312 - accuracy: 0.9102\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.2428 - accuracy: 0.8909\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.2424 - accuracy: 0.8943\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.2199 - accuracy: 0.9095\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2148 - accuracy: 0.9049\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.2165 - accuracy: 0.9060\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.2215 - accuracy: 0.8979\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.2100 - accuracy: 0.9086\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1968 - accuracy: 0.9260\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.1985 - accuracy: 0.9090\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1751 - accuracy: 0.9221\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1499 - accuracy: 0.9339\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9054\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9137\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1748 - accuracy: 0.9190\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1591 - accuracy: 0.9278\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1886 - accuracy: 0.9106\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1611 - accuracy: 0.9337\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1472 - accuracy: 0.9377\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1540 - accuracy: 0.9268\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1497 - accuracy: 0.9325\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1511 - accuracy: 0.9271\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 967us/step - loss: 0.1243 - accuracy: 0.9502\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1299 - accuracy: 0.9503\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1135 - accuracy: 0.9497\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1717 - accuracy: 0.9128\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1815 - accuracy: 0.9180\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1350 - accuracy: 0.9503\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1456 - accuracy: 0.9410\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1247 - accuracy: 0.9440\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1407 - accuracy: 0.9373\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1460 - accuracy: 0.9380\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0999 - accuracy: 0.9626\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0975 - accuracy: 0.9651\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1385 - accuracy: 0.9221\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1191 - accuracy: 0.9447\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1206 - accuracy: 0.9397\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1339 - accuracy: 0.9412\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1084 - accuracy: 0.9407\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1008 - accuracy: 0.9594\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0993 - accuracy: 0.9634\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0947 - accuracy: 0.9605\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0886 - accuracy: 0.9736\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1206 - accuracy: 0.9428\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1473 - accuracy: 0.9465\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1182 - accuracy: 0.9539\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1050 - accuracy: 0.9589\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1435 - accuracy: 0.9417\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0704 - accuracy: 0.9746\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0842 - accuracy: 0.9690\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9534\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1184 - accuracy: 0.9474\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0734 - accuracy: 0.9701\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0893 - accuracy: 0.9592\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1318 - accuracy: 0.9392\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1415 - accuracy: 0.9241\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9291\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1364 - accuracy: 0.9216\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1135 - accuracy: 0.9478\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1111 - accuracy: 0.9384\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1156 - accuracy: 0.9496\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1357 - accuracy: 0.9339\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1158 - accuracy: 0.9425\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1208 - accuracy: 0.9384\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9525\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0890 - accuracy: 0.9423\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0897 - accuracy: 0.9474\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0616 - accuracy: 0.9662\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0883 - accuracy: 0.9462\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0946 - accuracy: 0.9591\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0832 - accuracy: 0.9537\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9582\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1018 - accuracy: 0.9360\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0765 - accuracy: 0.9557\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9472\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1191 - accuracy: 0.9466\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1655 - accuracy: 0.8905\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1491 - accuracy: 0.9127\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1158 - accuracy: 0.9500\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0705 - accuracy: 0.9708\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0667 - accuracy: 0.9741\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1031 - accuracy: 0.9567\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1052 - accuracy: 0.9527\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0897 - accuracy: 0.9631\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1007 - accuracy: 0.9619\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1366 - accuracy: 0.9291\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1309 - accuracy: 0.9403\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.9266\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1400 - accuracy: 0.9226\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1625 - accuracy: 0.9057\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1423 - accuracy: 0.9212\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1348 - accuracy: 0.9351\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1194 - accuracy: 0.9445\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1151 - accuracy: 0.9412\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1143 - accuracy: 0.9465\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9431\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0820 - accuracy: 0.9667\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0832 - accuracy: 0.9624\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1008 - accuracy: 0.9572\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0939 - accuracy: 0.9527\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1337 - accuracy: 0.9292\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1061 - accuracy: 0.9384\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9626\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0777 - accuracy: 0.9679\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0844 - accuracy: 0.9623\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1069 - accuracy: 0.9504\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0912 - accuracy: 0.9592\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0852 - accuracy: 0.9555\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0618 - accuracy: 0.9769\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0777 - accuracy: 0.9629\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1202 - accuracy: 0.9571\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9213\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1327 - accuracy: 0.9394\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9576\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1173 - accuracy: 0.9428\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1621 - accuracy: 0.9217\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9284\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1112 - accuracy: 0.9387\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9348\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0989 - accuracy: 0.9443\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0969 - accuracy: 0.9508\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1166 - accuracy: 0.9412\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1199 - accuracy: 0.9315\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1154 - accuracy: 0.9233\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1043 - accuracy: 0.9538\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0853 - accuracy: 0.9711\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1049 - accuracy: 0.9563\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0875 - accuracy: 0.9661\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0772 - accuracy: 0.9641\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0926 - accuracy: 0.9544\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0895 - accuracy: 0.9552\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0618 - accuracy: 0.9746\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9730\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9661\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0544 - accuracy: 0.9854\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9689\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9739\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9662\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0710 - accuracy: 0.9699\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9707\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0956 - accuracy: 0.9534\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0896 - accuracy: 0.9620\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0866 - accuracy: 0.9616\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0971 - accuracy: 0.9484\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0647 - accuracy: 0.9755\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0678 - accuracy: 0.9693\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0684 - accuracy: 0.9739\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1045 - accuracy: 0.9575\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0585 - accuracy: 0.9859\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0672 - accuracy: 0.9785\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0829 - accuracy: 0.9690\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0683 - accuracy: 0.9731\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0759 - accuracy: 0.9686\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0837 - accuracy: 0.9644\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0948 - accuracy: 0.9527\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0867 - accuracy: 0.9595\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0653 - accuracy: 0.9736\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0955 - accuracy: 0.9536\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0600 - accuracy: 0.9755\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0758 - accuracy: 0.9645\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0707 - accuracy: 0.9648\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0412 - accuracy: 0.9873\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0531 - accuracy: 0.9820\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0655 - accuracy: 0.9726\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0596 - accuracy: 0.9805\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0594 - accuracy: 0.9736\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0569 - accuracy: 0.9807\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1174 - accuracy: 0.9538\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1272 - accuracy: 0.9423\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1198 - accuracy: 0.9488\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1025 - accuracy: 0.9475\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0855 - accuracy: 0.9602\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0862 - accuracy: 0.9556\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0618 - accuracy: 0.9756\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0518 - accuracy: 0.9788\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0461 - accuracy: 0.9860\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0585 - accuracy: 0.9788\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0455 - accuracy: 0.9846\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0712 - accuracy: 0.9749\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0434 - accuracy: 0.9869\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0521 - accuracy: 0.9813\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 952us/step - loss: 0.0536 - accuracy: 0.9828\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 944us/step - loss: 0.5695 - accuracy: 0.8170\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.4261 - accuracy: 0.8634\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.3345 - accuracy: 0.8946\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.3320 - accuracy: 0.8864\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.3422 - accuracy: 0.8804\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3705 - accuracy: 0.8668\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.3134 - accuracy: 0.8808\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.3242 - accuracy: 0.8751\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.3174 - accuracy: 0.8748\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.3123 - accuracy: 0.8680\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.3066 - accuracy: 0.8771\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8682\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.8931\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.2500 - accuracy: 0.8885\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.8924\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.2411 - accuracy: 0.8884\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.2485 - accuracy: 0.8873\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.8979\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1963 - accuracy: 0.9037\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.2270 - accuracy: 0.9036\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.2154 - accuracy: 0.9084\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.2040 - accuracy: 0.9296\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.2003 - accuracy: 0.9232\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1966 - accuracy: 0.9287\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1842 - accuracy: 0.9205\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1950 - accuracy: 0.9271\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1802 - accuracy: 0.9320\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9233\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1686 - accuracy: 0.9311\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1925 - accuracy: 0.9186\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1938 - accuracy: 0.9176\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1578 - accuracy: 0.9309\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1196 - accuracy: 0.9608\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1098 - accuracy: 0.9600\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1348 - accuracy: 0.9460\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1229 - accuracy: 0.9487\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9177\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1552 - accuracy: 0.9383\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1529 - accuracy: 0.9435\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9308\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1238 - accuracy: 0.9605\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1117 - accuracy: 0.9632\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1711 - accuracy: 0.9401\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1437 - accuracy: 0.9343\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9323\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1277 - accuracy: 0.9562\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9413\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9688\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0672 - accuracy: 0.9821\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0737 - accuracy: 0.9754\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1089 - accuracy: 0.9471\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1639 - accuracy: 0.9296\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1528 - accuracy: 0.9267\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1213 - accuracy: 0.9457\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0932 - accuracy: 0.9686\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0849 - accuracy: 0.9708\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0734 - accuracy: 0.9686\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9464\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1243 - accuracy: 0.9421\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9408\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1370 - accuracy: 0.9453\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1102 - accuracy: 0.9523\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9610\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0964 - accuracy: 0.9668\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0615 - accuracy: 0.9834\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0869 - accuracy: 0.9615\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0953 - accuracy: 0.9615\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1539 - accuracy: 0.9386\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0944 - accuracy: 0.9650\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0695 - accuracy: 0.9781\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1030 - accuracy: 0.9630\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0877 - accuracy: 0.9605\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0765 - accuracy: 0.9754\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0813 - accuracy: 0.9725\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0989 - accuracy: 0.9589\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0872 - accuracy: 0.9696\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0604 - accuracy: 0.9824\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0755 - accuracy: 0.9680\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9705\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 943us/step - loss: 0.0586 - accuracy: 0.9820\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0850 - accuracy: 0.9704\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0684 - accuracy: 0.9759\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0586 - accuracy: 0.9691\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0751 - accuracy: 0.9699\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0692 - accuracy: 0.9763\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0899 - accuracy: 0.9667\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1113 - accuracy: 0.9484\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9583\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1011 - accuracy: 0.9574\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9377\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1230 - accuracy: 0.9489\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0915 - accuracy: 0.9631\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1042 - accuracy: 0.9526\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0840 - accuracy: 0.9693\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0943 - accuracy: 0.9615\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0792 - accuracy: 0.9693\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1288 - accuracy: 0.9399\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1181 - accuracy: 0.9490\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0940 - accuracy: 0.9610\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1114 - accuracy: 0.9615\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0776 - accuracy: 0.9695\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0901 - accuracy: 0.9693\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0504 - accuracy: 0.9831\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9763\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0473 - accuracy: 0.9850\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0480 - accuracy: 0.9815\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0642 - accuracy: 0.9781\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1566 - accuracy: 0.9396\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1086 - accuracy: 0.9613\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0591 - accuracy: 0.9786\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0751 - accuracy: 0.9738\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0565 - accuracy: 0.9803\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0959 - accuracy: 0.9514\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9802\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9780\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9788\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0410 - accuracy: 0.9913\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0270 - accuracy: 0.9909\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0385 - accuracy: 0.9892\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9859\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0323 - accuracy: 0.9912\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9836\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0484 - accuracy: 0.9842\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0576 - accuracy: 0.9815\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0707 - accuracy: 0.9760\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9894\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9737\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0310 - accuracy: 0.9932\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9862\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0538 - accuracy: 0.9786\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9800\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9826\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0811 - accuracy: 0.9666\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0828 - accuracy: 0.9670\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1211 - accuracy: 0.9557\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0834 - accuracy: 0.9737\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9722\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0670 - accuracy: 0.9747\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0460 - accuracy: 0.9881\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0606 - accuracy: 0.9767\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0386 - accuracy: 0.9855\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0259 - accuracy: 0.9953\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0513 - accuracy: 0.9808\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0519 - accuracy: 0.9841\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0483 - accuracy: 0.9859\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0431 - accuracy: 0.9884\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0277 - accuracy: 0.9934\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0252 - accuracy: 0.9950\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0609 - accuracy: 0.9793\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0626 - accuracy: 0.9737\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0871 - accuracy: 0.9678\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0763 - accuracy: 0.9687\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0635 - accuracy: 0.9795\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0767 - accuracy: 0.9688\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0862 - accuracy: 0.9615\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0550 - accuracy: 0.9794\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0502 - accuracy: 0.9824\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0440 - accuracy: 0.9885\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0234 - accuracy: 0.9965\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 988us/step - loss: 0.0172 - accuracy: 0.9977\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0472 - accuracy: 0.9853\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9822\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0787 - accuracy: 0.9708\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0409 - accuracy: 0.9885\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0455 - accuracy: 0.9881\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0317 - accuracy: 0.9896\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9878\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9964\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0390 - accuracy: 0.9887\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0493 - accuracy: 0.9831\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0288 - accuracy: 0.9917\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0547 - accuracy: 0.9810\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9843\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9856\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0526 - accuracy: 0.9837\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0556 - accuracy: 0.9822\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0471 - accuracy: 0.9818\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9886\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0330 - accuracy: 0.9888\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0417 - accuracy: 0.9897\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0570 - accuracy: 0.9847\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0370 - accuracy: 0.9889\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9857\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0455 - accuracy: 0.9889\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0424 - accuracy: 0.9853\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0627 - accuracy: 0.9811\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0556 - accuracy: 0.9813\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0903 - accuracy: 0.9668\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0452 - accuracy: 0.9861\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9885\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0319 - accuracy: 0.9900\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9957\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9807\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0512 - accuracy: 0.9828\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0382 - accuracy: 0.9850\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9977\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0283 - accuracy: 0.9931\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0407 - accuracy: 0.9875\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0243 - accuracy: 0.9913\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7a78c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73f9e040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7a595790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 6: 77\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.9601 - accuracy: 0.5357\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.7300 - accuracy: 0.6318\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.6712 - accuracy: 0.6818\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6971\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7144\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.7328\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.7226\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7548\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7482\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.5439 - accuracy: 0.7607\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.4893 - accuracy: 0.7646\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7646\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7651\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4763 - accuracy: 0.7684\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7867\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7642\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8217\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8150\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8004\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8203\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8061\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8202\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.3530 - accuracy: 0.8303\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.3863 - accuracy: 0.8291\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.3753 - accuracy: 0.8255\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3747 - accuracy: 0.8395\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.3101 - accuracy: 0.8656\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.3380 - accuracy: 0.8516\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.3193 - accuracy: 0.8633\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.3207 - accuracy: 0.8709\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.3062 - accuracy: 0.8680\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8665\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.2767 - accuracy: 0.8783\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.2895 - accuracy: 0.8833\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.2746 - accuracy: 0.8877\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.2989 - accuracy: 0.8367\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.3035 - accuracy: 0.8740\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.2426 - accuracy: 0.9038\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.2871 - accuracy: 0.8644\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.3091 - accuracy: 0.8802\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2723 - accuracy: 0.8846\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2417 - accuracy: 0.8884\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.3207 - accuracy: 0.8661\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.2673 - accuracy: 0.8781\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.2632 - accuracy: 0.8793\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.2560 - accuracy: 0.8820\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.2164 - accuracy: 0.8977\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.8888\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.2591 - accuracy: 0.8821\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.2125 - accuracy: 0.8939\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.2406 - accuracy: 0.8868\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2665 - accuracy: 0.8829\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.2175 - accuracy: 0.9058\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.2578 - accuracy: 0.8721\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.2262 - accuracy: 0.8911\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.2099 - accuracy: 0.8916\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1693 - accuracy: 0.9342\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1940 - accuracy: 0.9135\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1796 - accuracy: 0.9167\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1908 - accuracy: 0.8990\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9031\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1851 - accuracy: 0.9180\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9330\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.8892\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.2016 - accuracy: 0.8933\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.2577 - accuracy: 0.8494\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.2724 - accuracy: 0.8617\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1966 - accuracy: 0.8733\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.2122 - accuracy: 0.8846\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1905 - accuracy: 0.9022\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1892 - accuracy: 0.9005\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.2130 - accuracy: 0.9069\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.1551 - accuracy: 0.9319\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 895us/step - loss: 0.1529 - accuracy: 0.9402\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1459 - accuracy: 0.9411\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.2492 - accuracy: 0.8952\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1607 - accuracy: 0.9313\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1974 - accuracy: 0.9049\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1544 - accuracy: 0.9316\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1326 - accuracy: 0.9421\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1720 - accuracy: 0.9216\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.2070 - accuracy: 0.8939\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1446 - accuracy: 0.9420\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1556 - accuracy: 0.9276\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1371 - accuracy: 0.9295\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1073 - accuracy: 0.9474\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1537 - accuracy: 0.9283\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1761 - accuracy: 0.9246\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1453 - accuracy: 0.9312\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1367 - accuracy: 0.9409\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1330 - accuracy: 0.9456\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1227 - accuracy: 0.9536\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1106 - accuracy: 0.9553\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1376 - accuracy: 0.9393\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1468 - accuracy: 0.9334\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1409 - accuracy: 0.9330\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1562 - accuracy: 0.9303\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1306 - accuracy: 0.9445\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1025 - accuracy: 0.9524\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1192 - accuracy: 0.9481\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9691\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1297 - accuracy: 0.9447\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1080 - accuracy: 0.9556\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.1444 - accuracy: 0.9314\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1294 - accuracy: 0.9506\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1666 - accuracy: 0.9388\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1768 - accuracy: 0.9154\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1929 - accuracy: 0.8837\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1365 - accuracy: 0.9302\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1357 - accuracy: 0.9246\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1483 - accuracy: 0.9227\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.2052 - accuracy: 0.8837\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1410 - accuracy: 0.9236\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9093\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1418 - accuracy: 0.9350\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9130\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9296\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9077\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1467 - accuracy: 0.9036\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1347 - accuracy: 0.9198\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1325 - accuracy: 0.9268\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1504 - accuracy: 0.9191\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9226\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1008 - accuracy: 0.9583\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1470 - accuracy: 0.9110\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1058 - accuracy: 0.9544\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1099 - accuracy: 0.9444\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.1811 - accuracy: 0.9031\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1693 - accuracy: 0.9012\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1569 - accuracy: 0.9265\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1608 - accuracy: 0.9118\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1295 - accuracy: 0.9355\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1550 - accuracy: 0.9114\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1059 - accuracy: 0.9484\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1259 - accuracy: 0.9509\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1425 - accuracy: 0.9286\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0875 - accuracy: 0.9603\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1328 - accuracy: 0.9319\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1207 - accuracy: 0.9409\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1358 - accuracy: 0.9312\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1064 - accuracy: 0.9487\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1219 - accuracy: 0.9386\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1324 - accuracy: 0.9417\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1541 - accuracy: 0.9107\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.9436\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1300 - accuracy: 0.9252\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1050 - accuracy: 0.9474\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1573 - accuracy: 0.9271\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1807 - accuracy: 0.9107\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1519 - accuracy: 0.9229\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0965 - accuracy: 0.9637\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1059 - accuracy: 0.9399\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0927 - accuracy: 0.9558\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 946us/step - loss: 0.0834 - accuracy: 0.9645\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1265 - accuracy: 0.9364\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9543\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0890 - accuracy: 0.9526\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1309 - accuracy: 0.9291\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1119 - accuracy: 0.9492\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1336 - accuracy: 0.9193\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1159 - accuracy: 0.9336\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1180 - accuracy: 0.9482\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1527 - accuracy: 0.9190\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1580 - accuracy: 0.9171\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1523 - accuracy: 0.8973\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1440 - accuracy: 0.9219\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1236 - accuracy: 0.9316\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9291\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1283 - accuracy: 0.9299\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1682 - accuracy: 0.9027\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1323 - accuracy: 0.9259\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1062 - accuracy: 0.9455\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1013 - accuracy: 0.9470\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9231\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1357 - accuracy: 0.9242\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1277 - accuracy: 0.9312\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1289 - accuracy: 0.9377\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1462 - accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1199 - accuracy: 0.9466\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9506\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1333 - accuracy: 0.9214\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1378 - accuracy: 0.9215\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9431\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1208 - accuracy: 0.9394\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1256 - accuracy: 0.9241\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1463 - accuracy: 0.9329\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1574 - accuracy: 0.9050\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1494 - accuracy: 0.9107\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1225 - accuracy: 0.9263\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1201 - accuracy: 0.9235\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1268 - accuracy: 0.9148\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1551 - accuracy: 0.9108\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1348 - accuracy: 0.9106\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1031 - accuracy: 0.9462\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1107 - accuracy: 0.9218\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9383\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1329 - accuracy: 0.9320\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1479 - accuracy: 0.9037\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9268\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9018\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.6995 - accuracy: 0.7971\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.4901 - accuracy: 0.8196\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8113\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.4435 - accuracy: 0.8301\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.4041 - accuracy: 0.8250\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.3837 - accuracy: 0.8477\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.3798 - accuracy: 0.8317\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.3812 - accuracy: 0.8281\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8481\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.3344 - accuracy: 0.8539\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.2855 - accuracy: 0.8734\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.2951 - accuracy: 0.8511\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.2914 - accuracy: 0.8628\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.2962 - accuracy: 0.8685\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.2940 - accuracy: 0.8614\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2944 - accuracy: 0.8593\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.3008 - accuracy: 0.8391\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2444 - accuracy: 0.8750\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.8985\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.2562 - accuracy: 0.8784\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.2236 - accuracy: 0.8987\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.2180 - accuracy: 0.9070\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.2417 - accuracy: 0.8977\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2161 - accuracy: 0.9080\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2287 - accuracy: 0.8932\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9074\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.2173 - accuracy: 0.9020\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1676 - accuracy: 0.9266\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2081 - accuracy: 0.9002\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1823 - accuracy: 0.9225\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.9075\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2110 - accuracy: 0.9026\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1474 - accuracy: 0.9283\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 972us/step - loss: 0.2070 - accuracy: 0.9201\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1486 - accuracy: 0.9303\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9145\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1493 - accuracy: 0.9286\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1761 - accuracy: 0.9194\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1607 - accuracy: 0.9272\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1252 - accuracy: 0.9493\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1371 - accuracy: 0.9362\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1279 - accuracy: 0.9445\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1492 - accuracy: 0.9315\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9596\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1548 - accuracy: 0.9410\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1696 - accuracy: 0.9107\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1958 - accuracy: 0.9047\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1466 - accuracy: 0.9474\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9372\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1122 - accuracy: 0.9595\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1091 - accuracy: 0.9498\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1142 - accuracy: 0.9438\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1065 - accuracy: 0.9637\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0930 - accuracy: 0.9617\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0952 - accuracy: 0.9603\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0985 - accuracy: 0.9580\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9659\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9613\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0939 - accuracy: 0.9684\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1485 - accuracy: 0.9217\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1787 - accuracy: 0.9065\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1426 - accuracy: 0.9400\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1222 - accuracy: 0.9412\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1152 - accuracy: 0.9488\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1251 - accuracy: 0.9438\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0999 - accuracy: 0.9589\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1482 - accuracy: 0.9401\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0829 - accuracy: 0.9632\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0786 - accuracy: 0.9650\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0871 - accuracy: 0.9624\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9477\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0808 - accuracy: 0.9684\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0647 - accuracy: 0.9714\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0937 - accuracy: 0.9604\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0501 - accuracy: 0.9826\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0889 - accuracy: 0.9607\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1377 - accuracy: 0.9343\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0750 - accuracy: 0.9580\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0645 - accuracy: 0.9721\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0606 - accuracy: 0.9766\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0854 - accuracy: 0.9656\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0722 - accuracy: 0.9735\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0941 - accuracy: 0.9547\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0977 - accuracy: 0.9602\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0707 - accuracy: 0.9753\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0910 - accuracy: 0.9577\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.1013 - accuracy: 0.9603\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0889 - accuracy: 0.9705\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0833 - accuracy: 0.9649\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9646\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9505\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0807 - accuracy: 0.9634\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9777\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0655 - accuracy: 0.9792\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0526 - accuracy: 0.9793\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0516 - accuracy: 0.9809\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0781 - accuracy: 0.9671\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0751 - accuracy: 0.9649\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0704 - accuracy: 0.9689\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0540 - accuracy: 0.9764\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0449 - accuracy: 0.9849\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0509 - accuracy: 0.9794\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0451 - accuracy: 0.9849\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0960 - accuracy: 0.9611\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1050 - accuracy: 0.9565\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0706 - accuracy: 0.9732\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0482 - accuracy: 0.9895\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0813 - accuracy: 0.9730\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0833 - accuracy: 0.9604\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1599 - accuracy: 0.9407\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0644 - accuracy: 0.9832\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0758 - accuracy: 0.9699\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0715 - accuracy: 0.9735\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 914us/step - loss: 0.0575 - accuracy: 0.9761\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0732 - accuracy: 0.9695\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0448 - accuracy: 0.9819\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0942 - accuracy: 0.9641\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0724 - accuracy: 0.9676\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0697 - accuracy: 0.9729\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0558 - accuracy: 0.9818\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0330 - accuracy: 0.9907\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0501 - accuracy: 0.9790\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0637 - accuracy: 0.9770\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0837 - accuracy: 0.9682\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0536 - accuracy: 0.9843\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9671\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0701 - accuracy: 0.9690\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0809 - accuracy: 0.9699\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1049 - accuracy: 0.9506\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0787 - accuracy: 0.9725\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0490 - accuracy: 0.9900\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0600 - accuracy: 0.9775\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0495 - accuracy: 0.9791\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0927 - accuracy: 0.9671\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0595 - accuracy: 0.9806\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0743 - accuracy: 0.9710\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0458 - accuracy: 0.9836\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9752\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0656 - accuracy: 0.9758\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0512 - accuracy: 0.9820\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0678 - accuracy: 0.9706\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0970 - accuracy: 0.9524\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9398\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1003 - accuracy: 0.9426\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1036 - accuracy: 0.9467\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1297 - accuracy: 0.9403\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0949 - accuracy: 0.9481\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0982 - accuracy: 0.9310\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0888 - accuracy: 0.9497\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0841 - accuracy: 0.9532\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0990 - accuracy: 0.9478\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9761\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9681\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9608\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9379\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0810 - accuracy: 0.9648\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0879 - accuracy: 0.9687\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0835 - accuracy: 0.9703\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0519 - accuracy: 0.9804\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0789 - accuracy: 0.9641\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0805 - accuracy: 0.9680\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0584 - accuracy: 0.9801\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0649 - accuracy: 0.9810\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0602 - accuracy: 0.9776\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0740 - accuracy: 0.9668\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0357 - accuracy: 0.9907\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0487 - accuracy: 0.9804\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0733 - accuracy: 0.9739\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0486 - accuracy: 0.9815\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0345 - accuracy: 0.9917\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0734 - accuracy: 0.9702\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0800 - accuracy: 0.9653\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0764 - accuracy: 0.9651\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0520 - accuracy: 0.9796\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1606 - accuracy: 0.9353\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0627 - accuracy: 0.9775\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0564 - accuracy: 0.9824\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0506 - accuracy: 0.9804\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0404 - accuracy: 0.9913\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0355 - accuracy: 0.9885\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9901\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0335 - accuracy: 0.9912\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0382 - accuracy: 0.9892\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0603 - accuracy: 0.9747\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9687\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0324 - accuracy: 0.9892\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0385 - accuracy: 0.9880\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0529 - accuracy: 0.9793\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0913 - accuracy: 0.9531\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0623 - accuracy: 0.9790\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0518 - accuracy: 0.9815\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0399 - accuracy: 0.9805\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 885us/step - loss: 0.0429 - accuracy: 0.9833\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0493 - accuracy: 0.9802\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0474 - accuracy: 0.9828\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1532 - accuracy: 0.9460\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0953 - accuracy: 0.9619\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0462 - accuracy: 0.9822\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9709\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0462 - accuracy: 0.9813\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.7314 - accuracy: 0.6950\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8562\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8902\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8916\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.3334 - accuracy: 0.8950\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.3593 - accuracy: 0.8766\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.3448 - accuracy: 0.8721\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.3257 - accuracy: 0.8864\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.3206 - accuracy: 0.8868\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.3186 - accuracy: 0.8781\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8790\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2922 - accuracy: 0.8899\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.2656 - accuracy: 0.8950\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.2897 - accuracy: 0.8973\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.2728 - accuracy: 0.8955\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.2703 - accuracy: 0.8802\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2824 - accuracy: 0.8863\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2211 - accuracy: 0.9075\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.2493 - accuracy: 0.8865\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2594 - accuracy: 0.8853\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.2169 - accuracy: 0.9238\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.2231 - accuracy: 0.9072\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.2194 - accuracy: 0.9119\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.2196 - accuracy: 0.9192\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1932 - accuracy: 0.9208\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.2025 - accuracy: 0.9122\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1909 - accuracy: 0.9238\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1992 - accuracy: 0.9269\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1686 - accuracy: 0.9310\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1893 - accuracy: 0.9330\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.2028 - accuracy: 0.9192\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9391\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1650 - accuracy: 0.9429\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9292\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1742 - accuracy: 0.9479\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1376 - accuracy: 0.9449\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9525\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9542\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9428\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1368 - accuracy: 0.9310\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0916 - accuracy: 0.9679\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1505 - accuracy: 0.9434\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1190 - accuracy: 0.9508\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1320 - accuracy: 0.9457\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1312 - accuracy: 0.9375\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1523 - accuracy: 0.9250\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1550 - accuracy: 0.9418\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1267 - accuracy: 0.9450\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1040 - accuracy: 0.9601\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1068 - accuracy: 0.9625\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9599\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0931 - accuracy: 0.9633\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0836 - accuracy: 0.9751\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0901 - accuracy: 0.9715\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0653 - accuracy: 0.9763\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0722 - accuracy: 0.9671\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1069 - accuracy: 0.9588\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0901 - accuracy: 0.9741\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9625\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9645\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0659 - accuracy: 0.9737\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0735 - accuracy: 0.9735\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9570\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0921 - accuracy: 0.9694\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0793 - accuracy: 0.9701\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0982 - accuracy: 0.9586\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0961 - accuracy: 0.9587\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9680\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0524 - accuracy: 0.9807\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0883 - accuracy: 0.9652\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9804\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9809\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9799\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9805\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9776\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9649\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9520\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9024\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9492\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9168\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9339\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9528\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1396 - accuracy: 0.9405\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.9329\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9480\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9629\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9768\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9710\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9703\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0803 - accuracy: 0.9705\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0575 - accuracy: 0.9701\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0794 - accuracy: 0.9575\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0824 - accuracy: 0.9575\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0788 - accuracy: 0.9688\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0571 - accuracy: 0.9755\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0858 - accuracy: 0.9636\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0929 - accuracy: 0.9518\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0764 - accuracy: 0.9691\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0512 - accuracy: 0.9837\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0734 - accuracy: 0.9678\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1119 - accuracy: 0.9576\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0790 - accuracy: 0.9666\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0693 - accuracy: 0.9648\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0583 - accuracy: 0.9739\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0669 - accuracy: 0.9689\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0675 - accuracy: 0.9701\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0519 - accuracy: 0.9772\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0710 - accuracy: 0.9641\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0550 - accuracy: 0.9818\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0501 - accuracy: 0.9824\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0716 - accuracy: 0.9655\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0478 - accuracy: 0.9805\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0479 - accuracy: 0.9780\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0563 - accuracy: 0.9748\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0479 - accuracy: 0.9838\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0616 - accuracy: 0.9790\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9693\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0670 - accuracy: 0.9723\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9764\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0506 - accuracy: 0.9802\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0580 - accuracy: 0.9737\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0627 - accuracy: 0.9738\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0589 - accuracy: 0.9774\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0394 - accuracy: 0.9848\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0688 - accuracy: 0.9742\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0441 - accuracy: 0.9856\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0348 - accuracy: 0.9871\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0540 - accuracy: 0.9774\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0440 - accuracy: 0.9830\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0310 - accuracy: 0.9960\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0371 - accuracy: 0.9848\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0661 - accuracy: 0.9714\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1200 - accuracy: 0.9611\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0597 - accuracy: 0.9773\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0326 - accuracy: 0.9924\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0449 - accuracy: 0.9866\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0336 - accuracy: 0.9873\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0367 - accuracy: 0.9842\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0309 - accuracy: 0.9844\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0721 - accuracy: 0.9675\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0586 - accuracy: 0.9810\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0670 - accuracy: 0.9778\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0858 - accuracy: 0.9671\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0622 - accuracy: 0.9735\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0345 - accuracy: 0.9945\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0352 - accuracy: 0.9894\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0440 - accuracy: 0.9904\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0207 - accuracy: 0.9956\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0661 - accuracy: 0.9773\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0645 - accuracy: 0.9780\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0918 - accuracy: 0.9667\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0539 - accuracy: 0.9812\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 902us/step - loss: 0.0927 - accuracy: 0.9651\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0597 - accuracy: 0.9755\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0677 - accuracy: 0.9737\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0302 - accuracy: 0.9903\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0337 - accuracy: 0.9876\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0698 - accuracy: 0.9734\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0423 - accuracy: 0.9835\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0469 - accuracy: 0.9852\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0508 - accuracy: 0.9843\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0275 - accuracy: 0.9931\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0516 - accuracy: 0.9822\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0637 - accuracy: 0.9763\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1053 - accuracy: 0.9544\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0509 - accuracy: 0.9821\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0288 - accuracy: 0.9913\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0246 - accuracy: 0.9912\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0525 - accuracy: 0.9777\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0245 - accuracy: 0.9916\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0397 - accuracy: 0.9858\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9846\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9867\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9759\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9774\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9960\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0608 - accuracy: 0.9795\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0575 - accuracy: 0.9797\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0277 - accuracy: 0.9895\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0339 - accuracy: 0.9892\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0275 - accuracy: 0.9921\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0534 - accuracy: 0.9776\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0327 - accuracy: 0.9893\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0256 - accuracy: 0.9898\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0315 - accuracy: 0.9893\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0261 - accuracy: 0.9876\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0355 - accuracy: 0.9895\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0331 - accuracy: 0.9881\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0430 - accuracy: 0.9853\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0290 - accuracy: 0.9887\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0321 - accuracy: 0.9894\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0206 - accuracy: 0.9952\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0244 - accuracy: 0.9934\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0301 - accuracy: 0.9896\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0626 - accuracy: 0.9827\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0628 - accuracy: 0.9733\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0909 - accuracy: 0.9643\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0548 - accuracy: 0.9743\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0297 - accuracy: 0.9930\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0823 - accuracy: 0.9564\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75135ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c739d4940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c739d4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 7: 78\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8586 - accuracy: 0.6478\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.7127 - accuracy: 0.6609\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.7225\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.5612 - accuracy: 0.7227\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.5838 - accuracy: 0.6840\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.5655 - accuracy: 0.7289\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.4923 - accuracy: 0.7819\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.5296 - accuracy: 0.7439\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.5027 - accuracy: 0.7390\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.4626 - accuracy: 0.7504\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.4955 - accuracy: 0.7836\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.4964 - accuracy: 0.7756\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.4255 - accuracy: 0.7998\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.4305 - accuracy: 0.7973\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.4511 - accuracy: 0.7832\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.4141 - accuracy: 0.8069\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.4235 - accuracy: 0.8277\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.4100 - accuracy: 0.8171\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.4467 - accuracy: 0.7926\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.3990 - accuracy: 0.8147\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.3770 - accuracy: 0.8371\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8319\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.3863 - accuracy: 0.8254\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.3762 - accuracy: 0.8347\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.3872 - accuracy: 0.8377\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.3583 - accuracy: 0.8345\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 0.8405\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.2995 - accuracy: 0.8815\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.2982 - accuracy: 0.8853\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.2907 - accuracy: 0.8735\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8247\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.3080 - accuracy: 0.8576\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.2923 - accuracy: 0.8903\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.3082 - accuracy: 0.8588\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.3205 - accuracy: 0.8662\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.2636 - accuracy: 0.8949\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.2632 - accuracy: 0.8874\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.2637 - accuracy: 0.8824\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2750 - accuracy: 0.8735\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.8911\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9139\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.2559 - accuracy: 0.8634\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.9052\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2566 - accuracy: 0.8823\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.8825\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.2367 - accuracy: 0.9072\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2179 - accuracy: 0.9025\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.2210 - accuracy: 0.9092\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.2587 - accuracy: 0.8667\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.2842 - accuracy: 0.8605\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.2103 - accuracy: 0.9057\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.2454 - accuracy: 0.8925\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8977\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9106\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2134 - accuracy: 0.9041\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.2391 - accuracy: 0.8738\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9018\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.2570 - accuracy: 0.8931\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.2415 - accuracy: 0.8885\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.2321 - accuracy: 0.9116\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.2078 - accuracy: 0.9093\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2108 - accuracy: 0.9057\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1835 - accuracy: 0.9280\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2007 - accuracy: 0.9086\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1715 - accuracy: 0.9175\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1914 - accuracy: 0.9088\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1798 - accuracy: 0.9158\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1570 - accuracy: 0.9304\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1498 - accuracy: 0.9300\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.8734\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.8834\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.2154 - accuracy: 0.9108\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2109 - accuracy: 0.9197\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 935us/step - loss: 0.2032 - accuracy: 0.9118\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1973 - accuracy: 0.9186\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1632 - accuracy: 0.9243\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1621 - accuracy: 0.9274\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1908 - accuracy: 0.9034\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.2229 - accuracy: 0.9016\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1514 - accuracy: 0.9347\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1534 - accuracy: 0.9296\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1757 - accuracy: 0.9098\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.2392 - accuracy: 0.8895\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.2278 - accuracy: 0.9142\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.2131 - accuracy: 0.9161\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.2648 - accuracy: 0.8873\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1859 - accuracy: 0.9264\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1526 - accuracy: 0.9382\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9109\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1768 - accuracy: 0.9195\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.2426 - accuracy: 0.9139\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.2214 - accuracy: 0.9074\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.2012 - accuracy: 0.9076\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1551 - accuracy: 0.9425\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.9174\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1625 - accuracy: 0.9335\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1588 - accuracy: 0.9394\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1864 - accuracy: 0.9291\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1491 - accuracy: 0.9407\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1654 - accuracy: 0.9381\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1624 - accuracy: 0.9132\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1786 - accuracy: 0.9217\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1545 - accuracy: 0.9311\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1765 - accuracy: 0.9221\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1570 - accuracy: 0.9331\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1382 - accuracy: 0.9369\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.2152 - accuracy: 0.9237\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9131\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.2496 - accuracy: 0.8835\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1694 - accuracy: 0.9250\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1708 - accuracy: 0.9276\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1854 - accuracy: 0.9205\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.9041\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.9242\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.2212 - accuracy: 0.9028\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1763 - accuracy: 0.9378\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1556 - accuracy: 0.9479\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1697 - accuracy: 0.9330\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1524 - accuracy: 0.9375\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9105\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9118\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1739 - accuracy: 0.9250\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.2356 - accuracy: 0.8958\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1459 - accuracy: 0.9392\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1651 - accuracy: 0.9294\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1981 - accuracy: 0.9199\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1737 - accuracy: 0.9207\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1542 - accuracy: 0.9277\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9398\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1405 - accuracy: 0.9390\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1494 - accuracy: 0.9110\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1201 - accuracy: 0.9459\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1123 - accuracy: 0.9496\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1532 - accuracy: 0.9330\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.1660 - accuracy: 0.9277\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1589 - accuracy: 0.9318\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1211 - accuracy: 0.9327\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1309 - accuracy: 0.9401\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1383 - accuracy: 0.9248\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1411 - accuracy: 0.9312\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1570 - accuracy: 0.9160\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1263 - accuracy: 0.9298\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1590 - accuracy: 0.9170\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1357 - accuracy: 0.9389\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1820 - accuracy: 0.9155\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9380\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1203 - accuracy: 0.9348\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.1341 - accuracy: 0.9438\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1232 - accuracy: 0.9449\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1354 - accuracy: 0.9399\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1285 - accuracy: 0.9458\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1391 - accuracy: 0.9394\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1518 - accuracy: 0.9378\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 869us/step - loss: 0.1424 - accuracy: 0.9324\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1467 - accuracy: 0.9403\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2228 - accuracy: 0.9098\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1581 - accuracy: 0.9344\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1289 - accuracy: 0.9411\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1306 - accuracy: 0.9451\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9242\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1736 - accuracy: 0.9147\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1244 - accuracy: 0.9414\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1499 - accuracy: 0.9379\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1474 - accuracy: 0.9345\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1305 - accuracy: 0.9368\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1432 - accuracy: 0.9353\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1599 - accuracy: 0.9393\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1285 - accuracy: 0.9456\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1316 - accuracy: 0.9474\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1256 - accuracy: 0.9319\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1589 - accuracy: 0.9232\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1345 - accuracy: 0.9538\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1232 - accuracy: 0.9476\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1304 - accuracy: 0.9392\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1252 - accuracy: 0.9502\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1407 - accuracy: 0.9313\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1537 - accuracy: 0.9277\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1751 - accuracy: 0.9117\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1656 - accuracy: 0.9120\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1551 - accuracy: 0.9322\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1412 - accuracy: 0.9347\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1687 - accuracy: 0.9131\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1593 - accuracy: 0.9335\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1268 - accuracy: 0.9433\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1256 - accuracy: 0.9433\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.1420 - accuracy: 0.9332\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1369 - accuracy: 0.9344\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1247 - accuracy: 0.9420\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1266 - accuracy: 0.9275\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1318 - accuracy: 0.9301\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1034 - accuracy: 0.9486\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1288 - accuracy: 0.9421\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1338 - accuracy: 0.9244\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1093 - accuracy: 0.9478\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1167 - accuracy: 0.9473\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1344 - accuracy: 0.9185\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0980 - accuracy: 0.9440\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1490 - accuracy: 0.9305\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1335 - accuracy: 0.9401\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1021 - accuracy: 0.9366\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.6754 - accuracy: 0.8241\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.4559 - accuracy: 0.8481\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8276\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.4053 - accuracy: 0.8444\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8509\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.3920 - accuracy: 0.8399\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.3397 - accuracy: 0.8636\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.3422 - accuracy: 0.8432\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.3336 - accuracy: 0.8493\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.3301 - accuracy: 0.8471\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.3408 - accuracy: 0.8487\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.3132 - accuracy: 0.8500\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.8701\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.3177 - accuracy: 0.8594\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2835 - accuracy: 0.8606\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.3084 - accuracy: 0.8546\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.2609 - accuracy: 0.8698\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.2327 - accuracy: 0.8880\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.2345 - accuracy: 0.8878\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.2456 - accuracy: 0.8963\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.2250 - accuracy: 0.8925\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.2174 - accuracy: 0.8920\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.2183 - accuracy: 0.8933\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.9103\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.2581 - accuracy: 0.8867\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9069\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.2137 - accuracy: 0.9041\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2209 - accuracy: 0.8939\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2397 - accuracy: 0.8977\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9093\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1662 - accuracy: 0.9286\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1810 - accuracy: 0.9090\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.2009 - accuracy: 0.9113\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 923us/step - loss: 0.1844 - accuracy: 0.9285\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1681 - accuracy: 0.9249\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9422\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1427 - accuracy: 0.9434\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1596 - accuracy: 0.9366\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1592 - accuracy: 0.9363\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1151 - accuracy: 0.9520\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1405 - accuracy: 0.9354\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.2342 - accuracy: 0.8921\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1695 - accuracy: 0.9165\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1665 - accuracy: 0.9080\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1436 - accuracy: 0.9385\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1218 - accuracy: 0.9524\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1482 - accuracy: 0.9373\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0925 - accuracy: 0.9616\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0929 - accuracy: 0.9707\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1288 - accuracy: 0.9438\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1266 - accuracy: 0.9497\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1386 - accuracy: 0.9470\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1265 - accuracy: 0.9403\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1166 - accuracy: 0.9584\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.1160 - accuracy: 0.9432\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0967 - accuracy: 0.9710\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0957 - accuracy: 0.9664\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.1100 - accuracy: 0.9550\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0734 - accuracy: 0.9776\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.1981 - accuracy: 0.9419\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1098 - accuracy: 0.9650\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0878 - accuracy: 0.9673\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.1192 - accuracy: 0.9530\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.1116 - accuracy: 0.9480\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0942 - accuracy: 0.9573\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1012 - accuracy: 0.9624\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0771 - accuracy: 0.9739\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0917 - accuracy: 0.9626\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.0805 - accuracy: 0.9690\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.0745 - accuracy: 0.9790\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0824 - accuracy: 0.9689\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0784 - accuracy: 0.9736\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0835 - accuracy: 0.9641\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0869 - accuracy: 0.9703\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0816 - accuracy: 0.9665\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1074 - accuracy: 0.9597\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0784 - accuracy: 0.9692\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0741 - accuracy: 0.9717\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0703 - accuracy: 0.9721\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0465 - accuracy: 0.9841\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0707 - accuracy: 0.9683\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0699 - accuracy: 0.9750\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0524 - accuracy: 0.9806\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0610 - accuracy: 0.9779\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0637 - accuracy: 0.9725\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.1119 - accuracy: 0.9534\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0853 - accuracy: 0.9595\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0568 - accuracy: 0.9861\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0564 - accuracy: 0.9765\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0528 - accuracy: 0.9848\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0823 - accuracy: 0.9666\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0892 - accuracy: 0.9684\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.0684 - accuracy: 0.9759\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0472 - accuracy: 0.9857\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0577 - accuracy: 0.9789\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0796 - accuracy: 0.9691\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0545 - accuracy: 0.9827\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0574 - accuracy: 0.9754\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0620 - accuracy: 0.9733\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0528 - accuracy: 0.9865\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0470 - accuracy: 0.9809\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0542 - accuracy: 0.9824\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.1038 - accuracy: 0.9544\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0606 - accuracy: 0.9763\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0560 - accuracy: 0.9776\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0589 - accuracy: 0.9767\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0557 - accuracy: 0.9799\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0605 - accuracy: 0.9760\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0748 - accuracy: 0.9714\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0629 - accuracy: 0.9785\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0752 - accuracy: 0.9674\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.0563 - accuracy: 0.9773\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0638 - accuracy: 0.9751\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 731us/step - loss: 0.0476 - accuracy: 0.9813\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0478 - accuracy: 0.9816\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0523 - accuracy: 0.9816\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0838 - accuracy: 0.9693\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0724 - accuracy: 0.9702\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0539 - accuracy: 0.9808\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0464 - accuracy: 0.9849\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0314 - accuracy: 0.9913\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0608 - accuracy: 0.9815\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0475 - accuracy: 0.9868\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0392 - accuracy: 0.9895\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0505 - accuracy: 0.9843\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0377 - accuracy: 0.9873\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0748 - accuracy: 0.9725\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0856 - accuracy: 0.9646\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0861 - accuracy: 0.9641\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0639 - accuracy: 0.9765\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0480 - accuracy: 0.9858\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0463 - accuracy: 0.9857\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.0578 - accuracy: 0.9808\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0379 - accuracy: 0.9869\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0320 - accuracy: 0.9932\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0665 - accuracy: 0.9789\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0269 - accuracy: 0.9924\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0812 - accuracy: 0.9782\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.0358 - accuracy: 0.9884\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0381 - accuracy: 0.9883\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0856 - accuracy: 0.9699\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0729 - accuracy: 0.9829\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0287 - accuracy: 0.9922\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0439 - accuracy: 0.9868\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.0360 - accuracy: 0.9894\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0433 - accuracy: 0.9841\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9877\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9839\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0439 - accuracy: 0.9843\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0598 - accuracy: 0.9782\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9744\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9883\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9911\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9891\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9931\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9848\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9765\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0384 - accuracy: 0.9858\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9898\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9930\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9863\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0363 - accuracy: 0.9828\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9853\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0426 - accuracy: 0.9886\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9881\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0619 - accuracy: 0.9807\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9801\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0313 - accuracy: 0.9941\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9921\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0583 - accuracy: 0.9750\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0479 - accuracy: 0.9819\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0463 - accuracy: 0.9865\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0398 - accuracy: 0.9906\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0334 - accuracy: 0.9915\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0297 - accuracy: 0.9918\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0782 - accuracy: 0.9775\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0311 - accuracy: 0.9929\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0232 - accuracy: 0.9929\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0257 - accuracy: 0.9943\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0806 - accuracy: 0.9683\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9706\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9713\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0248 - accuracy: 0.9938\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0564 - accuracy: 0.9789\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0303 - accuracy: 0.9871\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0405 - accuracy: 0.9862\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0453 - accuracy: 0.9875\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0228 - accuracy: 0.9954\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0190 - accuracy: 0.9963\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0166 - accuracy: 0.9966\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0406 - accuracy: 0.9878\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9847\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0605 - accuracy: 0.9778\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 984us/step - loss: 0.0405 - accuracy: 0.9850\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9817\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0429 - accuracy: 0.9884\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0738 - accuracy: 0.9686\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0654 - accuracy: 0.9732\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1005 - accuracy: 0.9603\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0601 - accuracy: 0.9781\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7824 - accuracy: 0.6918\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.8580\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8674\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.3723 - accuracy: 0.8848\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.3665 - accuracy: 0.8747\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.3300 - accuracy: 0.8948\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.3494 - accuracy: 0.8781\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.3278 - accuracy: 0.8822\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.3152 - accuracy: 0.8803\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.3097 - accuracy: 0.8801\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.3169 - accuracy: 0.8756\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.3051 - accuracy: 0.8721\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.2610 - accuracy: 0.8969\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3038 - accuracy: 0.8776\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.2964 - accuracy: 0.8623\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.2921 - accuracy: 0.8572\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.2405 - accuracy: 0.8885\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.2455 - accuracy: 0.8854\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.2438 - accuracy: 0.8926\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.2141 - accuracy: 0.9037\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.2235 - accuracy: 0.9134\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.2110 - accuracy: 0.9091\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.2116 - accuracy: 0.9136\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2245 - accuracy: 0.9166\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9110\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1943 - accuracy: 0.9164\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1547 - accuracy: 0.9398\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1608 - accuracy: 0.9242\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9311\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1692 - accuracy: 0.9250\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1451 - accuracy: 0.9368\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1673 - accuracy: 0.9295\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1152 - accuracy: 0.9605\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1336 - accuracy: 0.9435\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1553 - accuracy: 0.9303\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1455 - accuracy: 0.9396\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9292\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1637 - accuracy: 0.9325\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9389\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9458\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1148 - accuracy: 0.9511\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9282\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.9278\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.9167\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1517 - accuracy: 0.9317\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9496\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1092 - accuracy: 0.9617\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0983 - accuracy: 0.9598\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0868 - accuracy: 0.9628\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1054 - accuracy: 0.9595\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9529\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9562\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1404 - accuracy: 0.9361\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9472\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1106 - accuracy: 0.9599\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1018 - accuracy: 0.9590\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1036 - accuracy: 0.9520\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0845 - accuracy: 0.9648\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0657 - accuracy: 0.9751\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1213 - accuracy: 0.9499\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0953 - accuracy: 0.9562\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0871 - accuracy: 0.9660\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0876 - accuracy: 0.9679\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0870 - accuracy: 0.9655\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0660 - accuracy: 0.9679\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0665 - accuracy: 0.9743\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0847 - accuracy: 0.9701\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0895 - accuracy: 0.9593\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9505\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9567\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9578\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0626 - accuracy: 0.9724\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0877 - accuracy: 0.9552\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9445\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1160 - accuracy: 0.9394\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9535\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1046 - accuracy: 0.9510\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1400 - accuracy: 0.9347\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0973 - accuracy: 0.9447\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0952 - accuracy: 0.9536\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1195 - accuracy: 0.9387\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0855 - accuracy: 0.9553\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9363\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0729 - accuracy: 0.9685\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0810 - accuracy: 0.9693\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0630 - accuracy: 0.9707\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0696 - accuracy: 0.9666\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0726 - accuracy: 0.9656\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1148 - accuracy: 0.9495\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0962 - accuracy: 0.9532\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0864 - accuracy: 0.9700\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1107 - accuracy: 0.9599\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1196 - accuracy: 0.9398\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1010 - accuracy: 0.9475\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1350 - accuracy: 0.9342\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1012 - accuracy: 0.9406\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0925 - accuracy: 0.9647\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0929 - accuracy: 0.9547\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0905 - accuracy: 0.9602\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0921 - accuracy: 0.9637\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9761\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9747\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9780\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9753\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0916 - accuracy: 0.9736\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0704 - accuracy: 0.9722\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1018 - accuracy: 0.9560\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0912 - accuracy: 0.9589\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9693\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1289 - accuracy: 0.9360\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0655 - accuracy: 0.9777\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0544 - accuracy: 0.9740\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9481\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9653\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9804\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0505 - accuracy: 0.9811\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0432 - accuracy: 0.9840\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0495 - accuracy: 0.9763\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0685 - accuracy: 0.9687\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0791 - accuracy: 0.9735\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0742 - accuracy: 0.9706\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0570 - accuracy: 0.9776\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0461 - accuracy: 0.9840\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0574 - accuracy: 0.9739\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0308 - accuracy: 0.9896\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0453 - accuracy: 0.9857\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0573 - accuracy: 0.9763\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0389 - accuracy: 0.9892\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0612 - accuracy: 0.9735\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0708 - accuracy: 0.9688\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0661 - accuracy: 0.9681\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0666 - accuracy: 0.9708\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0440 - accuracy: 0.9833\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0592 - accuracy: 0.9783\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0483 - accuracy: 0.9831\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0438 - accuracy: 0.9843\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0588 - accuracy: 0.9776\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0642 - accuracy: 0.9750\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0392 - accuracy: 0.9883\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0259 - accuracy: 0.9943\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0325 - accuracy: 0.9900\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0594 - accuracy: 0.9801\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0413 - accuracy: 0.9843\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9791\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0685 - accuracy: 0.9713\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9471\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9840\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0692 - accuracy: 0.9779\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0642 - accuracy: 0.9773\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0665 - accuracy: 0.9788\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0543 - accuracy: 0.9768\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0715 - accuracy: 0.9664\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0615 - accuracy: 0.9802\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 884us/step - loss: 0.0878 - accuracy: 0.9601\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0896 - accuracy: 0.9546\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0547 - accuracy: 0.9774\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1099 - accuracy: 0.9546\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0689 - accuracy: 0.9639\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0660 - accuracy: 0.9684\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0778 - accuracy: 0.9618\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0470 - accuracy: 0.9820\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0479 - accuracy: 0.9728\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0556 - accuracy: 0.9710\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0483 - accuracy: 0.9747\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0507 - accuracy: 0.9828\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0742 - accuracy: 0.9738\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0741 - accuracy: 0.9652\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0372 - accuracy: 0.9825\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0381 - accuracy: 0.9873\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0616 - accuracy: 0.9708\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0332 - accuracy: 0.9864\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0476 - accuracy: 0.9849\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0360 - accuracy: 0.9854\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0432 - accuracy: 0.9861\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0501 - accuracy: 0.9820\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0376 - accuracy: 0.9855\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0435 - accuracy: 0.9821\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0412 - accuracy: 0.9808\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0333 - accuracy: 0.9855\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0462 - accuracy: 0.9731\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0270 - accuracy: 0.9882\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0475 - accuracy: 0.9846\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0391 - accuracy: 0.9916\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9899\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0516 - accuracy: 0.9774\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0472 - accuracy: 0.9798\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0349 - accuracy: 0.9893\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0387 - accuracy: 0.9868\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0322 - accuracy: 0.9888\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0277 - accuracy: 0.9897\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0307 - accuracy: 0.9838\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9758\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9899\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0718 - accuracy: 0.9719\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.93 - 0s 992us/step - loss: 0.0725 - accuracy: 0.9638\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0841 - accuracy: 0.9688\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0754 - accuracy: 0.9783\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0669 - accuracy: 0.9760\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0606 - accuracy: 0.9747\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0624 - accuracy: 0.9760\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75393a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c760731f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73eec5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 8: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8791 - accuracy: 0.5873\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.6932\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6940\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.5930 - accuracy: 0.7287\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.5433 - accuracy: 0.7291\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.5503 - accuracy: 0.7317\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.5420 - accuracy: 0.7417\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.5435 - accuracy: 0.7291\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.5126 - accuracy: 0.7690\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.4921 - accuracy: 0.7753\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.4735 - accuracy: 0.7835\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.4481 - accuracy: 0.8019\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8019\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.8005\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.4574 - accuracy: 0.7925\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.4014 - accuracy: 0.8097\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.3881 - accuracy: 0.8463\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.3801 - accuracy: 0.8401\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.3838 - accuracy: 0.8327\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.4028 - accuracy: 0.8230\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.3977 - accuracy: 0.8157\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.3697 - accuracy: 0.8374\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.3678 - accuracy: 0.8388\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.3130 - accuracy: 0.8693\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.3372 - accuracy: 0.8629\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8592\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8495\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.3054 - accuracy: 0.8385\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2873 - accuracy: 0.8877\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.3117 - accuracy: 0.8765\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.2886 - accuracy: 0.8803\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.2625 - accuracy: 0.8939\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.3017 - accuracy: 0.8676\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.3009 - accuracy: 0.8847\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2734 - accuracy: 0.8858\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.2901 - accuracy: 0.8658\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.2511 - accuracy: 0.8960\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.2630 - accuracy: 0.8942\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.2290 - accuracy: 0.9012\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.3185 - accuracy: 0.8607\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9122\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.2009 - accuracy: 0.9040\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2118 - accuracy: 0.9065\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.2075 - accuracy: 0.9118\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2235 - accuracy: 0.9087\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.2268 - accuracy: 0.8930\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1793 - accuracy: 0.9327\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2283 - accuracy: 0.9005\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.2161 - accuracy: 0.8992\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.2256 - accuracy: 0.8992\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9276\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9046\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.2000 - accuracy: 0.9167\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1672 - accuracy: 0.9257\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1861 - accuracy: 0.9167\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.2006 - accuracy: 0.9084\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1908 - accuracy: 0.9161\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1411 - accuracy: 0.9457\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1789 - accuracy: 0.9247\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1677 - accuracy: 0.9272\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1427 - accuracy: 0.9365\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1773 - accuracy: 0.9122\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1503 - accuracy: 0.9469\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1616 - accuracy: 0.9279\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1634 - accuracy: 0.9285\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.2237 - accuracy: 0.9001\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1872 - accuracy: 0.9125\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1806 - accuracy: 0.9113\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1524 - accuracy: 0.9294\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1488 - accuracy: 0.9431\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0996 - accuracy: 0.9596\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1332 - accuracy: 0.9512\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1406 - accuracy: 0.9441\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1506 - accuracy: 0.9360\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1454 - accuracy: 0.9396\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.1426 - accuracy: 0.9424\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1297 - accuracy: 0.9392\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1343 - accuracy: 0.9467\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1537 - accuracy: 0.9289\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1441 - accuracy: 0.9362\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 940us/step - loss: 0.1130 - accuracy: 0.9481\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1120 - accuracy: 0.9550\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0997 - accuracy: 0.9586\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1107 - accuracy: 0.9600\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1507 - accuracy: 0.9431\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1330 - accuracy: 0.9456\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1377 - accuracy: 0.9381\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1182 - accuracy: 0.9532\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1293 - accuracy: 0.9373\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0994 - accuracy: 0.9578\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1004 - accuracy: 0.9666\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0944 - accuracy: 0.9587\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1896 - accuracy: 0.9156\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1235 - accuracy: 0.9556\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0893 - accuracy: 0.9645\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1289 - accuracy: 0.9418\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1122 - accuracy: 0.9430\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1028 - accuracy: 0.9520\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1011 - accuracy: 0.9533\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1269 - accuracy: 0.9533\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0984 - accuracy: 0.9487\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1077 - accuracy: 0.9595\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1012 - accuracy: 0.9555\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0967 - accuracy: 0.9536\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1199 - accuracy: 0.9501\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0877 - accuracy: 0.9651\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1167 - accuracy: 0.9516\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1661 - accuracy: 0.9251\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1355 - accuracy: 0.9366\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1298 - accuracy: 0.9436\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1099 - accuracy: 0.9483\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1016 - accuracy: 0.9620\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0947 - accuracy: 0.9614\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0825 - accuracy: 0.9714\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9585\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9643\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9625\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9609\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9602\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0865 - accuracy: 0.9602\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1051 - accuracy: 0.9514\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9519\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1363 - accuracy: 0.9318\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1609 - accuracy: 0.9294\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1234 - accuracy: 0.9538\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9629\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1179 - accuracy: 0.9498\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9590\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0856 - accuracy: 0.9643\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9410\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1108 - accuracy: 0.9546\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0846 - accuracy: 0.9666\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0689 - accuracy: 0.9684\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1173 - accuracy: 0.9513\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0785 - accuracy: 0.9661\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1234 - accuracy: 0.9469\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0790 - accuracy: 0.9737\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1139 - accuracy: 0.9482\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9563\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0873 - accuracy: 0.9790\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0694 - accuracy: 0.9794\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0551 - accuracy: 0.9772\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0802 - accuracy: 0.9650\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0723 - accuracy: 0.9698\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0966 - accuracy: 0.9599\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1556 - accuracy: 0.9276\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1083 - accuracy: 0.9489\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0922 - accuracy: 0.9590\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1017 - accuracy: 0.9606\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0753 - accuracy: 0.9687\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0611 - accuracy: 0.9778\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0744 - accuracy: 0.9720\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0978 - accuracy: 0.9580\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1164 - accuracy: 0.9428\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1608 - accuracy: 0.9200\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.1304 - accuracy: 0.9461\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.1267 - accuracy: 0.9396\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1144 - accuracy: 0.9523\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0676 - accuracy: 0.9744\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0548 - accuracy: 0.9810\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 900us/step - loss: 0.0634 - accuracy: 0.9787\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9768\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9608\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9720\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1149 - accuracy: 0.9508\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0823 - accuracy: 0.9638\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9669\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0828 - accuracy: 0.9654\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0942 - accuracy: 0.9646\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0467 - accuracy: 0.9814\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0593 - accuracy: 0.9763\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0487 - accuracy: 0.9833\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0733 - accuracy: 0.9686\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0642 - accuracy: 0.9749\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0980 - accuracy: 0.9587\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0828 - accuracy: 0.9637\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0995 - accuracy: 0.9549\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1105 - accuracy: 0.9506\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0928 - accuracy: 0.9521\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0651 - accuracy: 0.9803\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0893 - accuracy: 0.9583\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0807 - accuracy: 0.9672\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0571 - accuracy: 0.9779\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0910 - accuracy: 0.9617\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0872 - accuracy: 0.9531\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0849 - accuracy: 0.9600\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1161 - accuracy: 0.9535\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1358 - accuracy: 0.9191\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0772 - accuracy: 0.9673\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0821 - accuracy: 0.9792\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0721 - accuracy: 0.9751\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0740 - accuracy: 0.9714\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0756 - accuracy: 0.9695\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1031 - accuracy: 0.9560\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0902 - accuracy: 0.9648\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9839\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0726 - accuracy: 0.9693\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0551 - accuracy: 0.9789\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0848 - accuracy: 0.9674\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0759 - accuracy: 0.9661\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8206 - accuracy: 0.6216\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.8147\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8214\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.8171\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8553\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8208\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8255\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8370\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.3421 - accuracy: 0.8500\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8409\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8545\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8383\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.3114 - accuracy: 0.8665\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.3215 - accuracy: 0.8566\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.2775 - accuracy: 0.8729\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.3042 - accuracy: 0.8611\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.2817 - accuracy: 0.8568\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.2540 - accuracy: 0.8784\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.2311 - accuracy: 0.9046\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2701 - accuracy: 0.8750\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.2758 - accuracy: 0.8796\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2481 - accuracy: 0.8938\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.2457 - accuracy: 0.8988\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.2090 - accuracy: 0.9070\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1941 - accuracy: 0.9222\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2233 - accuracy: 0.9018\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1835 - accuracy: 0.9267\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1834 - accuracy: 0.9247\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1708 - accuracy: 0.9260\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9358\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9262\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9113\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.9255\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1941 - accuracy: 0.9152\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9423\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9480\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1607 - accuracy: 0.9472\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9154\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1421 - accuracy: 0.9365\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1123 - accuracy: 0.9588\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 958us/step - loss: 0.1092 - accuracy: 0.9491\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9402\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9350\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1281 - accuracy: 0.9362\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9643\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1372 - accuracy: 0.9404\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1101 - accuracy: 0.9581\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9597\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1301 - accuracy: 0.9444\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1530 - accuracy: 0.9357\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1273 - accuracy: 0.9451\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9504\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1033 - accuracy: 0.9611\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1011 - accuracy: 0.9576\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1438 - accuracy: 0.9409\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0798 - accuracy: 0.9731\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1065 - accuracy: 0.9511\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0742 - accuracy: 0.9732\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0785 - accuracy: 0.9797\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0944 - accuracy: 0.9605\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0920 - accuracy: 0.9588\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0882 - accuracy: 0.9668\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0782 - accuracy: 0.9657\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9633\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1019 - accuracy: 0.9627\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0840 - accuracy: 0.9617\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0742 - accuracy: 0.9749\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0627 - accuracy: 0.9818\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0562 - accuracy: 0.9843\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0708 - accuracy: 0.9741\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0447 - accuracy: 0.9821\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0956 - accuracy: 0.9610\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0678 - accuracy: 0.9802\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0638 - accuracy: 0.9774\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.9598\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0571 - accuracy: 0.9857\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9813\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9593\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0896 - accuracy: 0.9651\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0523 - accuracy: 0.9829\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0586 - accuracy: 0.9777\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0738 - accuracy: 0.9698\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0602 - accuracy: 0.9738\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0594 - accuracy: 0.9769\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0645 - accuracy: 0.9775\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0551 - accuracy: 0.9840\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0754 - accuracy: 0.9789\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0770 - accuracy: 0.9652\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0733 - accuracy: 0.9675\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0526 - accuracy: 0.9839\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0741 - accuracy: 0.9749\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0447 - accuracy: 0.9824\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9866\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0403 - accuracy: 0.9868\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9927\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0460 - accuracy: 0.9838\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0692 - accuracy: 0.9715\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0659 - accuracy: 0.9739\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9710\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0570 - accuracy: 0.9810\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9846\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0645 - accuracy: 0.9786\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0848 - accuracy: 0.9632\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0675 - accuracy: 0.9677\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0739 - accuracy: 0.9716\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0678 - accuracy: 0.9814\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0447 - accuracy: 0.9889\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0592 - accuracy: 0.9826\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9814\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0805 - accuracy: 0.9711\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0513 - accuracy: 0.9773\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0569 - accuracy: 0.9815\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9651\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0448 - accuracy: 0.9859\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0444 - accuracy: 0.9835\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0695 - accuracy: 0.9772\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.0689 - accuracy: 0.9776\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0723 - accuracy: 0.9677\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0699 - accuracy: 0.9719\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0562 - accuracy: 0.9788\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 995us/step - loss: 0.0700 - accuracy: 0.9760\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0531 - accuracy: 0.9844\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9927\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0383 - accuracy: 0.9878\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0444 - accuracy: 0.9855\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0696 - accuracy: 0.9737\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0591 - accuracy: 0.9774\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0843 - accuracy: 0.9703\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0548 - accuracy: 0.9737\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0999 - accuracy: 0.9581\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0632 - accuracy: 0.9808\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0482 - accuracy: 0.9883\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0431 - accuracy: 0.9853\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0275 - accuracy: 0.9889\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0492 - accuracy: 0.9838\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0873 - accuracy: 0.9614\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0611 - accuracy: 0.9742\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9712\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0577 - accuracy: 0.9762\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0698 - accuracy: 0.9791\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0437 - accuracy: 0.9852\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0358 - accuracy: 0.9873\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0526 - accuracy: 0.9823\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0423 - accuracy: 0.9850\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0461 - accuracy: 0.9776\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0312 - accuracy: 0.9893\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0666 - accuracy: 0.9744\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0562 - accuracy: 0.9778\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0428 - accuracy: 0.9869\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0489 - accuracy: 0.9809\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0498 - accuracy: 0.9808\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0606 - accuracy: 0.9738\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0409 - accuracy: 0.9897\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9664\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0859 - accuracy: 0.9689\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0383 - accuracy: 0.9882\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0636 - accuracy: 0.9742\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0417 - accuracy: 0.9861\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0293 - accuracy: 0.9916\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0363 - accuracy: 0.9883\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0363 - accuracy: 0.9841\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0475 - accuracy: 0.9811\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0560 - accuracy: 0.9803\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0524 - accuracy: 0.9806\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0493 - accuracy: 0.9843\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0282 - accuracy: 0.9925\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0744 - accuracy: 0.9735\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0350 - accuracy: 0.9887\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0481 - accuracy: 0.9810\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0609 - accuracy: 0.9786\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0557 - accuracy: 0.9794\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0460 - accuracy: 0.9809\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0466 - accuracy: 0.9856\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0681 - accuracy: 0.9744\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0695 - accuracy: 0.9747\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0465 - accuracy: 0.9866\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0615 - accuracy: 0.9812\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0450 - accuracy: 0.9833\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0342 - accuracy: 0.9882\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9983\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0371 - accuracy: 0.9896\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0510 - accuracy: 0.9779\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0344 - accuracy: 0.9900\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0713 - accuracy: 0.9785\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0600 - accuracy: 0.9821\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0853 - accuracy: 0.9660\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0399 - accuracy: 0.9857\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0570 - accuracy: 0.9751\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0490 - accuracy: 0.9820\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0395 - accuracy: 0.9847\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0478 - accuracy: 0.9866\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0421 - accuracy: 0.9824\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0229 - accuracy: 0.9960\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0423 - accuracy: 0.9865\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0267 - accuracy: 0.9931\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0397 - accuracy: 0.9836\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0291 - accuracy: 0.9913\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0552 - accuracy: 0.9785\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0879 - accuracy: 0.9616\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 906us/step - loss: 0.0724 - accuracy: 0.9706\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.7129 - accuracy: 0.7345\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.4900 - accuracy: 0.8513\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.3861 - accuracy: 0.8862\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8944\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.3922 - accuracy: 0.8658\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.3429 - accuracy: 0.8910\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.3349 - accuracy: 0.8835\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.3081 - accuracy: 0.8959\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3401 - accuracy: 0.8776\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.3190 - accuracy: 0.8784\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8930\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.3080 - accuracy: 0.8759\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.2856 - accuracy: 0.8848\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2972 - accuracy: 0.8747\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2807 - accuracy: 0.8953\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.2426 - accuracy: 0.9010\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.2469 - accuracy: 0.9002\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.2306 - accuracy: 0.9157\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.2491 - accuracy: 0.8906\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.2105 - accuracy: 0.9152\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1956 - accuracy: 0.9186\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1808 - accuracy: 0.9209\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1959 - accuracy: 0.9278\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1992 - accuracy: 0.9293\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.2122 - accuracy: 0.9158\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1847 - accuracy: 0.9342\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1706 - accuracy: 0.9422\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1790 - accuracy: 0.9263\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1806 - accuracy: 0.9442\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1593 - accuracy: 0.9423\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1699 - accuracy: 0.9453\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9466\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1305 - accuracy: 0.9476\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1184 - accuracy: 0.9534\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1355 - accuracy: 0.9370\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1091 - accuracy: 0.9610\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9725\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1733 - accuracy: 0.9354\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1240 - accuracy: 0.9529\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1282 - accuracy: 0.9479\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1023 - accuracy: 0.9560\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1404 - accuracy: 0.9481\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0714 - accuracy: 0.9686\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0882 - accuracy: 0.9681\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1586 - accuracy: 0.9404\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0877 - accuracy: 0.9638\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0912 - accuracy: 0.9699\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1070 - accuracy: 0.9603\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9573\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9780\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9737\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0717 - accuracy: 0.9797\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0694 - accuracy: 0.9769\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1018 - accuracy: 0.9671\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9584\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0687 - accuracy: 0.9778\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0683 - accuracy: 0.9800\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0584 - accuracy: 0.9761\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0547 - accuracy: 0.9767\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0658 - accuracy: 0.9785\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9790\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0438 - accuracy: 0.9840\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9741\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0638 - accuracy: 0.9783\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9705\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9826\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0447 - accuracy: 0.9841\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0483 - accuracy: 0.9867\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0447 - accuracy: 0.9878\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0612 - accuracy: 0.9797\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0299 - accuracy: 0.9901\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9898\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0423 - accuracy: 0.9871\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0591 - accuracy: 0.9789\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9655\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0496 - accuracy: 0.9823\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0798 - accuracy: 0.9682\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0567 - accuracy: 0.9804\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9876\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 955us/step - loss: 0.0528 - accuracy: 0.9818\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0350 - accuracy: 0.9862\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9829\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9855\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0641 - accuracy: 0.9748\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0717 - accuracy: 0.9731\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0803 - accuracy: 0.9701\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0663 - accuracy: 0.9765\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0573 - accuracy: 0.9778\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0452 - accuracy: 0.9922\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0659 - accuracy: 0.9830\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0638 - accuracy: 0.9739\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0332 - accuracy: 0.9938\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9822\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9783\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9942\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9901\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9864\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0346 - accuracy: 0.9896\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0434 - accuracy: 0.9843\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0520 - accuracy: 0.9814\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0573 - accuracy: 0.9742\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0467 - accuracy: 0.9856\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0413 - accuracy: 0.9796\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0591 - accuracy: 0.9784\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0511 - accuracy: 0.9804\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0513 - accuracy: 0.9831\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0363 - accuracy: 0.9912\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0411 - accuracy: 0.9830\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0270 - accuracy: 0.9894\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0403 - accuracy: 0.9860\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0709 - accuracy: 0.9744\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0472 - accuracy: 0.9810\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0412 - accuracy: 0.9882\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0300 - accuracy: 0.9944\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0253 - accuracy: 0.9923\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9854\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9850\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0599 - accuracy: 0.9784\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9860\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0510 - accuracy: 0.9835\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0579 - accuracy: 0.9794\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9757\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9843\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9836\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9899\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0407 - accuracy: 0.9892\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0488 - accuracy: 0.9887\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0228 - accuracy: 0.9932\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9910\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0362 - accuracy: 0.9880\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9873\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0412 - accuracy: 0.9833\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9726\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0499 - accuracy: 0.9837\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9796\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9736\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0329 - accuracy: 0.9912\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9673\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9739\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0505 - accuracy: 0.9775\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0703 - accuracy: 0.9715\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0508 - accuracy: 0.9788\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0406 - accuracy: 0.9878\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9907\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0283 - accuracy: 0.9916\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0267 - accuracy: 0.9935\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0225 - accuracy: 0.9914\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0218 - accuracy: 0.9961\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0497 - accuracy: 0.9844\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0386 - accuracy: 0.9878\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0413 - accuracy: 0.9829\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0413 - accuracy: 0.9872\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0350 - accuracy: 0.9922\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0285 - accuracy: 0.9896\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0293 - accuracy: 0.9928\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0324 - accuracy: 0.9909\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.0583 - accuracy: 0.9839\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0548 - accuracy: 0.9798\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0328 - accuracy: 0.9906\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 933us/step - loss: 0.0260 - accuracy: 0.9924\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0591 - accuracy: 0.9763\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0497 - accuracy: 0.9840\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0452 - accuracy: 0.9862\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0631 - accuracy: 0.9731\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0395 - accuracy: 0.9840\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0337 - accuracy: 0.9873\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0527 - accuracy: 0.9810\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0436 - accuracy: 0.9776\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0380 - accuracy: 0.9910\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9965\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0285 - accuracy: 0.9890\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0378 - accuracy: 0.9929\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0433 - accuracy: 0.9887\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0424 - accuracy: 0.9797\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0240 - accuracy: 0.9918\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0232 - accuracy: 0.9915\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9874\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0324 - accuracy: 0.9903\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0323 - accuracy: 0.9898\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0139 - accuracy: 0.9978\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0220 - accuracy: 0.9936\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9888\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0102 - accuracy: 0.9993\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9923\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0295 - accuracy: 0.9901\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0427 - accuracy: 0.9860\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0212 - accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0373 - accuracy: 0.9869\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0331 - accuracy: 0.9873\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0598 - accuracy: 0.9812\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0367 - accuracy: 0.9846\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0448 - accuracy: 0.9838\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0431 - accuracy: 0.9842\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0296 - accuracy: 0.9916\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0212 - accuracy: 0.9952\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0302 - accuracy: 0.9922\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0199 - accuracy: 0.9945\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0313 - accuracy: 0.9906\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0430 - accuracy: 0.9871\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0515 - accuracy: 0.9849\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c76b6a8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c751cb8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c751fd430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 9: 90\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 890us/step - loss: 0.8518 - accuracy: 0.6213\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.6479\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.6532 - accuracy: 0.6803\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.5998 - accuracy: 0.7155\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.5881 - accuracy: 0.7133\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.5556 - accuracy: 0.7301\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.5422 - accuracy: 0.7347\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.5478 - accuracy: 0.7220\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.5044 - accuracy: 0.7443\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.4728 - accuracy: 0.7831\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.4963 - accuracy: 0.7690\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.4660 - accuracy: 0.7691\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.4727 - accuracy: 0.7822\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.4692 - accuracy: 0.7975\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.4483 - accuracy: 0.7905\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.4113 - accuracy: 0.8153\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.4124 - accuracy: 0.8255\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.3992 - accuracy: 0.8086\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8283\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.3836 - accuracy: 0.8567\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.3590 - accuracy: 0.8412\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.3826 - accuracy: 0.8246\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3493 - accuracy: 0.8522\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.3516 - accuracy: 0.8414\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.3577 - accuracy: 0.8506\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.3131 - accuracy: 0.8677\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.3013 - accuracy: 0.8816\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.2552 - accuracy: 0.8964\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.3231 - accuracy: 0.8621\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.2515 - accuracy: 0.8962\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.2822 - accuracy: 0.8929\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.2737 - accuracy: 0.8964\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8657\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.2682 - accuracy: 0.8954\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.8971\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.2047 - accuracy: 0.9151\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.2143 - accuracy: 0.9150\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.2607 - accuracy: 0.8964\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.2458 - accuracy: 0.8931\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1748 - accuracy: 0.9422\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.2213 - accuracy: 0.8986\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1743 - accuracy: 0.9393\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.8995\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9044\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9267\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1766 - accuracy: 0.9358\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9242\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1767 - accuracy: 0.9272\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9222\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9354\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9077\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.9136\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1936 - accuracy: 0.9254\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1849 - accuracy: 0.9150\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9418\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9173\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.9356\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9432\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9271\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9361\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9463\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9516\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1181 - accuracy: 0.9478\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1198 - accuracy: 0.9520\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1120 - accuracy: 0.9569\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1692 - accuracy: 0.9259\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1663 - accuracy: 0.9076\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1186 - accuracy: 0.9373\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.1057 - accuracy: 0.9648\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1227 - accuracy: 0.9450\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1647 - accuracy: 0.9229\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1597 - accuracy: 0.9329\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1096 - accuracy: 0.9558\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0948 - accuracy: 0.9654\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0774 - accuracy: 0.9686\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0975 - accuracy: 0.9591\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1059 - accuracy: 0.9586\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0825 - accuracy: 0.9679\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1143 - accuracy: 0.9597\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9538\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 999us/step - loss: 0.1214 - accuracy: 0.9498\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1558 - accuracy: 0.9455\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9396\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0746 - accuracy: 0.9728\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1154 - accuracy: 0.9480\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0900 - accuracy: 0.9611\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1125 - accuracy: 0.9643\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1037 - accuracy: 0.9539\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9707\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1310 - accuracy: 0.9497\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1006 - accuracy: 0.9697\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0982 - accuracy: 0.9608\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9558\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9649\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9707\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0814 - accuracy: 0.9669\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0716 - accuracy: 0.9719\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0939 - accuracy: 0.9610\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9416\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9618\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0992 - accuracy: 0.9556\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0751 - accuracy: 0.9684\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0974 - accuracy: 0.9579\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9556\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9704\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9451\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1155 - accuracy: 0.9568\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9487\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0945 - accuracy: 0.9646\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0558 - accuracy: 0.9807\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0693 - accuracy: 0.9728\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0851 - accuracy: 0.9599\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9568\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0954 - accuracy: 0.9501\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1196 - accuracy: 0.9424\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9589\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9569\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9485\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9623\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0950 - accuracy: 0.9522\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9651\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9650\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0634 - accuracy: 0.9770\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9719\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1058 - accuracy: 0.9552\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9589\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9504\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1248 - accuracy: 0.9343\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9553\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0984 - accuracy: 0.9519\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0770 - accuracy: 0.9556\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0826 - accuracy: 0.9648\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9562\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0890 - accuracy: 0.9611\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0859 - accuracy: 0.9564\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0915 - accuracy: 0.9575\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1412 - accuracy: 0.9624\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0874 - accuracy: 0.9622\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1156 - accuracy: 0.9545\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9380\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0883 - accuracy: 0.9620\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1284 - accuracy: 0.9417\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1010 - accuracy: 0.9559\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0805 - accuracy: 0.9571\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0872 - accuracy: 0.9747\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0891 - accuracy: 0.9681\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1115 - accuracy: 0.9424\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1004 - accuracy: 0.9625\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0776 - accuracy: 0.9655\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9616\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9594\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0919 - accuracy: 0.9689\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1283 - accuracy: 0.9604\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0488 - accuracy: 0.9822\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0707 - accuracy: 0.9698\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0588 - accuracy: 0.9856\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0631 - accuracy: 0.9791\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0495 - accuracy: 0.9815\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0575 - accuracy: 0.9810\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0634 - accuracy: 0.9758\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 940us/step - loss: 0.0504 - accuracy: 0.9846\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0447 - accuracy: 0.9882\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0838 - accuracy: 0.9624\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1199 - accuracy: 0.9527\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0942 - accuracy: 0.9632\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0777 - accuracy: 0.9682\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0552 - accuracy: 0.9783\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1066 - accuracy: 0.9507\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0768 - accuracy: 0.9686\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1036 - accuracy: 0.9501\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0903 - accuracy: 0.9537\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0942 - accuracy: 0.9551\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0749 - accuracy: 0.9648\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1172 - accuracy: 0.9375\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1039 - accuracy: 0.9388\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9324\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0762 - accuracy: 0.9633\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0791 - accuracy: 0.9601\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1035 - accuracy: 0.9457\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0647 - accuracy: 0.9680\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0862 - accuracy: 0.9495\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0771 - accuracy: 0.9660\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0543 - accuracy: 0.9796\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0471 - accuracy: 0.9884\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0611 - accuracy: 0.9831\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0381 - accuracy: 0.9888\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1377 - accuracy: 0.9554\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0965 - accuracy: 0.9653\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0706 - accuracy: 0.9710\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0684 - accuracy: 0.9752\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0969 - accuracy: 0.9573\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0934 - accuracy: 0.9599\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0770 - accuracy: 0.9698\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0440 - accuracy: 0.9799\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0842 - accuracy: 0.9711\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0889 - accuracy: 0.9647\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9633\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9700\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0536 - accuracy: 0.9808\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9807\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8381 - accuracy: 0.5590\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.5459 - accuracy: 0.7970\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7642\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.8062\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.8132\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8488\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8251\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8409\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8438\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8322\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.3311 - accuracy: 0.8669\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8432\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8640\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.3063 - accuracy: 0.8606\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.2879 - accuracy: 0.8793\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8809\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8655\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8610\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8776\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.8713\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9065\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.9107\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.8845\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9056\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9001\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.2066 - accuracy: 0.9084\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1839 - accuracy: 0.9078\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.2099 - accuracy: 0.9194\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9020\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.9194\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9326\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9171\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9467\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9449\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9537\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9293\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9373\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9349\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1259 - accuracy: 0.9490\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1272 - accuracy: 0.9516\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 975us/step - loss: 0.1548 - accuracy: 0.9278\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9683\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9589\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9546\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9382\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1384 - accuracy: 0.9434\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1359 - accuracy: 0.9487\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9724\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0917 - accuracy: 0.9676\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1057 - accuracy: 0.9600\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0830 - accuracy: 0.9711\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0986 - accuracy: 0.9630\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1036 - accuracy: 0.9560\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0735 - accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1308 - accuracy: 0.9466\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0993 - accuracy: 0.9606\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0988 - accuracy: 0.9608\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0747 - accuracy: 0.9688\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0891 - accuracy: 0.9753\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0916 - accuracy: 0.9564\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0945 - accuracy: 0.9649\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1312 - accuracy: 0.9456\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0887 - accuracy: 0.9700\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0644 - accuracy: 0.9770\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9791\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9748\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0916 - accuracy: 0.9635\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0741 - accuracy: 0.9635\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0878 - accuracy: 0.9638\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0806 - accuracy: 0.9698\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1177 - accuracy: 0.9469\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0642 - accuracy: 0.9786\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1048 - accuracy: 0.9592\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0846 - accuracy: 0.9672\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0794 - accuracy: 0.9681\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0830 - accuracy: 0.9711\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0958 - accuracy: 0.9562\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0963 - accuracy: 0.9648\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9552\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9734\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0870 - accuracy: 0.9651\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0837 - accuracy: 0.9648\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0722 - accuracy: 0.9724\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0673 - accuracy: 0.9814\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9681\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0480 - accuracy: 0.9855\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9847\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0482 - accuracy: 0.9837\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0969 - accuracy: 0.9595\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0661 - accuracy: 0.9746\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0542 - accuracy: 0.9830\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0926 - accuracy: 0.9613\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0803 - accuracy: 0.9719\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0558 - accuracy: 0.9752\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0709 - accuracy: 0.9725\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9693\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0452 - accuracy: 0.9846\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9818\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9640\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9794\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9813\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9819\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9825\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9841\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9869\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0468 - accuracy: 0.9811\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0473 - accuracy: 0.9864\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9820\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0491 - accuracy: 0.9819\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9796\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0669 - accuracy: 0.9757\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0737 - accuracy: 0.9754\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0407 - accuracy: 0.9901\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0759 - accuracy: 0.9715\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0471 - accuracy: 0.9869\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0698 - accuracy: 0.9746\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0532 - accuracy: 0.9836\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0423 - accuracy: 0.9905\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0616 - accuracy: 0.9801\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9796\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9823\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0770 - accuracy: 0.9705\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0574 - accuracy: 0.9811\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9771\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0507 - accuracy: 0.9830\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0352 - accuracy: 0.9896\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9770\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9765\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9894\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9839\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9856\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9875\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0489 - accuracy: 0.9870\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9827\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0291 - accuracy: 0.9907\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0397 - accuracy: 0.9860\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9746\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9718\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0914 - accuracy: 0.9665\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9839\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9796\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9816\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0281 - accuracy: 0.9932\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0374 - accuracy: 0.9880\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0364 - accuracy: 0.9917\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0380 - accuracy: 0.9861\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0556 - accuracy: 0.9833\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0412 - accuracy: 0.9873\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9852\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0763 - accuracy: 0.9736\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0653 - accuracy: 0.9811\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0864 - accuracy: 0.9729\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0642 - accuracy: 0.9800\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0430 - accuracy: 0.9858\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0208 - accuracy: 0.9933\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0329 - accuracy: 0.9898\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0656 - accuracy: 0.9809\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0399 - accuracy: 0.9854\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9817\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0453 - accuracy: 0.9859\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9850\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9846\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0502 - accuracy: 0.9811\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0540 - accuracy: 0.9795\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0536 - accuracy: 0.9859\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0170 - accuracy: 0.9982\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0262 - accuracy: 0.9912\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0249 - accuracy: 0.9911\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0380 - accuracy: 0.9874\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9851\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0280 - accuracy: 0.9941\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0650 - accuracy: 0.9776\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0814 - accuracy: 0.9775\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0469 - accuracy: 0.9875\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0430 - accuracy: 0.9856\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0314 - accuracy: 0.9899\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0342 - accuracy: 0.9909\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0501 - accuracy: 0.9839\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0486 - accuracy: 0.9858\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0677 - accuracy: 0.9747\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0468 - accuracy: 0.9862\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0502 - accuracy: 0.9812\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9747\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0469 - accuracy: 0.9837\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9791\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9889\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9875\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9905\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.9964\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9835\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9943\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9902\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9853\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9884\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0339 - accuracy: 0.9922\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9828\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9886\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0407 - accuracy: 0.9866\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9897\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 987us/step - loss: 0.6355 - accuracy: 0.7966\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.8739\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8876\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8770\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.3621 - accuracy: 0.8879\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8803\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.3544 - accuracy: 0.8655\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.3679 - accuracy: 0.8750\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8773\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8793\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8603\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.3278 - accuracy: 0.8626\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.3332 - accuracy: 0.8702\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.2700 - accuracy: 0.8947\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.3010 - accuracy: 0.8881\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8819\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2563 - accuracy: 0.8827\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.2611 - accuracy: 0.8876\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2445 - accuracy: 0.8996\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.2684 - accuracy: 0.8894\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.2278 - accuracy: 0.9093\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.2135 - accuracy: 0.9231\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.2160 - accuracy: 0.9226\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.2119 - accuracy: 0.9224\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.2035 - accuracy: 0.9295\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1887 - accuracy: 0.9336\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1789 - accuracy: 0.9349\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1807 - accuracy: 0.9363\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1565 - accuracy: 0.9469\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.1477 - accuracy: 0.9411\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1769 - accuracy: 0.9155\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1604 - accuracy: 0.9305\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1790 - accuracy: 0.9298\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1878 - accuracy: 0.9186\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1622 - accuracy: 0.9260\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1677 - accuracy: 0.9266\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1344 - accuracy: 0.9469\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1464 - accuracy: 0.9527\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1296 - accuracy: 0.9498\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1035 - accuracy: 0.9638\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9549\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0913 - accuracy: 0.9617\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1179 - accuracy: 0.9587\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1443 - accuracy: 0.9425\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9652\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0899 - accuracy: 0.9638\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9697\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0658 - accuracy: 0.9693\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9606\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0715 - accuracy: 0.9740\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9521\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1471 - accuracy: 0.9373\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9631\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0874 - accuracy: 0.9652\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0887 - accuracy: 0.9551\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1155 - accuracy: 0.9498\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.9632\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1333 - accuracy: 0.9405\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0866 - accuracy: 0.9611\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1442 - accuracy: 0.9316\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0789 - accuracy: 0.9737\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0861 - accuracy: 0.9639\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0767 - accuracy: 0.9731\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0985 - accuracy: 0.9602\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9532\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9583\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.9601\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9736\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0653 - accuracy: 0.9735\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0964 - accuracy: 0.9619\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0890 - accuracy: 0.9590\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0611 - accuracy: 0.9787\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0567 - accuracy: 0.9772\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0572 - accuracy: 0.9756\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0732 - accuracy: 0.9735\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1041 - accuracy: 0.9487\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0733 - accuracy: 0.9709\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0668 - accuracy: 0.9678\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0751 - accuracy: 0.9627\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0685 - accuracy: 0.9702\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 971us/step - loss: 0.0717 - accuracy: 0.9754\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0563 - accuracy: 0.9796\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0806 - accuracy: 0.9657\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0647 - accuracy: 0.9726\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0652 - accuracy: 0.9753\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9702\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0675 - accuracy: 0.9738\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0739 - accuracy: 0.9728\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0872 - accuracy: 0.9691\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9719\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9776\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9640\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9904\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9637\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9859\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0587 - accuracy: 0.9752\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9815\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0591 - accuracy: 0.9729\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9849\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0491 - accuracy: 0.9821\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0508 - accuracy: 0.9845\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9881\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9737\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9800\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9753\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9575\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9639\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9803\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0464 - accuracy: 0.9831\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0720 - accuracy: 0.9759\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0422 - accuracy: 0.9839\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0589 - accuracy: 0.9725\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0655 - accuracy: 0.9700\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9790\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9852\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9669\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9530\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9440\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9680\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9772\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9814\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9659\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9645\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0592 - accuracy: 0.9799\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0632 - accuracy: 0.9695\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0565 - accuracy: 0.9773\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9736\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9866\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9812\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9705\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9527\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9695\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9828\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0389 - accuracy: 0.9861\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0650 - accuracy: 0.9732\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9829\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9859\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9868\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9701\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9722\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9717\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9776\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9833\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9849\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9873\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9837\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9857\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9842\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9928\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0298 - accuracy: 0.9929\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9892\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9848\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9871\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9893\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9869\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9856\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9810\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9839\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9896\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9880\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9860\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9776\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9772\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9853\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9912\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9948\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9826\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9849\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9710\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9599\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9945\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9814\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9761\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9870\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9830\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9651\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9866\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9933\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9841\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9929\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9896\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9799\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0398 - accuracy: 0.9855\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9853\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9706\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0807 - accuracy: 0.9694\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0400 - accuracy: 0.9831\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0513 - accuracy: 0.9812\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0371 - accuracy: 0.9885\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9919\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9971\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9827\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9874\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9840\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9738\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9648\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9787\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9941\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9891\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c760fd160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c739d40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75135ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 10: 77\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.9470 - accuracy: 0.4635\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.6625\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6771\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.6924\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6098 - accuracy: 0.6935\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7256\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.7165\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7397\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7543\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7602\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7776\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7793\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7695\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7859\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.7989\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7974\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8196\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8163\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8333\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.8202\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8262\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8453\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8262\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8304\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.8741\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8589\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.3552 - accuracy: 0.8483\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8489\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3024 - accuracy: 0.8752\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.2999 - accuracy: 0.8739\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.8836\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2746 - accuracy: 0.8976\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.2551 - accuracy: 0.8965\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.3076 - accuracy: 0.8682\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.2746 - accuracy: 0.8833\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.2914 - accuracy: 0.8641\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8760\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.2237 - accuracy: 0.9093\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8844\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.2293 - accuracy: 0.9141\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9053\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.8956\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9076\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.8750\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.8837\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2571 - accuracy: 0.8931\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9045\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.8982\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.2142 - accuracy: 0.8932\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1635 - accuracy: 0.9317\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.2024 - accuracy: 0.9125\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9148\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.9077\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1736 - accuracy: 0.9312\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.2529 - accuracy: 0.8899\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1834 - accuracy: 0.9088\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9389\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1671 - accuracy: 0.9274\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1861 - accuracy: 0.9205\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1987 - accuracy: 0.9035\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1708 - accuracy: 0.9389\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9169\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1685 - accuracy: 0.9268\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1543 - accuracy: 0.9307\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9245\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1638 - accuracy: 0.9223\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1758 - accuracy: 0.9196\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9121\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1945 - accuracy: 0.9122\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9331\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9220\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1229 - accuracy: 0.9447\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9350\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9139\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9426\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9229\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9275\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9422\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9370\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9535\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9348\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9022\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9274\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.9128\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.9385\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9357\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9503\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1132 - accuracy: 0.9369\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9451\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9464\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1426 - accuracy: 0.9358\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1652 - accuracy: 0.9356\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9573\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9188\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9514\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9460\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1458 - accuracy: 0.9429\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1311 - accuracy: 0.9373\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9026\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1593 - accuracy: 0.9305\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9516\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1547 - accuracy: 0.9291\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1216 - accuracy: 0.9485\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1718 - accuracy: 0.9179\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1209 - accuracy: 0.9326\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0893 - accuracy: 0.9543\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1049 - accuracy: 0.9370\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9613\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9489\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1045 - accuracy: 0.9482\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1016 - accuracy: 0.9449\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9271\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1001 - accuracy: 0.9409\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1420 - accuracy: 0.9285\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.9487\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1505 - accuracy: 0.9265\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9599\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9599\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1254 - accuracy: 0.9467\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1041 - accuracy: 0.9478\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9227\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1055 - accuracy: 0.9548\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9485\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1168 - accuracy: 0.9342\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1084 - accuracy: 0.9317\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0944 - accuracy: 0.9362\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9370\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0986 - accuracy: 0.9507\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9280\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1356 - accuracy: 0.9243\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9301\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1154 - accuracy: 0.9390\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9440\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1238 - accuracy: 0.9285\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9309\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1137 - accuracy: 0.9447\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9504\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9491\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9438\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9350\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0889 - accuracy: 0.9497\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9504\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9352\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1567 - accuracy: 0.9287\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9465\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1097 - accuracy: 0.9384\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0876 - accuracy: 0.9514\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0832 - accuracy: 0.9609\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0813 - accuracy: 0.9599\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0943 - accuracy: 0.9519\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0706 - accuracy: 0.9635\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9526\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0894 - accuracy: 0.9515\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 980us/step - loss: 0.0475 - accuracy: 0.9754\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0810 - accuracy: 0.9466\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9578\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1130 - accuracy: 0.9340\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1374 - accuracy: 0.9345\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1512 - accuracy: 0.9262\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9356\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9409\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1106 - accuracy: 0.9295\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1386 - accuracy: 0.9192\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1142 - accuracy: 0.9373\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0858 - accuracy: 0.9460\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9394\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0974 - accuracy: 0.9394\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0930 - accuracy: 0.9454\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0967 - accuracy: 0.9508\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1127 - accuracy: 0.9253\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0926 - accuracy: 0.9474\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0995 - accuracy: 0.9422\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9572\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1215 - accuracy: 0.9274\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1003 - accuracy: 0.9388\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0831 - accuracy: 0.9516\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9431\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0821 - accuracy: 0.9498\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0844 - accuracy: 0.9574\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0465 - accuracy: 0.9690\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9466\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1055 - accuracy: 0.9419\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0997 - accuracy: 0.9413\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0776 - accuracy: 0.9613\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0716 - accuracy: 0.9501\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0731 - accuracy: 0.9503\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1258 - accuracy: 0.9275\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1257 - accuracy: 0.9360\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0784 - accuracy: 0.9531\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0683 - accuracy: 0.9513\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0833 - accuracy: 0.9514\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0998 - accuracy: 0.9570\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0578 - accuracy: 0.9647\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0711 - accuracy: 0.9566\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9594\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1564 - accuracy: 0.9434\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0833 - accuracy: 0.9517\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1049 - accuracy: 0.9476\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9671\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0847 - accuracy: 0.9538\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.7613 - accuracy: 0.6909\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.4723 - accuracy: 0.8249\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8157\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.4431 - accuracy: 0.8318\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.3633 - accuracy: 0.8527\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.3784 - accuracy: 0.8429\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3368 - accuracy: 0.8728\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8421\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.3393 - accuracy: 0.8333\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.3090 - accuracy: 0.8605\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.3231 - accuracy: 0.8428\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2997 - accuracy: 0.8576\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.2583 - accuracy: 0.8673\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.8595\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2687 - accuracy: 0.8886\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.2427 - accuracy: 0.8908\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.2408 - accuracy: 0.8783\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.2447 - accuracy: 0.8946\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2534 - accuracy: 0.8744\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.2327 - accuracy: 0.9054\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.2086 - accuracy: 0.9200\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1933 - accuracy: 0.9243\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9266\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9397\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1767 - accuracy: 0.9206\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1681 - accuracy: 0.9270\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1643 - accuracy: 0.9334\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1723 - accuracy: 0.9359\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1476 - accuracy: 0.9286\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9319\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1442 - accuracy: 0.9475\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9477\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1290 - accuracy: 0.9482\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 939us/step - loss: 0.1236 - accuracy: 0.9449\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1380 - accuracy: 0.9469\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1489 - accuracy: 0.9353\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1298 - accuracy: 0.9463\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1355 - accuracy: 0.9470\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1026 - accuracy: 0.9604\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1389 - accuracy: 0.9457\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1967 - accuracy: 0.9167\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1460 - accuracy: 0.9346\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1249 - accuracy: 0.9582\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0930 - accuracy: 0.9641\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0901 - accuracy: 0.9604\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1361 - accuracy: 0.9527\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0945 - accuracy: 0.9659\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9571\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9739\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9752\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0647 - accuracy: 0.9766\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0639 - accuracy: 0.9779\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1115 - accuracy: 0.9565\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0727 - accuracy: 0.9719\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0715 - accuracy: 0.9752\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0910 - accuracy: 0.9648\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0934 - accuracy: 0.9646\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0733 - accuracy: 0.9758\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0814 - accuracy: 0.9707\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1228 - accuracy: 0.9521\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0740 - accuracy: 0.9706\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1405 - accuracy: 0.9387\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0790 - accuracy: 0.9795\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0951 - accuracy: 0.9545\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0748 - accuracy: 0.9762\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0640 - accuracy: 0.9821\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0738 - accuracy: 0.9729\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9735\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9727\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0794 - accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9770\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0674 - accuracy: 0.9802\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0696 - accuracy: 0.9748\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0747 - accuracy: 0.9683\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0677 - accuracy: 0.9741\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0810 - accuracy: 0.9742\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0567 - accuracy: 0.9806\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1107 - accuracy: 0.9512\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0710 - accuracy: 0.9759\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0693 - accuracy: 0.9751\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0599 - accuracy: 0.9743\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0528 - accuracy: 0.9813\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0685 - accuracy: 0.9749\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0714 - accuracy: 0.9752\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0806 - accuracy: 0.9699\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0714 - accuracy: 0.9779\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0642 - accuracy: 0.9750\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0720 - accuracy: 0.9756\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9718\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9868\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9716\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0896 - accuracy: 0.9645\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9763\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9658\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9744\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0585 - accuracy: 0.9779\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9796\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9659\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9468\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0832 - accuracy: 0.9641\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9550\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0959 - accuracy: 0.9686\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9653\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9702\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9830\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9773\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9732\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9678\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0525 - accuracy: 0.9810\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0600 - accuracy: 0.9813\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0554 - accuracy: 0.9880\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0519 - accuracy: 0.9848\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0795 - accuracy: 0.9769\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9646\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0801 - accuracy: 0.9653\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9665\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0579 - accuracy: 0.9804\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0543 - accuracy: 0.9828\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0966 - accuracy: 0.9640\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0596 - accuracy: 0.9803\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9804\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0385 - accuracy: 0.9893\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0857 - accuracy: 0.9668\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0786 - accuracy: 0.9754\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0827 - accuracy: 0.9710\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9577\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0779 - accuracy: 0.9701\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0541 - accuracy: 0.9786\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0648 - accuracy: 0.9792\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9934\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9747\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0765 - accuracy: 0.9756\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0250 - accuracy: 0.9973\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0331 - accuracy: 0.9913\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9913\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9758\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0493 - accuracy: 0.9855\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0366 - accuracy: 0.9856\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0539 - accuracy: 0.9817\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0537 - accuracy: 0.9855\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0504 - accuracy: 0.9850\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0549 - accuracy: 0.9841\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0514 - accuracy: 0.9870\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0676 - accuracy: 0.9816\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1248 - accuracy: 0.9571\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0836 - accuracy: 0.9763\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1225 - accuracy: 0.9522\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0796 - accuracy: 0.9700\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0690 - accuracy: 0.9732\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0668 - accuracy: 0.9785\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0553 - accuracy: 0.9789\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0399 - accuracy: 0.9860\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9753\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1080 - accuracy: 0.9655\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0722 - accuracy: 0.9708\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0310 - accuracy: 0.9938\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0358 - accuracy: 0.9933\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0470 - accuracy: 0.9863\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0743 - accuracy: 0.9732\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0387 - accuracy: 0.9892\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0389 - accuracy: 0.9905\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0315 - accuracy: 0.9904\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0312 - accuracy: 0.9911\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9931\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0609 - accuracy: 0.9739\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9877\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0660 - accuracy: 0.9795\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0492 - accuracy: 0.9889\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0452 - accuracy: 0.9892\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9813\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0338 - accuracy: 0.9899\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0253 - accuracy: 0.9957\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9839\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0520 - accuracy: 0.9839\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0678 - accuracy: 0.9794\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0525 - accuracy: 0.9863\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0757 - accuracy: 0.9815\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9710\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1108 - accuracy: 0.9579\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0415 - accuracy: 0.9857\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0382 - accuracy: 0.9891\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9930\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0337 - accuracy: 0.9886\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9932\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0245 - accuracy: 0.9938\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0243 - accuracy: 0.9946\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0151 - accuracy: 0.9979\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0287 - accuracy: 0.9923\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9844\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0473 - accuracy: 0.9839\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0418 - accuracy: 0.9861\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0614 - accuracy: 0.9774\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0647 - accuracy: 0.9758\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9742\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9908\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9732\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0432 - accuracy: 0.9893\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9824\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0212 - accuracy: 0.9952\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9823\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.6112 - accuracy: 0.8281\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.4140 - accuracy: 0.8722\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.4051 - accuracy: 0.8655\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.4162 - accuracy: 0.8578\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.3397 - accuracy: 0.8842\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.3717 - accuracy: 0.8539\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.3464 - accuracy: 0.8733\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.3556 - accuracy: 0.8727\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.3319 - accuracy: 0.8679\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.3521 - accuracy: 0.8671\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.3409 - accuracy: 0.8781\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2709 - accuracy: 0.8938\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.2960 - accuracy: 0.8781\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2864 - accuracy: 0.8912\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.2440 - accuracy: 0.8959\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.2433 - accuracy: 0.9081\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2366 - accuracy: 0.9091\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.2259 - accuracy: 0.9140\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.2443 - accuracy: 0.9167\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.2420 - accuracy: 0.8994\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.2028 - accuracy: 0.9179\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.2297 - accuracy: 0.9130\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.2207 - accuracy: 0.9244\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.2094 - accuracy: 0.9142\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1711 - accuracy: 0.9328\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2150 - accuracy: 0.9100\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1856 - accuracy: 0.9274\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1537 - accuracy: 0.9464\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9324\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1464 - accuracy: 0.9392\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1465 - accuracy: 0.9418\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1714 - accuracy: 0.9336\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1811 - accuracy: 0.9325\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1469 - accuracy: 0.9504\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9312\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1754 - accuracy: 0.9453\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1599 - accuracy: 0.9280\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9516\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1262 - accuracy: 0.9528\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1363 - accuracy: 0.9514\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1356 - accuracy: 0.9439\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1309 - accuracy: 0.9388\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1305 - accuracy: 0.9492\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9735\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0970 - accuracy: 0.9639\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0715 - accuracy: 0.9836\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1071 - accuracy: 0.9571\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1112 - accuracy: 0.9634\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0656 - accuracy: 0.9759\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.9449\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1192 - accuracy: 0.9570\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9705\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9557\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9498\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1203 - accuracy: 0.9453\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9296\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9506\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9613\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9686\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9621\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.9640\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9818\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9806\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9707\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9775\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9597\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9671\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0879 - accuracy: 0.9521\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9380\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9567\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9424\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9697\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9695\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0824 - accuracy: 0.9694\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9788\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9741\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9669\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9642\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9558\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9585\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9658\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9744\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9650\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9795\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9549\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9767\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0592 - accuracy: 0.9758\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9664\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0742 - accuracy: 0.9736\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0784 - accuracy: 0.9723\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0598 - accuracy: 0.9726\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0536 - accuracy: 0.9777\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9819\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0494 - accuracy: 0.9859\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0437 - accuracy: 0.9786\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9766\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9784\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0536 - accuracy: 0.9795\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9863\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9840\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9648\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9567\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9701\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9718\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9768\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9724\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9862\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0379 - accuracy: 0.9851\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0378 - accuracy: 0.9893\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9756\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9703\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0568 - accuracy: 0.9787\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9755\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9826\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9712\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9843\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9769\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9712\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0735 - accuracy: 0.9692\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.9803\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0571 - accuracy: 0.9811\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9752\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0677 - accuracy: 0.9752\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9802\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0532 - accuracy: 0.9768\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9862\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0565 - accuracy: 0.9776\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9864\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0385 - accuracy: 0.9890\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0661 - accuracy: 0.9772\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0537 - accuracy: 0.9805\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0547 - accuracy: 0.9865\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9822\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0383 - accuracy: 0.9896\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0508 - accuracy: 0.9828\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9794\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9774\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9622\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1040 - accuracy: 0.9499\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0733 - accuracy: 0.9751\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0823 - accuracy: 0.9644\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0732 - accuracy: 0.9687\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9659\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0690 - accuracy: 0.9681\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9632\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9685\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9507\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9767\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9673\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9768\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9752\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9683\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9742\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9679\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0669 - accuracy: 0.9687\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9769\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9796\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9836\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0590 - accuracy: 0.9781\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0521 - accuracy: 0.9775\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0449 - accuracy: 0.9846\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0690 - accuracy: 0.9700\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0602 - accuracy: 0.9756\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0427 - accuracy: 0.9833\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0416 - accuracy: 0.9854\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0289 - accuracy: 0.9944\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0501 - accuracy: 0.9795\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9703\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9641\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0693 - accuracy: 0.9714\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9817\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9790\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9784\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0381 - accuracy: 0.9862\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0416 - accuracy: 0.9839\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9861\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9932\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9818\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9898\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9810\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9744\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9842\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9863\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 0.9791\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9905\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9947\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0523 - accuracy: 0.9813\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0474 - accuracy: 0.9805\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0914 - accuracy: 0.9607\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0791 - accuracy: 0.9642\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0508 - accuracy: 0.9832\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0283 - accuracy: 0.9899\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9826\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9799\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0208 - accuracy: 0.9955\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0489 - accuracy: 0.9851\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0199 - accuracy: 0.9949\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0335 - accuracy: 0.9887\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75bf0d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c77601160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7767a8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 11: 78\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 1.0399 - accuracy: 0.4706\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.6627\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.7217\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.7231\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.5604 - accuracy: 0.7118\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.5581 - accuracy: 0.7504\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.4914 - accuracy: 0.7613\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.5332 - accuracy: 0.7338\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.4676 - accuracy: 0.7909\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.4496 - accuracy: 0.7599\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.4442 - accuracy: 0.7865\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7835\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.5052 - accuracy: 0.7715\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.4602 - accuracy: 0.8070\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.4450 - accuracy: 0.7961\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.4044 - accuracy: 0.8253\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7959\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.4224 - accuracy: 0.8190\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.4019 - accuracy: 0.8351\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.3628 - accuracy: 0.8440\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.4086 - accuracy: 0.8347\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7978\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8458\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.3655 - accuracy: 0.8505\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.3661 - accuracy: 0.8392\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.3268 - accuracy: 0.8371\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.3627 - accuracy: 0.8430\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8380\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.3290 - accuracy: 0.8674\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.2962 - accuracy: 0.8722\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.2973 - accuracy: 0.8766\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.2986 - accuracy: 0.8834\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2864 - accuracy: 0.8762\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8848\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.3035 - accuracy: 0.8728\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8831\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.2626 - accuracy: 0.8968\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.2739 - accuracy: 0.8843\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2923 - accuracy: 0.8789\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.2517 - accuracy: 0.8678\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9174\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8864\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.2795 - accuracy: 0.8732\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.8946\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.2719 - accuracy: 0.8795\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2520 - accuracy: 0.9103\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.8777\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.8865\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.2235 - accuracy: 0.9130\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9131\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1896 - accuracy: 0.9014\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1834 - accuracy: 0.9166\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.9227\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1895 - accuracy: 0.9075\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1872 - accuracy: 0.8990\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1813 - accuracy: 0.9289\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.2006 - accuracy: 0.9220\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.2143 - accuracy: 0.8962\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1721 - accuracy: 0.9108\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.9159\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9212\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9310\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1781 - accuracy: 0.9125\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1997 - accuracy: 0.9273\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.2149 - accuracy: 0.8913\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1780 - accuracy: 0.9225\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1702 - accuracy: 0.9266\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9480\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1880 - accuracy: 0.9081\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1742 - accuracy: 0.9192\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9610\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1305 - accuracy: 0.9488\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1786 - accuracy: 0.9208\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1832 - accuracy: 0.9171\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1743 - accuracy: 0.9143\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1700 - accuracy: 0.9298\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1467 - accuracy: 0.9398\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1421 - accuracy: 0.9316\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1933 - accuracy: 0.9145\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1460 - accuracy: 0.9231\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9332\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1418 - accuracy: 0.9381\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9278\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1549 - accuracy: 0.9266\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1369 - accuracy: 0.9303\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.9344\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.1182 - accuracy: 0.9447\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1227 - accuracy: 0.9405\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1040 - accuracy: 0.9494\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9347\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1426 - accuracy: 0.9354\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1756 - accuracy: 0.9065\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1152 - accuracy: 0.9402\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1097 - accuracy: 0.9478\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9342\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.9191\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1279 - accuracy: 0.9252\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1702 - accuracy: 0.9161\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1739 - accuracy: 0.9085\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1120 - accuracy: 0.9403\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1031 - accuracy: 0.9439\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0969 - accuracy: 0.9589\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0974 - accuracy: 0.9588\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0979 - accuracy: 0.9507\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1210 - accuracy: 0.9409\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0918 - accuracy: 0.9660\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0912 - accuracy: 0.9627\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9501\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1361 - accuracy: 0.9488\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9496\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1601 - accuracy: 0.9125\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1786 - accuracy: 0.9044\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1397 - accuracy: 0.9264\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1558 - accuracy: 0.9213\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9378\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1011 - accuracy: 0.9394\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9562\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0913 - accuracy: 0.9531\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1315 - accuracy: 0.9379\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0998 - accuracy: 0.9511\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9619\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9489\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9448\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9580\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9533\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9454\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9490\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9632\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9559\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.9067\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9129\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9287\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9451\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9619\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9560\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9506\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9582\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9634\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9666\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9485\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9641\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9640\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9675\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9633\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9645\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1587 - accuracy: 0.9100\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.9135\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9347\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1288 - accuracy: 0.9274\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9465\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9441\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9567\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9606\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9597\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9509\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9524\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9649\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0505 - accuracy: 0.9853\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9655\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0971 - accuracy: 0.9660\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9513\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1115 - accuracy: 0.9484\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9435\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9577\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1030 - accuracy: 0.9505\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0849 - accuracy: 0.9698\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0706 - accuracy: 0.9666\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9617\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9667\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1198 - accuracy: 0.9533\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9544\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9662\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9459\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9646\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0905 - accuracy: 0.9679\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0934 - accuracy: 0.9547\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1232 - accuracy: 0.9353\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1178 - accuracy: 0.9439\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1513 - accuracy: 0.9188\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1146 - accuracy: 0.9359\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9610\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1972 - accuracy: 0.8981\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1600 - accuracy: 0.9009\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.2228 - accuracy: 0.8737\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.1031 - accuracy: 0.9491\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1086 - accuracy: 0.9468\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0890 - accuracy: 0.9529\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0955 - accuracy: 0.9488\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0859 - accuracy: 0.9528\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9372\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9486\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9491\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9398\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9483\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0812 - accuracy: 0.9569\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1487 - accuracy: 0.9205\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1500 - accuracy: 0.9091\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1121 - accuracy: 0.9426\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0963 - accuracy: 0.9576\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0929 - accuracy: 0.9505\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.7173 - accuracy: 0.7457\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.8221\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.8321\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8351\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8308\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.3651 - accuracy: 0.8459\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.3652 - accuracy: 0.8343\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.3575 - accuracy: 0.8284\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.3463 - accuracy: 0.8371\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.3315 - accuracy: 0.8510\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.3064 - accuracy: 0.8665\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.2998 - accuracy: 0.8540\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.2899 - accuracy: 0.8651\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.3147 - accuracy: 0.8624\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.2766 - accuracy: 0.8777\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2712 - accuracy: 0.8921\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.2716 - accuracy: 0.8616\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.2509 - accuracy: 0.8944\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.2219 - accuracy: 0.9000\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.2321 - accuracy: 0.9049\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.2252 - accuracy: 0.8926\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.2104 - accuracy: 0.9233\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1938 - accuracy: 0.9091\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.2092 - accuracy: 0.9061\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1588 - accuracy: 0.9390\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1840 - accuracy: 0.9141\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1768 - accuracy: 0.9248\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1736 - accuracy: 0.9232\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1504 - accuracy: 0.9334\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1969 - accuracy: 0.9028\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1817 - accuracy: 0.9204\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1627 - accuracy: 0.9143\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.2104 - accuracy: 0.9104\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1311 - accuracy: 0.9554\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1176 - accuracy: 0.9428\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1357 - accuracy: 0.9383\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1490 - accuracy: 0.9391\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1446 - accuracy: 0.9390\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9542\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1384 - accuracy: 0.9373\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 897us/step - loss: 0.1199 - accuracy: 0.9478\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0971 - accuracy: 0.9603\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1266 - accuracy: 0.9431\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1308 - accuracy: 0.9443\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9614\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1307 - accuracy: 0.9459\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1044 - accuracy: 0.9520\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0993 - accuracy: 0.9602\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0946 - accuracy: 0.9660\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1070 - accuracy: 0.9572\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1215 - accuracy: 0.9521\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1590 - accuracy: 0.9242\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1158 - accuracy: 0.9507\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0898 - accuracy: 0.9631\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1185 - accuracy: 0.9444\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1491 - accuracy: 0.9278\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1292 - accuracy: 0.9363\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0981 - accuracy: 0.9610\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0972 - accuracy: 0.9559\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1278 - accuracy: 0.9562\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1008 - accuracy: 0.9663\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0895 - accuracy: 0.9681\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0942 - accuracy: 0.9673\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1070 - accuracy: 0.9540\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0795 - accuracy: 0.9753\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0725 - accuracy: 0.9673\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0828 - accuracy: 0.9730\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0700 - accuracy: 0.9778\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0676 - accuracy: 0.9745\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0562 - accuracy: 0.9870\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0724 - accuracy: 0.9671\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0636 - accuracy: 0.9798\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0534 - accuracy: 0.9737\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0502 - accuracy: 0.9856\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0818 - accuracy: 0.9680\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.1571 - accuracy: 0.9401\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1179 - accuracy: 0.9524\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1278 - accuracy: 0.9379\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0944 - accuracy: 0.9612\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0745 - accuracy: 0.9714\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1063 - accuracy: 0.9492\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0838 - accuracy: 0.9660\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.1185 - accuracy: 0.9425\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1023 - accuracy: 0.9558\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0702 - accuracy: 0.9737\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0687 - accuracy: 0.9794\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1271 - accuracy: 0.9338\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1175 - accuracy: 0.9395\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0993 - accuracy: 0.9573\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0822 - accuracy: 0.9716\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0711 - accuracy: 0.9727\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0602 - accuracy: 0.9784\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0692 - accuracy: 0.9740\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0799 - accuracy: 0.9718\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0545 - accuracy: 0.9815\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0705 - accuracy: 0.9741\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0521 - accuracy: 0.9768\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0603 - accuracy: 0.9783\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0570 - accuracy: 0.9845\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0606 - accuracy: 0.9779\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0806 - accuracy: 0.9694\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0840 - accuracy: 0.9684\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0677 - accuracy: 0.9733\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0457 - accuracy: 0.9916\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0418 - accuracy: 0.9868\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0380 - accuracy: 0.9906\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0460 - accuracy: 0.9859\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0257 - accuracy: 0.9913\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0464 - accuracy: 0.9841\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0593 - accuracy: 0.9781\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0513 - accuracy: 0.9796\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0640 - accuracy: 0.9726\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0579 - accuracy: 0.9788\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0368 - accuracy: 0.9894\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.0608 - accuracy: 0.9768\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0733 - accuracy: 0.9645\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0747 - accuracy: 0.9682\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0797 - accuracy: 0.9726\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0786 - accuracy: 0.9709\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0687 - accuracy: 0.9707\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 895us/step - loss: 0.0658 - accuracy: 0.9783\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0770 - accuracy: 0.9738\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0826 - accuracy: 0.9684\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1046 - accuracy: 0.9609\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0568 - accuracy: 0.9799\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0490 - accuracy: 0.9782\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0578 - accuracy: 0.9796\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0602 - accuracy: 0.9805\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0580 - accuracy: 0.9749\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0675 - accuracy: 0.9716\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0455 - accuracy: 0.9796\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0558 - accuracy: 0.9806\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0542 - accuracy: 0.9789\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0479 - accuracy: 0.9847\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0373 - accuracy: 0.9897\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0570 - accuracy: 0.9804\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0613 - accuracy: 0.9747\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0442 - accuracy: 0.9819\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9855\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9873\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9704\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9812\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9812\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9914\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9869\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9750\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9662\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9848\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0424 - accuracy: 0.9847\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0274 - accuracy: 0.9903\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0469 - accuracy: 0.9786\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0539 - accuracy: 0.9797\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0547 - accuracy: 0.9789\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9842\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9834\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9918\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9859\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9889\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9720\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0612 - accuracy: 0.9775\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0363 - accuracy: 0.9864\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9867\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9908\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9957\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0512 - accuracy: 0.9805\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0605 - accuracy: 0.9758\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0637 - accuracy: 0.9778\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0357 - accuracy: 0.9873\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0405 - accuracy: 0.9854\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0404 - accuracy: 0.9837\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0562 - accuracy: 0.9790\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0322 - accuracy: 0.9880\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9812\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0627 - accuracy: 0.9761\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.0398 - accuracy: 0.9876\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0441 - accuracy: 0.9806\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0586 - accuracy: 0.9743\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0511 - accuracy: 0.9840\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0417 - accuracy: 0.9866\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0336 - accuracy: 0.9876\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0266 - accuracy: 0.9921\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0435 - accuracy: 0.9816\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0446 - accuracy: 0.9792\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0352 - accuracy: 0.9884\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0496 - accuracy: 0.9859\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0585 - accuracy: 0.9757\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0352 - accuracy: 0.9865\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0852 - accuracy: 0.9652\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0370 - accuracy: 0.9930\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0356 - accuracy: 0.9872\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0886 - accuracy: 0.9538\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0440 - accuracy: 0.9861\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0615 - accuracy: 0.9734\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0521 - accuracy: 0.9757\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0446 - accuracy: 0.9853\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0759 - accuracy: 0.9761\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0457 - accuracy: 0.9844\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0448 - accuracy: 0.9821\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0894 - accuracy: 0.9656\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8569 - accuracy: 0.6201\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.8368\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.4132 - accuracy: 0.8728\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.4311 - accuracy: 0.8540\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.3814 - accuracy: 0.8758\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.3694 - accuracy: 0.8854\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.3438 - accuracy: 0.8896\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.3720 - accuracy: 0.8496\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.3400 - accuracy: 0.8798\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.3403 - accuracy: 0.8683\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.3450 - accuracy: 0.8751\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.2735 - accuracy: 0.8882\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.2735 - accuracy: 0.8843\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.2985 - accuracy: 0.8769\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.3005 - accuracy: 0.8915\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.2606 - accuracy: 0.8885\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.2395 - accuracy: 0.9013\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.2389 - accuracy: 0.8881\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.2319 - accuracy: 0.8977\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.2312 - accuracy: 0.9084\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.2113 - accuracy: 0.9114\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.2169 - accuracy: 0.9103\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.2305 - accuracy: 0.8952\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.1953 - accuracy: 0.9175\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1895 - accuracy: 0.9243\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.1936 - accuracy: 0.9114\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1450 - accuracy: 0.9484\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9361\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1563 - accuracy: 0.9377\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1708 - accuracy: 0.9329\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1398 - accuracy: 0.9425\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1543 - accuracy: 0.9277\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.1886 - accuracy: 0.9222\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1653 - accuracy: 0.9256\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1898 - accuracy: 0.9256\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.1753 - accuracy: 0.9207\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1224 - accuracy: 0.9578\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.1473 - accuracy: 0.9404\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0995 - accuracy: 0.9616\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1171 - accuracy: 0.9542\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1507 - accuracy: 0.9357\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9736\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9580\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9554\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9500\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1053 - accuracy: 0.9647\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0722 - accuracy: 0.9756\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0868 - accuracy: 0.9679\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1106 - accuracy: 0.9523\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0950 - accuracy: 0.9597\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0950 - accuracy: 0.9641\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0672 - accuracy: 0.9698\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0804 - accuracy: 0.9697\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.1066 - accuracy: 0.9631\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0808 - accuracy: 0.9657\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0725 - accuracy: 0.9779\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0899 - accuracy: 0.9631\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1610 - accuracy: 0.9414\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0756 - accuracy: 0.9715\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0821 - accuracy: 0.9727\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0724 - accuracy: 0.9745\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0882 - accuracy: 0.9688\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.1217 - accuracy: 0.9583\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2045 - accuracy: 0.9360\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1217 - accuracy: 0.9494\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0857 - accuracy: 0.9631\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0879 - accuracy: 0.9679\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0548 - accuracy: 0.9797\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0637 - accuracy: 0.9677\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0638 - accuracy: 0.9748\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0879 - accuracy: 0.9652\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0760 - accuracy: 0.9704\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0667 - accuracy: 0.9748\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0593 - accuracy: 0.9773\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0640 - accuracy: 0.9788\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0366 - accuracy: 0.9914\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0505 - accuracy: 0.9836\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0769 - accuracy: 0.9677\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0624 - accuracy: 0.9717\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0460 - accuracy: 0.9814\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 882us/step - loss: 0.0425 - accuracy: 0.9871\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0678 - accuracy: 0.9696\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0265 - accuracy: 0.9930\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0398 - accuracy: 0.9865\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0844 - accuracy: 0.9618\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1266 - accuracy: 0.9522\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0604 - accuracy: 0.9798\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0684 - accuracy: 0.9696\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1568 - accuracy: 0.9432\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0781 - accuracy: 0.9707\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0810 - accuracy: 0.9679\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0660 - accuracy: 0.9740\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0486 - accuracy: 0.9866\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0545 - accuracy: 0.9832\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0821 - accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0965 - accuracy: 0.9541\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0710 - accuracy: 0.9677\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0451 - accuracy: 0.9882\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.0488 - accuracy: 0.9852\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9844\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.9703\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9652\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9789\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9762\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0400 - accuracy: 0.9888\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0831 - accuracy: 0.9669\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0554 - accuracy: 0.9767\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0665 - accuracy: 0.9704\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0799 - accuracy: 0.9704\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0403 - accuracy: 0.9885\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0607 - accuracy: 0.9774\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0563 - accuracy: 0.9762\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0625 - accuracy: 0.9745\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0599 - accuracy: 0.9794\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0873 - accuracy: 0.9582\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0747 - accuracy: 0.9719\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0840 - accuracy: 0.9629\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0639 - accuracy: 0.9721\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0458 - accuracy: 0.9909\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0738 - accuracy: 0.9663\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0415 - accuracy: 0.9832\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0414 - accuracy: 0.9862\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0511 - accuracy: 0.9811\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0586 - accuracy: 0.9776\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1103 - accuracy: 0.9640\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0398 - accuracy: 0.9869\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0763 - accuracy: 0.9674\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0595 - accuracy: 0.9764\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0627 - accuracy: 0.9797\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0583 - accuracy: 0.9792\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0692 - accuracy: 0.9655\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1077 - accuracy: 0.9544\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0775 - accuracy: 0.9615\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0614 - accuracy: 0.9756\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0528 - accuracy: 0.9818\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0528 - accuracy: 0.9893\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.1008 - accuracy: 0.9485\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0504 - accuracy: 0.9837\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0433 - accuracy: 0.9830\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0359 - accuracy: 0.9900\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0405 - accuracy: 0.9870\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0361 - accuracy: 0.9896\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0758 - accuracy: 0.9692\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0868 - accuracy: 0.9626\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0943 - accuracy: 0.9550\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0553 - accuracy: 0.9777\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0644 - accuracy: 0.9763\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0589 - accuracy: 0.9779\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0805 - accuracy: 0.9698\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0758 - accuracy: 0.9701\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0889 - accuracy: 0.9510\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0883 - accuracy: 0.9595\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0562 - accuracy: 0.9805\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0594 - accuracy: 0.9794\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0644 - accuracy: 0.9720\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0474 - accuracy: 0.9815\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0372 - accuracy: 0.9888\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0476 - accuracy: 0.9834\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0600 - accuracy: 0.9780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0719 - accuracy: 0.9753\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0701 - accuracy: 0.9672\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0827 - accuracy: 0.9662\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1134 - accuracy: 0.9508\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0789 - accuracy: 0.9635\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0984 - accuracy: 0.9486\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1375 - accuracy: 0.9332\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0873 - accuracy: 0.9589\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0726 - accuracy: 0.9647\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0525 - accuracy: 0.9786\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0858 - accuracy: 0.9604\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0793 - accuracy: 0.9604\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0511 - accuracy: 0.9866\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0552 - accuracy: 0.9788\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0472 - accuracy: 0.9809\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0564 - accuracy: 0.9768\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0664 - accuracy: 0.9687\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0770 - accuracy: 0.9586\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0526 - accuracy: 0.9813\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9711\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9748\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0438 - accuracy: 0.9831\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0498 - accuracy: 0.9801\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0442 - accuracy: 0.9836\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0410 - accuracy: 0.9843\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0344 - accuracy: 0.9892\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0291 - accuracy: 0.9928\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9978\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9943\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9821\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0376 - accuracy: 0.9893\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0195 - accuracy: 0.9954\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0379 - accuracy: 0.9849\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0241 - accuracy: 0.9927\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0283 - accuracy: 0.9891\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0262 - accuracy: 0.9933\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0474 - accuracy: 0.9844\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0535 - accuracy: 0.9827\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0654 - accuracy: 0.9738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7ae1c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7ae1cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c78cd5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 12: 91\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 983us/step - loss: 0.9906 - accuracy: 0.4532\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.7353 - accuracy: 0.6318\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.6170 - accuracy: 0.6832\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.6443 - accuracy: 0.6605\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.5846 - accuracy: 0.6945\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.5594 - accuracy: 0.7261\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.5584 - accuracy: 0.7323\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.5120 - accuracy: 0.7539\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.5115 - accuracy: 0.7441\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.5253 - accuracy: 0.7392\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.4590 - accuracy: 0.7760\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.5117 - accuracy: 0.7595\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.4793 - accuracy: 0.7660\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.4565 - accuracy: 0.7874\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.4992 - accuracy: 0.7689\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.4410 - accuracy: 0.7834\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.4431 - accuracy: 0.7780\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.4254 - accuracy: 0.8146\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.4286 - accuracy: 0.8013\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.4295 - accuracy: 0.7997\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.4313 - accuracy: 0.7969\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.4037 - accuracy: 0.7954\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.4049 - accuracy: 0.8095\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.4190 - accuracy: 0.8104\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.3919 - accuracy: 0.8307\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.3432 - accuracy: 0.8518\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.3880 - accuracy: 0.8280\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.3642 - accuracy: 0.8468\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.3686 - accuracy: 0.8303\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.3621 - accuracy: 0.8374\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.3334 - accuracy: 0.8702\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.3189 - accuracy: 0.8603\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.3387 - accuracy: 0.8570\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.3230 - accuracy: 0.8701\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.3141 - accuracy: 0.8626\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.2969 - accuracy: 0.8784\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.2596 - accuracy: 0.8887\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.3084 - accuracy: 0.8571\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.2482 - accuracy: 0.8928\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.2592 - accuracy: 0.8795\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.2670 - accuracy: 0.8806\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.2485 - accuracy: 0.8951\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.2704 - accuracy: 0.8861\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.2813 - accuracy: 0.8715\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.2489 - accuracy: 0.8939\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.2481 - accuracy: 0.9026\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.2457 - accuracy: 0.8864\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2261 - accuracy: 0.9108\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.2234 - accuracy: 0.9110\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1851 - accuracy: 0.9192\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.2059 - accuracy: 0.9144\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1485 - accuracy: 0.9449\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.2111 - accuracy: 0.9044\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1974 - accuracy: 0.9108\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.2015 - accuracy: 0.9093\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1842 - accuracy: 0.9223\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1764 - accuracy: 0.9169\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.2174 - accuracy: 0.8804\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.2242 - accuracy: 0.9097\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.2096 - accuracy: 0.9169\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1908 - accuracy: 0.9143\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.1749 - accuracy: 0.9120\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1530 - accuracy: 0.9324\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1453 - accuracy: 0.9301\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.1544 - accuracy: 0.9279\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1681 - accuracy: 0.9233\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.2183 - accuracy: 0.9145\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1903 - accuracy: 0.9225\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.2201 - accuracy: 0.8961\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.2287 - accuracy: 0.8910\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1780 - accuracy: 0.9258\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.2390 - accuracy: 0.8751\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 824us/step - loss: 0.1906 - accuracy: 0.9169\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1585 - accuracy: 0.9259\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1941 - accuracy: 0.8985\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1870 - accuracy: 0.9102\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1650 - accuracy: 0.9133\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1438 - accuracy: 0.9409\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.2154 - accuracy: 0.9033\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.1425 - accuracy: 0.9343\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1641 - accuracy: 0.9171\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.1603 - accuracy: 0.9252\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1393 - accuracy: 0.9309\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.1492 - accuracy: 0.9426\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1685 - accuracy: 0.9331\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1637 - accuracy: 0.9198\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1707 - accuracy: 0.9260\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.1600 - accuracy: 0.9285\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1264 - accuracy: 0.9319\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1144 - accuracy: 0.9524\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9279\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9462\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.9309\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1718 - accuracy: 0.9307\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1150 - accuracy: 0.9369\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.1348 - accuracy: 0.9442\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1066 - accuracy: 0.9582\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.1110 - accuracy: 0.9458\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.1096 - accuracy: 0.9500\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1584 - accuracy: 0.9414\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.1800 - accuracy: 0.9121\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.1393 - accuracy: 0.9315\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1401 - accuracy: 0.9205\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1196 - accuracy: 0.9457\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1066 - accuracy: 0.9366\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1640 - accuracy: 0.9246\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1871 - accuracy: 0.8924\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.1721 - accuracy: 0.9168\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.1478 - accuracy: 0.9350\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1362 - accuracy: 0.9269\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1280 - accuracy: 0.9198\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.1654 - accuracy: 0.9064\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1869 - accuracy: 0.9110\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1157 - accuracy: 0.9339\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.1265 - accuracy: 0.9426\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.1762 - accuracy: 0.9108\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1233 - accuracy: 0.9377\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1312 - accuracy: 0.9395\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.1262 - accuracy: 0.9337\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.1122 - accuracy: 0.9477\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.1336 - accuracy: 0.9454\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.1448 - accuracy: 0.9186\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1536 - accuracy: 0.9225\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1247 - accuracy: 0.9292\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1490 - accuracy: 0.9150\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1521 - accuracy: 0.9274\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1492 - accuracy: 0.9361\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.1671 - accuracy: 0.9076\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1310 - accuracy: 0.9358\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.1328 - accuracy: 0.9393\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.1361 - accuracy: 0.9160\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1074 - accuracy: 0.9302\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1125 - accuracy: 0.9317\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.1173 - accuracy: 0.9287\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.1366 - accuracy: 0.9268\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1374 - accuracy: 0.9218\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.1296 - accuracy: 0.9402\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.1337 - accuracy: 0.9223\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1068 - accuracy: 0.9477\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.1253 - accuracy: 0.9363\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9351\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.9234\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9170\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9427\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9450\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9334\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9350\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9282\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1255 - accuracy: 0.9366\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1476 - accuracy: 0.9289\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0930 - accuracy: 0.9437\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1341 - accuracy: 0.9303\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 872us/step - loss: 0.1421 - accuracy: 0.9415\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1064 - accuracy: 0.9394\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1366 - accuracy: 0.9386\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9381\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9362\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9440\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9239\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9448\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9369\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0880 - accuracy: 0.9547\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1287 - accuracy: 0.9215\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9260\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1108 - accuracy: 0.9262\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1050 - accuracy: 0.9290\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1213 - accuracy: 0.9446\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1066 - accuracy: 0.9355\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.1003 - accuracy: 0.9412\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0925 - accuracy: 0.9508\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1106 - accuracy: 0.9396\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1562 - accuracy: 0.9184\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.1172 - accuracy: 0.9517\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0977 - accuracy: 0.9416\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1169 - accuracy: 0.9278\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1207 - accuracy: 0.9273\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0997 - accuracy: 0.9474\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1179 - accuracy: 0.9372\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.1307 - accuracy: 0.9365\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0947 - accuracy: 0.9547\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0825 - accuracy: 0.9553\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0868 - accuracy: 0.9401\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0884 - accuracy: 0.9470\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0800 - accuracy: 0.9492\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1196 - accuracy: 0.9380\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.1431 - accuracy: 0.9214\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0921 - accuracy: 0.9510\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0791 - accuracy: 0.9630\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0931 - accuracy: 0.9432\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1121 - accuracy: 0.9355\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1377 - accuracy: 0.9402\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1232 - accuracy: 0.9354\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.1235 - accuracy: 0.9522\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1719 - accuracy: 0.9297\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1226 - accuracy: 0.9423\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0980 - accuracy: 0.9567\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1147 - accuracy: 0.9509\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0948 - accuracy: 0.9666\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1238 - accuracy: 0.9484\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0936 - accuracy: 0.9546\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.9133 - accuracy: 0.5904\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.5348 - accuracy: 0.7994\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.4481 - accuracy: 0.8239\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.4219 - accuracy: 0.8293\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.3897 - accuracy: 0.8458\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.8290\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8612\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.3593 - accuracy: 0.8491\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.3795 - accuracy: 0.8393\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.3454 - accuracy: 0.8418\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.3166 - accuracy: 0.8602\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.3294 - accuracy: 0.8552\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.3290 - accuracy: 0.8386\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.2884 - accuracy: 0.8621\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.2886 - accuracy: 0.8725\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.3108 - accuracy: 0.8503\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.2947 - accuracy: 0.8563\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.2798 - accuracy: 0.8970\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.2714 - accuracy: 0.8889\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.2697 - accuracy: 0.8638\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.2798 - accuracy: 0.8506\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.2541 - accuracy: 0.8810\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.2382 - accuracy: 0.8795\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.2377 - accuracy: 0.8888\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.2369 - accuracy: 0.8807\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.2411 - accuracy: 0.8805\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.2021 - accuracy: 0.8994\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.1959 - accuracy: 0.9090\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1927 - accuracy: 0.9218\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.2211 - accuracy: 0.9004\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.2215 - accuracy: 0.9029\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.8942\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 893us/step - loss: 0.1899 - accuracy: 0.9208\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.1895 - accuracy: 0.9097\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1763 - accuracy: 0.9264\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.1462 - accuracy: 0.9374\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1710 - accuracy: 0.9156\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1744 - accuracy: 0.9200\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1626 - accuracy: 0.9272\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.1930 - accuracy: 0.8961\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.1490 - accuracy: 0.9405\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1557 - accuracy: 0.9277\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1257 - accuracy: 0.9450\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1333 - accuracy: 0.9507\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.1295 - accuracy: 0.9469\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9259\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.9162\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.9329\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1470 - accuracy: 0.9287\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1644 - accuracy: 0.9241\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1596 - accuracy: 0.9185\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.1331 - accuracy: 0.9381\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.1469 - accuracy: 0.9332\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1438 - accuracy: 0.9395\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1367 - accuracy: 0.9416\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.1069 - accuracy: 0.9583\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1296 - accuracy: 0.9546\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1221 - accuracy: 0.9454\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1013 - accuracy: 0.9668\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1058 - accuracy: 0.9612\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.1200 - accuracy: 0.9521\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.1289 - accuracy: 0.9450\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.1201 - accuracy: 0.9465\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1061 - accuracy: 0.9483\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.1109 - accuracy: 0.9542\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1223 - accuracy: 0.9574\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1607 - accuracy: 0.9318\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1363 - accuracy: 0.9340\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1045 - accuracy: 0.9593\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1264 - accuracy: 0.9402\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1401 - accuracy: 0.9333\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1080 - accuracy: 0.9422\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1242 - accuracy: 0.9431\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.1483 - accuracy: 0.9253\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0992 - accuracy: 0.9566\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.1111 - accuracy: 0.9497\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1653 - accuracy: 0.9103\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0849 - accuracy: 0.9647\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0996 - accuracy: 0.9661\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0784 - accuracy: 0.9722\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0975 - accuracy: 0.9594\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0972 - accuracy: 0.9628\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0972 - accuracy: 0.9568\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0698 - accuracy: 0.9715\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0730 - accuracy: 0.9679\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0619 - accuracy: 0.9785\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0587 - accuracy: 0.9809\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0746 - accuracy: 0.9736\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1223 - accuracy: 0.9464\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0857 - accuracy: 0.9685\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0781 - accuracy: 0.9730\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0831 - accuracy: 0.9643\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0872 - accuracy: 0.9625\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0758 - accuracy: 0.9715\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0940 - accuracy: 0.9576\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0946 - accuracy: 0.9597\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1060 - accuracy: 0.9630\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0823 - accuracy: 0.9657\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0650 - accuracy: 0.9751\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0776 - accuracy: 0.9726\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0968 - accuracy: 0.9644\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0917 - accuracy: 0.9703\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0888 - accuracy: 0.9653\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0933 - accuracy: 0.9658\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0875 - accuracy: 0.9583\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0895 - accuracy: 0.9592\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9704\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0591 - accuracy: 0.9823\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9742\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9813\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9567\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9562\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 997us/step - loss: 0.0855 - accuracy: 0.9688\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1027 - accuracy: 0.9549\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0655 - accuracy: 0.9739\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0888 - accuracy: 0.9627\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0768 - accuracy: 0.9629\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0834 - accuracy: 0.9657\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0988 - accuracy: 0.9571\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1066 - accuracy: 0.9524\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0716 - accuracy: 0.9758\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0771 - accuracy: 0.9647\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0660 - accuracy: 0.9729\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0924 - accuracy: 0.9586\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0750 - accuracy: 0.9670\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0842 - accuracy: 0.9649\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0388 - accuracy: 0.9932\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0662 - accuracy: 0.9788\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0732 - accuracy: 0.9723\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0531 - accuracy: 0.9807\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0475 - accuracy: 0.9884\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0954 - accuracy: 0.9600\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0607 - accuracy: 0.9733\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0778 - accuracy: 0.9635\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0785 - accuracy: 0.9671\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0944 - accuracy: 0.9670\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0528 - accuracy: 0.9840\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0850 - accuracy: 0.9590\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0620 - accuracy: 0.9797\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0571 - accuracy: 0.9798\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0419 - accuracy: 0.9849\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0374 - accuracy: 0.9899\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1080 - accuracy: 0.9688\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0652 - accuracy: 0.9732\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0437 - accuracy: 0.9888\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0448 - accuracy: 0.9833\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0694 - accuracy: 0.9809\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0409 - accuracy: 0.9875\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0734 - accuracy: 0.9764\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0541 - accuracy: 0.9822\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0475 - accuracy: 0.9843\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0694 - accuracy: 0.9727\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0562 - accuracy: 0.9795\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0460 - accuracy: 0.9849\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0721 - accuracy: 0.9719\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0581 - accuracy: 0.9795\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0542 - accuracy: 0.9839\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0464 - accuracy: 0.9860\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0355 - accuracy: 0.9871\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0399 - accuracy: 0.9860\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0565 - accuracy: 0.9775\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9932\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0517 - accuracy: 0.9834\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0482 - accuracy: 0.9852\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0325 - accuracy: 0.9910\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0390 - accuracy: 0.9900\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1019 - accuracy: 0.9704\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0546 - accuracy: 0.9844\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0718 - accuracy: 0.9747\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0657 - accuracy: 0.9756\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.0392 - accuracy: 0.9936\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0479 - accuracy: 0.9829\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0524 - accuracy: 0.9786\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.1133 - accuracy: 0.9529\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0526 - accuracy: 0.9779\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0639 - accuracy: 0.9731\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0784 - accuracy: 0.9666\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0783 - accuracy: 0.9671\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0628 - accuracy: 0.9792\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0330 - accuracy: 0.9924\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0742 - accuracy: 0.9701\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0650 - accuracy: 0.9766\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0625 - accuracy: 0.9743\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0736 - accuracy: 0.9621\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0637 - accuracy: 0.9743\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0437 - accuracy: 0.9881\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0395 - accuracy: 0.9879\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0598 - accuracy: 0.9746\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0740 - accuracy: 0.9694\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0991 - accuracy: 0.9588\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0641 - accuracy: 0.9752\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 757us/step - loss: 0.0572 - accuracy: 0.9831\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0530 - accuracy: 0.9845\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0636 - accuracy: 0.9765\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0658 - accuracy: 0.9733\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0571 - accuracy: 0.9773\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0568 - accuracy: 0.9780\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0538 - accuracy: 0.9810\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0531 - accuracy: 0.9818\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0579 - accuracy: 0.9759\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.6487 - accuracy: 0.7804\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.4635 - accuracy: 0.8569\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.4013 - accuracy: 0.8707\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.3822 - accuracy: 0.8695\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.3631 - accuracy: 0.8703\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.3651 - accuracy: 0.8758\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.3322 - accuracy: 0.8819\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.3583 - accuracy: 0.8720\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.3181 - accuracy: 0.8782\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8724\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.2854 - accuracy: 0.8754\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.2568 - accuracy: 0.8883\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.3006 - accuracy: 0.8798\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.2639 - accuracy: 0.8820\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.2284 - accuracy: 0.8896\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2597 - accuracy: 0.8802\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9017\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.2337 - accuracy: 0.9028\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.2332 - accuracy: 0.8954\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1977 - accuracy: 0.9295\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.2080 - accuracy: 0.9121\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1916 - accuracy: 0.9283\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.2029 - accuracy: 0.9195\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1982 - accuracy: 0.9283\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.1824 - accuracy: 0.9214\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.2301 - accuracy: 0.9162\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1946 - accuracy: 0.9212\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1906 - accuracy: 0.9235\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.1635 - accuracy: 0.9463\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.2276 - accuracy: 0.9122\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.2288 - accuracy: 0.8962\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1863 - accuracy: 0.9114\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.1371 - accuracy: 0.9338\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9152\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9349\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1496 - accuracy: 0.9389\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1342 - accuracy: 0.9519\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.1307 - accuracy: 0.9460\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1268 - accuracy: 0.9606\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1146 - accuracy: 0.9596\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0816 - accuracy: 0.9677\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.1474 - accuracy: 0.9338\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.1127 - accuracy: 0.9603\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1262 - accuracy: 0.9493\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1181 - accuracy: 0.9617\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1481 - accuracy: 0.9441\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.1460 - accuracy: 0.9477\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.1233 - accuracy: 0.9431\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1144 - accuracy: 0.9570\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.1090 - accuracy: 0.9569\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0878 - accuracy: 0.9754\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0753 - accuracy: 0.9730\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0587 - accuracy: 0.9882\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0779 - accuracy: 0.9627\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.1165 - accuracy: 0.9525\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1212 - accuracy: 0.9505\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.1351 - accuracy: 0.9408\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0981 - accuracy: 0.9601\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1131 - accuracy: 0.9531\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0956 - accuracy: 0.9694\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0937 - accuracy: 0.9658\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0743 - accuracy: 0.9730\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0627 - accuracy: 0.9706\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.1026 - accuracy: 0.9543\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0836 - accuracy: 0.9634\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0662 - accuracy: 0.9777\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0676 - accuracy: 0.9788\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0645 - accuracy: 0.9769\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0593 - accuracy: 0.9761\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0670 - accuracy: 0.9801\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.1027 - accuracy: 0.9608\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 756us/step - loss: 0.1110 - accuracy: 0.9505\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0802 - accuracy: 0.9692\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0721 - accuracy: 0.9663\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.1316 - accuracy: 0.9460\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0894 - accuracy: 0.9660\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0697 - accuracy: 0.9752\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0682 - accuracy: 0.9734\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0450 - accuracy: 0.9879\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0606 - accuracy: 0.9746\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0481 - accuracy: 0.9859\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0343 - accuracy: 0.9895\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0795 - accuracy: 0.9688\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0438 - accuracy: 0.9881\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0708 - accuracy: 0.9690\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0668 - accuracy: 0.9736\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0480 - accuracy: 0.9831\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1033 - accuracy: 0.9549\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0550 - accuracy: 0.9809\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0514 - accuracy: 0.9809\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.0852 - accuracy: 0.9666\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0927 - accuracy: 0.9693\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0655 - accuracy: 0.9730\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0589 - accuracy: 0.9824\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0449 - accuracy: 0.9869\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0550 - accuracy: 0.9828\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0513 - accuracy: 0.9834\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0421 - accuracy: 0.9871\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0592 - accuracy: 0.9775\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0689 - accuracy: 0.9747\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0785 - accuracy: 0.9677\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0737 - accuracy: 0.9738\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9570\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0587 - accuracy: 0.9795\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0778 - accuracy: 0.9744\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0850 - accuracy: 0.9622\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0793 - accuracy: 0.9688\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0583 - accuracy: 0.9769\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9749\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0723 - accuracy: 0.9684\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0639 - accuracy: 0.9726\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0611 - accuracy: 0.9770\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0825 - accuracy: 0.9708\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0845 - accuracy: 0.9662\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9835\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0785 - accuracy: 0.9684\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0903 - accuracy: 0.9594\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0557 - accuracy: 0.9842\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0597 - accuracy: 0.9795\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0728 - accuracy: 0.9748\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0393 - accuracy: 0.9904\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0525 - accuracy: 0.9811\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0311 - accuracy: 0.9918\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0482 - accuracy: 0.9825\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0420 - accuracy: 0.9851\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0985 - accuracy: 0.9551\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0809 - accuracy: 0.9546\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0673 - accuracy: 0.9751\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0509 - accuracy: 0.9774\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9848\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0279 - accuracy: 0.9923\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0473 - accuracy: 0.9862\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0649 - accuracy: 0.9808\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0688 - accuracy: 0.9778\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0457 - accuracy: 0.9834\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0491 - accuracy: 0.9839\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0618 - accuracy: 0.9779\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0353 - accuracy: 0.9900\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0530 - accuracy: 0.9797\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0407 - accuracy: 0.9853\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0606 - accuracy: 0.9820\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0335 - accuracy: 0.9883\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9968\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9836\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9842\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9742\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9934\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0438 - accuracy: 0.9878\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0468 - accuracy: 0.9793\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1065 - accuracy: 0.9667\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 862us/step - loss: 0.0334 - accuracy: 0.9864\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0704 - accuracy: 0.9698\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0369 - accuracy: 0.9884\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0286 - accuracy: 0.9917\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0259 - accuracy: 0.9909\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0262 - accuracy: 0.9884\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0518 - accuracy: 0.9806\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0467 - accuracy: 0.9888\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0428 - accuracy: 0.9871\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0539 - accuracy: 0.9782\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0512 - accuracy: 0.9793\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0541 - accuracy: 0.9871\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0456 - accuracy: 0.9875\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0516 - accuracy: 0.9799\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0253 - accuracy: 0.9946\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0313 - accuracy: 0.9881\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0619 - accuracy: 0.9797\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0334 - accuracy: 0.9924\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0361 - accuracy: 0.9873\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0355 - accuracy: 0.9899\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0459 - accuracy: 0.9857\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0287 - accuracy: 0.9925\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9965\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9791\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9834\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9905\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9922\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9930\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9858\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.9957\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9961\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9871\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9913\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9897\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9922\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9884\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9803\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0442 - accuracy: 0.9886\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9871\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9843\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9613\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9702\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9827\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9854\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9887\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9941\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9882\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9886\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9919\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7b7a6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75b66af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c750b81f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 13: 78\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8298 - accuracy: 0.6223\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.7017\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.7259\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.7160\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.5785 - accuracy: 0.7166\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.5627 - accuracy: 0.7180\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.5322 - accuracy: 0.7338\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7324\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7683\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7514\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.4822 - accuracy: 0.7853\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.4546 - accuracy: 0.7866\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.4407 - accuracy: 0.8004\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.4488 - accuracy: 0.7944\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.4797 - accuracy: 0.7789\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.4208 - accuracy: 0.8100\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.4154 - accuracy: 0.7965\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.4173 - accuracy: 0.8116\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.3867 - accuracy: 0.8170\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.3917 - accuracy: 0.8131\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.3900 - accuracy: 0.8356\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.3568 - accuracy: 0.8532\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.3514 - accuracy: 0.8523\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.3533 - accuracy: 0.8356\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.4061 - accuracy: 0.8220\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.3580 - accuracy: 0.8420\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.3498 - accuracy: 0.8686\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.3306 - accuracy: 0.8581\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.3259 - accuracy: 0.8664\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.3508 - accuracy: 0.8453\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.3357 - accuracy: 0.8584\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.2959 - accuracy: 0.8621\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.2655 - accuracy: 0.8890\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.2542 - accuracy: 0.8963\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.2736 - accuracy: 0.8788\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.2577 - accuracy: 0.9028\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.2555 - accuracy: 0.8914\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.2302 - accuracy: 0.9067\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.2779 - accuracy: 0.8862\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.2368 - accuracy: 0.8953\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.2853 - accuracy: 0.8720\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.2283 - accuracy: 0.9202\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.2288 - accuracy: 0.9000\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.2317 - accuracy: 0.8749\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.2510 - accuracy: 0.9008\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.2667 - accuracy: 0.8640\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.3056 - accuracy: 0.8563\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.2917 - accuracy: 0.8663\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.2310 - accuracy: 0.8919\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8848\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.2651 - accuracy: 0.8716\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.2386 - accuracy: 0.8846\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.2115 - accuracy: 0.8942\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2377 - accuracy: 0.8799\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.2624 - accuracy: 0.8895\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.2211 - accuracy: 0.8986\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.2199 - accuracy: 0.8969\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.2354 - accuracy: 0.8779\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1941 - accuracy: 0.9099\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1951 - accuracy: 0.9044\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.2298 - accuracy: 0.8836\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.2441 - accuracy: 0.8719\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9230\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.8922\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.8976\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1901 - accuracy: 0.9106\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.2326 - accuracy: 0.8752\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1569 - accuracy: 0.9176\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.1828 - accuracy: 0.9157\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1983 - accuracy: 0.8868\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1947 - accuracy: 0.9008\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.2545 - accuracy: 0.8861\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.2730 - accuracy: 0.8856\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 811us/step - loss: 0.2330 - accuracy: 0.8984\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.2394 - accuracy: 0.8766\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1975 - accuracy: 0.8986\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.8940\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.8981\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9151\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.2319 - accuracy: 0.8910\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.2113 - accuracy: 0.9066\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.1850 - accuracy: 0.9129\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.1832 - accuracy: 0.9259\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.1733 - accuracy: 0.9149\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.2624 - accuracy: 0.8296\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.2092 - accuracy: 0.8744\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.2071 - accuracy: 0.9030\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9029\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.9061\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9294\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9057\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9067\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9062\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1678 - accuracy: 0.8965\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9019\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9188\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9059\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9131\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9113\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.8947\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.8973\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.9107\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1663 - accuracy: 0.9011\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2150 - accuracy: 0.8903\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.2000 - accuracy: 0.8706\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.2110 - accuracy: 0.8628\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.2007 - accuracy: 0.9052\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.2201 - accuracy: 0.8987\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.1470 - accuracy: 0.9234\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.1592 - accuracy: 0.8997\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1586 - accuracy: 0.9127\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.1863 - accuracy: 0.8717\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.2076 - accuracy: 0.8726\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.1617 - accuracy: 0.9232\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1367 - accuracy: 0.9243\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1279 - accuracy: 0.9379\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.1756 - accuracy: 0.9017\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1653 - accuracy: 0.8930\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1354 - accuracy: 0.9255\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.1466 - accuracy: 0.9141\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.1701 - accuracy: 0.8989\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1536 - accuracy: 0.9250\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.2213 - accuracy: 0.9062\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.2103 - accuracy: 0.9009\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.2077 - accuracy: 0.9034\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1905 - accuracy: 0.9055\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1750 - accuracy: 0.9021\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.1487 - accuracy: 0.9140\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1223 - accuracy: 0.9253\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9331\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9206\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9176\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9172\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9255\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9272\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9341\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9108\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.8978\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9070\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1519 - accuracy: 0.9020\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9005\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9190\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9391\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9268\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9116\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1727 - accuracy: 0.8977\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.8943\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9241\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9121\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9314\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9362\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9258\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9396\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9359\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9499\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9213\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9350\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9598\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9269\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9339\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9286\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1280 - accuracy: 0.9401\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0894 - accuracy: 0.9576\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1175 - accuracy: 0.9277\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0910 - accuracy: 0.9476\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1146 - accuracy: 0.9307\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1191 - accuracy: 0.9308\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9061\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9469\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9288\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1199 - accuracy: 0.9419\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.1209 - accuracy: 0.9416\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1072 - accuracy: 0.9377\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.1718 - accuracy: 0.9139\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.1845 - accuracy: 0.8935\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.1351 - accuracy: 0.9158\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1043 - accuracy: 0.9414\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.1248 - accuracy: 0.9367\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.0927 - accuracy: 0.9505\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.1690 - accuracy: 0.9139\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.2455 - accuracy: 0.8643\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1797 - accuracy: 0.8913\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1620 - accuracy: 0.8951\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1514 - accuracy: 0.8952\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1485 - accuracy: 0.9224\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1487 - accuracy: 0.9142\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1643 - accuracy: 0.9058\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1340 - accuracy: 0.9391\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1183 - accuracy: 0.9447\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0988 - accuracy: 0.9513\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1090 - accuracy: 0.9441\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1108 - accuracy: 0.9501\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0867 - accuracy: 0.9539\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0920 - accuracy: 0.9566\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1621 - accuracy: 0.9081\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1499 - accuracy: 0.9217\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.1560 - accuracy: 0.9108\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.1470 - accuracy: 0.9168\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1361 - accuracy: 0.9246\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.1188 - accuracy: 0.9482\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.6335 - accuracy: 0.7137\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.4725 - accuracy: 0.8337\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.4746 - accuracy: 0.8171\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.4273 - accuracy: 0.8263\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.3878 - accuracy: 0.8199\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.3704 - accuracy: 0.8348\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.3806 - accuracy: 0.8317\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.4045 - accuracy: 0.8455\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.3357 - accuracy: 0.8398\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.3540 - accuracy: 0.8162\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.2979 - accuracy: 0.8509\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.2990 - accuracy: 0.8587\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.3123 - accuracy: 0.8549\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.2581 - accuracy: 0.8818\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.2594 - accuracy: 0.8684\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.8848\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.2681 - accuracy: 0.8801\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.2570 - accuracy: 0.8797\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.2523 - accuracy: 0.8772\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.2161 - accuracy: 0.9005\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.2163 - accuracy: 0.8975\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.1917 - accuracy: 0.9056\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.2360 - accuracy: 0.8934\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.2005 - accuracy: 0.8938\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9355\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.8858\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9195\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1913 - accuracy: 0.9124\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1777 - accuracy: 0.9197\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1843 - accuracy: 0.9139\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.2011 - accuracy: 0.8981\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.2070 - accuracy: 0.9042\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1582 - accuracy: 0.9242\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 845us/step - loss: 0.1402 - accuracy: 0.9325\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1552 - accuracy: 0.9505\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1433 - accuracy: 0.9319\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1315 - accuracy: 0.9520\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1189 - accuracy: 0.9588\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1388 - accuracy: 0.9405\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1279 - accuracy: 0.9476\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1689 - accuracy: 0.9187\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1506 - accuracy: 0.9321\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1032 - accuracy: 0.9531\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1171 - accuracy: 0.9480\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0943 - accuracy: 0.9616\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1105 - accuracy: 0.9536\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1450 - accuracy: 0.9339\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1400 - accuracy: 0.9406\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1156 - accuracy: 0.9518\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1222 - accuracy: 0.9343\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1190 - accuracy: 0.9319\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1490 - accuracy: 0.9405\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1440 - accuracy: 0.9316\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1324 - accuracy: 0.9261\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1338 - accuracy: 0.9358\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1365 - accuracy: 0.9133\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1264 - accuracy: 0.9328\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1381 - accuracy: 0.9268\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1113 - accuracy: 0.9454\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9515\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1004 - accuracy: 0.9493\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0934 - accuracy: 0.9539\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9676\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1246 - accuracy: 0.9452\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1243 - accuracy: 0.9380\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.1426 - accuracy: 0.9291\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1137 - accuracy: 0.9443\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1188 - accuracy: 0.9415\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1158 - accuracy: 0.9363\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1201 - accuracy: 0.9401\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.1131 - accuracy: 0.9341\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.1229 - accuracy: 0.9254\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1403 - accuracy: 0.9234\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0999 - accuracy: 0.9593\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.1302 - accuracy: 0.9327\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1010 - accuracy: 0.9453\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0771 - accuracy: 0.9651\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0777 - accuracy: 0.9652\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1235 - accuracy: 0.9409\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0982 - accuracy: 0.9374\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0955 - accuracy: 0.9537\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1732 - accuracy: 0.9143\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0953 - accuracy: 0.9502\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0901 - accuracy: 0.9696\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.1014 - accuracy: 0.9576\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0697 - accuracy: 0.9727\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0946 - accuracy: 0.9551\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0901 - accuracy: 0.9584\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0837 - accuracy: 0.9561\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0710 - accuracy: 0.9621\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0825 - accuracy: 0.9554\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1129 - accuracy: 0.9398\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1363 - accuracy: 0.9366\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.1310 - accuracy: 0.9246\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1218 - accuracy: 0.9288\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0986 - accuracy: 0.9635\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1039 - accuracy: 0.9500\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1016 - accuracy: 0.9557\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0912 - accuracy: 0.9646\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1117 - accuracy: 0.9495\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1089 - accuracy: 0.9558\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9604\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9665\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9547\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9557\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0857 - accuracy: 0.9644\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0635 - accuracy: 0.9779\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0719 - accuracy: 0.9733\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0749 - accuracy: 0.9683\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0785 - accuracy: 0.9657\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0690 - accuracy: 0.9692\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1226 - accuracy: 0.9364\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0961 - accuracy: 0.9675\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 833us/step - loss: 0.0884 - accuracy: 0.9681\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0948 - accuracy: 0.9578\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0922 - accuracy: 0.9579\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0924 - accuracy: 0.9635\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0831 - accuracy: 0.9663\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0800 - accuracy: 0.9681\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0782 - accuracy: 0.9718\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0761 - accuracy: 0.9662\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0808 - accuracy: 0.9694\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0584 - accuracy: 0.9812\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0925 - accuracy: 0.9620\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0414 - accuracy: 0.9863\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0581 - accuracy: 0.9758\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0487 - accuracy: 0.9829\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0723 - accuracy: 0.9731\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9698\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0691 - accuracy: 0.9700\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0644 - accuracy: 0.9750\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0662 - accuracy: 0.9742\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0901 - accuracy: 0.9575\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.1459 - accuracy: 0.9334\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1319 - accuracy: 0.9424\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0991 - accuracy: 0.9537\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0940 - accuracy: 0.9601\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0670 - accuracy: 0.9758\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0800 - accuracy: 0.9697\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0897 - accuracy: 0.9614\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0866 - accuracy: 0.9673\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0707 - accuracy: 0.9751\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0948 - accuracy: 0.9699\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0665 - accuracy: 0.9687\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0796 - accuracy: 0.9679\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0804 - accuracy: 0.9634\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0774 - accuracy: 0.9630\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0992 - accuracy: 0.9590\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0744 - accuracy: 0.9713\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0845 - accuracy: 0.9638\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0821 - accuracy: 0.9601\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9745\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0664 - accuracy: 0.9688\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0787 - accuracy: 0.9682\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0681 - accuracy: 0.9724\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0764 - accuracy: 0.9666\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0849 - accuracy: 0.9667\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0582 - accuracy: 0.9778\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0591 - accuracy: 0.9696\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9776\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0932 - accuracy: 0.9574\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0793 - accuracy: 0.9674\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0856 - accuracy: 0.9608\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0746 - accuracy: 0.9689\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1034 - accuracy: 0.9496\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9669\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9521\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9746\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.9669\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0613 - accuracy: 0.9749\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0662 - accuracy: 0.9740\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0756 - accuracy: 0.9656\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0605 - accuracy: 0.9766\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0742 - accuracy: 0.9625\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0696 - accuracy: 0.9711\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1020 - accuracy: 0.9492\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1041 - accuracy: 0.9533\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0784 - accuracy: 0.9531\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0933 - accuracy: 0.9524\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0974 - accuracy: 0.9487\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1130 - accuracy: 0.9524\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0912 - accuracy: 0.9760\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0986 - accuracy: 0.9562\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0972 - accuracy: 0.9644\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1156 - accuracy: 0.9396\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0936 - accuracy: 0.9635\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0621 - accuracy: 0.9760\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0864 - accuracy: 0.9552\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0452 - accuracy: 0.9844\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0581 - accuracy: 0.9766\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9649\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0773 - accuracy: 0.9681\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9803\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0671 - accuracy: 0.9716\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0594 - accuracy: 0.9787\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0571 - accuracy: 0.9773\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0943 - accuracy: 0.9617\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0555 - accuracy: 0.9772\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0596 - accuracy: 0.9760\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0688 - accuracy: 0.9729\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.6236 - accuracy: 0.7925\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.4177 - accuracy: 0.8837\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.4007 - accuracy: 0.8676\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.3820 - accuracy: 0.8668\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.3839 - accuracy: 0.8713\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.3673 - accuracy: 0.8775\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.3820 - accuracy: 0.8768\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.2981 - accuracy: 0.8939\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.3610 - accuracy: 0.8692\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.3375 - accuracy: 0.8636\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.2968 - accuracy: 0.8736\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.2971 - accuracy: 0.8840\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.2694 - accuracy: 0.8911\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.2842 - accuracy: 0.8776\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.2537 - accuracy: 0.8972\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.2790 - accuracy: 0.8571\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.2409 - accuracy: 0.8843\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.2314 - accuracy: 0.9052\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.2115 - accuracy: 0.9050\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.2343 - accuracy: 0.8973\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1947 - accuracy: 0.9060\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.2585 - accuracy: 0.8987\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1875 - accuracy: 0.9273\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1857 - accuracy: 0.9313\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1847 - accuracy: 0.9413\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.1638 - accuracy: 0.9342\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1709 - accuracy: 0.9351\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1879 - accuracy: 0.9126\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.2050 - accuracy: 0.9260\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1629 - accuracy: 0.9401\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1982 - accuracy: 0.9279\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1401 - accuracy: 0.9559\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1378 - accuracy: 0.9387\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.1701 - accuracy: 0.9291\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.2327 - accuracy: 0.8917\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1556 - accuracy: 0.9405\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.1683 - accuracy: 0.9260\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1632 - accuracy: 0.9268\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.1494 - accuracy: 0.9360\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1930 - accuracy: 0.9155\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.1401 - accuracy: 0.9361\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1723 - accuracy: 0.9261\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1294 - accuracy: 0.9432\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1103 - accuracy: 0.9585\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1477 - accuracy: 0.9400\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1375 - accuracy: 0.9373\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1161 - accuracy: 0.9605\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1262 - accuracy: 0.9476\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.1265 - accuracy: 0.9573\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1229 - accuracy: 0.9543\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0799 - accuracy: 0.9696\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.1332 - accuracy: 0.9412\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1214 - accuracy: 0.9493\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.1215 - accuracy: 0.9439\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1264 - accuracy: 0.9383\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0945 - accuracy: 0.9615\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0811 - accuracy: 0.9694\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0816 - accuracy: 0.9716\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0860 - accuracy: 0.9658\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0973 - accuracy: 0.9631\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.1305 - accuracy: 0.9385\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0977 - accuracy: 0.9570\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0987 - accuracy: 0.9576\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0984 - accuracy: 0.9522\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0677 - accuracy: 0.9777\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0874 - accuracy: 0.9707\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0776 - accuracy: 0.9614\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0719 - accuracy: 0.9797\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0687 - accuracy: 0.9803\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0674 - accuracy: 0.9713\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1124 - accuracy: 0.9604\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0629 - accuracy: 0.9822\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 796us/step - loss: 0.0579 - accuracy: 0.9881\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0651 - accuracy: 0.9809\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0545 - accuracy: 0.9828\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0651 - accuracy: 0.9786\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0778 - accuracy: 0.9737\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0872 - accuracy: 0.9651\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1122 - accuracy: 0.9451\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1554 - accuracy: 0.9355\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.1848 - accuracy: 0.9158\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.1543 - accuracy: 0.9246\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.1315 - accuracy: 0.9547\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.1085 - accuracy: 0.9556\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0964 - accuracy: 0.9616\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0772 - accuracy: 0.9720\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.1165 - accuracy: 0.9495\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0848 - accuracy: 0.9663\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1141 - accuracy: 0.9574\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0757 - accuracy: 0.9759\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0650 - accuracy: 0.9791\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0864 - accuracy: 0.9576\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0800 - accuracy: 0.9705\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0832 - accuracy: 0.9664\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0544 - accuracy: 0.9846\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0661 - accuracy: 0.9757\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0887 - accuracy: 0.9618\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0965 - accuracy: 0.9542\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0733 - accuracy: 0.9781\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0879 - accuracy: 0.9613\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0836 - accuracy: 0.9652\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0689 - accuracy: 0.9775\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0654 - accuracy: 0.9775\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0738 - accuracy: 0.9681\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0808 - accuracy: 0.9673\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.1036 - accuracy: 0.9671\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0942 - accuracy: 0.9677\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0533 - accuracy: 0.9828\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.1368 - accuracy: 0.9461\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0853 - accuracy: 0.9689\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0736 - accuracy: 0.9729\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0910 - accuracy: 0.9571\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0711 - accuracy: 0.9731\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0697 - accuracy: 0.9762\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0763 - accuracy: 0.9683\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0981 - accuracy: 0.9582\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.0815 - accuracy: 0.9665\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0840 - accuracy: 0.9699\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0656 - accuracy: 0.9769\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0625 - accuracy: 0.9804\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0621 - accuracy: 0.9789\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0680 - accuracy: 0.9730\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0665 - accuracy: 0.9766\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0867 - accuracy: 0.9646\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0913 - accuracy: 0.9627\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0498 - accuracy: 0.9836\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0586 - accuracy: 0.9797\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0533 - accuracy: 0.9819\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0341 - accuracy: 0.9914\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0493 - accuracy: 0.9834\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0584 - accuracy: 0.9839\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0756 - accuracy: 0.9740\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0471 - accuracy: 0.9862\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0652 - accuracy: 0.9796\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1825 - accuracy: 0.9468\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0805 - accuracy: 0.9673\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0541 - accuracy: 0.9785\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0647 - accuracy: 0.9748\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0732 - accuracy: 0.9710\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0447 - accuracy: 0.9851\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.0728 - accuracy: 0.9722\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0367 - accuracy: 0.9938\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0531 - accuracy: 0.9822\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0686 - accuracy: 0.9789\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0740 - accuracy: 0.9748\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0812 - accuracy: 0.9690\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0721 - accuracy: 0.9666\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0536 - accuracy: 0.9810\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0375 - accuracy: 0.9878\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0506 - accuracy: 0.9812\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 816us/step - loss: 0.0453 - accuracy: 0.9861\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0704 - accuracy: 0.9783\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0788 - accuracy: 0.9684\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0942 - accuracy: 0.9637\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0768 - accuracy: 0.9732\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0418 - accuracy: 0.9871\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0384 - accuracy: 0.9892\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0470 - accuracy: 0.9806\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0506 - accuracy: 0.9832\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0709 - accuracy: 0.9741\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0827 - accuracy: 0.9664\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0646 - accuracy: 0.9761\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0444 - accuracy: 0.9845\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0621 - accuracy: 0.9792\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0872 - accuracy: 0.9680\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0502 - accuracy: 0.9846\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0617 - accuracy: 0.9793\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0275 - accuracy: 0.9945\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0416 - accuracy: 0.9864\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0332 - accuracy: 0.9906\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0372 - accuracy: 0.9883\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0519 - accuracy: 0.9814\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0888 - accuracy: 0.9674\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0724 - accuracy: 0.9722\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0478 - accuracy: 0.9830\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0725 - accuracy: 0.9758\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0683 - accuracy: 0.9808\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0434 - accuracy: 0.9888\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0707 - accuracy: 0.9750\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0660 - accuracy: 0.9782\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0358 - accuracy: 0.9898\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0392 - accuracy: 0.9878\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0277 - accuracy: 0.9936\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0595 - accuracy: 0.9782\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0660 - accuracy: 0.9763\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0354 - accuracy: 0.9902\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0737 - accuracy: 0.9705\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0820 - accuracy: 0.9648\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0749 - accuracy: 0.9705\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0640 - accuracy: 0.9778\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0789 - accuracy: 0.9696\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0719 - accuracy: 0.9755\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0623 - accuracy: 0.9807\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0595 - accuracy: 0.9775\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0446 - accuracy: 0.9882\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0636 - accuracy: 0.9758\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0534 - accuracy: 0.9858\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0738 - accuracy: 0.9673\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0681 - accuracy: 0.9779\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c753d7430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7538b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c753d74c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 14: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.9993 - accuracy: 0.4859\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.6743 - accuracy: 0.6718\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.6152 - accuracy: 0.7212\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.6053 - accuracy: 0.6909\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.5729 - accuracy: 0.7251\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.5653 - accuracy: 0.7222\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.5464 - accuracy: 0.7329\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.5385 - accuracy: 0.7280\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.5192 - accuracy: 0.7669\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.5156 - accuracy: 0.7449\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.5002 - accuracy: 0.7571\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7752\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.5012 - accuracy: 0.7521\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.4807 - accuracy: 0.7617\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.4780 - accuracy: 0.7958\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.4213 - accuracy: 0.8069\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.4623 - accuracy: 0.7870\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.4350 - accuracy: 0.7991\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.4225 - accuracy: 0.8143\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.4081 - accuracy: 0.8354\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.3763 - accuracy: 0.8287\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.4146 - accuracy: 0.8103\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.3878 - accuracy: 0.8148\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.3680 - accuracy: 0.8439\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.3657 - accuracy: 0.8426\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8504\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8559\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8690\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.3840 - accuracy: 0.8358\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.3417 - accuracy: 0.8629\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8670\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.3207 - accuracy: 0.8597\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.3204 - accuracy: 0.8436\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.2646 - accuracy: 0.8931\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8796\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.2679 - accuracy: 0.8891\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.3019 - accuracy: 0.8718\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.2848 - accuracy: 0.8821\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.8910\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.8666\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8889\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.9141\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2705 - accuracy: 0.8836\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8661\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.8807\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2562 - accuracy: 0.8881\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.2945 - accuracy: 0.8683\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.2501 - accuracy: 0.8840\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.2423 - accuracy: 0.8906\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.8701\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.2723 - accuracy: 0.8835\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2581 - accuracy: 0.8780\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9038\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.8968\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9137\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.9130\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.9134\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.2256 - accuracy: 0.9026\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1607 - accuracy: 0.9371\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2569 - accuracy: 0.8847\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.2034 - accuracy: 0.9122\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.1852 - accuracy: 0.9274\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.2086 - accuracy: 0.9136\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.2279 - accuracy: 0.8916\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.2261 - accuracy: 0.9033\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.2311 - accuracy: 0.8868\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9125\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.8705\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.8722\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.8802\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9095\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9197\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.1808 - accuracy: 0.9293\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.2266 - accuracy: 0.8912\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.1917 - accuracy: 0.9134\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1625 - accuracy: 0.9181\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9218\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1549 - accuracy: 0.9296\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1736 - accuracy: 0.9333\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1909 - accuracy: 0.9002\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1728 - accuracy: 0.9155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.2097 - accuracy: 0.9196\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1664 - accuracy: 0.9348\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.1825 - accuracy: 0.9098\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1470 - accuracy: 0.9473\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.1320 - accuracy: 0.9526\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1673 - accuracy: 0.9303\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1659 - accuracy: 0.9270\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1873 - accuracy: 0.9092\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1542 - accuracy: 0.9358\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.1516 - accuracy: 0.9301\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1403 - accuracy: 0.9474\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1744 - accuracy: 0.9224\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1535 - accuracy: 0.9391\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.1555 - accuracy: 0.9449\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.1013 - accuracy: 0.9623\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1122 - accuracy: 0.9508\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.1740 - accuracy: 0.9299\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.1633 - accuracy: 0.9312\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1084 - accuracy: 0.9558\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1891 - accuracy: 0.9141\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0965 - accuracy: 0.9708\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1445 - accuracy: 0.9392\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.1430 - accuracy: 0.9383\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.1437 - accuracy: 0.9415\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1611 - accuracy: 0.9209\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1551 - accuracy: 0.9272\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1397 - accuracy: 0.9388\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1306 - accuracy: 0.9466\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1583 - accuracy: 0.9483\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1293 - accuracy: 0.9332\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1030 - accuracy: 0.9632\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1630 - accuracy: 0.9368\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1146 - accuracy: 0.9549\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1127 - accuracy: 0.9529\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.1053 - accuracy: 0.9588\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1204 - accuracy: 0.9513\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.1476 - accuracy: 0.9309\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.1421 - accuracy: 0.9339\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1187 - accuracy: 0.9473\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.1367 - accuracy: 0.9373\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1363 - accuracy: 0.9379\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1831 - accuracy: 0.9246\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9450\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1478 - accuracy: 0.9485\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1026 - accuracy: 0.9587\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9570\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9595\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9625\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1088 - accuracy: 0.9585\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9292\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9426\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1525 - accuracy: 0.9339\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1231 - accuracy: 0.9481\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0966 - accuracy: 0.9635\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1259 - accuracy: 0.9438\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1030 - accuracy: 0.9582\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1306 - accuracy: 0.9444\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1322 - accuracy: 0.9517\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1329 - accuracy: 0.9432\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.1021 - accuracy: 0.9593\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1210 - accuracy: 0.9526\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.1199 - accuracy: 0.9536\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0852 - accuracy: 0.9686\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1020 - accuracy: 0.9634\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1159 - accuracy: 0.9492\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.1253 - accuracy: 0.9421\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1092 - accuracy: 0.9591\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.1181 - accuracy: 0.9498\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1170 - accuracy: 0.9535\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1231 - accuracy: 0.9477\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0901 - accuracy: 0.9628\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1376 - accuracy: 0.9417\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0866 - accuracy: 0.9730\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0926 - accuracy: 0.9667\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1051 - accuracy: 0.9589\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0887 - accuracy: 0.9669\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.1085 - accuracy: 0.9567\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1048 - accuracy: 0.9553\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0936 - accuracy: 0.9631\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 795us/step - loss: 0.0867 - accuracy: 0.9709\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1135 - accuracy: 0.9531\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1113 - accuracy: 0.9656\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0910 - accuracy: 0.9689\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1308 - accuracy: 0.9562\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0972 - accuracy: 0.9610\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0828 - accuracy: 0.9701\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1145 - accuracy: 0.9577\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1054 - accuracy: 0.9530\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9675\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9749\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9466\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9509\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1700 - accuracy: 0.9377\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9601\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9519\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9524\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0821 - accuracy: 0.9708\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1025 - accuracy: 0.9576\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1260 - accuracy: 0.9505\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0954 - accuracy: 0.9675\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1079 - accuracy: 0.9635\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0538 - accuracy: 0.9847\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0844 - accuracy: 0.9686\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.1055 - accuracy: 0.9555\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0940 - accuracy: 0.9636\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9579\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9569\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9623\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1041 - accuracy: 0.9539\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.1095 - accuracy: 0.9603\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0757 - accuracy: 0.9785\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0640 - accuracy: 0.9827\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0915 - accuracy: 0.9620\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.1024 - accuracy: 0.9593\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0740 - accuracy: 0.9744\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0667 - accuracy: 0.9777\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1252 - accuracy: 0.9442\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0881 - accuracy: 0.9668\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0996 - accuracy: 0.9618\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 1.1009 - accuracy: 0.3050\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.5997 - accuracy: 0.8032\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.5472 - accuracy: 0.7880\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.4417 - accuracy: 0.8379\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.4491 - accuracy: 0.8435\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.4148 - accuracy: 0.8340\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.3809 - accuracy: 0.8483\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.3749 - accuracy: 0.8379\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.3413 - accuracy: 0.8621\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.3329 - accuracy: 0.8753\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.3263 - accuracy: 0.8800\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.3081 - accuracy: 0.8817\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.3183 - accuracy: 0.8682\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.3211 - accuracy: 0.8595\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.3117 - accuracy: 0.8593\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.3042 - accuracy: 0.8703\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.2448 - accuracy: 0.8922\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.2671 - accuracy: 0.8887\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.2884 - accuracy: 0.8745\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2557 - accuracy: 0.8832\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.2335 - accuracy: 0.8899\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.8713\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.2174 - accuracy: 0.9122\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.2156 - accuracy: 0.8994\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.2127 - accuracy: 0.8950\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.2145 - accuracy: 0.9165\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.2048 - accuracy: 0.9117\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9051\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.2011 - accuracy: 0.8935\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.2125 - accuracy: 0.9065\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1667 - accuracy: 0.9277\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1671 - accuracy: 0.9323\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1549 - accuracy: 0.9314\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1498 - accuracy: 0.9324\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1567 - accuracy: 0.9255\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.1686 - accuracy: 0.9205\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1611 - accuracy: 0.9203\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1534 - accuracy: 0.9283\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1343 - accuracy: 0.9473\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.1152 - accuracy: 0.9388\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 862us/step - loss: 0.1449 - accuracy: 0.9265\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1225 - accuracy: 0.9460\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1247 - accuracy: 0.9471\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0977 - accuracy: 0.9608\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1091 - accuracy: 0.9440\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1393 - accuracy: 0.9331\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0849 - accuracy: 0.9630\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1013 - accuracy: 0.9623\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.1216 - accuracy: 0.9331\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1175 - accuracy: 0.9419\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.1114 - accuracy: 0.9594\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0914 - accuracy: 0.9566\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0983 - accuracy: 0.9545\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1105 - accuracy: 0.9506\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.1091 - accuracy: 0.9451\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0963 - accuracy: 0.9585\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1220 - accuracy: 0.9435\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1020 - accuracy: 0.9523\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9656\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9413\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1629 - accuracy: 0.9092\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9439\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9437\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1192 - accuracy: 0.9318\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1309 - accuracy: 0.9442\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1214 - accuracy: 0.9311\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1167 - accuracy: 0.9480\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1547 - accuracy: 0.9112\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1011 - accuracy: 0.9565\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1115 - accuracy: 0.9426\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0839 - accuracy: 0.9612\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1231 - accuracy: 0.9522\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0932 - accuracy: 0.9488\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1006 - accuracy: 0.9494\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0976 - accuracy: 0.9534\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0854 - accuracy: 0.9519\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0807 - accuracy: 0.9451\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1068 - accuracy: 0.9324\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0834 - accuracy: 0.9602\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1559 - accuracy: 0.9133\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1069 - accuracy: 0.9443\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.1069 - accuracy: 0.9476\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0857 - accuracy: 0.9511\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0812 - accuracy: 0.9598\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0874 - accuracy: 0.9541\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0944 - accuracy: 0.9544\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1033 - accuracy: 0.9461\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0936 - accuracy: 0.9504\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0781 - accuracy: 0.9620\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0806 - accuracy: 0.9584\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0892 - accuracy: 0.9418\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.1109 - accuracy: 0.9408\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.1095 - accuracy: 0.9468\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0751 - accuracy: 0.9435\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0855 - accuracy: 0.9507\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0767 - accuracy: 0.9620\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0811 - accuracy: 0.9702\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0753 - accuracy: 0.9550\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0628 - accuracy: 0.9594\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0707 - accuracy: 0.9579\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.0801 - accuracy: 0.9575\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0767 - accuracy: 0.9534\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0733 - accuracy: 0.9612\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0655 - accuracy: 0.9733\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0643 - accuracy: 0.9744\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0873 - accuracy: 0.9569\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0753 - accuracy: 0.9682\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.1002 - accuracy: 0.9447\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0698 - accuracy: 0.9645\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0543 - accuracy: 0.9740\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0799 - accuracy: 0.9696\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0829 - accuracy: 0.9664\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0815 - accuracy: 0.9604\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0759 - accuracy: 0.9706\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0840 - accuracy: 0.9676\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0961 - accuracy: 0.9607\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1025 - accuracy: 0.9328\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0835 - accuracy: 0.9629\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0921 - accuracy: 0.9459\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0844 - accuracy: 0.9446\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 771us/step - loss: 0.0943 - accuracy: 0.9421\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.1090 - accuracy: 0.9326\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0674 - accuracy: 0.9609\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0505 - accuracy: 0.9726\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0561 - accuracy: 0.9753\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0593 - accuracy: 0.9709\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0732 - accuracy: 0.9520\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0787 - accuracy: 0.9583\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0556 - accuracy: 0.9689\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0458 - accuracy: 0.9790\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0668 - accuracy: 0.9695\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0794 - accuracy: 0.9617\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.1028 - accuracy: 0.9399\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1014 - accuracy: 0.9438\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0848 - accuracy: 0.9588\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0503 - accuracy: 0.9761\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0583 - accuracy: 0.9748\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.1041 - accuracy: 0.9497\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0593 - accuracy: 0.9776\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0706 - accuracy: 0.9690\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0502 - accuracy: 0.9733\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0695 - accuracy: 0.9621\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0610 - accuracy: 0.9688\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0467 - accuracy: 0.9803\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0716 - accuracy: 0.9577\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0418 - accuracy: 0.9764\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1008 - accuracy: 0.9578\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0888 - accuracy: 0.9612\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1084 - accuracy: 0.9476\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0806 - accuracy: 0.9470\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0653 - accuracy: 0.9630\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0669 - accuracy: 0.9592\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0582 - accuracy: 0.9680\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0561 - accuracy: 0.9795\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0787 - accuracy: 0.9634\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0564 - accuracy: 0.9726\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0489 - accuracy: 0.9772\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0693 - accuracy: 0.9645\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0645 - accuracy: 0.9638\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0536 - accuracy: 0.9695\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0767 - accuracy: 0.9581\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0407 - accuracy: 0.9811\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0681 - accuracy: 0.9669\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0534 - accuracy: 0.9822\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0617 - accuracy: 0.9660\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0758 - accuracy: 0.9619\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0511 - accuracy: 0.9819\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0746 - accuracy: 0.9627\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0589 - accuracy: 0.9632\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0634 - accuracy: 0.9673\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0688 - accuracy: 0.9672\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0606 - accuracy: 0.9698\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0517 - accuracy: 0.9769\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0541 - accuracy: 0.9769\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0751 - accuracy: 0.9663\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0965 - accuracy: 0.9477\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0617 - accuracy: 0.9690\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0641 - accuracy: 0.9759\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0619 - accuracy: 0.9715\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0424 - accuracy: 0.9867\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0598 - accuracy: 0.9709\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0724 - accuracy: 0.9623\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0568 - accuracy: 0.9746\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0724 - accuracy: 0.9629\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0485 - accuracy: 0.9747\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0534 - accuracy: 0.9766\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0622 - accuracy: 0.9632\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0494 - accuracy: 0.9736\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0870 - accuracy: 0.9458\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0753 - accuracy: 0.9686\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0462 - accuracy: 0.9819\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0527 - accuracy: 0.9774\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0395 - accuracy: 0.9870\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0526 - accuracy: 0.9728\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0458 - accuracy: 0.9843\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0967 - accuracy: 0.9497\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0579 - accuracy: 0.9773\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0567 - accuracy: 0.9786\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0832 - accuracy: 0.9695\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 807us/step - loss: 0.0490 - accuracy: 0.9800\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 1.5158 - accuracy: 0.1225\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.8087 - accuracy: 0.7705\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.4750 - accuracy: 0.8815\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.4530 - accuracy: 0.8774\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.3900 - accuracy: 0.8867\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.3814 - accuracy: 0.8707\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.3586 - accuracy: 0.8870\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.3431 - accuracy: 0.8867\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.3515 - accuracy: 0.8801\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.3704 - accuracy: 0.8631\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.3084 - accuracy: 0.8931\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.3331 - accuracy: 0.8842\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.3537 - accuracy: 0.8676\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.3125 - accuracy: 0.8887\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.3145 - accuracy: 0.8738\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.3034 - accuracy: 0.8851\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.2529 - accuracy: 0.9062\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.3101 - accuracy: 0.8791\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.3000 - accuracy: 0.8733\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.2664 - accuracy: 0.8930\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.2880 - accuracy: 0.8667\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.3168 - accuracy: 0.8647\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.2425 - accuracy: 0.8953\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.2212 - accuracy: 0.9020\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.2372 - accuracy: 0.8787\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.2701 - accuracy: 0.8865\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.2448 - accuracy: 0.8912\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.2169 - accuracy: 0.8961\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.2498 - accuracy: 0.8711\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.2383 - accuracy: 0.8720\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.2100 - accuracy: 0.8856\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1966 - accuracy: 0.8882\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1966 - accuracy: 0.8856\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.1952 - accuracy: 0.9013\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.1795 - accuracy: 0.9043\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1692 - accuracy: 0.9025\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.1776 - accuracy: 0.9182\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.1931 - accuracy: 0.9066\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.2144 - accuracy: 0.9017\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.2025 - accuracy: 0.9102\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1701 - accuracy: 0.9277\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1817 - accuracy: 0.9244\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1771 - accuracy: 0.9296\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1368 - accuracy: 0.9487\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1307 - accuracy: 0.9464\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1236 - accuracy: 0.9499\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1359 - accuracy: 0.9405\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.1487 - accuracy: 0.9337\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.1285 - accuracy: 0.9520\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1598 - accuracy: 0.9328\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1378 - accuracy: 0.9434\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.1759 - accuracy: 0.9301\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.1479 - accuracy: 0.9380\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1413 - accuracy: 0.9429\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1382 - accuracy: 0.9425\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.1352 - accuracy: 0.9499\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.1543 - accuracy: 0.9397\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1181 - accuracy: 0.9547\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.1378 - accuracy: 0.9480\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0966 - accuracy: 0.9693\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0952 - accuracy: 0.9673\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0934 - accuracy: 0.9715\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1234 - accuracy: 0.9486\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0920 - accuracy: 0.9605\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1194 - accuracy: 0.9453\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1209 - accuracy: 0.9490\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.1044 - accuracy: 0.9617\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.1026 - accuracy: 0.9653\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0685 - accuracy: 0.9838\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0642 - accuracy: 0.9870\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.1019 - accuracy: 0.9633\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0976 - accuracy: 0.9666\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0740 - accuracy: 0.9751\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1382 - accuracy: 0.9576\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1305 - accuracy: 0.9574\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1242 - accuracy: 0.9530\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0865 - accuracy: 0.9697\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.1784 - accuracy: 0.9235\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.1102 - accuracy: 0.9640\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 806us/step - loss: 0.1200 - accuracy: 0.9539\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0761 - accuracy: 0.9724\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0948 - accuracy: 0.9695\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0547 - accuracy: 0.9833\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0795 - accuracy: 0.9740\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0880 - accuracy: 0.9717\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0967 - accuracy: 0.9561\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.0812 - accuracy: 0.9767\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0607 - accuracy: 0.9761\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0790 - accuracy: 0.9715\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0724 - accuracy: 0.9684\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0809 - accuracy: 0.9713\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0959 - accuracy: 0.9706\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0916 - accuracy: 0.9581\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0927 - accuracy: 0.9671\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1064 - accuracy: 0.9538\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0721 - accuracy: 0.9788\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0761 - accuracy: 0.9720\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0587 - accuracy: 0.9819\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0628 - accuracy: 0.9786\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0971 - accuracy: 0.9664\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0597 - accuracy: 0.9818\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0625 - accuracy: 0.9810\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0630 - accuracy: 0.9775\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0692 - accuracy: 0.9771\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.1258 - accuracy: 0.9531\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.1235 - accuracy: 0.9537\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0875 - accuracy: 0.9704\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0763 - accuracy: 0.9746\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0680 - accuracy: 0.9782\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0668 - accuracy: 0.9818\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0947 - accuracy: 0.9659\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0697 - accuracy: 0.9745\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0497 - accuracy: 0.9850\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0573 - accuracy: 0.9828\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0709 - accuracy: 0.9673\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0974 - accuracy: 0.9590\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0630 - accuracy: 0.9781\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0557 - accuracy: 0.9815\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0797 - accuracy: 0.9617\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.1039 - accuracy: 0.9500\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.1173 - accuracy: 0.9466\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0730 - accuracy: 0.9755\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0703 - accuracy: 0.9750\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0855 - accuracy: 0.9745\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0374 - accuracy: 0.9938\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0635 - accuracy: 0.9810\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0825 - accuracy: 0.9677\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0623 - accuracy: 0.9814\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0849 - accuracy: 0.9749\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0659 - accuracy: 0.9794\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0490 - accuracy: 0.9844\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.0695 - accuracy: 0.9692\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0783 - accuracy: 0.9692\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0478 - accuracy: 0.9819\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0523 - accuracy: 0.9803\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0677 - accuracy: 0.9794\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0584 - accuracy: 0.9753\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0407 - accuracy: 0.9913\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0740 - accuracy: 0.9710\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0539 - accuracy: 0.9816\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0447 - accuracy: 0.9856\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0474 - accuracy: 0.9877\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0396 - accuracy: 0.9894\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0409 - accuracy: 0.9881\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0494 - accuracy: 0.9851\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0705 - accuracy: 0.9774\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0403 - accuracy: 0.9888\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0812 - accuracy: 0.9722\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0490 - accuracy: 0.9871\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0464 - accuracy: 0.9880\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0446 - accuracy: 0.9857\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0413 - accuracy: 0.9898\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0378 - accuracy: 0.9879\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0563 - accuracy: 0.9817\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0584 - accuracy: 0.9797\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1139 - accuracy: 0.9652\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0935 - accuracy: 0.9729\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0465 - accuracy: 0.9880\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 864us/step - loss: 0.0903 - accuracy: 0.9692\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0556 - accuracy: 0.9803\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1547 - accuracy: 0.9422\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0999 - accuracy: 0.9541\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0529 - accuracy: 0.9818\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0706 - accuracy: 0.9765\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0633 - accuracy: 0.9747\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0365 - accuracy: 0.9906\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0550 - accuracy: 0.9804\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0549 - accuracy: 0.9820\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0868 - accuracy: 0.9643\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0769 - accuracy: 0.9740\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0586 - accuracy: 0.9774\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0628 - accuracy: 0.9773\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0525 - accuracy: 0.9863\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0626 - accuracy: 0.9787\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0609 - accuracy: 0.9770\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0496 - accuracy: 0.9833\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0372 - accuracy: 0.9877\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0501 - accuracy: 0.9847\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0679 - accuracy: 0.9719\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0607 - accuracy: 0.9801\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0463 - accuracy: 0.9870\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.0480 - accuracy: 0.9854\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0640 - accuracy: 0.9761\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0606 - accuracy: 0.9720\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0499 - accuracy: 0.9857\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0553 - accuracy: 0.9839\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0506 - accuracy: 0.9856\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0316 - accuracy: 0.9916\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.1162 - accuracy: 0.9588\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0669 - accuracy: 0.9772\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0877 - accuracy: 0.9659\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0588 - accuracy: 0.9760\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0478 - accuracy: 0.9873\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0434 - accuracy: 0.9878\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0497 - accuracy: 0.9836\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0425 - accuracy: 0.9863\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0440 - accuracy: 0.9876\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0947 - accuracy: 0.9648\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0835 - accuracy: 0.9646\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1072 - accuracy: 0.9619\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75beac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7878f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c780a0790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 15: 78\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 895us/step - loss: 0.8858 - accuracy: 0.5622\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.6689 - accuracy: 0.6527\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.6400 - accuracy: 0.6717\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.5918 - accuracy: 0.7179\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.5578 - accuracy: 0.7328\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.5463 - accuracy: 0.7329\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.5457 - accuracy: 0.7530\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.5506 - accuracy: 0.7136\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.5070 - accuracy: 0.7431\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.4902 - accuracy: 0.7635\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.4882 - accuracy: 0.7630\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.4488 - accuracy: 0.8063\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.5070 - accuracy: 0.7563\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.4613 - accuracy: 0.7772\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.4437 - accuracy: 0.8048\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.4444 - accuracy: 0.7888\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.4359 - accuracy: 0.7937\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.3907 - accuracy: 0.8273\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.4134 - accuracy: 0.8294\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.3704 - accuracy: 0.8310\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.3588 - accuracy: 0.8317\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.3355 - accuracy: 0.8649\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.3477 - accuracy: 0.8674\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.3414 - accuracy: 0.8554\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.3319 - accuracy: 0.8620\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.3642 - accuracy: 0.8436\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.3449 - accuracy: 0.8808\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.3824 - accuracy: 0.8555\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.2929 - accuracy: 0.8907\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.2825 - accuracy: 0.9069\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.2774 - accuracy: 0.8819\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.2661 - accuracy: 0.9002\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.2842 - accuracy: 0.8796\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.2435 - accuracy: 0.9116\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.2768 - accuracy: 0.8898\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.2842 - accuracy: 0.8771\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.2309 - accuracy: 0.8978\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.3209 - accuracy: 0.8707\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.2847 - accuracy: 0.8615\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.2735 - accuracy: 0.8860\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.2210 - accuracy: 0.9130\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.2454 - accuracy: 0.9023\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.2550 - accuracy: 0.8926\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.2329 - accuracy: 0.9195\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.2182 - accuracy: 0.9070\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.3139 - accuracy: 0.8796\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.3007 - accuracy: 0.8673\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.2087 - accuracy: 0.9164\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.2188 - accuracy: 0.9165\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.2250 - accuracy: 0.9123\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1657 - accuracy: 0.9273\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.2113 - accuracy: 0.9047\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.1927 - accuracy: 0.9165\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.2184 - accuracy: 0.9121\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.2231 - accuracy: 0.9066\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.1948 - accuracy: 0.9249\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.1414 - accuracy: 0.9463\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1894 - accuracy: 0.9200\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.2169 - accuracy: 0.9058\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.2102 - accuracy: 0.9139\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1446 - accuracy: 0.9409\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.1472 - accuracy: 0.9410\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1531 - accuracy: 0.9465\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1488 - accuracy: 0.9472\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.1485 - accuracy: 0.9436\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1474 - accuracy: 0.9503\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.1925 - accuracy: 0.9195\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.1346 - accuracy: 0.9464\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1902 - accuracy: 0.9125\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1588 - accuracy: 0.9466\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1582 - accuracy: 0.9452\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.1761 - accuracy: 0.9273\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1428 - accuracy: 0.9447\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1558 - accuracy: 0.9462\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1550 - accuracy: 0.9341\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1869 - accuracy: 0.9165\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1991 - accuracy: 0.9224\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.1734 - accuracy: 0.9338\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.1868 - accuracy: 0.9197\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1594 - accuracy: 0.9337\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 797us/step - loss: 0.1513 - accuracy: 0.9506\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.1534 - accuracy: 0.9376\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.1443 - accuracy: 0.9425\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.2009 - accuracy: 0.9253\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.2063 - accuracy: 0.9055\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.1667 - accuracy: 0.9358\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1244 - accuracy: 0.9586\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1303 - accuracy: 0.9531\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1171 - accuracy: 0.9538\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.1473 - accuracy: 0.9403\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.1308 - accuracy: 0.9499\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0857 - accuracy: 0.9736\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1267 - accuracy: 0.9468\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1048 - accuracy: 0.9621\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.2372 - accuracy: 0.9164\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.2466 - accuracy: 0.9010\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1993 - accuracy: 0.9208\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.1743 - accuracy: 0.9380\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1642 - accuracy: 0.9334\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1579 - accuracy: 0.9293\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1793 - accuracy: 0.9097\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1331 - accuracy: 0.9450\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1492 - accuracy: 0.9420\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.1323 - accuracy: 0.9455\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1866 - accuracy: 0.9038\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.1607 - accuracy: 0.9272\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.1296 - accuracy: 0.9385\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1434 - accuracy: 0.9446\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.1720 - accuracy: 0.9287\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.1766 - accuracy: 0.9138\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.1288 - accuracy: 0.9481\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1423 - accuracy: 0.9298\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1270 - accuracy: 0.9425\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1450 - accuracy: 0.9396\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1529 - accuracy: 0.9505\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1738 - accuracy: 0.9234\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1700 - accuracy: 0.9267\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1772 - accuracy: 0.9276\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1583 - accuracy: 0.9487\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1229 - accuracy: 0.9580\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.1266 - accuracy: 0.9633\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1161 - accuracy: 0.9549\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.1360 - accuracy: 0.9509\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1890 - accuracy: 0.9288\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1079 - accuracy: 0.9547\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1070 - accuracy: 0.9517\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1315 - accuracy: 0.9606\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1344 - accuracy: 0.9496\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1193 - accuracy: 0.9564\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1208 - accuracy: 0.9480\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.1360 - accuracy: 0.9477\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1236 - accuracy: 0.9388\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0845 - accuracy: 0.9708\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.1117 - accuracy: 0.9516\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.1255 - accuracy: 0.9462\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.1039 - accuracy: 0.9554\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1395 - accuracy: 0.9434\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1265 - accuracy: 0.9442\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1147 - accuracy: 0.9521\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1450 - accuracy: 0.9450\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.1544 - accuracy: 0.9324\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1319 - accuracy: 0.9553\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1153 - accuracy: 0.9526\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1201 - accuracy: 0.9526\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.1004 - accuracy: 0.9626\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0833 - accuracy: 0.9739\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0879 - accuracy: 0.9724\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0951 - accuracy: 0.9608\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0986 - accuracy: 0.9644\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0829 - accuracy: 0.9724\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.1007 - accuracy: 0.9602\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0893 - accuracy: 0.9641\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1407 - accuracy: 0.9401\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1036 - accuracy: 0.9586\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0955 - accuracy: 0.9618\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0979 - accuracy: 0.9656\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0943 - accuracy: 0.9619\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1118 - accuracy: 0.9512\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1419 - accuracy: 0.9402\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 772us/step - loss: 0.1253 - accuracy: 0.9442\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.1512 - accuracy: 0.9402\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.1059 - accuracy: 0.9597\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1039 - accuracy: 0.9573\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0839 - accuracy: 0.9665\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.1167 - accuracy: 0.9589\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0833 - accuracy: 0.9686\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0845 - accuracy: 0.9686\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1253 - accuracy: 0.9472\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1089 - accuracy: 0.9540\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.1479 - accuracy: 0.9379\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.1415 - accuracy: 0.9475\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1601 - accuracy: 0.9376\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1117 - accuracy: 0.9418\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.1469 - accuracy: 0.9448\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1396 - accuracy: 0.9267\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0932 - accuracy: 0.9674\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0985 - accuracy: 0.9640\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0827 - accuracy: 0.9712\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0783 - accuracy: 0.9700\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.1028 - accuracy: 0.9634\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.1204 - accuracy: 0.9585\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0699 - accuracy: 0.9748\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0579 - accuracy: 0.9830\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0878 - accuracy: 0.9675\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0722 - accuracy: 0.9749\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0697 - accuracy: 0.9727\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0759 - accuracy: 0.9728\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0854 - accuracy: 0.9620\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1012 - accuracy: 0.9578\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1014 - accuracy: 0.9519\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9709\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0993 - accuracy: 0.9605\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.1298 - accuracy: 0.9395\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0841 - accuracy: 0.9641\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9621\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0985 - accuracy: 0.9626\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0949 - accuracy: 0.9606\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1408 - accuracy: 0.9336\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.1547 - accuracy: 0.9257\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1004 - accuracy: 0.9563\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.6633 - accuracy: 0.7433\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.5104 - accuracy: 0.8239\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.4430 - accuracy: 0.8374\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.4017 - accuracy: 0.8543\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.3889 - accuracy: 0.8377\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.3914 - accuracy: 0.8379\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.3768 - accuracy: 0.8531\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.3140 - accuracy: 0.8751\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.3150 - accuracy: 0.8754\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.3510 - accuracy: 0.8426\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.3416 - accuracy: 0.8430\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.3002 - accuracy: 0.8656\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.2807 - accuracy: 0.8787\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.3163 - accuracy: 0.8633\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.2765 - accuracy: 0.8782\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.2598 - accuracy: 0.8832\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.2720 - accuracy: 0.8867\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.2651 - accuracy: 0.8779\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.2725 - accuracy: 0.8859\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.2252 - accuracy: 0.9098\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.2499 - accuracy: 0.8987\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.2691 - accuracy: 0.8796\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.2380 - accuracy: 0.8963\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.2340 - accuracy: 0.8995\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.2369 - accuracy: 0.8943\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1914 - accuracy: 0.9057\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.2060 - accuracy: 0.9128\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.2212 - accuracy: 0.9049\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.2036 - accuracy: 0.9051\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1825 - accuracy: 0.9330\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.1930 - accuracy: 0.9193\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.2032 - accuracy: 0.9144\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1992 - accuracy: 0.9078\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.1857 - accuracy: 0.9123\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.1678 - accuracy: 0.9279\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.1671 - accuracy: 0.9269\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1445 - accuracy: 0.9382\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1602 - accuracy: 0.9358\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1466 - accuracy: 0.9357\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 775us/step - loss: 0.1675 - accuracy: 0.9244\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1845 - accuracy: 0.9254\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.1244 - accuracy: 0.9412\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1223 - accuracy: 0.9442\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.1125 - accuracy: 0.9589\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.1054 - accuracy: 0.9607\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1798 - accuracy: 0.9247\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1529 - accuracy: 0.9360\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1359 - accuracy: 0.9358\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.1450 - accuracy: 0.9396\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1512 - accuracy: 0.9265\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1353 - accuracy: 0.9469\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.1058 - accuracy: 0.9585\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.1042 - accuracy: 0.9528\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.1818 - accuracy: 0.9252\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1871 - accuracy: 0.9010\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.1919 - accuracy: 0.9171\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.1500 - accuracy: 0.9293\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1911 - accuracy: 0.8906\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1462 - accuracy: 0.9163\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1444 - accuracy: 0.9313\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.1085 - accuracy: 0.9448\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1008 - accuracy: 0.9553\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1136 - accuracy: 0.9372\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0868 - accuracy: 0.9630\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.1571 - accuracy: 0.9204\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1030 - accuracy: 0.9536\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.1108 - accuracy: 0.9475\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.1147 - accuracy: 0.9378\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1558 - accuracy: 0.9392\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.1178 - accuracy: 0.9449\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.1139 - accuracy: 0.9463\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.1363 - accuracy: 0.9363\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.1440 - accuracy: 0.9213\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1119 - accuracy: 0.9417\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1026 - accuracy: 0.9540\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.1068 - accuracy: 0.9533\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0984 - accuracy: 0.9567\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.1015 - accuracy: 0.9645\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1257 - accuracy: 0.9418\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1195 - accuracy: 0.9455\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1393 - accuracy: 0.9338\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0998 - accuracy: 0.9529\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0933 - accuracy: 0.9605\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0925 - accuracy: 0.9660\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0615 - accuracy: 0.9776\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0940 - accuracy: 0.9639\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0914 - accuracy: 0.9613\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1302 - accuracy: 0.9424\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1180 - accuracy: 0.9456\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.1310 - accuracy: 0.9302\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0939 - accuracy: 0.9578\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1105 - accuracy: 0.9457\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0998 - accuracy: 0.9529\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1097 - accuracy: 0.9430\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1105 - accuracy: 0.9490\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1321 - accuracy: 0.9353\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0995 - accuracy: 0.9543\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0818 - accuracy: 0.9617\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.1097 - accuracy: 0.9419\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0890 - accuracy: 0.9632\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0889 - accuracy: 0.9573\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0966 - accuracy: 0.9647\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1326 - accuracy: 0.9294\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0959 - accuracy: 0.9633\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1051 - accuracy: 0.9525\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0738 - accuracy: 0.9742\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0902 - accuracy: 0.9602\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0722 - accuracy: 0.9726\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1003 - accuracy: 0.9485\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1221 - accuracy: 0.9393\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0914 - accuracy: 0.9588\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0830 - accuracy: 0.9608\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0900 - accuracy: 0.9578\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1387 - accuracy: 0.9547\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0891 - accuracy: 0.9667\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.1063 - accuracy: 0.9548\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1156 - accuracy: 0.9443\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0885 - accuracy: 0.9630\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0653 - accuracy: 0.9773\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 813us/step - loss: 0.0856 - accuracy: 0.9610\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0721 - accuracy: 0.9709\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0618 - accuracy: 0.9743\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0781 - accuracy: 0.9601\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1144 - accuracy: 0.9445\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0799 - accuracy: 0.9695\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0903 - accuracy: 0.9694\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0789 - accuracy: 0.9686\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0884 - accuracy: 0.9611\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0870 - accuracy: 0.9610\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1054 - accuracy: 0.9457\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1157 - accuracy: 0.9480\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0709 - accuracy: 0.9735\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0954 - accuracy: 0.9529\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1258 - accuracy: 0.9248\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.1053 - accuracy: 0.9572\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1325 - accuracy: 0.9249\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1208 - accuracy: 0.9449\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.1430 - accuracy: 0.9158\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9342\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9432\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1021 - accuracy: 0.9542\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0679 - accuracy: 0.9787\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0669 - accuracy: 0.9662\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0947 - accuracy: 0.9611\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0713 - accuracy: 0.9709\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0953 - accuracy: 0.9583\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0728 - accuracy: 0.9707\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0665 - accuracy: 0.9696\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0675 - accuracy: 0.9731\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0554 - accuracy: 0.9778\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0582 - accuracy: 0.9754\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0617 - accuracy: 0.9770\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0680 - accuracy: 0.9756\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0454 - accuracy: 0.9849\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.0481 - accuracy: 0.9806\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1024 - accuracy: 0.9485\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0635 - accuracy: 0.9734\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0783 - accuracy: 0.9727\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1059 - accuracy: 0.9531\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1208 - accuracy: 0.9464\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0856 - accuracy: 0.9639\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0817 - accuracy: 0.9677\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0910 - accuracy: 0.9557\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0757 - accuracy: 0.9648\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0834 - accuracy: 0.9564\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0940 - accuracy: 0.9571\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0672 - accuracy: 0.9794\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0754 - accuracy: 0.9650\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1136 - accuracy: 0.9471\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0827 - accuracy: 0.9641\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0842 - accuracy: 0.9635\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0925 - accuracy: 0.9581\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0950 - accuracy: 0.9592\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.1095 - accuracy: 0.9479\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.1001 - accuracy: 0.9443\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.1100 - accuracy: 0.9409\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1148 - accuracy: 0.9406\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0868 - accuracy: 0.9534\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0837 - accuracy: 0.9630\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0662 - accuracy: 0.9754\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0831 - accuracy: 0.9718\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0781 - accuracy: 0.9657\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0765 - accuracy: 0.9644\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0531 - accuracy: 0.9863\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0597 - accuracy: 0.9794\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0389 - accuracy: 0.9864\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0618 - accuracy: 0.9770\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.0599 - accuracy: 0.9784\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0626 - accuracy: 0.9787\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0618 - accuracy: 0.9714\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0831 - accuracy: 0.9668\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0973 - accuracy: 0.9546\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0841 - accuracy: 0.9660\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0901 - accuracy: 0.9604\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0617 - accuracy: 0.9774\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0730 - accuracy: 0.9648\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0625 - accuracy: 0.9796\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0772 - accuracy: 0.9616\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 788us/step - loss: 0.0815 - accuracy: 0.9615\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0764 - accuracy: 0.9608\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.8249 - accuracy: 0.6444\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.4892 - accuracy: 0.8523\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.4170 - accuracy: 0.8695\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.3742 - accuracy: 0.8786\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.3698 - accuracy: 0.8750\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.3691 - accuracy: 0.8801\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.3656 - accuracy: 0.8725\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.4031 - accuracy: 0.8489\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.3106 - accuracy: 0.8778\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.2923 - accuracy: 0.8873\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.3356 - accuracy: 0.8764\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.3345 - accuracy: 0.8704\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.3032 - accuracy: 0.8697\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.2929 - accuracy: 0.8609\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.3303 - accuracy: 0.8662\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.2938 - accuracy: 0.8695\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.2381 - accuracy: 0.8851\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.2433 - accuracy: 0.8817\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.2286 - accuracy: 0.8872\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.2359 - accuracy: 0.8906\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.2354 - accuracy: 0.9062\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.2395 - accuracy: 0.9203\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.2258 - accuracy: 0.9049\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.2046 - accuracy: 0.9217\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.1756 - accuracy: 0.9263\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.2342 - accuracy: 0.9024\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.1970 - accuracy: 0.9362\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1840 - accuracy: 0.9262\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1801 - accuracy: 0.9328\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1638 - accuracy: 0.9374\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.1594 - accuracy: 0.9310\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.1447 - accuracy: 0.9419\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.1874 - accuracy: 0.9243\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1690 - accuracy: 0.9331\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.1772 - accuracy: 0.9230\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1431 - accuracy: 0.9471\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1242 - accuracy: 0.9628\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.1109 - accuracy: 0.9633\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.1022 - accuracy: 0.9637\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.1610 - accuracy: 0.9350\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.1883 - accuracy: 0.9103\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.1165 - accuracy: 0.9522\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1265 - accuracy: 0.9495\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0947 - accuracy: 0.9660\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0945 - accuracy: 0.9673\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1297 - accuracy: 0.9454\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.1215 - accuracy: 0.9479\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.1046 - accuracy: 0.9574\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.1004 - accuracy: 0.9640\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0895 - accuracy: 0.9677\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1072 - accuracy: 0.9572\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0988 - accuracy: 0.9650\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0852 - accuracy: 0.9764\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.1502 - accuracy: 0.9293\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0814 - accuracy: 0.9677\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0956 - accuracy: 0.9640\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0797 - accuracy: 0.9721\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0624 - accuracy: 0.9753\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0879 - accuracy: 0.9636\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0808 - accuracy: 0.9687\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1117 - accuracy: 0.9566\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0973 - accuracy: 0.9674\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0911 - accuracy: 0.9657\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0838 - accuracy: 0.9633\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0996 - accuracy: 0.9578\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0773 - accuracy: 0.9704\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0791 - accuracy: 0.9703\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0782 - accuracy: 0.9662\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0687 - accuracy: 0.9788\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0572 - accuracy: 0.9747\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0523 - accuracy: 0.9846\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0881 - accuracy: 0.9664\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0519 - accuracy: 0.9813\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0669 - accuracy: 0.9689\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0804 - accuracy: 0.9621\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1175 - accuracy: 0.9569\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0996 - accuracy: 0.9529\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0825 - accuracy: 0.9648\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 781us/step - loss: 0.0810 - accuracy: 0.9742\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0797 - accuracy: 0.9604\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0945 - accuracy: 0.9642\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0759 - accuracy: 0.9687\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0735 - accuracy: 0.9817\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0546 - accuracy: 0.9822\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0587 - accuracy: 0.9732\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0623 - accuracy: 0.9763\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0955 - accuracy: 0.9628\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0616 - accuracy: 0.9742\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0748 - accuracy: 0.9769\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0813 - accuracy: 0.9612\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0555 - accuracy: 0.9796\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0567 - accuracy: 0.9747\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0336 - accuracy: 0.9931\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0446 - accuracy: 0.9859\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0487 - accuracy: 0.9857\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0769 - accuracy: 0.9739\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0921 - accuracy: 0.9592\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0845 - accuracy: 0.9680\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0583 - accuracy: 0.9823\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0590 - accuracy: 0.9774\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0585 - accuracy: 0.9781\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0582 - accuracy: 0.9776\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0598 - accuracy: 0.9791\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0427 - accuracy: 0.9851\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0722 - accuracy: 0.9748\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0613 - accuracy: 0.9806\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1009 - accuracy: 0.9643\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0923 - accuracy: 0.9658\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0921 - accuracy: 0.9685\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.1226 - accuracy: 0.9388\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0905 - accuracy: 0.9642\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0747 - accuracy: 0.9732\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0826 - accuracy: 0.9689\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0925 - accuracy: 0.9562\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1156 - accuracy: 0.9524\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1947 - accuracy: 0.9259\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1246 - accuracy: 0.9450\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.1199 - accuracy: 0.9366\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1100 - accuracy: 0.9479\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1251 - accuracy: 0.9353\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1142 - accuracy: 0.9502\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.1021 - accuracy: 0.9480\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1070 - accuracy: 0.9522\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1057 - accuracy: 0.9449\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1259 - accuracy: 0.9447\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1055 - accuracy: 0.9444\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0905 - accuracy: 0.9587\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0921 - accuracy: 0.9569\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1098 - accuracy: 0.9493\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.1302 - accuracy: 0.9419\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1001 - accuracy: 0.9625\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0823 - accuracy: 0.9652\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0732 - accuracy: 0.9678\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0988 - accuracy: 0.9491\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1054 - accuracy: 0.9567\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0907 - accuracy: 0.9581\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0877 - accuracy: 0.9571\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0909 - accuracy: 0.9631\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1043 - accuracy: 0.9511\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0963 - accuracy: 0.9558\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0809 - accuracy: 0.9686\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.0950 - accuracy: 0.9595\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0999 - accuracy: 0.9493\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1524 - accuracy: 0.9301\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.1200 - accuracy: 0.9417\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0942 - accuracy: 0.9586\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0935 - accuracy: 0.9529\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0980 - accuracy: 0.9538\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1130 - accuracy: 0.9491\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1405 - accuracy: 0.9182\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1326 - accuracy: 0.9211\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1103 - accuracy: 0.9454\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1285 - accuracy: 0.9343\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1110 - accuracy: 0.9397\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0977 - accuracy: 0.9428\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0966 - accuracy: 0.9531\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0963 - accuracy: 0.9577\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 929us/step - loss: 0.0848 - accuracy: 0.9559\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0958 - accuracy: 0.9555\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1134 - accuracy: 0.9438\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0876 - accuracy: 0.9562\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0996 - accuracy: 0.9443\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1045 - accuracy: 0.9507\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0702 - accuracy: 0.9788\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0537 - accuracy: 0.9855\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0770 - accuracy: 0.9720\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0825 - accuracy: 0.9614\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0594 - accuracy: 0.9787\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0830 - accuracy: 0.9678\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.1123 - accuracy: 0.9591\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.1144 - accuracy: 0.9508\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0709 - accuracy: 0.9748\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9707\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0654 - accuracy: 0.9741\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0832 - accuracy: 0.9654\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0422 - accuracy: 0.9905\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0386 - accuracy: 0.9871\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0491 - accuracy: 0.9834\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0794 - accuracy: 0.9694\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0441 - accuracy: 0.9858\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0648 - accuracy: 0.9745\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9650\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9690\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9606\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0818 - accuracy: 0.9615\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0488 - accuracy: 0.9833\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0627 - accuracy: 0.9769\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0387 - accuracy: 0.9877\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0636 - accuracy: 0.9759\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0642 - accuracy: 0.9797\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0658 - accuracy: 0.9742\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0376 - accuracy: 0.9808\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0739 - accuracy: 0.9712\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0458 - accuracy: 0.9851\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0607 - accuracy: 0.9677\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0423 - accuracy: 0.9830\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0494 - accuracy: 0.9818\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0870 - accuracy: 0.9665\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0342 - accuracy: 0.9882\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0510 - accuracy: 0.9851\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7530db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c760fd940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c760278b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size in CV fold 16: 91\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8301 - accuracy: 0.5373\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.6690 - accuracy: 0.6934\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.6093 - accuracy: 0.6973\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.5707 - accuracy: 0.7358\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.5847 - accuracy: 0.7120\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.5322 - accuracy: 0.7431\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.5285 - accuracy: 0.7441\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.5458 - accuracy: 0.7193\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.4948 - accuracy: 0.7614\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.4860 - accuracy: 0.7725\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.5014 - accuracy: 0.7608\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.4575 - accuracy: 0.7993\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.4494 - accuracy: 0.7978\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.4590 - accuracy: 0.7836\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.4887 - accuracy: 0.7647\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.4229 - accuracy: 0.8158\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.4009 - accuracy: 0.8172\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.4238 - accuracy: 0.8112\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.3744 - accuracy: 0.8296\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.3865 - accuracy: 0.8225\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.3907 - accuracy: 0.8499\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.4059 - accuracy: 0.8175\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.4563 - accuracy: 0.7972\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.4046 - accuracy: 0.8256\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8576\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8601\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8785\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8742\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2923 - accuracy: 0.8711\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8644\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8652\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8332\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8852\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8870\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2802 - accuracy: 0.8680\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.9010\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.2703 - accuracy: 0.8729\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.2583 - accuracy: 0.8935\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.3070 - accuracy: 0.8522\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.2468 - accuracy: 0.9084\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.2000 - accuracy: 0.9128\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.2654 - accuracy: 0.8793\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.3039 - accuracy: 0.8549\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.2218 - accuracy: 0.8992\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.2744 - accuracy: 0.8525\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.2342 - accuracy: 0.8856\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.2572 - accuracy: 0.8811\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.2430 - accuracy: 0.9058\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.2498 - accuracy: 0.8759\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.2225 - accuracy: 0.8976\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1720 - accuracy: 0.9206\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.2064 - accuracy: 0.9058\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1705 - accuracy: 0.9193\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.1897 - accuracy: 0.9068\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.2357 - accuracy: 0.8979\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1795 - accuracy: 0.9157\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9222\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9066\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9343\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9090\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.9257\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.8940\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.8950\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1666 - accuracy: 0.9234\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.1810 - accuracy: 0.9056\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2111 - accuracy: 0.8949\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9349\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9051\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9006\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9263\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9383\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9463\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.1465 - accuracy: 0.9309\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9338\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1678 - accuracy: 0.9132\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1441 - accuracy: 0.9225\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1277 - accuracy: 0.9305\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.1058 - accuracy: 0.9478\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1514 - accuracy: 0.9173\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9321\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 877us/step - loss: 0.1293 - accuracy: 0.9408\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.9446\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9134\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9003\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.9074\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9283\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1485 - accuracy: 0.9123\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1943 - accuracy: 0.9142\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9249\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9131\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9405\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9380\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9489\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9375\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0987 - accuracy: 0.9578\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1206 - accuracy: 0.9381\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0869 - accuracy: 0.9626\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0949 - accuracy: 0.9465\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.1344 - accuracy: 0.9321\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1244 - accuracy: 0.9331\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1316 - accuracy: 0.9383\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0914 - accuracy: 0.9557\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.1025 - accuracy: 0.9479\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1046 - accuracy: 0.9422\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1186 - accuracy: 0.9412\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.1166 - accuracy: 0.9454\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.1101 - accuracy: 0.9460\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1139 - accuracy: 0.9385\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9417\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9475\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9620\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9421\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9721\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9647\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9463\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1310 - accuracy: 0.9328\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9414\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.9310\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9388\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1077 - accuracy: 0.9453\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0798 - accuracy: 0.9709\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9649\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9351\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.1149 - accuracy: 0.9518\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0788 - accuracy: 0.9604\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.1235 - accuracy: 0.9352\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0914 - accuracy: 0.9537\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0928 - accuracy: 0.9639\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.1549 - accuracy: 0.9222\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0823 - accuracy: 0.9574\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0888 - accuracy: 0.9479\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0961 - accuracy: 0.9562\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.1022 - accuracy: 0.9472\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.1284 - accuracy: 0.9482\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0832 - accuracy: 0.9601\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.1638 - accuracy: 0.8987\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1548 - accuracy: 0.9114\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.1372 - accuracy: 0.9440\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.1043 - accuracy: 0.9557\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0928 - accuracy: 0.9556\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0903 - accuracy: 0.9664\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.0941 - accuracy: 0.9477\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0956 - accuracy: 0.9609\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.1219 - accuracy: 0.9433\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0993 - accuracy: 0.9485\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0947 - accuracy: 0.9589\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9621\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0904 - accuracy: 0.9685\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1141 - accuracy: 0.9397\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1054 - accuracy: 0.9560\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.1062 - accuracy: 0.9576\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9632\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9441\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9546\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9630\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9512\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0941 - accuracy: 0.9536\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1356 - accuracy: 0.9264\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9498\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9519\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9382\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9444\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1072 - accuracy: 0.9508\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1381 - accuracy: 0.9292\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.1053 - accuracy: 0.9520\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.1090 - accuracy: 0.9422\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0840 - accuracy: 0.9632\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0823 - accuracy: 0.9649\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1036 - accuracy: 0.9394\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0999 - accuracy: 0.9438\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.1040 - accuracy: 0.9478\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0907 - accuracy: 0.9530\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0882 - accuracy: 0.9521\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.1162 - accuracy: 0.9332\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.1081 - accuracy: 0.9455\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.1107 - accuracy: 0.9497\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.0874 - accuracy: 0.9510\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.0613 - accuracy: 0.9737\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.1160 - accuracy: 0.9323\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0826 - accuracy: 0.9604\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.1107 - accuracy: 0.9495\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1052 - accuracy: 0.9465\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0946 - accuracy: 0.9526\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0862 - accuracy: 0.9576\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.0857 - accuracy: 0.9552\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0931 - accuracy: 0.9495\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0797 - accuracy: 0.9635\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.1500 - accuracy: 0.9410\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.1074 - accuracy: 0.9675\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1299 - accuracy: 0.9415\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9589\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9694\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9616\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9572\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9609\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9622\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.9585\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9385\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9591\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9514\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.7636\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8043\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.8236\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8361\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8445\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.3644 - accuracy: 0.8396\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.3193 - accuracy: 0.8639\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.3124 - accuracy: 0.8456\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8398\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8470\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8460\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8849\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.8743\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.8745\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.8798\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.9057\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2039 - accuracy: 0.9150\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.2235 - accuracy: 0.8968\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.2120 - accuracy: 0.9038\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1966 - accuracy: 0.9315\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.2312 - accuracy: 0.9058\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1684 - accuracy: 0.9380\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1686 - accuracy: 0.9254\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.1639 - accuracy: 0.9300\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.2591 - accuracy: 0.9037\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.2064 - accuracy: 0.9060\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1757 - accuracy: 0.9220\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1625 - accuracy: 0.9486\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.1438 - accuracy: 0.9476\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1554 - accuracy: 0.9465\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1447 - accuracy: 0.9301\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1418 - accuracy: 0.9395\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.1405 - accuracy: 0.9353\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1565 - accuracy: 0.9309\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.1512 - accuracy: 0.9366\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.1179 - accuracy: 0.9583\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.1093 - accuracy: 0.9590\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.1201 - accuracy: 0.9533\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1682 - accuracy: 0.9259\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.1250 - accuracy: 0.9367\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 768us/step - loss: 0.1182 - accuracy: 0.9401\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.1181 - accuracy: 0.9371\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1139 - accuracy: 0.9592\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1141 - accuracy: 0.9460\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1134 - accuracy: 0.9516\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0955 - accuracy: 0.9655\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.1345 - accuracy: 0.9486\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0991 - accuracy: 0.9625\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0908 - accuracy: 0.9638\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.0932 - accuracy: 0.9587\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.1224 - accuracy: 0.9427\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.0851 - accuracy: 0.9627\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0752 - accuracy: 0.9680\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0860 - accuracy: 0.9669\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.1281 - accuracy: 0.9414\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1071 - accuracy: 0.9482\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0708 - accuracy: 0.9723\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 714us/step - loss: 0.1231 - accuracy: 0.9497\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.1090 - accuracy: 0.9573\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.0691 - accuracy: 0.9770\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0790 - accuracy: 0.9699\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0815 - accuracy: 0.9679\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0470 - accuracy: 0.9869\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0692 - accuracy: 0.9722\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.0631 - accuracy: 0.9774\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.0884 - accuracy: 0.9579\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.1163 - accuracy: 0.9548\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.1046 - accuracy: 0.9463\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0702 - accuracy: 0.9655\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0680 - accuracy: 0.9725\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0590 - accuracy: 0.9831\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0467 - accuracy: 0.9833\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9811\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9841\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9880\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9655\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9606\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9852\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9731\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9711\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9591\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9703\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0528 - accuracy: 0.9797\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0688 - accuracy: 0.9763\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0538 - accuracy: 0.9843\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0598 - accuracy: 0.9811\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0316 - accuracy: 0.9888\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0837 - accuracy: 0.9673\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9771\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9834\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9652\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9932\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9850\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9801\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9733\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9878\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9678\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9775\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0518 - accuracy: 0.9807\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9788\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9738\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9852\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9854\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0807 - accuracy: 0.9744\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9642\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0812 - accuracy: 0.9630\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0819 - accuracy: 0.9756\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0678 - accuracy: 0.9704\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9652\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9734\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9881\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9866\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9747\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9818\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9837\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9760\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9836\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9764\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9844\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9755\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9801\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9766\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9777\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9494\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9596\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0915 - accuracy: 0.9657\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9884\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9737\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9853\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0260 - accuracy: 0.9973\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0278 - accuracy: 0.9924\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0440 - accuracy: 0.9784\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9849\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9674\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9886\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9937\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9725\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9883\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9846\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9852\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9792\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9781\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9907\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9842\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9888\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9840\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9787\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9972\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9862\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9653\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9632\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9876\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0435 - accuracy: 0.9819\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0272 - accuracy: 0.9924\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0298 - accuracy: 0.9913\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0439 - accuracy: 0.9866\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0311 - accuracy: 0.9913\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0174 - accuracy: 0.9961\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0377 - accuracy: 0.9859\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.0407 - accuracy: 0.9833\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0246 - accuracy: 0.9947\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0451 - accuracy: 0.9883\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0403 - accuracy: 0.9872\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0288 - accuracy: 0.9896\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0385 - accuracy: 0.9845\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0489 - accuracy: 0.9837\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0509 - accuracy: 0.9823\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0446 - accuracy: 0.9831\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0848 - accuracy: 0.9776\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9893\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0280 - accuracy: 0.9875\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0520 - accuracy: 0.9835\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0556 - accuracy: 0.9809\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0328 - accuracy: 0.9898\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0492 - accuracy: 0.9761\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.0565 - accuracy: 0.9868\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0315 - accuracy: 0.9887\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0397 - accuracy: 0.9880\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0421 - accuracy: 0.9840\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0202 - accuracy: 0.9955\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0687 - accuracy: 0.9728\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.0382 - accuracy: 0.9879\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0273 - accuracy: 0.9898\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0563 - accuracy: 0.9769\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0517 - accuracy: 0.9836\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0362 - accuracy: 0.9844\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0318 - accuracy: 0.9876\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0348 - accuracy: 0.9880\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0324 - accuracy: 0.9924\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0536 - accuracy: 0.9795\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0393 - accuracy: 0.9868\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.0380 - accuracy: 0.9846\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0252 - accuracy: 0.9926\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0366 - accuracy: 0.9877\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0437 - accuracy: 0.9808\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0440 - accuracy: 0.9840\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.0569 - accuracy: 0.9808\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0335 - accuracy: 0.9890\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.0218 - accuracy: 0.9949\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.6862 - accuracy: 0.7154\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 802us/step - loss: 0.4262 - accuracy: 0.8648\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.4133 - accuracy: 0.8700\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.3697 - accuracy: 0.8880\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.4062 - accuracy: 0.8762\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.3529 - accuracy: 0.8840\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.3626 - accuracy: 0.8726\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 700us/step - loss: 0.3425 - accuracy: 0.8703\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.3250 - accuracy: 0.8817\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.3350 - accuracy: 0.8805\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.3254 - accuracy: 0.8761\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.3107 - accuracy: 0.8756\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.2780 - accuracy: 0.8896\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.2714 - accuracy: 0.8898\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.2722 - accuracy: 0.8874\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.2893 - accuracy: 0.8821\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.2710 - accuracy: 0.8961\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.2335 - accuracy: 0.9216\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.2258 - accuracy: 0.9217\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.2212 - accuracy: 0.9039\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.2176 - accuracy: 0.9037\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.1994 - accuracy: 0.9242\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.1784 - accuracy: 0.9262\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1911 - accuracy: 0.9151\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 691us/step - loss: 0.1606 - accuracy: 0.9353\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.1536 - accuracy: 0.9406\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 705us/step - loss: 0.1590 - accuracy: 0.9396\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.1411 - accuracy: 0.9464\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.1590 - accuracy: 0.9361\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 706us/step - loss: 0.1680 - accuracy: 0.9340\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.1246 - accuracy: 0.9490\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1417 - accuracy: 0.9420\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.1326 - accuracy: 0.9433\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.1288 - accuracy: 0.9343\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9475\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9499\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1588 - accuracy: 0.9282\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.1606 - accuracy: 0.9240\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1133 - accuracy: 0.9475\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0976 - accuracy: 0.9686\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1117 - accuracy: 0.9496\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.1064 - accuracy: 0.9565\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1127 - accuracy: 0.9564\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.1193 - accuracy: 0.9417\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1012 - accuracy: 0.9464\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.1001 - accuracy: 0.9549\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0850 - accuracy: 0.9667\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.0819 - accuracy: 0.9783\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1040 - accuracy: 0.9442\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.1224 - accuracy: 0.9269\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1257 - accuracy: 0.9385\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.1521 - accuracy: 0.9256\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.1328 - accuracy: 0.9308\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.1149 - accuracy: 0.9465\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.1081 - accuracy: 0.9535\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0857 - accuracy: 0.9569\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0820 - accuracy: 0.9548\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0779 - accuracy: 0.9655\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.1043 - accuracy: 0.9481\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0862 - accuracy: 0.9600\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0920 - accuracy: 0.9590\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0979 - accuracy: 0.9576\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0618 - accuracy: 0.9731\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0653 - accuracy: 0.9773\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0796 - accuracy: 0.9651\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0823 - accuracy: 0.9671\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0681 - accuracy: 0.9786\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0697 - accuracy: 0.9761\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0582 - accuracy: 0.9781\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0662 - accuracy: 0.9663\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0602 - accuracy: 0.9674\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0730 - accuracy: 0.9722\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0691 - accuracy: 0.9724\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0919 - accuracy: 0.9681\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0678 - accuracy: 0.9780\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0581 - accuracy: 0.9816\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0699 - accuracy: 0.9672\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0705 - accuracy: 0.9708\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0929 - accuracy: 0.9525\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0592 - accuracy: 0.9758\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0418 - accuracy: 0.9857\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 809us/step - loss: 0.0580 - accuracy: 0.9839\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0760 - accuracy: 0.9738\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0737 - accuracy: 0.9663\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0540 - accuracy: 0.9782\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0406 - accuracy: 0.9886\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0417 - accuracy: 0.9823\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0513 - accuracy: 0.9713\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0412 - accuracy: 0.9847\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0438 - accuracy: 0.9807\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0678 - accuracy: 0.9755\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0929 - accuracy: 0.9543\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0531 - accuracy: 0.9795\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0549 - accuracy: 0.9734\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0684 - accuracy: 0.9731\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0531 - accuracy: 0.9818\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.0953 - accuracy: 0.9641\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0599 - accuracy: 0.9735\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0804 - accuracy: 0.9664\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0287 - accuracy: 0.9951\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0533 - accuracy: 0.9776\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0640 - accuracy: 0.9734\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0647 - accuracy: 0.9736\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0382 - accuracy: 0.9893\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0360 - accuracy: 0.9907\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0628 - accuracy: 0.9720\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0637 - accuracy: 0.9744\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0671 - accuracy: 0.9841\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0410 - accuracy: 0.9835\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0346 - accuracy: 0.9825\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0355 - accuracy: 0.9837\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0268 - accuracy: 0.9896\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0308 - accuracy: 0.9910\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0420 - accuracy: 0.9845\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0502 - accuracy: 0.9746\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0403 - accuracy: 0.9876\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0278 - accuracy: 0.9940\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0221 - accuracy: 0.9963\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0238 - accuracy: 0.9952\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0354 - accuracy: 0.9859\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0468 - accuracy: 0.9773\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.0306 - accuracy: 0.9913\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0378 - accuracy: 0.9874\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0408 - accuracy: 0.9876\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0504 - accuracy: 0.9810\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0382 - accuracy: 0.9823\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0406 - accuracy: 0.9858\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0267 - accuracy: 0.9924\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0303 - accuracy: 0.9914\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0445 - accuracy: 0.9853\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0614 - accuracy: 0.9749\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0449 - accuracy: 0.9834\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0316 - accuracy: 0.9864\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0568 - accuracy: 0.9820\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0556 - accuracy: 0.9812\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0779 - accuracy: 0.9669\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0641 - accuracy: 0.9739\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0525 - accuracy: 0.9798\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0384 - accuracy: 0.9824\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0707 - accuracy: 0.9731\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0326 - accuracy: 0.9955\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0360 - accuracy: 0.9872\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0231 - accuracy: 0.9917\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0176 - accuracy: 0.9959\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0261 - accuracy: 0.9908\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0484 - accuracy: 0.9791\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0174 - accuracy: 0.9932\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0285 - accuracy: 0.9913\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0534 - accuracy: 0.9818\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0253 - accuracy: 0.9913\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0429 - accuracy: 0.9885\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0454 - accuracy: 0.9842\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0330 - accuracy: 0.9893\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0353 - accuracy: 0.9848\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0320 - accuracy: 0.9904\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0334 - accuracy: 0.9837\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.0399 - accuracy: 0.9842\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0348 - accuracy: 0.9898\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 864us/step - loss: 0.0717 - accuracy: 0.9681\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0609 - accuracy: 0.9773\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0312 - accuracy: 0.9893\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0420 - accuracy: 0.9861\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.0332 - accuracy: 0.9884\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0313 - accuracy: 0.9894\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.0295 - accuracy: 0.9885\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0355 - accuracy: 0.9891\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0412 - accuracy: 0.9805\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0340 - accuracy: 0.9861\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0439 - accuracy: 0.9836\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0431 - accuracy: 0.9830\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0348 - accuracy: 0.9863\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0312 - accuracy: 0.9866\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9897\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9830\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0231 - accuracy: 0.9935\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0305 - accuracy: 0.9921\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0211 - accuracy: 0.9945\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0189 - accuracy: 0.9941\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0319 - accuracy: 0.9880\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0377 - accuracy: 0.9848\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0347 - accuracy: 0.9889\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0246 - accuracy: 0.9926\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0373 - accuracy: 0.9863\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0219 - accuracy: 0.9937\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0586 - accuracy: 0.9790\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0325 - accuracy: 0.9886\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0326 - accuracy: 0.9878\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0331 - accuracy: 0.9876\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0668 - accuracy: 0.9761\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1312 - accuracy: 0.9349\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0899 - accuracy: 0.9607\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0556 - accuracy: 0.9792\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0450 - accuracy: 0.9810\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9744\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0622 - accuracy: 0.9779\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0560 - accuracy: 0.9735\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0490 - accuracy: 0.9778\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0492 - accuracy: 0.9811\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c76be3dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c796dde50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c76b9fd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 17: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.8503 - accuracy: 0.6137\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.6761 - accuracy: 0.6801\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.6048 - accuracy: 0.7135\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 890us/step - loss: 0.6321 - accuracy: 0.6984\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.5886 - accuracy: 0.7145\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.5641 - accuracy: 0.7092\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.5168 - accuracy: 0.7529\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.5270 - accuracy: 0.7275\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.5115 - accuracy: 0.7658\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.4729 - accuracy: 0.7919\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.4970 - accuracy: 0.7829\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.4606 - accuracy: 0.7742\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.4798 - accuracy: 0.7632\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.4305 - accuracy: 0.8077\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.4676 - accuracy: 0.7880\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.4418 - accuracy: 0.8063\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.4373 - accuracy: 0.8215\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.4156 - accuracy: 0.8149\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.4074 - accuracy: 0.8220\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.3750 - accuracy: 0.8484\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.3903 - accuracy: 0.8071\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.3753 - accuracy: 0.8360\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.3550 - accuracy: 0.8549\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.3404 - accuracy: 0.8408\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.3665 - accuracy: 0.8388\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.3348 - accuracy: 0.8462\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.2954 - accuracy: 0.8724\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.3244 - accuracy: 0.8568\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.3159 - accuracy: 0.8809\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.2868 - accuracy: 0.8753\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.3097 - accuracy: 0.8789\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.3194 - accuracy: 0.8685\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.2641 - accuracy: 0.8895\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.2887 - accuracy: 0.8789\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.2917 - accuracy: 0.8766\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.2516 - accuracy: 0.8920\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.2735 - accuracy: 0.8916\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.2224 - accuracy: 0.9073\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.8919\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.2412 - accuracy: 0.8967\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.2769 - accuracy: 0.8977\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2898 - accuracy: 0.8787\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.2091 - accuracy: 0.9072\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.2876 - accuracy: 0.8829\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.2446 - accuracy: 0.8977\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.2022 - accuracy: 0.9153\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.2186 - accuracy: 0.9008\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.2231 - accuracy: 0.9073\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.2017 - accuracy: 0.9047\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.2386 - accuracy: 0.9002\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1731 - accuracy: 0.9188\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1857 - accuracy: 0.9222\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.2254 - accuracy: 0.8928\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1540 - accuracy: 0.9299\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1790 - accuracy: 0.9267\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.2197 - accuracy: 0.8967\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.2074 - accuracy: 0.9063\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.2027 - accuracy: 0.8946\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.2075 - accuracy: 0.8999\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1698 - accuracy: 0.9303\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1701 - accuracy: 0.9203\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.1662 - accuracy: 0.9204\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.1816 - accuracy: 0.9257\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.1457 - accuracy: 0.9339\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.1681 - accuracy: 0.9194\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1677 - accuracy: 0.9202\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.1373 - accuracy: 0.9407\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1546 - accuracy: 0.9288\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.1541 - accuracy: 0.9276\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.1748 - accuracy: 0.9139\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1601 - accuracy: 0.9069\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.1426 - accuracy: 0.9264\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.1449 - accuracy: 0.9280\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1483 - accuracy: 0.9229\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.1569 - accuracy: 0.9327\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1388 - accuracy: 0.9361\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1200 - accuracy: 0.9425\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1295 - accuracy: 0.9335\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1457 - accuracy: 0.9397\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.1840 - accuracy: 0.9084\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 834us/step - loss: 0.1310 - accuracy: 0.9169\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.1289 - accuracy: 0.9365\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.1169 - accuracy: 0.9536\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1285 - accuracy: 0.9415\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1303 - accuracy: 0.9461\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1399 - accuracy: 0.9317\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.1389 - accuracy: 0.9388\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1423 - accuracy: 0.9165\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1221 - accuracy: 0.9327\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0939 - accuracy: 0.9548\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1177 - accuracy: 0.9349\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1297 - accuracy: 0.9508\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1208 - accuracy: 0.9518\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.1136 - accuracy: 0.9366\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.1289 - accuracy: 0.9431\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0847 - accuracy: 0.9665\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.1120 - accuracy: 0.9401\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.1135 - accuracy: 0.9433\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.1071 - accuracy: 0.9440\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1012 - accuracy: 0.9511\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1269 - accuracy: 0.9404\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1554 - accuracy: 0.9402\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1880 - accuracy: 0.9083\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.1574 - accuracy: 0.9144\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1356 - accuracy: 0.9513\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0911 - accuracy: 0.9458\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.1182 - accuracy: 0.9447\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.1081 - accuracy: 0.9583\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1051 - accuracy: 0.9406\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.1055 - accuracy: 0.9531\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0832 - accuracy: 0.9629\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.1066 - accuracy: 0.9514\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.1155 - accuracy: 0.9436\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1876 - accuracy: 0.9213\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.1471 - accuracy: 0.9216\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.1305 - accuracy: 0.9147\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.1375 - accuracy: 0.9270\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.1096 - accuracy: 0.9356\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1055 - accuracy: 0.9380\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.1499 - accuracy: 0.9417\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1123 - accuracy: 0.9420\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1057 - accuracy: 0.9482\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1189 - accuracy: 0.9386\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.1305 - accuracy: 0.9293\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1246 - accuracy: 0.9484\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0768 - accuracy: 0.9692\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0888 - accuracy: 0.9596\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1378 - accuracy: 0.9404\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1247 - accuracy: 0.9320\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1117 - accuracy: 0.9420\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1350 - accuracy: 0.9326\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1045 - accuracy: 0.9379\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1365 - accuracy: 0.9234\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.1574 - accuracy: 0.9305\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.1733 - accuracy: 0.9322\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.1364 - accuracy: 0.9366\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.1032 - accuracy: 0.9475\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.1364 - accuracy: 0.9237\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1245 - accuracy: 0.9277\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1406 - accuracy: 0.9186\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1359 - accuracy: 0.9297\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.1076 - accuracy: 0.9537\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.1237 - accuracy: 0.9377\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.1261 - accuracy: 0.9320\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.1168 - accuracy: 0.9437\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.1621 - accuracy: 0.9230\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1525 - accuracy: 0.9339\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.1384 - accuracy: 0.9285\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.1058 - accuracy: 0.9469\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.1341 - accuracy: 0.9253\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0832 - accuracy: 0.9505\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0834 - accuracy: 0.9539\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1123 - accuracy: 0.9360\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.1278 - accuracy: 0.9321\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.1367 - accuracy: 0.9288\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.1751 - accuracy: 0.9257\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1158 - accuracy: 0.9385\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.1244 - accuracy: 0.9523\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.1148 - accuracy: 0.9497\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 796us/step - loss: 0.0992 - accuracy: 0.9492\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.1272 - accuracy: 0.9331\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.1202 - accuracy: 0.9301\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0687 - accuracy: 0.9618\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0971 - accuracy: 0.9434\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0931 - accuracy: 0.9570\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1154 - accuracy: 0.9255\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0990 - accuracy: 0.9422\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.1284 - accuracy: 0.9377\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1320 - accuracy: 0.9221\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1029 - accuracy: 0.9364\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0887 - accuracy: 0.9486\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1254 - accuracy: 0.9297\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.1116 - accuracy: 0.9376\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0798 - accuracy: 0.9517\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0979 - accuracy: 0.9469\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 860us/step - loss: 0.1016 - accuracy: 0.9489\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0980 - accuracy: 0.9418\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.1744 - accuracy: 0.9415\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.1189 - accuracy: 0.9457\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1018 - accuracy: 0.9489\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.1473 - accuracy: 0.9435\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.1306 - accuracy: 0.9442\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1004 - accuracy: 0.9504\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1040 - accuracy: 0.9416\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0948 - accuracy: 0.9513\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1266 - accuracy: 0.9265\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.1096 - accuracy: 0.9507\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0944 - accuracy: 0.9494\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1049 - accuracy: 0.9434\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0706 - accuracy: 0.9586\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.1339 - accuracy: 0.9287\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1001 - accuracy: 0.9396\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0863 - accuracy: 0.9477\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.1005 - accuracy: 0.9515\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.1354 - accuracy: 0.9330\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0866 - accuracy: 0.9574\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.0985 - accuracy: 0.9450\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0910 - accuracy: 0.9506\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0664 - accuracy: 0.9637\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0808 - accuracy: 0.9706\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.7396 - accuracy: 0.7368\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.5030 - accuracy: 0.8187\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.4378 - accuracy: 0.8320\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.4444 - accuracy: 0.8311\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.4288 - accuracy: 0.8204\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.3754 - accuracy: 0.8362\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.3498 - accuracy: 0.8455\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.3847 - accuracy: 0.8242\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.3528 - accuracy: 0.8246\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.3440 - accuracy: 0.8505\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.3271 - accuracy: 0.8547\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.2955 - accuracy: 0.8753\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.2852 - accuracy: 0.8744\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.3111 - accuracy: 0.8606\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.3011 - accuracy: 0.8360\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.2690 - accuracy: 0.8728\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.2836 - accuracy: 0.8579\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.2795 - accuracy: 0.8690\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.2591 - accuracy: 0.8730\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.2447 - accuracy: 0.8845\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.2594 - accuracy: 0.8698\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.2251 - accuracy: 0.8867\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.2232 - accuracy: 0.9005\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.1916 - accuracy: 0.9154\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.2356 - accuracy: 0.8809\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1981 - accuracy: 0.9022\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.2094 - accuracy: 0.9119\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.2105 - accuracy: 0.9181\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.2085 - accuracy: 0.9023\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.2251 - accuracy: 0.9045\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.2038 - accuracy: 0.9132\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2189 - accuracy: 0.8953\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9182\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1557 - accuracy: 0.9382\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.2046 - accuracy: 0.9102\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.1867 - accuracy: 0.9166\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.1848 - accuracy: 0.9151\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1560 - accuracy: 0.9323\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.2157 - accuracy: 0.9057\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 853us/step - loss: 0.1738 - accuracy: 0.9139\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1287 - accuracy: 0.9377\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1182 - accuracy: 0.9559\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 874us/step - loss: 0.2125 - accuracy: 0.9005\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.1333 - accuracy: 0.9353\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1772 - accuracy: 0.9187\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1090 - accuracy: 0.9588\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1046 - accuracy: 0.9584\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 881us/step - loss: 0.1304 - accuracy: 0.9434\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1272 - accuracy: 0.9422\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1387 - accuracy: 0.9473\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1391 - accuracy: 0.9437\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1218 - accuracy: 0.9498\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.1036 - accuracy: 0.9537\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1183 - accuracy: 0.9521\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1150 - accuracy: 0.9549\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.1243 - accuracy: 0.9410\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.1444 - accuracy: 0.9466\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1304 - accuracy: 0.9406\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.1166 - accuracy: 0.9537\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1282 - accuracy: 0.9415\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.1299 - accuracy: 0.9364\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1377 - accuracy: 0.9316\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1307 - accuracy: 0.9275\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1233 - accuracy: 0.9467\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9415\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9536\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9352\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9494\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9488\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1052 - accuracy: 0.9534\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9402\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1587 - accuracy: 0.9313\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.1829 - accuracy: 0.8930\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1333 - accuracy: 0.9246\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.1612 - accuracy: 0.9324\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 816us/step - loss: 0.0952 - accuracy: 0.9456\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.0970 - accuracy: 0.9542\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.1022 - accuracy: 0.9440\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1095 - accuracy: 0.9464\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0746 - accuracy: 0.9726\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0938 - accuracy: 0.9574\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0736 - accuracy: 0.9590\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0645 - accuracy: 0.9719\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 872us/step - loss: 0.0968 - accuracy: 0.9490\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0765 - accuracy: 0.9678\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0942 - accuracy: 0.9589\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.1724 - accuracy: 0.9126\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.1506 - accuracy: 0.9287\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.1541 - accuracy: 0.9190\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.1387 - accuracy: 0.9365\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 843us/step - loss: 0.0980 - accuracy: 0.9513\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.1216 - accuracy: 0.9225\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0916 - accuracy: 0.9618\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.1259 - accuracy: 0.9404\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0681 - accuracy: 0.9556\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0823 - accuracy: 0.9617\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0842 - accuracy: 0.9583\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 847us/step - loss: 0.0773 - accuracy: 0.9581\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0804 - accuracy: 0.9641\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0589 - accuracy: 0.9723\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 889us/step - loss: 0.0681 - accuracy: 0.9625\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.0777 - accuracy: 0.9564\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0820 - accuracy: 0.9530\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9539\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9680\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0701 - accuracy: 0.9659\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9474\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0794 - accuracy: 0.9640\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0922 - accuracy: 0.9641\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0835 - accuracy: 0.9687\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 888us/step - loss: 0.0886 - accuracy: 0.9559\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.1085 - accuracy: 0.9458\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1395 - accuracy: 0.9076\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1696 - accuracy: 0.9145\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0970 - accuracy: 0.9399\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0690 - accuracy: 0.9665\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 892us/step - loss: 0.0963 - accuracy: 0.9490\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0890 - accuracy: 0.9624\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9712\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9702\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9649\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9630\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1050 - accuracy: 0.9553\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0823 - accuracy: 0.9624\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9636\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 884us/step - loss: 0.0589 - accuracy: 0.9701\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0581 - accuracy: 0.9800\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0610 - accuracy: 0.9742\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0620 - accuracy: 0.9720\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0558 - accuracy: 0.9758\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0805 - accuracy: 0.9695\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0955 - accuracy: 0.9520\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0853 - accuracy: 0.9661\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0664 - accuracy: 0.9659\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.1179 - accuracy: 0.9511\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.1345 - accuracy: 0.9312\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.1145 - accuracy: 0.9468\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.1158 - accuracy: 0.9394\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0826 - accuracy: 0.9484\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0974 - accuracy: 0.9499\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0691 - accuracy: 0.9692\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0850 - accuracy: 0.9543\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0698 - accuracy: 0.9687\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0658 - accuracy: 0.9703\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0779 - accuracy: 0.9695\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0721 - accuracy: 0.9714\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0809 - accuracy: 0.9593\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 795us/step - loss: 0.1028 - accuracy: 0.9523\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.1505 - accuracy: 0.9111\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.1140 - accuracy: 0.9387\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0872 - accuracy: 0.9625\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0846 - accuracy: 0.9616\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0757 - accuracy: 0.9650\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0971 - accuracy: 0.9559\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9621\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9714\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0511 - accuracy: 0.9852\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 865us/step - loss: 0.0796 - accuracy: 0.9644\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0790 - accuracy: 0.9712\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0713 - accuracy: 0.9704\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0889 - accuracy: 0.9527\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0669 - accuracy: 0.9661\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0937 - accuracy: 0.9497\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0915 - accuracy: 0.9496\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.1008 - accuracy: 0.9497\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0988 - accuracy: 0.9559\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0764 - accuracy: 0.9614\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0711 - accuracy: 0.9641\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0913 - accuracy: 0.9657\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0853 - accuracy: 0.9566\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0799 - accuracy: 0.9621\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0592 - accuracy: 0.9719\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0724 - accuracy: 0.9655\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0799 - accuracy: 0.9607\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0872 - accuracy: 0.9508\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0664 - accuracy: 0.9617\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0763 - accuracy: 0.9649\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0757 - accuracy: 0.9670\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9614\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9668\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1070 - accuracy: 0.9417\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0942 - accuracy: 0.9549\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0939 - accuracy: 0.9684\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0939 - accuracy: 0.9564\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0781 - accuracy: 0.9622\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0711 - accuracy: 0.9740\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.1109 - accuracy: 0.9573\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0555 - accuracy: 0.9779\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0727 - accuracy: 0.9654\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0652 - accuracy: 0.9700\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0524 - accuracy: 0.9830\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0638 - accuracy: 0.9701\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0568 - accuracy: 0.9763\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0502 - accuracy: 0.9783\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0557 - accuracy: 0.9770\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.0605 - accuracy: 0.9716\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.0675 - accuracy: 0.9576\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0441 - accuracy: 0.9811\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 790us/step - loss: 0.0615 - accuracy: 0.9669\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0660 - accuracy: 0.9694\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.7336 - accuracy: 0.7354\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.4073 - accuracy: 0.8849\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.3864 - accuracy: 0.8740\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.3621 - accuracy: 0.8850\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.3521 - accuracy: 0.8815\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.3534 - accuracy: 0.8820\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.3606 - accuracy: 0.8722\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8899\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.3087 - accuracy: 0.8834\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.2991 - accuracy: 0.8921\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.3074 - accuracy: 0.8888\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.2800 - accuracy: 0.8952\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 799us/step - loss: 0.2788 - accuracy: 0.9001\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.2808 - accuracy: 0.8915\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.2721 - accuracy: 0.8920\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.2296 - accuracy: 0.8962\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.2638 - accuracy: 0.8865\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 764us/step - loss: 0.2653 - accuracy: 0.8864\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.2523 - accuracy: 0.8818\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.2046 - accuracy: 0.9130\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.2248 - accuracy: 0.9058\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.2305 - accuracy: 0.9044\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 752us/step - loss: 0.2092 - accuracy: 0.9168\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.1982 - accuracy: 0.9157\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.1959 - accuracy: 0.9231\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.1982 - accuracy: 0.9229\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 828us/step - loss: 0.1626 - accuracy: 0.9287\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.1761 - accuracy: 0.9332\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 834us/step - loss: 0.1539 - accuracy: 0.9388\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.1847 - accuracy: 0.9302\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.1308 - accuracy: 0.9434\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.1668 - accuracy: 0.9242\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 841us/step - loss: 0.1393 - accuracy: 0.9421\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 804us/step - loss: 0.1272 - accuracy: 0.9438\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.1511 - accuracy: 0.9395\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.1515 - accuracy: 0.9365\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1696 - accuracy: 0.9272\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.1256 - accuracy: 0.9484\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.1165 - accuracy: 0.9609\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.1177 - accuracy: 0.9509\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.1023 - accuracy: 0.9623\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.1044 - accuracy: 0.9633\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.1055 - accuracy: 0.9502\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0996 - accuracy: 0.9581\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 835us/step - loss: 0.1300 - accuracy: 0.9474\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.1029 - accuracy: 0.9599\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 767us/step - loss: 0.0986 - accuracy: 0.9698\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0849 - accuracy: 0.9679\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0921 - accuracy: 0.9622\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.1223 - accuracy: 0.9528\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0970 - accuracy: 0.9643\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.1022 - accuracy: 0.9546\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9301\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9604\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.1059 - accuracy: 0.9588\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.9685\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0687 - accuracy: 0.9767\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0610 - accuracy: 0.9841\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 885us/step - loss: 0.0941 - accuracy: 0.9603\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.1011 - accuracy: 0.9566\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0946 - accuracy: 0.9600\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0550 - accuracy: 0.9815\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0795 - accuracy: 0.9741\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0739 - accuracy: 0.9678\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0595 - accuracy: 0.9743\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.1023 - accuracy: 0.9555\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0659 - accuracy: 0.9809\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0444 - accuracy: 0.9886\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 818us/step - loss: 0.0489 - accuracy: 0.9841\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0483 - accuracy: 0.9784\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0469 - accuracy: 0.9815\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0512 - accuracy: 0.9781\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.0641 - accuracy: 0.9733\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0514 - accuracy: 0.9797\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9841\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9772\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0461 - accuracy: 0.9870\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1043 - accuracy: 0.9612\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 939us/step - loss: 0.0539 - accuracy: 0.9740\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0579 - accuracy: 0.9812\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0427 - accuracy: 0.9853\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0660 - accuracy: 0.9730\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.0442 - accuracy: 0.9833\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0432 - accuracy: 0.9839\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0361 - accuracy: 0.9932\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0527 - accuracy: 0.9827\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 879us/step - loss: 0.0667 - accuracy: 0.9698\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0534 - accuracy: 0.9761\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 905us/step - loss: 0.0462 - accuracy: 0.9839\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0645 - accuracy: 0.9748\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0625 - accuracy: 0.9694\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 824us/step - loss: 0.0418 - accuracy: 0.9878\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0569 - accuracy: 0.9806\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0657 - accuracy: 0.9749\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.0680 - accuracy: 0.9769\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0430 - accuracy: 0.9873\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0704 - accuracy: 0.9696\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0681 - accuracy: 0.9704\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9655\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0793 - accuracy: 0.9622\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9556\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9707\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9800\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0766 - accuracy: 0.9631\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0572 - accuracy: 0.9783\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0626 - accuracy: 0.9746\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0554 - accuracy: 0.9780\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0695 - accuracy: 0.9729\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0516 - accuracy: 0.9803\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0991 - accuracy: 0.9608\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0634 - accuracy: 0.9794\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0331 - accuracy: 0.9869\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0552 - accuracy: 0.9811\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0288 - accuracy: 0.9946\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0345 - accuracy: 0.9874\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9836\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0291 - accuracy: 0.9916\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0339 - accuracy: 0.9847\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0480 - accuracy: 0.9754\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0413 - accuracy: 0.9825\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0624 - accuracy: 0.9715\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0640 - accuracy: 0.9743\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0535 - accuracy: 0.9758\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.0258 - accuracy: 0.9946\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0361 - accuracy: 0.9837\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0365 - accuracy: 0.9877\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0267 - accuracy: 0.9946\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0510 - accuracy: 0.9804\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0581 - accuracy: 0.9750\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0353 - accuracy: 0.9892\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0567 - accuracy: 0.9751\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0458 - accuracy: 0.9812\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0483 - accuracy: 0.9851\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.0329 - accuracy: 0.9886\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0342 - accuracy: 0.9802\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9848\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9821\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0451 - accuracy: 0.9851\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0772 - accuracy: 0.9661\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0462 - accuracy: 0.9870\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0695 - accuracy: 0.9688\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.0556 - accuracy: 0.9716\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0653 - accuracy: 0.9732\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0682 - accuracy: 0.9747\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 805us/step - loss: 0.0596 - accuracy: 0.9769\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0472 - accuracy: 0.9754\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0401 - accuracy: 0.9856\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0357 - accuracy: 0.9883\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0340 - accuracy: 0.9908\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0185 - accuracy: 0.9964\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0458 - accuracy: 0.9782\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 776us/step - loss: 0.0165 - accuracy: 0.9965\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0431 - accuracy: 0.9871\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.0265 - accuracy: 0.9942\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0278 - accuracy: 0.9907\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0269 - accuracy: 0.9921\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0192 - accuracy: 0.9947\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0235 - accuracy: 0.9905\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 863us/step - loss: 0.0646 - accuracy: 0.9745\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0635 - accuracy: 0.9733\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0442 - accuracy: 0.9829\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0384 - accuracy: 0.9846\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.0624 - accuracy: 0.9759\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0514 - accuracy: 0.9789\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0578 - accuracy: 0.9791\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0549 - accuracy: 0.9779\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0487 - accuracy: 0.9783\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0416 - accuracy: 0.9872\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 794us/step - loss: 0.0174 - accuracy: 0.9941\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0255 - accuracy: 0.9880\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0257 - accuracy: 0.9909\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0333 - accuracy: 0.9822\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0541 - accuracy: 0.9780\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.0262 - accuracy: 0.9911\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0338 - accuracy: 0.9852\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.0229 - accuracy: 0.9944\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0238 - accuracy: 0.9880\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0442 - accuracy: 0.9838\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 779us/step - loss: 0.0539 - accuracy: 0.9767\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 788us/step - loss: 0.0504 - accuracy: 0.9789\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 801us/step - loss: 0.0498 - accuracy: 0.9831\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0560 - accuracy: 0.9745\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0729 - accuracy: 0.9662\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0722 - accuracy: 0.9680\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 803us/step - loss: 0.0447 - accuracy: 0.9812\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0449 - accuracy: 0.9824\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9906\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9888\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0212 - accuracy: 0.9959\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.9949\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 891us/step - loss: 0.0180 - accuracy: 0.9934\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0385 - accuracy: 0.9815\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0218 - accuracy: 0.9936\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0243 - accuracy: 0.9894\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0185 - accuracy: 0.9962\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0440 - accuracy: 0.9848\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.0653 - accuracy: 0.9817\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 773us/step - loss: 0.0655 - accuracy: 0.9766\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0252 - accuracy: 0.9923\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.0456 - accuracy: 0.9814\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7873c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c797b43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c796a71f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 18: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.7804 - accuracy: 0.6418\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 793us/step - loss: 0.6265 - accuracy: 0.7150\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.5903 - accuracy: 0.7365\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7134\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7302\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7494\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7736\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7937\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7692\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7672\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7746\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7977\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8080\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8349\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8473\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.4170 - accuracy: 0.8242\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.4034 - accuracy: 0.8247\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 821us/step - loss: 0.3713 - accuracy: 0.8381\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.3832 - accuracy: 0.8423\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.3473 - accuracy: 0.8581\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.3317 - accuracy: 0.8729\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.2843 - accuracy: 0.8838\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.3919 - accuracy: 0.8259\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.3074 - accuracy: 0.8659\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.2961 - accuracy: 0.8664\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.3066 - accuracy: 0.8570\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.3436 - accuracy: 0.8419\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 694us/step - loss: 0.2793 - accuracy: 0.8775\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.2795 - accuracy: 0.8758\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.2663 - accuracy: 0.8719\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.2887 - accuracy: 0.8789\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 708us/step - loss: 0.2361 - accuracy: 0.8898\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.2422 - accuracy: 0.9001\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 716us/step - loss: 0.2487 - accuracy: 0.8985\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.2348 - accuracy: 0.8933\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.2310 - accuracy: 0.9068\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.2200 - accuracy: 0.8985\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 721us/step - loss: 0.2061 - accuracy: 0.9012\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.2392 - accuracy: 0.8879\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.2253 - accuracy: 0.8894\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.2457 - accuracy: 0.8772\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 712us/step - loss: 0.2367 - accuracy: 0.8740\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.2610 - accuracy: 0.8866\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.2260 - accuracy: 0.8929\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.2369 - accuracy: 0.8941\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.2278 - accuracy: 0.8863\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.2577 - accuracy: 0.8702\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.2760 - accuracy: 0.8621\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.2105 - accuracy: 0.9026\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 725us/step - loss: 0.2013 - accuracy: 0.9056\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.1894 - accuracy: 0.8988\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 714us/step - loss: 0.2029 - accuracy: 0.8929\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.1860 - accuracy: 0.9064\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 839us/step - loss: 0.1908 - accuracy: 0.9086\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.1388 - accuracy: 0.9330\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.1801 - accuracy: 0.9079\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.1976 - accuracy: 0.9117\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 716us/step - loss: 0.1372 - accuracy: 0.9457\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.1763 - accuracy: 0.9174\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 716us/step - loss: 0.1935 - accuracy: 0.9306\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1695 - accuracy: 0.9122\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.1772 - accuracy: 0.9121\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.1578 - accuracy: 0.9265\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 714us/step - loss: 0.1804 - accuracy: 0.9113\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.1439 - accuracy: 0.9376\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.2250 - accuracy: 0.8868\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.2211 - accuracy: 0.8939\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 725us/step - loss: 0.1590 - accuracy: 0.9230\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.2302 - accuracy: 0.8901\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.1682 - accuracy: 0.9120\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.2171 - accuracy: 0.8894\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.1871 - accuracy: 0.9027\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.1302 - accuracy: 0.9385\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.1699 - accuracy: 0.9059\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.1589 - accuracy: 0.9236\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.1290 - accuracy: 0.9338\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.1170 - accuracy: 0.9479\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.1298 - accuracy: 0.9350\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.1984 - accuracy: 0.8809\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 716us/step - loss: 0.1749 - accuracy: 0.9187\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 745us/step - loss: 0.1544 - accuracy: 0.9079\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.1647 - accuracy: 0.9177\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.1697 - accuracy: 0.9024\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 698us/step - loss: 0.1609 - accuracy: 0.9274\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.1839 - accuracy: 0.9042\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.1685 - accuracy: 0.9081\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.1179 - accuracy: 0.9414\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.1404 - accuracy: 0.9256\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.1243 - accuracy: 0.9378\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.1398 - accuracy: 0.9343\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.1210 - accuracy: 0.9258\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.1419 - accuracy: 0.9053\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0953 - accuracy: 0.9433\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.1192 - accuracy: 0.9298\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0796 - accuracy: 0.9579\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.1070 - accuracy: 0.9428\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.1127 - accuracy: 0.9336\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.1373 - accuracy: 0.9194\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.1231 - accuracy: 0.9445\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 701us/step - loss: 0.1332 - accuracy: 0.9424\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.1328 - accuracy: 0.9421\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 697us/step - loss: 0.1222 - accuracy: 0.9520\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.1024 - accuracy: 0.9451\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 690us/step - loss: 0.0947 - accuracy: 0.9363\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.1245 - accuracy: 0.9415\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 715us/step - loss: 0.1007 - accuracy: 0.9452\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0911 - accuracy: 0.9613\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 701us/step - loss: 0.1104 - accuracy: 0.9489\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.1013 - accuracy: 0.9483\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.0986 - accuracy: 0.9479\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.1096 - accuracy: 0.9444\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 700us/step - loss: 0.0955 - accuracy: 0.9537\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.0889 - accuracy: 0.9452\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 704us/step - loss: 0.0949 - accuracy: 0.9394\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 777us/step - loss: 0.1049 - accuracy: 0.9445\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.1097 - accuracy: 0.9643\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.0998 - accuracy: 0.9491\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.1020 - accuracy: 0.9516\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9650\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0840 - accuracy: 0.9463\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9555\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9386\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9353\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1307 - accuracy: 0.9103\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1248 - accuracy: 0.9201\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.1758 - accuracy: 0.8976\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1490 - accuracy: 0.9294\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 772us/step - loss: 0.1189 - accuracy: 0.9314\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.1273 - accuracy: 0.9072\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.1361 - accuracy: 0.9220\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.1025 - accuracy: 0.9426\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.1109 - accuracy: 0.9461\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.0889 - accuracy: 0.9628\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.1120 - accuracy: 0.9471\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.0768 - accuracy: 0.9627\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.0652 - accuracy: 0.9721\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9681\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9384\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1035 - accuracy: 0.9541\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9521\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9450\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9514\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9362\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9503\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9571\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9706\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.9477\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0898 - accuracy: 0.9564\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0899 - accuracy: 0.9368\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0890 - accuracy: 0.9563\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0843 - accuracy: 0.9589\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 808us/step - loss: 0.1362 - accuracy: 0.9293\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 778us/step - loss: 0.1017 - accuracy: 0.9489\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.1050 - accuracy: 0.9209\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.1230 - accuracy: 0.9396\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.1051 - accuracy: 0.9467\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0633 - accuracy: 0.9600\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0999 - accuracy: 0.9547\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.1076 - accuracy: 0.9474\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0971 - accuracy: 0.9503\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9426\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9411\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9599\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9491\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9538\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9581\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9494\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0850 - accuracy: 0.9572\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1209 - accuracy: 0.9169\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9535\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9590\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9575\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0941 - accuracy: 0.9447\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0986 - accuracy: 0.9528\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0705 - accuracy: 0.9639\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0754 - accuracy: 0.9532\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0819 - accuracy: 0.9623\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0588 - accuracy: 0.9716\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.0692 - accuracy: 0.9588\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0909 - accuracy: 0.9421\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.0983 - accuracy: 0.9436\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.1039 - accuracy: 0.9534\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.0888 - accuracy: 0.9515\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.1182 - accuracy: 0.9460\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 701us/step - loss: 0.0886 - accuracy: 0.9477\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.0949 - accuracy: 0.9485\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.1016 - accuracy: 0.9333\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0811 - accuracy: 0.9608\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.0986 - accuracy: 0.9497\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.0701 - accuracy: 0.9557\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 705us/step - loss: 0.0934 - accuracy: 0.9448\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.1028 - accuracy: 0.9380\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.0824 - accuracy: 0.9560\n",
      "Epoch 194/200\n",
      " 1/32 [..............................] - ETA: 0s - loss: 0.0749 - accuracy: 0.9333WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6400 batches). You may need to use the repeat() function when building your dataset.\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9535\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 1s 844us/step - loss: 1.0725 - accuracy: 0.4135\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 783us/step - loss: 0.6132 - accuracy: 0.7970\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.5261 - accuracy: 0.8178\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.4488 - accuracy: 0.8335\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.4384 - accuracy: 0.8381\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 722us/step - loss: 0.3810 - accuracy: 0.8435\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.3821 - accuracy: 0.8549\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.3728 - accuracy: 0.8410\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.3483 - accuracy: 0.8585\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.3514 - accuracy: 0.8771\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.3269 - accuracy: 0.8492\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.3190 - accuracy: 0.8513\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.3159 - accuracy: 0.8863\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.3069 - accuracy: 0.8691\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.3187 - accuracy: 0.8812\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.2951 - accuracy: 0.8594\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.2937 - accuracy: 0.8699\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.2596 - accuracy: 0.8999\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 744us/step - loss: 0.2547 - accuracy: 0.9110\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.2260 - accuracy: 0.8974\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.2663 - accuracy: 0.8812\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.2611 - accuracy: 0.8969\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.1963 - accuracy: 0.9247\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.2108 - accuracy: 0.9139\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 746us/step - loss: 0.2442 - accuracy: 0.8968\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.2007 - accuracy: 0.9256\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.2174 - accuracy: 0.9036\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.2054 - accuracy: 0.9229\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.2344 - accuracy: 0.9045\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.2105 - accuracy: 0.9153\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.1955 - accuracy: 0.9231\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.1648 - accuracy: 0.9346\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 757us/step - loss: 0.1792 - accuracy: 0.9285\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.1867 - accuracy: 0.9266\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.1976 - accuracy: 0.9005\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.2015 - accuracy: 0.9185\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.1314 - accuracy: 0.9395\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.1400 - accuracy: 0.9539\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 768us/step - loss: 0.1336 - accuracy: 0.9557\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 739us/step - loss: 0.1435 - accuracy: 0.9428\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.1307 - accuracy: 0.9446\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1915 - accuracy: 0.9175\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.1289 - accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.1218 - accuracy: 0.9474\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.1029 - accuracy: 0.9565\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.1372 - accuracy: 0.9404\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.1361 - accuracy: 0.9434\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.1477 - accuracy: 0.9351\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.1239 - accuracy: 0.9532\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.1170 - accuracy: 0.9541\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.1050 - accuracy: 0.9594\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.1007 - accuracy: 0.9628\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9640\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9634\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9549\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9552\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9362\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9509\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9459\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9581\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9617\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9479\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9648\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9468\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9604\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9686\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9598\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9503\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9596\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.9490\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9605\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0854 - accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 822us/step - loss: 0.0871 - accuracy: 0.9633\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.1009 - accuracy: 0.9574\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1036 - accuracy: 0.9542\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0586 - accuracy: 0.9763\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 790us/step - loss: 0.0694 - accuracy: 0.9699\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0651 - accuracy: 0.9738\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0714 - accuracy: 0.9700\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 770us/step - loss: 0.0880 - accuracy: 0.9622\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0640 - accuracy: 0.9679\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 771us/step - loss: 0.0817 - accuracy: 0.9644\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.0952 - accuracy: 0.9599\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.0768 - accuracy: 0.9625\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.0482 - accuracy: 0.9795\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0773 - accuracy: 0.9597\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.0894 - accuracy: 0.9544\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.1077 - accuracy: 0.9538\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.0841 - accuracy: 0.9674\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0858 - accuracy: 0.9685\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.0624 - accuracy: 0.9760\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0822 - accuracy: 0.9617\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.1004 - accuracy: 0.9511\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.1008 - accuracy: 0.9493\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0937 - accuracy: 0.9593\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 853us/step - loss: 0.0779 - accuracy: 0.9643\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0432 - accuracy: 0.9822\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0584 - accuracy: 0.9687\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0494 - accuracy: 0.9738\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0689 - accuracy: 0.9680\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0628 - accuracy: 0.9577\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 851us/step - loss: 0.0608 - accuracy: 0.9697\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 823us/step - loss: 0.0622 - accuracy: 0.9635\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 845us/step - loss: 0.0665 - accuracy: 0.9662\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0928 - accuracy: 0.9630\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 775us/step - loss: 0.0820 - accuracy: 0.9624\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0639 - accuracy: 0.9617\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9652\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9758\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9776\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9770\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9682\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9753\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9705\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0909 - accuracy: 0.9691\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9609\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1311 - accuracy: 0.9356\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 856us/step - loss: 0.0973 - accuracy: 0.9454\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0805 - accuracy: 0.9634\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 809us/step - loss: 0.0685 - accuracy: 0.9653\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0740 - accuracy: 0.9524\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0877 - accuracy: 0.9483\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9480\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9394\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9598\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9580\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9532\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9675\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9588\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9475\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9692\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9683\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9605\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9531\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9619\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9672\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9552\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1096 - accuracy: 0.9410\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0787 - accuracy: 0.9614\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 869us/step - loss: 0.0709 - accuracy: 0.9666\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0534 - accuracy: 0.9759\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0484 - accuracy: 0.9751\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0735 - accuracy: 0.9612\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0590 - accuracy: 0.9719\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.0836 - accuracy: 0.9512\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0830 - accuracy: 0.9548\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0725 - accuracy: 0.9643\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 766us/step - loss: 0.0798 - accuracy: 0.9731\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 708us/step - loss: 0.0518 - accuracy: 0.9756\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0621 - accuracy: 0.9723\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.0755 - accuracy: 0.9571\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0673 - accuracy: 0.9716\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.0644 - accuracy: 0.9658\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0462 - accuracy: 0.9623\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.0536 - accuracy: 0.9701\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0537 - accuracy: 0.9637\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 731us/step - loss: 0.0708 - accuracy: 0.9614\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 753us/step - loss: 0.0806 - accuracy: 0.9602\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.0770 - accuracy: 0.9632\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0910 - accuracy: 0.9588\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.0653 - accuracy: 0.9684\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0576 - accuracy: 0.9786\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 820us/step - loss: 0.0651 - accuracy: 0.9593\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 878us/step - loss: 0.0617 - accuracy: 0.9746\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0540 - accuracy: 0.9711\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 864us/step - loss: 0.0425 - accuracy: 0.9788\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 880us/step - loss: 0.0568 - accuracy: 0.9681\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0479 - accuracy: 0.9718\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0440 - accuracy: 0.9717\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0526 - accuracy: 0.9767\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0612 - accuracy: 0.9607\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0457 - accuracy: 0.9709\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.0566 - accuracy: 0.9697\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 765us/step - loss: 0.0810 - accuracy: 0.9543\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 743us/step - loss: 0.0481 - accuracy: 0.9692\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0541 - accuracy: 0.9622\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0501 - accuracy: 0.9699\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0601 - accuracy: 0.9693\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.0547 - accuracy: 0.9723\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0482 - accuracy: 0.9709\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 728us/step - loss: 0.0700 - accuracy: 0.9668\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 811us/step - loss: 0.0506 - accuracy: 0.9662\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9738\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0529 - accuracy: 0.9722\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 877us/step - loss: 0.0532 - accuracy: 0.9707\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 887us/step - loss: 0.0558 - accuracy: 0.9632\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.0464 - accuracy: 0.9737\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 815us/step - loss: 0.0763 - accuracy: 0.9654\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0247 - accuracy: 0.9842\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0565 - accuracy: 0.9691\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0468 - accuracy: 0.9695\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 849us/step - loss: 0.0571 - accuracy: 0.9711\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0539 - accuracy: 0.9683\n",
      "Epoch 194/200\n",
      " 1/32 [..............................] - ETA: 0s - loss: 0.0818 - accuracy: 0.9667WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6400 batches). You may need to use the repeat() function when building your dataset.\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0663 - accuracy: 0.9562\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.5939 - accuracy: 0.8315\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.3890 - accuracy: 0.8746\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.3825 - accuracy: 0.8790\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.3983 - accuracy: 0.8653\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.3275 - accuracy: 0.8978\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 729us/step - loss: 0.3415 - accuracy: 0.8854\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.3118 - accuracy: 0.8901\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.3070 - accuracy: 0.9011\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.3481 - accuracy: 0.8758\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 707us/step - loss: 0.3980 - accuracy: 0.8547\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.3072 - accuracy: 0.8703\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 711us/step - loss: 0.2571 - accuracy: 0.9066\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.2558 - accuracy: 0.9082\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.2893 - accuracy: 0.8805\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.2313 - accuracy: 0.9143\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 720us/step - loss: 0.2271 - accuracy: 0.9058\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 716us/step - loss: 0.2188 - accuracy: 0.9126\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 703us/step - loss: 0.2158 - accuracy: 0.9055\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.2262 - accuracy: 0.9130\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 709us/step - loss: 0.2008 - accuracy: 0.9277\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.2191 - accuracy: 0.9210\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 708us/step - loss: 0.1967 - accuracy: 0.9203\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 745us/step - loss: 0.2058 - accuracy: 0.9167\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 713us/step - loss: 0.2000 - accuracy: 0.9281\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.2152 - accuracy: 0.9130\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.1697 - accuracy: 0.9390\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.1951 - accuracy: 0.9293\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 712us/step - loss: 0.1499 - accuracy: 0.9319\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.1252 - accuracy: 0.9543\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.1568 - accuracy: 0.9477\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.1275 - accuracy: 0.9507\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 718us/step - loss: 0.1482 - accuracy: 0.9345\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 761us/step - loss: 0.1236 - accuracy: 0.9553\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 716us/step - loss: 0.1504 - accuracy: 0.9407\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.1174 - accuracy: 0.9529\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 826us/step - loss: 0.1370 - accuracy: 0.9356\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.1325 - accuracy: 0.9465\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.0974 - accuracy: 0.9551\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.1086 - accuracy: 0.9509\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 729us/step - loss: 0.0815 - accuracy: 0.9633\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.0950 - accuracy: 0.9667\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 754us/step - loss: 0.0929 - accuracy: 0.9689\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0934 - accuracy: 0.9637\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 774us/step - loss: 0.0724 - accuracy: 0.9736\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 763us/step - loss: 0.0919 - accuracy: 0.9601\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 736us/step - loss: 0.1158 - accuracy: 0.9540\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 735us/step - loss: 0.1240 - accuracy: 0.9493\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 755us/step - loss: 0.0894 - accuracy: 0.9647\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 723us/step - loss: 0.0781 - accuracy: 0.9683\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0803 - accuracy: 0.9650\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9728\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9714\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9747\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9679\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9834\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9874\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9807\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0674 - accuracy: 0.9750\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 838us/step - loss: 0.0618 - accuracy: 0.9764\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0512 - accuracy: 0.9815\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0970 - accuracy: 0.9573\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9791\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9889\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0629 - accuracy: 0.9776\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9933\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9782\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9652\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9802\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9813\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9882\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9855\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9913\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9784\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9766\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9917\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9763\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9554\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0702 - accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 867us/step - loss: 0.0729 - accuracy: 0.9742\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 863us/step - loss: 0.0789 - accuracy: 0.9657\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 831us/step - loss: 0.0536 - accuracy: 0.9779\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0675 - accuracy: 0.9777\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0453 - accuracy: 0.9847\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 825us/step - loss: 0.0521 - accuracy: 0.9781\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 796us/step - loss: 0.0710 - accuracy: 0.9765\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 826us/step - loss: 0.0368 - accuracy: 0.9890\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 812us/step - loss: 0.0424 - accuracy: 0.9850\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 791us/step - loss: 0.0448 - accuracy: 0.9849\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 786us/step - loss: 0.0432 - accuracy: 0.9838\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0354 - accuracy: 0.9877\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0728 - accuracy: 0.9670\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 780us/step - loss: 0.0752 - accuracy: 0.9723\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0712 - accuracy: 0.9762\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 844us/step - loss: 0.0365 - accuracy: 0.9873\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 810us/step - loss: 0.0630 - accuracy: 0.9742\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0431 - accuracy: 0.9837\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.0593 - accuracy: 0.9833\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0954 - accuracy: 0.9553\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 719us/step - loss: 0.0450 - accuracy: 0.9841\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 748us/step - loss: 0.0477 - accuracy: 0.9789\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 727us/step - loss: 0.0445 - accuracy: 0.9876\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 733us/step - loss: 0.0493 - accuracy: 0.9789\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 699us/step - loss: 0.0530 - accuracy: 0.9782\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 724us/step - loss: 0.0819 - accuracy: 0.9698\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 726us/step - loss: 0.0677 - accuracy: 0.9753\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 730us/step - loss: 0.0793 - accuracy: 0.9634\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 732us/step - loss: 0.0358 - accuracy: 0.9918\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 747us/step - loss: 0.0374 - accuracy: 0.9879\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0487 - accuracy: 0.9788\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0349 - accuracy: 0.9900\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0337 - accuracy: 0.9897\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0414 - accuracy: 0.9848\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 738us/step - loss: 0.0235 - accuracy: 0.9948\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0365 - accuracy: 0.9884\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 800us/step - loss: 0.0497 - accuracy: 0.9793\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 798us/step - loss: 0.0565 - accuracy: 0.9791\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 785us/step - loss: 0.0477 - accuracy: 0.9821\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 760us/step - loss: 0.0319 - accuracy: 0.9902\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 741us/step - loss: 0.0517 - accuracy: 0.9789\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 742us/step - loss: 0.0600 - accuracy: 0.9768\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9825\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9875\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9844\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 886us/step - loss: 0.0323 - accuracy: 0.9907\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 854us/step - loss: 0.0437 - accuracy: 0.9844\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 837us/step - loss: 0.0263 - accuracy: 0.9921\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0531 - accuracy: 0.9847\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 758us/step - loss: 0.0321 - accuracy: 0.9929\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 749us/step - loss: 0.0381 - accuracy: 0.9859\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0279 - accuracy: 0.9921\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0479 - accuracy: 0.9847\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 762us/step - loss: 0.0583 - accuracy: 0.9771\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0986 - accuracy: 0.9669\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 900us/step - loss: 0.0584 - accuracy: 0.9750\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0791 - accuracy: 0.9660\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 871us/step - loss: 0.0801 - accuracy: 0.9625\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 827us/step - loss: 0.0734 - accuracy: 0.9695\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 832us/step - loss: 0.0708 - accuracy: 0.9725\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 819us/step - loss: 0.1037 - accuracy: 0.9438\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 840us/step - loss: 0.0718 - accuracy: 0.9701\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 870us/step - loss: 0.0536 - accuracy: 0.9824\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0378 - accuracy: 0.9869\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0508 - accuracy: 0.9811\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.0520 - accuracy: 0.9804\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 855us/step - loss: 0.0677 - accuracy: 0.9730\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0449 - accuracy: 0.9842\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 868us/step - loss: 0.0619 - accuracy: 0.9769\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 829us/step - loss: 0.0721 - accuracy: 0.9692\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0523 - accuracy: 0.9763\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 792us/step - loss: 0.0740 - accuracy: 0.9646\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 802us/step - loss: 0.0509 - accuracy: 0.9850\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 756us/step - loss: 0.0383 - accuracy: 0.9857\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 750us/step - loss: 0.0332 - accuracy: 0.9946\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 740us/step - loss: 0.0438 - accuracy: 0.9871\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 737us/step - loss: 0.0530 - accuracy: 0.9803\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 852us/step - loss: 0.0362 - accuracy: 0.9839\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 813us/step - loss: 0.0554 - accuracy: 0.9786\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 842us/step - loss: 0.0269 - accuracy: 0.9902\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0262 - accuracy: 0.9925\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0368 - accuracy: 0.9857\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0526 - accuracy: 0.9794\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9682\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9897\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0299 - accuracy: 0.9907\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 911us/step - loss: 0.0390 - accuracy: 0.9885\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0406 - accuracy: 0.9851\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0465 - accuracy: 0.9841\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0418 - accuracy: 0.9898\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0351 - accuracy: 0.9912\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0340 - accuracy: 0.9895\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0426 - accuracy: 0.9829\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0212 - accuracy: 0.9949\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0159 - accuracy: 0.9968\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0259 - accuracy: 0.9898\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0345 - accuracy: 0.9911\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0135 - accuracy: 0.9976\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 895us/step - loss: 0.0248 - accuracy: 0.9940\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0381 - accuracy: 0.9858\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 897us/step - loss: 0.0378 - accuracy: 0.9792\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0565 - accuracy: 0.9701\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0338 - accuracy: 0.9881\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0378 - accuracy: 0.9883\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0212 - accuracy: 0.9936\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0332 - accuracy: 0.9903\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0245 - accuracy: 0.9923\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0217 - accuracy: 0.9930\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0791 - accuracy: 0.9710\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9800\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0274 - accuracy: 0.9952\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0276 - accuracy: 0.9926\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 894us/step - loss: 0.0193 - accuracy: 0.9948\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0260 - accuracy: 0.9946\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0271 - accuracy: 0.9861\n",
      "Epoch 194/200\n",
      " 1/32 [..............................] - ETA: 0s - loss: 0.0798 - accuracy: 0.9667WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6400 batches). You may need to use the repeat() function when building your dataset.\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0716 - accuracy: 0.9737\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c76be3940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75135d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75b66940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 19: 91\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.9773 - accuracy: 0.4819\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.7048 - accuracy: 0.6596\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.6417 - accuracy: 0.6803\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.5852 - accuracy: 0.7284\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.5832 - accuracy: 0.7351\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.5631 - accuracy: 0.7278\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.5500 - accuracy: 0.7315\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.5192 - accuracy: 0.7494\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.5010 - accuracy: 0.7608\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.4707 - accuracy: 0.7767\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.4904 - accuracy: 0.7886\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.4588 - accuracy: 0.8107\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.4513 - accuracy: 0.7828\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.4521 - accuracy: 0.7770\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.4396 - accuracy: 0.8070\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.4306 - accuracy: 0.7926\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.4129 - accuracy: 0.8138\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.4136 - accuracy: 0.8103\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.4027 - accuracy: 0.8227\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.3776 - accuracy: 0.8441\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.4199 - accuracy: 0.8307\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.3979 - accuracy: 0.8198\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.3665 - accuracy: 0.8580\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.3722 - accuracy: 0.8439\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.3363 - accuracy: 0.8523\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.3333 - accuracy: 0.8569\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.3651 - accuracy: 0.8646\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.3472 - accuracy: 0.8473\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.3199 - accuracy: 0.8662\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.3305 - accuracy: 0.8659\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.2824 - accuracy: 0.8881\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2683 - accuracy: 0.8982\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.2797 - accuracy: 0.8644\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.3095 - accuracy: 0.8646\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.8855\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.9050\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.2516 - accuracy: 0.8962\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.2189 - accuracy: 0.9021\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.8924\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.3018 - accuracy: 0.8734\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.2920 - accuracy: 0.8647\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.2392 - accuracy: 0.9015\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.2373 - accuracy: 0.8907\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.9130\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.2602 - accuracy: 0.8814\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.2603 - accuracy: 0.8914\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.2191 - accuracy: 0.9165\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.2428 - accuracy: 0.8929\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1505 - accuracy: 0.9362\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9269\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9014\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9044\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9162\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.9168\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.9329\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.2462 - accuracy: 0.8903\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.2006 - accuracy: 0.9097\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.9250\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.1476 - accuracy: 0.9374\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.1733 - accuracy: 0.9286\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1469 - accuracy: 0.9417\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.9210\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1445 - accuracy: 0.9352\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9384\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9259\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9018\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1709 - accuracy: 0.9263\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9477\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1382 - accuracy: 0.9275\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1659 - accuracy: 0.9299\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.8738\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1617 - accuracy: 0.9192\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.2101 - accuracy: 0.8846\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 974us/step - loss: 0.1795 - accuracy: 0.9089\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1877 - accuracy: 0.8864\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.9162\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.2025 - accuracy: 0.8863\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1571 - accuracy: 0.9237\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9292\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1468 - accuracy: 0.9331\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1733 - accuracy: 0.9057\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1757 - accuracy: 0.9116\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1490 - accuracy: 0.9227\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2066 - accuracy: 0.8919\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.1422 - accuracy: 0.9180\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1549 - accuracy: 0.9107\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.1535 - accuracy: 0.9248\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1300 - accuracy: 0.9417\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1409 - accuracy: 0.9231\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1386 - accuracy: 0.9230\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1636 - accuracy: 0.9157\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.8940\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1680 - accuracy: 0.9179\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9117\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9463\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1148 - accuracy: 0.9526\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1208 - accuracy: 0.9363\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1178 - accuracy: 0.9324\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.1184 - accuracy: 0.9258\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1334 - accuracy: 0.9298\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1068 - accuracy: 0.9558\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1509 - accuracy: 0.9367\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1335 - accuracy: 0.9506\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1188 - accuracy: 0.9428\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9317\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.1572 - accuracy: 0.9037\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1323 - accuracy: 0.9204\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1300 - accuracy: 0.9240\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1232 - accuracy: 0.9293\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1487 - accuracy: 0.9244\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1334 - accuracy: 0.9300\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1384 - accuracy: 0.9274\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1497 - accuracy: 0.8974\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1464 - accuracy: 0.9129\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1129 - accuracy: 0.9410\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1061 - accuracy: 0.9471\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1038 - accuracy: 0.9428\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1202 - accuracy: 0.9496\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1194 - accuracy: 0.9362\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1092 - accuracy: 0.9528\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1225 - accuracy: 0.9434\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0901 - accuracy: 0.9581\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9332\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9183\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9428\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9371\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9545\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9283\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9040\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9296\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1368 - accuracy: 0.9340\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1463 - accuracy: 0.9181\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9540\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0894 - accuracy: 0.9508\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.1034 - accuracy: 0.9391\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1216 - accuracy: 0.9465\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1496 - accuracy: 0.9260\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9174\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9291\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1318 - accuracy: 0.9172\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1266 - accuracy: 0.9245\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0752 - accuracy: 0.9596\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1084 - accuracy: 0.9472\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1969 - accuracy: 0.9011\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1455 - accuracy: 0.9138\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1157 - accuracy: 0.9361\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1112 - accuracy: 0.9455\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9506\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0998 - accuracy: 0.9422\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.0984 - accuracy: 0.9546\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1437 - accuracy: 0.9273\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9596\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1127 - accuracy: 0.9305\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9654\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1019 - accuracy: 0.9541\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0986 - accuracy: 0.9555\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0846 - accuracy: 0.9617\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1227 - accuracy: 0.9312\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0849 - accuracy: 0.9596\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1001 - accuracy: 0.9477\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1338 - accuracy: 0.9494\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1130 - accuracy: 0.9400\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0863 - accuracy: 0.9536\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0772 - accuracy: 0.9618\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1054 - accuracy: 0.9580\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0918 - accuracy: 0.9545\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0946 - accuracy: 0.9587\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9419\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9647\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.1001 - accuracy: 0.9437\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0836 - accuracy: 0.9629\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0951 - accuracy: 0.9667\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0817 - accuracy: 0.9691\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0698 - accuracy: 0.9663\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0761 - accuracy: 0.9652\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0772 - accuracy: 0.9639\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1137 - accuracy: 0.9503\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1153 - accuracy: 0.9484\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1230 - accuracy: 0.9548\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1410 - accuracy: 0.9400\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1641 - accuracy: 0.9224\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1843 - accuracy: 0.8947\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1516 - accuracy: 0.9288\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9486\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1001 - accuracy: 0.9606\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0837 - accuracy: 0.9620\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0846 - accuracy: 0.9691\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9621\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1172 - accuracy: 0.9521\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9401\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.1138 - accuracy: 0.9578\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0954 - accuracy: 0.9567\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9587\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.9267\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0787 - accuracy: 0.9646\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.0831 - accuracy: 0.9625\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1037 - accuracy: 0.9568\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9670\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9644\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.9607\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.7703 - accuracy: 0.7023\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 883us/step - loss: 0.5691 - accuracy: 0.7666\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.8092\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.4584 - accuracy: 0.8249\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.4323 - accuracy: 0.8188\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.4105 - accuracy: 0.8240\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.3740 - accuracy: 0.8490\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.3721 - accuracy: 0.8331\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.4195 - accuracy: 0.8108\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.3669 - accuracy: 0.8298\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.3495 - accuracy: 0.8391\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 907us/step - loss: 0.3339 - accuracy: 0.8548\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.3482 - accuracy: 0.8491\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.3054 - accuracy: 0.8621\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8578\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.2772 - accuracy: 0.8815\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.3204 - accuracy: 0.8532\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.2652 - accuracy: 0.8863\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9103\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.2448 - accuracy: 0.8959\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.2421 - accuracy: 0.8807\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.2794 - accuracy: 0.8750\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9008\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.2338 - accuracy: 0.8901\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1859 - accuracy: 0.9254\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9330\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1800 - accuracy: 0.9338\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1692 - accuracy: 0.9287\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1667 - accuracy: 0.9360\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.1886 - accuracy: 0.9212\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.1722 - accuracy: 0.9344\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1372 - accuracy: 0.9385\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9491\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 936us/step - loss: 0.1287 - accuracy: 0.9558\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9307\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9231\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.9189\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9489\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1288 - accuracy: 0.9472\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.1258 - accuracy: 0.9469\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9200\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1480 - accuracy: 0.9404\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1627 - accuracy: 0.9333\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1469 - accuracy: 0.9390\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1494 - accuracy: 0.9302\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1092 - accuracy: 0.9552\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1159 - accuracy: 0.9471\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1133 - accuracy: 0.9608\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.1091 - accuracy: 0.9551\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1191 - accuracy: 0.9556\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1390 - accuracy: 0.9358\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.1252 - accuracy: 0.9406\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9615\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9605\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9610\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9785\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9647\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9671\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0992 - accuracy: 0.9482\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9648\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9666\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9546\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0917 - accuracy: 0.9601\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9734\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9614\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9860\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9715\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9710\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9650\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9645\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9354\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9549\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0628 - accuracy: 0.9785\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0920 - accuracy: 0.9685\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0918 - accuracy: 0.9627\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1028 - accuracy: 0.9609\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0640 - accuracy: 0.9799\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0478 - accuracy: 0.9845\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0519 - accuracy: 0.9789\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0650 - accuracy: 0.9747\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0664 - accuracy: 0.9768\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0850 - accuracy: 0.9629\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0816 - accuracy: 0.9648\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1113 - accuracy: 0.9570\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0617 - accuracy: 0.9780\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0613 - accuracy: 0.9761\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0707 - accuracy: 0.9720\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0348 - accuracy: 0.9911\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0582 - accuracy: 0.9742\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0730 - accuracy: 0.9663\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9535\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 914us/step - loss: 0.0983 - accuracy: 0.9592\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0786 - accuracy: 0.9725\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0714 - accuracy: 0.9721\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0556 - accuracy: 0.9806\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0597 - accuracy: 0.9863\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9763\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0385 - accuracy: 0.9889\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0576 - accuracy: 0.9794\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0329 - accuracy: 0.9919\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0674 - accuracy: 0.9791\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 901us/step - loss: 0.0471 - accuracy: 0.9843\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0876 - accuracy: 0.9646\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0598 - accuracy: 0.9776\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1038 - accuracy: 0.9568\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 893us/step - loss: 0.0401 - accuracy: 0.9883\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0840 - accuracy: 0.9736\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0693 - accuracy: 0.9770\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0309 - accuracy: 0.9893\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0893 - accuracy: 0.9640\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0767 - accuracy: 0.9687\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.0739 - accuracy: 0.9707\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9769\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9765\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0592 - accuracy: 0.9788\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9732\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9859\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0749 - accuracy: 0.9676\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0620 - accuracy: 0.9773\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9873\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0584 - accuracy: 0.9807\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9785\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0308 - accuracy: 0.9922\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9811\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9848\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0612 - accuracy: 0.9723\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0524 - accuracy: 0.9864\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0719 - accuracy: 0.9683\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9831\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9659\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0867 - accuracy: 0.9632\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.0636 - accuracy: 0.9731\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0622 - accuracy: 0.9813\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0705 - accuracy: 0.9696\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9883\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0357 - accuracy: 0.9852\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9788\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9876\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9828\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9742\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0417 - accuracy: 0.9891\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0693 - accuracy: 0.9747\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9659\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9534\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0787 - accuracy: 0.9701\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0429 - accuracy: 0.9868\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0429 - accuracy: 0.9864\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0467 - accuracy: 0.9819\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9738\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9929\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9910\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0448 - accuracy: 0.9873\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0683 - accuracy: 0.9752\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0504 - accuracy: 0.9805\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9794\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9769\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0309 - accuracy: 0.9941\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0278 - accuracy: 0.9918\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0625 - accuracy: 0.9808\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9879\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0593 - accuracy: 0.9775\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0566 - accuracy: 0.9843\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0348 - accuracy: 0.9890\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0528 - accuracy: 0.9789\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0516 - accuracy: 0.9792\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9816\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9732\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0904 - accuracy: 0.9535\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0669 - accuracy: 0.9757\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0423 - accuracy: 0.9871\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0661 - accuracy: 0.9757\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9864\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9862\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0305 - accuracy: 0.9896\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9843\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0335 - accuracy: 0.9911\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0350 - accuracy: 0.9909\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0600 - accuracy: 0.9759\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0741 - accuracy: 0.9700\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9845\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0509 - accuracy: 0.9791\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9728\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9837\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9917\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9845\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9809\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0268 - accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0431 - accuracy: 0.9821\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0489 - accuracy: 0.9852\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9771\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0848 - accuracy: 0.9650\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9821\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.0388 - accuracy: 0.9830\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 909us/step - loss: 0.0251 - accuracy: 0.9943\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0444 - accuracy: 0.9802\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9747\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9694\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0510 - accuracy: 0.9756\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0470 - accuracy: 0.9810\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0434 - accuracy: 0.9858\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.6167 - accuracy: 0.8154\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.8466\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8872\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8739\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.3597 - accuracy: 0.8867\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.3386 - accuracy: 0.8751\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.3379 - accuracy: 0.8707\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.3456 - accuracy: 0.8634\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.3699 - accuracy: 0.8599\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8925\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.8851\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.2856 - accuracy: 0.8812\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.2879 - accuracy: 0.8766\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.8801\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2912 - accuracy: 0.8632\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.2422 - accuracy: 0.8795\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.2669 - accuracy: 0.8810\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.2451 - accuracy: 0.9021\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2435 - accuracy: 0.8902\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.2130 - accuracy: 0.9077\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.2133 - accuracy: 0.9048\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 911us/step - loss: 0.1837 - accuracy: 0.9215\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.2179 - accuracy: 0.9066\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.9348\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1638 - accuracy: 0.9309\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1538 - accuracy: 0.9430\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1359 - accuracy: 0.9545\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2092 - accuracy: 0.9204\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.1701 - accuracy: 0.9378\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9296\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1397 - accuracy: 0.9387\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.2269 - accuracy: 0.9074\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1840 - accuracy: 0.9156\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1429 - accuracy: 0.9442\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1390 - accuracy: 0.9508\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9540\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.1163 - accuracy: 0.9564\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.1358 - accuracy: 0.9478\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1506 - accuracy: 0.9480\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9758\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1063 - accuracy: 0.9657\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0990 - accuracy: 0.9560\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1026 - accuracy: 0.9544\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9567\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.1350 - accuracy: 0.9385\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1034 - accuracy: 0.9542\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0910 - accuracy: 0.9625\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0859 - accuracy: 0.9660\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1025 - accuracy: 0.9542\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1125 - accuracy: 0.9499\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.0935 - accuracy: 0.9612\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0806 - accuracy: 0.9741\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.0958 - accuracy: 0.9649\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0701 - accuracy: 0.9723\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9594\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9554\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0745 - accuracy: 0.9692\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9488\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0957 - accuracy: 0.9613\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0790 - accuracy: 0.9759\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9868\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0497 - accuracy: 0.9862\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0586 - accuracy: 0.9814\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0930 - accuracy: 0.9684\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9771\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0391 - accuracy: 0.9896\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0623 - accuracy: 0.9777\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0573 - accuracy: 0.9804\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0843 - accuracy: 0.9637\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1278 - accuracy: 0.9530\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 902us/step - loss: 0.1276 - accuracy: 0.9448\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9688\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9704\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 952us/step - loss: 0.0979 - accuracy: 0.9543\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9536\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0738 - accuracy: 0.9753\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9674\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9668\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0697 - accuracy: 0.9723\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9694\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0745 - accuracy: 0.9694\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9816\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9573\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0978 - accuracy: 0.9574\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0642 - accuracy: 0.9745\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0893 - accuracy: 0.9666\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0646 - accuracy: 0.9756\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0681 - accuracy: 0.9782\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9840\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0472 - accuracy: 0.9861\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 975us/step - loss: 0.0497 - accuracy: 0.9837\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0689 - accuracy: 0.9738\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0460 - accuracy: 0.9858\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0415 - accuracy: 0.9885\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0427 - accuracy: 0.9825\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0350 - accuracy: 0.9910\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0501 - accuracy: 0.9836\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0357 - accuracy: 0.9837\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9746\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9768\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 898us/step - loss: 0.0353 - accuracy: 0.9878\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 797us/step - loss: 0.0669 - accuracy: 0.9791\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 859us/step - loss: 0.0450 - accuracy: 0.9829\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 787us/step - loss: 0.0357 - accuracy: 0.9896\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 846us/step - loss: 0.0605 - accuracy: 0.9769\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0406 - accuracy: 0.9871\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.0287 - accuracy: 0.9890\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 876us/step - loss: 0.0198 - accuracy: 0.9952\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9912\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9929\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9882\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9866\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9779\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9798\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0487 - accuracy: 0.9861\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9804\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9868\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0408 - accuracy: 0.9888\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.0239 - accuracy: 0.9922\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0253 - accuracy: 0.9896\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0279 - accuracy: 0.9907\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9778\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9765\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0427 - accuracy: 0.9847\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0769 - accuracy: 0.9707\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0575 - accuracy: 0.9783\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9908\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0151 - accuracy: 0.9985\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0238 - accuracy: 0.9936\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0234 - accuracy: 0.9933\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0287 - accuracy: 0.9916\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0312 - accuracy: 0.9871\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0320 - accuracy: 0.9905\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9787\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0524 - accuracy: 0.9779\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0586 - accuracy: 0.9791\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0413 - accuracy: 0.9871\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9844\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9886\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0273 - accuracy: 0.9924\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0502 - accuracy: 0.9753\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9826\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9902\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0365 - accuracy: 0.9899\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9854\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0229 - accuracy: 0.9912\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9848\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0367 - accuracy: 0.9880\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0853 - accuracy: 0.9763\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0387 - accuracy: 0.9875\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9769\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0316 - accuracy: 0.9916\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9912\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0293 - accuracy: 0.9932\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9824\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0393 - accuracy: 0.9892\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9921\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 0.9886\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0315 - accuracy: 0.9930\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0222 - accuracy: 0.9926\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0259 - accuracy: 0.9891\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9839\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9937\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9919\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0239 - accuracy: 0.9953\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9797\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9876\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9943\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0400 - accuracy: 0.9907\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9967\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0521 - accuracy: 0.9825\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9889\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0519 - accuracy: 0.9841\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0679 - accuracy: 0.9723\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9804\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9827\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0541 - accuracy: 0.9808\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0257 - accuracy: 0.9957\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0372 - accuracy: 0.9907\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0143 - accuracy: 0.9979\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0578 - accuracy: 0.9762\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 908us/step - loss: 0.0503 - accuracy: 0.9701\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9768\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0331 - accuracy: 0.9901\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9850\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0195 - accuracy: 0.9920\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9781\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0287 - accuracy: 0.9919\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9962\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0239 - accuracy: 0.9947\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0652 - accuracy: 0.9770\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0402 - accuracy: 0.9850\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9968\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0239 - accuracy: 0.9916\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0345 - accuracy: 0.9874\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0431 - accuracy: 0.9851\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0270 - accuracy: 0.9915\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7760a5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7538b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c751e19d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Validation set size in CV fold 20: 90\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.8184 - accuracy: 0.6376\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.6730\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.7035\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.5996 - accuracy: 0.7012\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7429\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7076\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7267\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7372\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7894\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.4732 - accuracy: 0.7935\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.4889 - accuracy: 0.7602\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.4427 - accuracy: 0.8005\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.4518 - accuracy: 0.7931\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7787\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8052\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.4739 - accuracy: 0.7888\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8574\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8232\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8233\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8348\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.3598 - accuracy: 0.8405\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.3629 - accuracy: 0.8403\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.3380 - accuracy: 0.8543\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8518\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8580\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8370\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.2956 - accuracy: 0.8646\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8591\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8885\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2719 - accuracy: 0.8768\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.2897 - accuracy: 0.8818\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.2708 - accuracy: 0.8684\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.3110 - accuracy: 0.8554\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8826\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.2634 - accuracy: 0.8961\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.2554 - accuracy: 0.8936\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.2474 - accuracy: 0.8995\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2554 - accuracy: 0.9011\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9061\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.9179\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.8919\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.2235 - accuracy: 0.9090\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.2044 - accuracy: 0.9180\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.2824 - accuracy: 0.8711\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.2595 - accuracy: 0.8873\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.2016 - accuracy: 0.9045\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.8748\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.2197 - accuracy: 0.8949\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.2013 - accuracy: 0.9263\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.2324 - accuracy: 0.8873\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9090\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.9364\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.1435 - accuracy: 0.9322\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9206\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.1385 - accuracy: 0.9369\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1629 - accuracy: 0.9232\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9069\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9124\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.2233 - accuracy: 0.8922\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.2511 - accuracy: 0.9012\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.2015 - accuracy: 0.9117\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.1726 - accuracy: 0.9334\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.8967\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1961 - accuracy: 0.9059\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.9115\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.2005 - accuracy: 0.9049\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1758 - accuracy: 0.9179\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1487 - accuracy: 0.9268\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.1455 - accuracy: 0.9274\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1620 - accuracy: 0.9221\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.2095 - accuracy: 0.9103\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1617 - accuracy: 0.9156\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9391\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9298\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.1389 - accuracy: 0.9302\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9095\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1532 - accuracy: 0.9261\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1706 - accuracy: 0.9261\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9135\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2090 - accuracy: 0.9246\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.2202 - accuracy: 0.8992\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1675 - accuracy: 0.9238\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.1369 - accuracy: 0.9469\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9552\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1314 - accuracy: 0.9314\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1491 - accuracy: 0.9392\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9210\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1620 - accuracy: 0.9300\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1520 - accuracy: 0.9300\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9413\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9516\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.9295\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.1585 - accuracy: 0.9268\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9093\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9134\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1166 - accuracy: 0.9473\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9305\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9541\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9367\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9245\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1725 - accuracy: 0.9324\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9428\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.1098 - accuracy: 0.9508\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.9303\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9478\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9472\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9404\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9318\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9436\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.1432 - accuracy: 0.9282\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9499\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9487\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9493\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9501\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1850 - accuracy: 0.9208\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9527\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.1219 - accuracy: 0.9551\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1308 - accuracy: 0.9499\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1308 - accuracy: 0.9389\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9197\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9492\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0962 - accuracy: 0.9562\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 949us/step - loss: 0.1240 - accuracy: 0.9506\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.0984 - accuracy: 0.9598\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9348\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0784 - accuracy: 0.9725\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9538\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9326\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.1311 - accuracy: 0.9236\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9477\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0840 - accuracy: 0.9585\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0921 - accuracy: 0.9520\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.9437\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1294 - accuracy: 0.9374\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9445\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9519\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1007 - accuracy: 0.9526\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9451\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9464\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9464\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9466\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.1280 - accuracy: 0.9288\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1140 - accuracy: 0.9332\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9126\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9121\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9322\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9317\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1359 - accuracy: 0.9281\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1243 - accuracy: 0.9218\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 899us/step - loss: 0.1024 - accuracy: 0.9366\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1163 - accuracy: 0.9327\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9532\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1592 - accuracy: 0.9088\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 955us/step - loss: 0.1069 - accuracy: 0.9258\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.1370 - accuracy: 0.9376\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.1183 - accuracy: 0.9425\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1152 - accuracy: 0.9309\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0868 - accuracy: 0.9533\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0995 - accuracy: 0.9404\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.1499 - accuracy: 0.9301\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1938 - accuracy: 0.9124\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1483 - accuracy: 0.9417\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.1682 - accuracy: 0.9208\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.1453 - accuracy: 0.9292\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.1019 - accuracy: 0.9551\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9654\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9432\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.8775\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9376\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1076 - accuracy: 0.9439\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1251 - accuracy: 0.9460\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9362\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1193 - accuracy: 0.9338\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9592\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9454\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.1310 - accuracy: 0.9445\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.1260 - accuracy: 0.9397\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1220 - accuracy: 0.9409\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0829 - accuracy: 0.9461\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0934 - accuracy: 0.9506\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.1081 - accuracy: 0.9475\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9535\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.1016 - accuracy: 0.9502\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0990 - accuracy: 0.9458\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0758 - accuracy: 0.9648\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0773 - accuracy: 0.9691\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1079 - accuracy: 0.9446\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.1029 - accuracy: 0.9472\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.1218 - accuracy: 0.9457\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9521\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9345\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0929 - accuracy: 0.9480\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.1245 - accuracy: 0.9426\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1323 - accuracy: 0.9402\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9536\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 920us/step - loss: 0.0956 - accuracy: 0.9497\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0664 - accuracy: 0.9680\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0845 - accuracy: 0.9580\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0713 - accuracy: 0.9677\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0877 - accuracy: 0.9535\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.7059 - accuracy: 0.7423\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 857us/step - loss: 0.4687 - accuracy: 0.8355\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.4412 - accuracy: 0.8344\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.4382 - accuracy: 0.8145\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.3601 - accuracy: 0.8467\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.3897 - accuracy: 0.8186\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.3528 - accuracy: 0.8590\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.3350 - accuracy: 0.8513\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.3062 - accuracy: 0.8546\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8491\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.2960 - accuracy: 0.8746\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.2830 - accuracy: 0.8543\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.2569 - accuracy: 0.8696\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.2990 - accuracy: 0.8641\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.3003 - accuracy: 0.8588\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.2741 - accuracy: 0.8710\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.2749 - accuracy: 0.8650\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.8915\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.2314 - accuracy: 0.8863\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.8924\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9033\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9222\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.2323 - accuracy: 0.8738\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.8980\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.9098\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.2175 - accuracy: 0.9124\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.1979 - accuracy: 0.9097\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 918us/step - loss: 0.1829 - accuracy: 0.9249\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.2048 - accuracy: 0.9163\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9089\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1549 - accuracy: 0.9256\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9464\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9554\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9389\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.9434\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1560 - accuracy: 0.9219\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9524\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1125 - accuracy: 0.9527\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9257\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.1562 - accuracy: 0.9369\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.1308 - accuracy: 0.9452\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1163 - accuracy: 0.9523\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.1088 - accuracy: 0.9556\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1640 - accuracy: 0.9297\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.9279\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9450\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9384\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9567\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9658\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9546\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0877 - accuracy: 0.9736\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9553\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9347\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9625\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0882 - accuracy: 0.9591\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1131 - accuracy: 0.9531\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0867 - accuracy: 0.9681\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0842 - accuracy: 0.9725\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0787 - accuracy: 0.9730\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.9676\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9770\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1051 - accuracy: 0.9569\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0893 - accuracy: 0.9644\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0669 - accuracy: 0.9774\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9797\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0851 - accuracy: 0.9689\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9605\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.2035 - accuracy: 0.9059\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9309\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1635 - accuracy: 0.9184\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0958 - accuracy: 0.9601\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1129 - accuracy: 0.9448\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.1153 - accuracy: 0.9438\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.1049 - accuracy: 0.9522\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1084 - accuracy: 0.9616\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.1355 - accuracy: 0.9277\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.1135 - accuracy: 0.9446\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0993 - accuracy: 0.9531\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.1065 - accuracy: 0.9484\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9700\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0967 - accuracy: 0.9591\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9504\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1155 - accuracy: 0.9477\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 926us/step - loss: 0.1304 - accuracy: 0.9286\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9478\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 925us/step - loss: 0.0949 - accuracy: 0.9595\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9371\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9543\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0918 - accuracy: 0.9687\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0754 - accuracy: 0.9731\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 977us/step - loss: 0.0818 - accuracy: 0.9644\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0666 - accuracy: 0.9755\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9433\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0853 - accuracy: 0.9666\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9755\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9611\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0643 - accuracy: 0.9783\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0821 - accuracy: 0.9745\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.1172 - accuracy: 0.9470\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.1197 - accuracy: 0.9490\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0977 - accuracy: 0.9556\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9802\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9754\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0901 - accuracy: 0.9601\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0859 - accuracy: 0.9632\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0678 - accuracy: 0.9764\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9759\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0782 - accuracy: 0.9704\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0923 - accuracy: 0.9615\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.1243 - accuracy: 0.9384\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0710 - accuracy: 0.9779\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 953us/step - loss: 0.0505 - accuracy: 0.9833\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 928us/step - loss: 0.0714 - accuracy: 0.9686\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9818\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0645 - accuracy: 0.9765\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0824 - accuracy: 0.9690\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 913us/step - loss: 0.0628 - accuracy: 0.9768\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0594 - accuracy: 0.9781\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0816 - accuracy: 0.9729\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0589 - accuracy: 0.9793\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9738\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9808\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9749\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0519 - accuracy: 0.9841\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.0487 - accuracy: 0.9831\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 956us/step - loss: 0.0744 - accuracy: 0.9749\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0719 - accuracy: 0.9728\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0962 - accuracy: 0.9599\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0763 - accuracy: 0.9650\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1340 - accuracy: 0.9344\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0873 - accuracy: 0.9626\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0864 - accuracy: 0.9554\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0865 - accuracy: 0.9674\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0917 - accuracy: 0.9623\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0551 - accuracy: 0.9774\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.0914 - accuracy: 0.9720\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0493 - accuracy: 0.9882\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0716 - accuracy: 0.9767\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0978 - accuracy: 0.9556\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0845 - accuracy: 0.9666\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0736 - accuracy: 0.9724\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0584 - accuracy: 0.9819\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9743\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9797\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9749\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 965us/step - loss: 0.1026 - accuracy: 0.9665\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 934us/step - loss: 0.0800 - accuracy: 0.9745\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 994us/step - loss: 0.0598 - accuracy: 0.9740\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0852 - accuracy: 0.9682\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.1110 - accuracy: 0.9476\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 909us/step - loss: 0.0965 - accuracy: 0.9618\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0710 - accuracy: 0.9745\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 919us/step - loss: 0.0581 - accuracy: 0.9760\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0793 - accuracy: 0.9663\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0560 - accuracy: 0.9750\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0388 - accuracy: 0.9882\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 995us/step - loss: 0.0753 - accuracy: 0.9740\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 917us/step - loss: 0.0839 - accuracy: 0.9691\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.1033 - accuracy: 0.9543\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0891 - accuracy: 0.9665\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0816 - accuracy: 0.9655\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0579 - accuracy: 0.9781\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0596 - accuracy: 0.9767\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0654 - accuracy: 0.9729\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 952us/step - loss: 0.0775 - accuracy: 0.9733\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.0736 - accuracy: 0.9752\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0794 - accuracy: 0.9639\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0641 - accuracy: 0.9757\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0392 - accuracy: 0.9853\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.0604 - accuracy: 0.9800\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9706\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.1112 - accuracy: 0.9504\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0941 - accuracy: 0.9555\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9586\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9610\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 987us/step - loss: 0.0856 - accuracy: 0.9642\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.0954 - accuracy: 0.9563\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0850 - accuracy: 0.9610\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0746 - accuracy: 0.9687\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0867 - accuracy: 0.9641\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9740\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0696 - accuracy: 0.9736\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 927us/step - loss: 0.0659 - accuracy: 0.9739\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0635 - accuracy: 0.9775\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1161 - accuracy: 0.9383\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0966 - accuracy: 0.9646\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0663 - accuracy: 0.9731\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.0770 - accuracy: 0.9665\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0555 - accuracy: 0.9790\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9759\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0669 - accuracy: 0.9735\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0599 - accuracy: 0.9777\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0465 - accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0539 - accuracy: 0.9784\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9814\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9877\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.0564 - accuracy: 0.9823\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0634 - accuracy: 0.9786\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 957us/step - loss: 0.0581 - accuracy: 0.9748\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0448 - accuracy: 0.9848\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 903us/step - loss: 0.5130 - accuracy: 0.8430\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.4458 - accuracy: 0.8446\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.3611 - accuracy: 0.8851\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 992us/step - loss: 0.3658 - accuracy: 0.8764\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.3691 - accuracy: 0.8752\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.3658 - accuracy: 0.8712\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.3373 - accuracy: 0.8817\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8680\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8585\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.3217 - accuracy: 0.8684\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8787\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.2443 - accuracy: 0.8983\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.2740 - accuracy: 0.8879\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.8618\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.8711\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.8660\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.2755 - accuracy: 0.8736\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.2454 - accuracy: 0.8917\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 922us/step - loss: 0.2177 - accuracy: 0.9058\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.9111\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.9185\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9198\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.1719 - accuracy: 0.9393\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9212\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1649 - accuracy: 0.9292\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9344\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.1338 - accuracy: 0.9517\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1879 - accuracy: 0.9342\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.1676 - accuracy: 0.9336\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.1571 - accuracy: 0.9399\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9170\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.1708 - accuracy: 0.9243\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.1451 - accuracy: 0.9332\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.1561 - accuracy: 0.9366\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1126 - accuracy: 0.9635\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9450\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.2266 - accuracy: 0.9013\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 947us/step - loss: 0.1609 - accuracy: 0.9351\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.1820 - accuracy: 0.9203\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.1763 - accuracy: 0.9107\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9626\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.1421 - accuracy: 0.9435\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.1162 - accuracy: 0.9493\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9781\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0925 - accuracy: 0.9616\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0943 - accuracy: 0.9631\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0954 - accuracy: 0.9604\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0692 - accuracy: 0.9827\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0832 - accuracy: 0.9687\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9592\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.1102 - accuracy: 0.9611\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0930 - accuracy: 0.9663\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9655\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0942 - accuracy: 0.9680\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9756\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9665\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0788 - accuracy: 0.9669\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.1054 - accuracy: 0.9506\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9593\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9771\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9781\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9669\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9670\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0733 - accuracy: 0.9734\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0799 - accuracy: 0.9667\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9398\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9612\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0693 - accuracy: 0.9742\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 910us/step - loss: 0.0673 - accuracy: 0.9766\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.9726\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0689 - accuracy: 0.9673\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 973us/step - loss: 0.0784 - accuracy: 0.9724\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0756 - accuracy: 0.9716\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 988us/step - loss: 0.0757 - accuracy: 0.9713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.1095 - accuracy: 0.9548\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.1208 - accuracy: 0.9466\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9661\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0680 - accuracy: 0.9778\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9816\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0620 - accuracy: 0.9766\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9522\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 921us/step - loss: 0.0889 - accuracy: 0.9619\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0585 - accuracy: 0.9765\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 954us/step - loss: 0.0552 - accuracy: 0.9836\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0662 - accuracy: 0.9753\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 964us/step - loss: 0.0952 - accuracy: 0.9598\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.1244 - accuracy: 0.9515\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0671 - accuracy: 0.9718\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 955us/step - loss: 0.0745 - accuracy: 0.9758\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 966us/step - loss: 0.0738 - accuracy: 0.9676\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9708\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0459 - accuracy: 0.9838\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9843\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0607 - accuracy: 0.9793\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0776 - accuracy: 0.9711\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9894\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0442 - accuracy: 0.9829\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0369 - accuracy: 0.9895\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0593 - accuracy: 0.9830\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 961us/step - loss: 0.0584 - accuracy: 0.9795\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0435 - accuracy: 0.9845\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0516 - accuracy: 0.9812\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0388 - accuracy: 0.9851\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0639 - accuracy: 0.9690\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0703 - accuracy: 0.9745\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 950us/step - loss: 0.0543 - accuracy: 0.9836\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0542 - accuracy: 0.9788\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 979us/step - loss: 0.0687 - accuracy: 0.9726\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 929us/step - loss: 0.0915 - accuracy: 0.9612\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 970us/step - loss: 0.0903 - accuracy: 0.9632\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9682\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9762\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9762\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 916us/step - loss: 0.0520 - accuracy: 0.9800\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 0s 983us/step - loss: 0.0339 - accuracy: 0.9899\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9802\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9774\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9844\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 978us/step - loss: 0.0423 - accuracy: 0.9865\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0419 - accuracy: 0.9899\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 958us/step - loss: 0.0538 - accuracy: 0.9803\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 935us/step - loss: 0.0574 - accuracy: 0.9812\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 912us/step - loss: 0.0392 - accuracy: 0.9859\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 960us/step - loss: 0.0521 - accuracy: 0.9782\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9837\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 980us/step - loss: 0.0487 - accuracy: 0.9888\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0486 - accuracy: 0.9858\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9835\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 933us/step - loss: 0.0352 - accuracy: 0.9913\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 976us/step - loss: 0.0650 - accuracy: 0.9747\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 986us/step - loss: 0.0487 - accuracy: 0.9820\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 923us/step - loss: 0.0628 - accuracy: 0.9748\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9828\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 940us/step - loss: 0.0373 - accuracy: 0.9851\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9682\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9789\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 963us/step - loss: 0.0561 - accuracy: 0.9742\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 932us/step - loss: 0.0582 - accuracy: 0.9783\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9859\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9798\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 959us/step - loss: 0.0438 - accuracy: 0.9833\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9837\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9877\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9865\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9900\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9861\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9863\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9726\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9908\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 972us/step - loss: 0.0821 - accuracy: 0.9748\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9844\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9859\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9904\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9874\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9958\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9806\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9755\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9870\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9914\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9759\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9938\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9921\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9799\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9661\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 974us/step - loss: 0.0603 - accuracy: 0.9773\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.0550 - accuracy: 0.9766\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.0602 - accuracy: 0.9768\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 939us/step - loss: 0.0892 - accuracy: 0.9537\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 993us/step - loss: 0.0667 - accuracy: 0.9766\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 984us/step - loss: 0.0354 - accuracy: 0.9934\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9763\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 0s 998us/step - loss: 0.0315 - accuracy: 0.9943\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 941us/step - loss: 0.0341 - accuracy: 0.9884\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 967us/step - loss: 0.0483 - accuracy: 0.9820\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 930us/step - loss: 0.0664 - accuracy: 0.9726\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0320 - accuracy: 0.9869\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 981us/step - loss: 0.0552 - accuracy: 0.9783\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 999us/step - loss: 0.0406 - accuracy: 0.9865\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 991us/step - loss: 0.0364 - accuracy: 0.9889\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9770\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9847\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 944us/step - loss: 0.0207 - accuracy: 0.9958\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0420 - accuracy: 0.9877\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 946us/step - loss: 0.0427 - accuracy: 0.9859\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9891\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.0360 - accuracy: 0.9858\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0230 - accuracy: 0.9937\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 942us/step - loss: 0.0386 - accuracy: 0.9854\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9898\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 990us/step - loss: 0.0231 - accuracy: 0.9924\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9811\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9843\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9932\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 931us/step - loss: 0.0239 - accuracy: 0.9945\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 989us/step - loss: 0.0306 - accuracy: 0.9906\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 915us/step - loss: 0.0330 - accuracy: 0.9888\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 962us/step - loss: 0.0880 - accuracy: 0.9680\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 997us/step - loss: 0.0294 - accuracy: 0.9899\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9687\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 996us/step - loss: 0.0897 - accuracy: 0.9597\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73edf670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c780000d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c76561a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MLmod.predictor_modified.MultiClassPredictions at 0x7f9c734d2610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.crossval_ksplit(splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pr.save_topfeat(outdir=\\'../data/chemgenetics/\\', \\n                fname=\"topfeat-multiclass-Nichols-signed\",\\n                    featname=X_onehot.columns.values)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pr.save_topfeat(outdir='../data/chemgenetics/', \n",
    "                fname=\"topfeat-multiclass-Nichols-signed\",\n",
    "                    featname=X_onehot.columns.values)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df = pr.aggregate_auc()\n",
    "ap_df = pr.aggregate_precision()\n",
    "metrics = pd.merge(auc_df, ap_df, on='cvfold', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows the cross-validation results sorted by average precision for antagonism prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvfold</th>\n",
       "      <th>AUCROC_none</th>\n",
       "      <th>AUCROC_antag</th>\n",
       "      <th>AUCROC_syn</th>\n",
       "      <th>AP_none</th>\n",
       "      <th>AP_antag</th>\n",
       "      <th>AP_syn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.868679</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.589372</td>\n",
       "      <td>0.895776</td>\n",
       "      <td>0.792228</td>\n",
       "      <td>0.218513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.845447</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.668008</td>\n",
       "      <td>0.943554</td>\n",
       "      <td>0.747892</td>\n",
       "      <td>0.170148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.722171</td>\n",
       "      <td>0.763320</td>\n",
       "      <td>0.659005</td>\n",
       "      <td>0.296397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.852316</td>\n",
       "      <td>0.584538</td>\n",
       "      <td>0.447602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.721751</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.875485</td>\n",
       "      <td>0.557530</td>\n",
       "      <td>0.553223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.739275</td>\n",
       "      <td>0.796371</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.848615</td>\n",
       "      <td>0.533146</td>\n",
       "      <td>0.662135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.667725</td>\n",
       "      <td>0.861598</td>\n",
       "      <td>0.570988</td>\n",
       "      <td>0.777321</td>\n",
       "      <td>0.522017</td>\n",
       "      <td>0.320894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>0.777017</td>\n",
       "      <td>0.897531</td>\n",
       "      <td>0.730422</td>\n",
       "      <td>0.936692</td>\n",
       "      <td>0.495296</td>\n",
       "      <td>0.272780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.874092</td>\n",
       "      <td>0.856725</td>\n",
       "      <td>0.885162</td>\n",
       "      <td>0.463707</td>\n",
       "      <td>0.539784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.780328</td>\n",
       "      <td>0.793129</td>\n",
       "      <td>0.769318</td>\n",
       "      <td>0.827106</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.397708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.679862</td>\n",
       "      <td>0.848471</td>\n",
       "      <td>0.414101</td>\n",
       "      <td>0.497812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>0.748120</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.871092</td>\n",
       "      <td>0.404713</td>\n",
       "      <td>0.610218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>0.746423</td>\n",
       "      <td>0.846467</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.856638</td>\n",
       "      <td>0.394840</td>\n",
       "      <td>0.622382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.720122</td>\n",
       "      <td>0.781977</td>\n",
       "      <td>0.668367</td>\n",
       "      <td>0.902192</td>\n",
       "      <td>0.386045</td>\n",
       "      <td>0.111526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>0.764519</td>\n",
       "      <td>0.705215</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.877820</td>\n",
       "      <td>0.360515</td>\n",
       "      <td>0.144604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.660656</td>\n",
       "      <td>0.718421</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.805379</td>\n",
       "      <td>0.280066</td>\n",
       "      <td>0.586942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>0.632143</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.752151</td>\n",
       "      <td>0.856928</td>\n",
       "      <td>0.262158</td>\n",
       "      <td>0.518720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>0.566459</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.645862</td>\n",
       "      <td>0.767179</td>\n",
       "      <td>0.239467</td>\n",
       "      <td>0.344829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0.751218</td>\n",
       "      <td>0.682497</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.882738</td>\n",
       "      <td>0.231526</td>\n",
       "      <td>0.515346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>0.747218</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.908338</td>\n",
       "      <td>0.183543</td>\n",
       "      <td>0.466309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cvfold  AUCROC_none  AUCROC_antag  AUCROC_syn   AP_none  AP_antag  \\\n",
       "0        6     0.868679      0.919355    0.589372  0.895776  0.792228   \n",
       "1       14     0.845447      0.929688    0.668008  0.943554  0.747892   \n",
       "2       13     0.673118      0.878378    0.722171  0.763320  0.659005   \n",
       "3        1     0.708333      0.849057    0.816667  0.852316  0.584538   \n",
       "4        5     0.721751      0.900000    0.805785  0.875485  0.557530   \n",
       "5       10     0.739275      0.796371    0.838235  0.848615  0.533146   \n",
       "6        3     0.667725      0.861598    0.570988  0.777321  0.522017   \n",
       "7       11     0.777017      0.897531    0.730422  0.936692  0.495296   \n",
       "8        7     0.759375      0.874092    0.856725  0.885162  0.463707   \n",
       "9        2     0.780328      0.793129    0.769318  0.827106  0.418568   \n",
       "10       8     0.578163      0.731250    0.679862  0.848471  0.414101   \n",
       "11      16     0.748120      0.760504    0.793651  0.871092  0.404713   \n",
       "12      17     0.746423      0.846467    0.787654  0.856638  0.394840   \n",
       "13       0     0.720122      0.781977    0.668367  0.902192  0.386045   \n",
       "14       9     0.764519      0.705215    0.663889  0.877820  0.360515   \n",
       "15      15     0.660656      0.718421    0.791228  0.805379  0.280066   \n",
       "16      19     0.632143      0.706294    0.752151  0.856928  0.262158   \n",
       "17      12     0.566459      0.735714    0.645862  0.767179  0.239467   \n",
       "18       4     0.751218      0.682497    0.778833  0.882738  0.231526   \n",
       "19      18     0.747218      0.714286    0.814815  0.908338  0.183543   \n",
       "\n",
       "      AP_syn  \n",
       "0   0.218513  \n",
       "1   0.170148  \n",
       "2   0.296397  \n",
       "3   0.447602  \n",
       "4   0.553223  \n",
       "5   0.662135  \n",
       "6   0.320894  \n",
       "7   0.272780  \n",
       "8   0.539784  \n",
       "9   0.397708  \n",
       "10  0.497812  \n",
       "11  0.610218  \n",
       "12  0.622382  \n",
       "13  0.111526  \n",
       "14  0.144604  \n",
       "15  0.586942  \n",
       "16  0.518720  \n",
       "17  0.344829  \n",
       "18  0.515346  \n",
       "19  0.466309  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(metrics.\n",
    " sort_values('AP_antag', ascending=False).\n",
    " reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for synergy prediction - arrange the table by average precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvfold</th>\n",
       "      <th>AUCROC_none</th>\n",
       "      <th>AUCROC_antag</th>\n",
       "      <th>AUCROC_syn</th>\n",
       "      <th>AP_none</th>\n",
       "      <th>AP_antag</th>\n",
       "      <th>AP_syn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.739275</td>\n",
       "      <td>0.796371</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.848615</td>\n",
       "      <td>0.533146</td>\n",
       "      <td>0.662135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0.746423</td>\n",
       "      <td>0.846467</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.856638</td>\n",
       "      <td>0.394840</td>\n",
       "      <td>0.622382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.748120</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.871092</td>\n",
       "      <td>0.404713</td>\n",
       "      <td>0.610218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.660656</td>\n",
       "      <td>0.718421</td>\n",
       "      <td>0.791228</td>\n",
       "      <td>0.805379</td>\n",
       "      <td>0.280066</td>\n",
       "      <td>0.586942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.721751</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.875485</td>\n",
       "      <td>0.557530</td>\n",
       "      <td>0.553223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.759375</td>\n",
       "      <td>0.874092</td>\n",
       "      <td>0.856725</td>\n",
       "      <td>0.885162</td>\n",
       "      <td>0.463707</td>\n",
       "      <td>0.539784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>0.632143</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.752151</td>\n",
       "      <td>0.856928</td>\n",
       "      <td>0.262158</td>\n",
       "      <td>0.518720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.751218</td>\n",
       "      <td>0.682497</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.882738</td>\n",
       "      <td>0.231526</td>\n",
       "      <td>0.515346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.679862</td>\n",
       "      <td>0.848471</td>\n",
       "      <td>0.414101</td>\n",
       "      <td>0.497812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>0.747218</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.908338</td>\n",
       "      <td>0.183543</td>\n",
       "      <td>0.466309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.852316</td>\n",
       "      <td>0.584538</td>\n",
       "      <td>0.447602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.780328</td>\n",
       "      <td>0.793129</td>\n",
       "      <td>0.769318</td>\n",
       "      <td>0.827106</td>\n",
       "      <td>0.418568</td>\n",
       "      <td>0.397708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.566459</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.645862</td>\n",
       "      <td>0.767179</td>\n",
       "      <td>0.239467</td>\n",
       "      <td>0.344829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.667725</td>\n",
       "      <td>0.861598</td>\n",
       "      <td>0.570988</td>\n",
       "      <td>0.777321</td>\n",
       "      <td>0.522017</td>\n",
       "      <td>0.320894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.722171</td>\n",
       "      <td>0.763320</td>\n",
       "      <td>0.659005</td>\n",
       "      <td>0.296397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>0.777017</td>\n",
       "      <td>0.897531</td>\n",
       "      <td>0.730422</td>\n",
       "      <td>0.936692</td>\n",
       "      <td>0.495296</td>\n",
       "      <td>0.272780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>0.868679</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.589372</td>\n",
       "      <td>0.895776</td>\n",
       "      <td>0.792228</td>\n",
       "      <td>0.218513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>0.845447</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.668008</td>\n",
       "      <td>0.943554</td>\n",
       "      <td>0.747892</td>\n",
       "      <td>0.170148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>0.764519</td>\n",
       "      <td>0.705215</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.877820</td>\n",
       "      <td>0.360515</td>\n",
       "      <td>0.144604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.720122</td>\n",
       "      <td>0.781977</td>\n",
       "      <td>0.668367</td>\n",
       "      <td>0.902192</td>\n",
       "      <td>0.386045</td>\n",
       "      <td>0.111526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cvfold  AUCROC_none  AUCROC_antag  AUCROC_syn   AP_none  AP_antag  \\\n",
       "0       10     0.739275      0.796371    0.838235  0.848615  0.533146   \n",
       "1       17     0.746423      0.846467    0.787654  0.856638  0.394840   \n",
       "2       16     0.748120      0.760504    0.793651  0.871092  0.404713   \n",
       "3       15     0.660656      0.718421    0.791228  0.805379  0.280066   \n",
       "4        5     0.721751      0.900000    0.805785  0.875485  0.557530   \n",
       "5        7     0.759375      0.874092    0.856725  0.885162  0.463707   \n",
       "6       19     0.632143      0.706294    0.752151  0.856928  0.262158   \n",
       "7        4     0.751218      0.682497    0.778833  0.882738  0.231526   \n",
       "8        8     0.578163      0.731250    0.679862  0.848471  0.414101   \n",
       "9       18     0.747218      0.714286    0.814815  0.908338  0.183543   \n",
       "10       1     0.708333      0.849057    0.816667  0.852316  0.584538   \n",
       "11       2     0.780328      0.793129    0.769318  0.827106  0.418568   \n",
       "12      12     0.566459      0.735714    0.645862  0.767179  0.239467   \n",
       "13       3     0.667725      0.861598    0.570988  0.777321  0.522017   \n",
       "14      13     0.673118      0.878378    0.722171  0.763320  0.659005   \n",
       "15      11     0.777017      0.897531    0.730422  0.936692  0.495296   \n",
       "16       6     0.868679      0.919355    0.589372  0.895776  0.792228   \n",
       "17      14     0.845447      0.929688    0.668008  0.943554  0.747892   \n",
       "18       9     0.764519      0.705215    0.663889  0.877820  0.360515   \n",
       "19       0     0.720122      0.781977    0.668367  0.902192  0.386045   \n",
       "\n",
       "      AP_syn  \n",
       "0   0.662135  \n",
       "1   0.622382  \n",
       "2   0.610218  \n",
       "3   0.586942  \n",
       "4   0.553223  \n",
       "5   0.539784  \n",
       "6   0.518720  \n",
       "7   0.515346  \n",
       "8   0.497812  \n",
       "9   0.466309  \n",
       "10  0.447602  \n",
       "11  0.397708  \n",
       "12  0.344829  \n",
       "13  0.320894  \n",
       "14  0.296397  \n",
       "15  0.272780  \n",
       "16  0.218513  \n",
       "17  0.170148  \n",
       "18  0.144604  \n",
       "19  0.111526  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(metrics.\n",
    " sort_values('AP_syn', ascending=False).\n",
    " reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the most important genetic features and rank them by the number of cross-validation folds in which these appeared as top 30 features based on the splitting criterion (Gini impurity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d662330c50c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m topvars = (pd.concat(pr.topfeat).\n\u001b[0m\u001b[1;32m      2\u001b[0m                    \u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"level_0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"cvfold\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    drop(columns=['level_1']))\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "topvars = (pd.concat(pr.topfeat).\n",
    "                   reset_index().\n",
    "                   rename(columns={\"level_0\": \"cvfold\"}).\n",
    "                   drop(columns=['level_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featname=X_onehot.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topvars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9cd0ea6d17e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m topvars = (topvars.assign(feature=featname[topvars.feat]).\n\u001b[0m\u001b[1;32m      2\u001b[0m            drop(columns=['feat']))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topvars' is not defined"
     ]
    }
   ],
   "source": [
    "topvars = (topvars.assign(feature=featname[topvars.feat]).\n",
    "           drop(columns=['feat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top genes for antagonism prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topvars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3ef4f58477d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m (topvars[topvars.type == 'antag'].\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cvfold > 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  sort_values('cvfold', ascending=False).iloc[:30,0])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topvars' is not defined"
     ]
    }
   ],
   "source": [
    "(topvars[topvars.type == 'antag'].\n",
    " groupby('feature').agg('count').\n",
    " query('cvfold > 1').\n",
    " sort_values('cvfold', ascending=False).iloc[:30,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top genes for synergy prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topvars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-47c1543b8678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m (topvars[topvars.type == 'syn'].\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cvfold > 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  sort_values('cvfold', ascending=False).iloc[:30,0])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topvars' is not defined"
     ]
    }
   ],
   "source": [
    "(topvars[topvars.type == 'syn'].\n",
    " groupby('feature').agg('count').\n",
    " query('cvfold > 1').\n",
    " sort_values('cvfold', ascending=False).iloc[:30,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"threshclass\"></a> \n",
    "## Choose Thresholds for Antagonisms and Synergies\n",
    "The 'probability' score $p_{RF}$ output by random forests does not correspond to the probability of being a synergy or antagonism, i.e. \n",
    "$$p_{RF}(c=C|X) \\neq P(c=C|X)$$\n",
    "\n",
    "By construction random forests do not approximate class probabilities (unlike logistic regression e.g.) and due to class imbalance (80% additive combinations, 10% synergies, 10% antagonisms) almost all combinations are predicted to be neutral if one takes \n",
    "$$ \\hat{C} = \\mathrm{argmax} (p_{RF}(c|X)) $$\n",
    "\n",
    "Since we are using `OneVsRestClassifier` however, we have technically 3 different binary classifiers, one for each combination type. We can use precision-recall characteristics in cross-validation folds to find thresholds for $p_{RF}(c=\\mathrm{antagonism}|X)$ and $p_{RF}(c=\\mathrm{synergy}|X)$.\n",
    "\n",
    "In each cross-validation fold select thresholds such that precision > 0.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose prob score cutoff such that precision > 0.6\n",
    "prec_thresh = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "TP_df = list()\n",
    "for cl in pr.predicted.keys():\n",
    "    # print(cl)\n",
    "    ycl = y[np.isin(combs, pr.predicted[cl]['comb'].values)]\n",
    "    gt = pd.DataFrame(ycl, columns=['none', 'antagonism', 'synergy'])\n",
    "    gt['comb'] = combs[np.isin(combs, pr.predicted[cl]['comb'].values)]\n",
    "    pred_df = pd.merge(left=pr.predicted[cl], right=gt, how='inner', on='comb')\n",
    "    \n",
    "    precision, recall, thresh = precision_recall_curve(pred_df['antagonism'].values,\n",
    "                                                        pred_df['score_antag'].values)\n",
    "    if np.any(precision > prec_thresh):\n",
    "        # maximum recall\n",
    "        rmax = np.max(recall[precision > prec_thresh])\n",
    "        # maximum precision\n",
    "        pmax = np.max(precision[recall == rmax])\n",
    "        # index with maximum recall and precision > prec_thresh\n",
    "        idx = np.where(np.logical_and(precision == pmax, recall == rmax))[0][0]\n",
    "        # corresponding threshold\n",
    "        antag_thresh = thresh[idx] if idx < len(thresh) else thresh[-1]\n",
    "        antag_tp = pred_df[(pred_df.score_antag > antag_thresh) == pred_df.antagonism]\n",
    "        antag_tp = antag_tp[antag_tp.antagonism == 1]\n",
    "        antag_tp['thresh'] = antag_thresh\n",
    "        antag_tp['precision'] = pmax\n",
    "        antag_tp['recall'] = rmax\n",
    "        antag_tp['cvfold'] = cl\n",
    "        TP_df.append(antag_tp)\n",
    "    \n",
    "    precision, recall, thresh = precision_recall_curve(pred_df['synergy'].values,\n",
    "                                                        pred_df['score_syn'].values)\n",
    "    if np.any(precision > prec_thresh):\n",
    "        # maximum recall\n",
    "        rmax = np.max(recall[precision > prec_thresh])\n",
    "        # maximum precision\n",
    "        pmax = np.max(precision[recall == rmax])\n",
    "        # index with maximum recall and precision > prec_thresh\n",
    "        idx = np.where(np.logical_and(precision == pmax, recall == rmax))[0][0]\n",
    "        # corresponding threshold\n",
    "        syn_thresh = thresh[idx] if idx < len(thresh) else thresh[-1]\n",
    "\n",
    "        syn_tp = pred_df[(pred_df.score_syn > syn_thresh) == pred_df.synergy]\n",
    "        syn_tp = syn_tp[syn_tp.synergy == 1]\n",
    "        syn_tp['thresh'] = syn_thresh\n",
    "        syn_tp['precision'] = pmax\n",
    "        syn_tp['recall'] = rmax\n",
    "        syn_tp['cvfold'] = cl\n",
    "        TP_df.append(syn_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_df = pd.concat(TP_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds to call antagonisms across cross-validation folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.5377693e-04, 6.5341182e-03, 9.9092470e-03, 4.2708057e-01,\n",
       "       5.7907206e-01, 6.6540402e-01, 9.4870734e-01, 9.9237072e-01,\n",
       "       9.9318552e-01, 9.9785632e-01, 9.9966407e-01], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(TP_df[TP_df['antagonism']==1]['thresh'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in most cases we end up with precision greater than 0.6 if we take a cutoff between 0.2-0.6. This already suggests  that $p_{RF}$ cannot be interpreted as probability $P(C|X)$ as we will see again in [Probability calibration](#calib) section. We can take the median as a cutoff for calling antagonisms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.665404"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antag_thresh = np.median(np.unique(TP_df[TP_df['antagonism']==1]['thresh'].values))\n",
    "antag_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds to call synergies in cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5956188e-04, 1.7755207e-03, 2.2099040e-02, 2.9603478e-01,\n",
       "       4.9024865e-01, 7.7143306e-01, 7.9479057e-01, 9.2803347e-01,\n",
       "       9.8884147e-01], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(TP_df[TP_df['synergy']==1]['thresh'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we achieve precision greater than 0.6 if we take relatively loose cutoffs between 0.15-0.45. We'll take the median as our threshold for calling synergies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49024865"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_thresh = np.median(np.unique(TP_df[TP_df['synergy']==1]['thresh'].values))\n",
    "syn_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TP_df.to_csv('Nichols-true-positives-CVfold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pr\"></a> \n",
    "## Plot Precision-Recall and ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(pr.auc.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add only mean average precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = (pd.concat(pr.predicted).\n",
    "                  reset_index().\n",
    "                  rename(columns={\"level_0\": \"cvfold\"}).\n",
    "                  drop(columns=['level_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt = targets.loc[:, ['comb', 'type']]\n",
    "y_gt['syn'] = 0\n",
    "y_gt['ant'] = 0\n",
    "y_gt.loc[y_gt.type == 1,'ant'] = 1\n",
    "y_gt.loc[y_gt.type == 2,'syn'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vs_true = pd.merge(preds_, y_gt, on='comb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "prec_micro, recall_micro, _ = precision_recall_curve(pred_vs_true['ant'].values,\n",
    "                                                    pred_vs_true['score_antag'].values)\n",
    "ap_micro = average_precision_score(pred_vs_true['ant'].values,\n",
    "                                   pred_vs_true['score_antag'].values,\n",
    "                                   average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'normal',\n",
    "        'size': 18}\n",
    "matplotlib.rc('font', **font)\n",
    "for cl in keys:\n",
    "    plt.plot(pr.recall[cl][1], pr.precision[cl][1],\n",
    "             color='grey', lw=1.5, alpha=0.6)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "plt.plot(recall_micro, prec_micro,\n",
    "        label='Aggregated (AP = {0:0.2f})'\n",
    "               ''.format(ap_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "#ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#plt.title(title)\n",
    "plt.legend(handles=handles, loc='upper right', prop={\"size\": 13},\n",
    "          frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-antagonism-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "prec_micro, recall_micro, _ = precision_recall_curve(pred_vs_true['syn'].values,\n",
    "                                                    pred_vs_true['score_syn'].values)\n",
    "ap_micro = average_precision_score(pred_vs_true['syn'].values,\n",
    "                                   pred_vs_true['score_syn'].values,\n",
    "                                   average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "for cl in keys:\n",
    "    plt.plot(pr.recall[cl][2], pr.precision[cl][2],\n",
    "            color='grey', lw=1.5, alpha=0.6)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot(recall_micro, prec_micro,\n",
    "        label='Aggregated (AP = {0:0.2f})'\n",
    "               ''.format(ap_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.ylim([-0.02, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "ax.yaxis.get_major_ticks()[1].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#plt.title(title)\n",
    "plt.legend(handles=handles, loc='upper right',\n",
    "           prop={\"size\": 13},\n",
    "            #bbox_to_anchor=(1.2,0.8),\n",
    "          frameon=False)\n",
    "#plt.legend([], frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-synergy-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_micro, tpr_micro, _ = roc_curve(pred_vs_true['ant'].values,\n",
    "                                                    pred_vs_true['score_antag'].values)\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "for cl in keys:\n",
    "    plt.plot(pr.fpr[cl][1], pr.tpr[cl][1],\n",
    "             color='grey', lw=1.5, alpha=0.6)\n",
    "plt.plot(fpr_micro, tpr_micro,\n",
    "        label='Aggregated (AUCROC = {0:0.2f})'\n",
    "               ''.format(roc_auc_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.legend(handles=handles, loc='lower right', prop={\"size\": 13},\n",
    "          frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-ROC-antagonism-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_micro, tpr_micro, _ = roc_curve(pred_vs_true['syn'].values,\n",
    "                                                    pred_vs_true['score_syn'].values)\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "for cl in keys:\n",
    "    plt.plot(pr.fpr[cl][2], pr.tpr[cl][2],\n",
    "             color='grey', lw=1.5, alpha=0.6)\n",
    "plt.plot(fpr_micro, tpr_micro,\n",
    "        label='Aggregated (AUCROC = {0:0.2f})'\n",
    "               ''.format(roc_auc_micro),\n",
    "         color='#f54248', linestyle='-', linewidth=3)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "patch = Line2D([0], [0], color='grey', linewidth=2, linestyle=\"-\",\n",
    "               label='Drug class withheld')\n",
    "handles.append(patch) \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "#ax.xaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.legend(handles=handles, loc='lower right', prop={\"size\": 13},\n",
    "          frameon=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-ROC-synergy-vs-rest-grey.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot average precision (AP) vs interaction rate for each cross-validation fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "# for antagonism predictions\n",
    "for cl in keys:\n",
    "    ycl = y[np.isin(combs, pr.predicted[cl]['comb'].values)].argmax(axis=1)\n",
    "    antag_rate = np.sum(ycl == 1) / ycl.size\n",
    "    plt.scatter(antag_rate, pr.avprec[cl][1], marker='o', \n",
    "             label=cl, s=50)\n",
    "    plt.xlim((0,0.8))\n",
    "    plt.ylim((0,0.8))\n",
    "plt.plot([0.01, 1], [0.01, 1], 'k--', lw=1)\n",
    "plt.xlabel('Proportion of antagonisms')\n",
    "plt.ylabel('Average precision')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-AP-antag-vs-rate.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAFPCAYAAADNzUzyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABFYUlEQVR4nO3deXxU5fX48c/JShYUAVFwYSkWLVZU0Fp3RQQFpe4iqNhaBBUVcSt1q0tdsfqzLkCtCsV+1YqgIFAQEVyqBAQFRUUEVJawhSUJ2eb8/nhuYBwmYSaZmTuTnPfrNa8hdz13Jpw89z6bqCrGGGOik+Z3AMYYk4oseRpjTB1Y8jTGmDqw5GmMMXVgydMYY+rAkqcxxtSBJU9jjKkDX5OniKSJyDARWSoiO0TkBxEZKSJ5Ee6fLyIjROQLEdkmIhtE5CMRGSgiEu/4jTGNl/jZSF5EngJuAN4EpgKHAUOBucAZqhqoZd804H3geOBl4H9ALtAPOBZ4VFVvj+sFGGMaLd+Sp4h0Br4A3lTVC4KWDwX+H9BfVV+pZf/fAh8BT6rqsKDlWcBSoLmqNotT+MaYRs7P2/Z+gABPhiwfA5QAA/aw/17e++rghapaDmwAiusfojHGhJfh47mPAQLAp8ELVXWHiCz01tfmU6AIuE1EVgCf4G7brwS6AoNjG64xxuziZ/JsA2xQ1bIw634CjheRLK8kuRtV3Swi5wL/AF4LWrUNuEBVJ8Y6YGOMqeZn8swFwiVOgB1B24RNnp7twGLgLdzzz+bAdcArItJXVWfUtKOIDAIGAfzqV7/qumTJkuiiN8YkvcrKSioqKsjJyYl56xs/n3mWANk1rGsStE1YIvJrXMKcoaq3quqbqvoCcCKwFhgjIuk17a+qo1W1m6p2y8nJqdsVGGOS1rRp0zjppJNo0qTJnjeuAz+T52qgpYiES6AH4G7payt1DsMl2deDF6pqCTAFaAu0i02oxphU8uGHH3LFFVcwcuRI4tXk28/kOc87/7HBC0WkCXAkULCH/Q/w3sOVLjNC3o0xjURJSQn9+vVj3LhxHH/88XE7j5/J81VAgZtClv8R96xzfPUCEfmFiBwast2X3vvA4IUi0gzoC2wGlsUsWmNM0isqKiI3N5eFCxfSs2fPuJ7Lt+Spql8AzwDni8gEEblaREYCT+B6DgU3kH8X+CrkEE8Cm4CHRWSciAwWkRHAZ0Br4E5VrYr3dRhjksMPP/zAkUceyfz582nevHncz+f3be1NwApcrXdvXOP2p4G7a+uaCaCqK0XkWOBuoDtwKVAKLASGq+qEuEVtjEkqhYWF9OjRg6FDh9K1a9eEnNPXvu3Jolu3blpQsKdHrMaYZDVs2DDy8/O5//77a9ok5rVGfpc8jTGmzkpLS9m4cSOPPvooGRmJTWc2nqcxJiWVl5dz4YUX8sQTT5CZmRm3Jkk1seRpjEk5VVVVXHnllaSnp/PII4/4EoPdthtjUs6SJUvYunUrb7zxBpmZmb7EYCVPY0xKmTVrFr/+9a+ZPHly3LpeRsKSpzEmZTz66KNcf/31FBcXJ/wZZyi7bTfGpITRo0fz3HPP8cEHH5Cfn+93OFbyNMYkP1WloKCAGTNmcMABB+x5hwSwkqcxJqnNnDmT9u3bM3r0aL9D+RkreRpjktbcuXPp168f69ev9zuU3VjyNMYkpQULFnDBBRfwyiuvcNxxx/kdzm4seRpjktKWLVsYNWoUPXr08DuUsOyZpzEmqaxatYpXX32VW2+91e9QamUlT2NM0qgeWi7Rg3zUhSVPY0xS2LJlCz179uSSSy5h2LBhfoezR8mf3o0xjUKTJk248cYbufLKK/0OJSJW8jTG+Kq8vJyrr76adevWMXDgQN+7XUbKSp7GGN9UVVVxxRVXsGPHDtq0aeN3OFGx5GmM8c2wYcNYv349U6ZMSYlKomCpFa0xpsFQVS6//HIOPfRQX4eWqytLnsaYhHv44YfJzMxk+PDhfodSZ5Y8jTEJ9fzzzzN69Gjmzp3rdyj1YsnTGJMw7733Hg888ADvv/9+0gwtV1eWPI0xCVFRUcGJJ57I3Llzad++vd/h1Ju18zTGxN2cOXPo1q0bItIgEidYydMYE2cLFizgwgsv5N///nfKNUeqjZU8jTFxU1FRwaWXXsqoUaPo3r273+HEVMP5M2CMSSqbNm1in3324ZNPPmGfffbxO5yYs5KnMSbm1q1bx3HHHcd7773XIBMnWPI0xsRYUVERPXv25LLLLuP000/3O5y4seRpjImpp556ilNPPZV77rnH71Diyp55GmNiory8nJ9++ok777wTEUmZoeXqypKnMabeqqqqGDBgAE2bNuWFF17wO5yEsORpjKkXVWXw4MFs3LiRsWPH+h1OwljyTGLbyyqZvGg1KzYW065FHn26tCE/274yk1y+//57Vq1axcSJE1NyaLm6ElX1OwbfdevWTQsKCvwO42fmrdjEwBc/RRVKyqvIzUpHBF666liOadfc7/CMAeDdd9/l9NNPT4XnmzEP0Grbk9D2skoGvvgpxWVVlJRXAS6BFpdVecsrfY7QGHjuuecYNGgQmzdv9jsUX1jyTEKTF62mphsCVZj8+erEBmRMiFdeeYUHH3yQGTNm0Lx547wTsuSZhFZsLN5Z4gxVUl7Fig0lCY7ImJ/79NNPmTZtGh06dPA7FN9Y7UMSatcij9ys9LAJNDcrnXYtc32IyhiYO3cuzZo148knn/Q7FN9ZyTMJ9enShpqev4tAnyNSa4pW0zAUFBRwwQUXsH79er9DSQqWPJNQfnYGL111LHnZ6eRmpQOuxJmXne4ttxsGk1hfffUV55xzDmPGjGnQ/dWjYU2VSM6mSgDFZZVM/nw1KzaU0K5lLn2OaGOJ0/hi3rx5fPvtt1x22WV+h1JXMW+qZMmT5E2exvht3bp1jBo1irvuuisV2nLWxtp5GmMSY/PmzZx55pmoaqonzriw5GmM2U1JSQl9+vTh9NNP5+677/Y7nKRkD9CMMbvJzs5m0KBBXH755VbqrEGdkqeI5AItCPMcQVVX1TcoUzdlZWUsXryYTZs20bx5cw4//HCys7P9DsukkKqqKq677jqGDRvGlVde6Xc4SS3i5CkiacBtwFBg/1o2Ta9vUCZ6K1euZPz48agqFRUVZGZmMn36dPr370/btm39Ds+kAFXlmmuuYeXKlbRr187vcJJeNCXPh4FbgCXAG8DGuERkolZWVsb48eMpLy/fuayiogKA8ePHM3z4cCuBmj26++67WbJkCTNmzLDflwhEkzwHANNU9ex4BWPqZvHixdTU5ExVWbJkCUcffXSCozKpRFW56KKLGDZsGPn5+X6HkxKiSZ77AJPiFYipu43rN+wsaYaqqKhg40a7STA1e+aZZ1izZg0PPPCA36GklGiS5xdA63gFYuqmbMUW0j/eQgZpVEpgt/WZmZm0aNHCh8hMKhg/fjwPP/wwc+bM8TuUlBNNO8+/AINF5KBYnVxE0kRkmIgsFZEdIvKDiIwUkbwojtFcRB4XkWXeMdaLyHsiclKs4kxWgbJKNry4hPZl+yI1dKAQETp37pzgyEwqKCgoYPjw4UyfPp327dv7HU7Kiabk2RVYCXwpIm8C3wOhY6apqt4fxTH/BtwAvAmMBA7zfj5KRM5Q1d2LUkFEpC0wG8gHXgC+AfYGjgAOiCKOlFS6aAOokkUGPcuPZHrWQhSlUgJkaBppGen079/fHv6b3ZSXl3P00Ufz8ccfW+Kso4j7touEuSfcnapqRE2VRKQz7lHAm6p6QdDyocD/A/qr6it7OMZcoB1wrKquieS84aRq3/aiqd+z/f0fd/5cQSXL0wvZIiXsrbn8+rdH0arPL32M0CSjgoICBgwYwGeffUZOTo7f4SRKzFv6R1PyjPWfp364C3oyZPkYXLOoAUCNyVNETgZOBG5Q1TUikglkqmqjGWY9s0UOkpWGlru/a5lk0KnKjfUpWWnk7beXn+GZJPTll1/Sp08fRo8e3ZgSZ1xE/MxTVVdG8ori3McAAeDTkPPsABZ662tT3WRqlYi8DZQCxSLyjYgMiCKOlJXTpSW1jZqcc8S+iQ3IJLVAIMBll13G448/zrnnnut3OCmvTgODiEgLEenmvepaldsG2KCqZWHW/QS0FJGsWvbv5L2PAZoDVwK/B8qBcSJyVW0nF5FBIlIgIgWpOjJ2WnYGLa/qjGSnI1nuq5SsNCQ7nZZXdSYt2zp7Gad6hsvZs2czYECjKFvEXVTJU0S6iMj7QCHwifcqFJHZInJElOfOBcIlToAdQdvUpKn3vg04TVXHq+qLwElAEfBXr0tpWKo6WlW7qWq3ffdN3RJadru9aT3iN+T3PIjSdhUU7ruGjcdvQ/bL9Ds0kyQ2b97MKaecwsSJE2nWrJnf4TQY0fRtPxz4AGiCayy/xFvVGTgHmCsix6vqkhoOEaoEaFXDuiZB29Sk1Hv/t6ru7JeoqptF5C3gClzp9KsI40lZq79fyoTR94IGqCgrI3NeNrNf+Qfn/+leDjzUmik1Ztu3b6d3796cccYZnHfeeX6H06BEU/K8D6gAuqrq+ap6l/c6HzgK12zpviiOtxp3ax6uHc0BuFv68jDrqlVXM68Ns6665n2fKOJJSeWlJUx46F4qdpRSUeYK8hVlZVTsKGXCQ/dSvqN0D0cwDdkLL7zAoYceysiRI21ouRiLJnmeDDyjqp+HrlDVxcCzwClRHG+ed/5jgxeKSBPgSGBPbYeqK5oODLOuellhFPGkpKUfzYWamsNqgK8/mpvYgExSqKys5JtvvuGGG25gzJgxljjjIJrkmUf4Ul61Nd42kXoVUOCmkOV/xD3rHF+9QER+ISKHhmw3Efe8c4CI5Adt2xr4HfCNqi6LIp6UVLR29c4SZ6iKsjKK1q5OcETGb4FAgEGDBjFixAhEhPR0qziMh2jaeS4H+gDP1LC+j7dNRFT1CxF5BrheRCYA77Crh9H7/LyN57tAW4IaunrPNm8BRgH/E5F/AlnAEO99aKSxpLJm+7chMzs7bALNzM6m2f42x3tjoqrccsstLF26lBkzZvgdToMWTclzLNBTRF4Rkc4iku69DheR8cCZwEtRnv8m3BihnXFJ+VLgaaDPnrpmgqsxBy4AtgP3A38GvsbVvv83ylhS0qHHnwQ1NSqQNDod3+C7+Jsg69atY/HixUyZMoW8vGhuBE20oumemY4rDV6Eu92uTm5puBLha8BlkSS9ZJOq3TOr/bh0CRMeundXbXt2Nkia1bY3MjNnzuTUU08lI8OmJgvD/3nbRaQH7plidXfN5cBEVZ0Z29ASJ9WTJ0D5jlK+/mguRWtX02z/NnQ6/iSymlj3u8Zi3LhxjBgxgk8++YQ2bexRTRj+J8+GqCEkT9N4TZo0icGDBzNr1iwOO+wwv8NJVjFPnjZvuzEprqCggLffftsSZ4LV+HBERO7GPdt8UFUD3s97Eu14niYK5aUlLA26NT/0+JPIyqmtB6tpyObNm0dlZSX332//5fxQ4227N36nAjmqWh7r8TyTSSrctlulkAm2ZMkSunfvzpgxYzjnnHP8DicVJHQ8z/YAQV0kbbhpnwR3waxW3a5zwkP3MnjUWKscakS+//57evXqxciRIy1x+qjG5Bk6NmeUY3WaGIqkC+avTz8zsUEZ35SWlnLffffRv39/v0Np1OpdYSQiLUXkkFgEY8KzLpgGYNOmTYwYMYJOnTpx1VW1DldrEiDi5CkiV4jI6JBlDwHrgKUi8qGINA2/t6mPvJb7UdVyf3bsewDlzVqiabu+NuuC2Ths376ds88+m/LyctLSrJFMMojmW7iGoNt8EekG3A7MxY3mfixwc0yjM6xcuZLp8xdS0qI1FS1bU7bfQWzv2IXKHG8sFOuC2eCVl5dz3nnncfjhh/PYY4/ZCElJIpp+XB2B14N+vgjYBJzp1cYrcDFufncTA2VlZYwfP57y8nJI8xoxeO+lBx/CPqu+4fw77rbKogYuMzOTK6+8kn79+lniTCLRlDz3BrYE/dwdmBlUG18AHByrwAwsXryYmpqSpWdk8tshw6yZUgMWCAQYOnQon332GQMGDLCh5ZJMNMlzLXAIgIjsixuwOHik3XzcaPImRjZt2kRFRUXYdVWBAFu2bktwRCZRVJWbb76ZBQsW0KlTpz3vYBIumtv2WcB1IrIJOA3XgH5K0PpOuFkvTYw0b96czMzMsAk0MzOTFi3qOnGpSXaPP/44s2fPZvbs2Ta0XJKKpuR5N260+EeBs4CHVHUFgIhk4MbVfD/WATZmhx9+eI3PuESEzp3tlr0hUlX69u3L9OnTbbbLJBZxyVNVfxSRzsCvgC2quipodS4wCFgU4/hS2vbKKiYVFrG8pIwOudn0bdWM/IzIn1tlZ2fTv39/xo8fj6pSUVFBZmYmIkL//v3Jzg43d55JZWPHjuXTTz/l73//u9+hmD2wIemIT9/2T4q20//z5QRUKQkouWlCmgjjj+jAb5rl7/kAQcrKyliyZAnrCzdQsSWDvdJa07L13nTs1oqsJjbwbUMxceJEhgwZwnvvvcehh4ZO2WXqycbzjIdYJ8/tlVUc+dEStlft3qUyPz2NRcd3Ji+KEijA6mVFTH56EapKZXmAjKw0RIQ+Q7vQpmOzGEVu/LJ06VJOPvlkpk6dSteuXf0OpyFK3HieIhIQkUoRyQr6uWoPr8pYB5iKJhUWEajhj1JAlUmFRVEdr3xHJZOfXkRFWRWV5S4hV5YHqCirYvLTiyjfYR97KisrK6NTp0588sknljhTSG33fGNxNepVIT+bPVheUkZJIPxHVRJQvi8N30+9JssKCmts76mqLJtfyK9OsC6aqWjx4sX07duX+fPn0769DVyWSmobVWlgbT+bmnXIzSY3TcIm0Nw0oX1OdBU9RYUlO0ucoSrLA2wpLKlTnMZfy5cvp1evXjz22GNWq56CbISBOOjbqhlpNTQxShOhb6tmUR2vWatcMrLCf1UZWWns3cpGk081qsrAgQO588476devn9/hmDqIZlSlM7xRlGpa/5CInBabsFJbfkY644/oQF66kOMNwJ8jAfLSXW17tJVFHbu1qrW9Z8eureods0mcoqIiKisrmTx5MoMHD/Y7HFNH0ZQ8b8MNDlKT9rhRlgzQiaU8E7iay/UFztEJXK4v8EzgajqxNOpjZTXJoM/QLmRmp+8sgWZkpZGZnU6foV2suVIK2bZtGz179uRf//oXe+21l9/hmHqIuKmSiKwDHlXVkTWsHwbcpqqtYxhfQsS6qVJl5XY++PB4qqqKd1uXnp7HiSd8TEZG9F3uyndUsmx+IVsKS9i7VS4du1o7z1SyY8cOevfuzS9+8QtGjRplIyQlVkLnMAq1N7B7NtilFNinfuE0DOsKp6A1TJuhGqCwcApt2lwc9XGzmmRYrXoKe+2112jZsiXPPfecJc4GIJrk+RNQWyO0rriRlxq9kpIVBAKlYdcFAqWUlNh0UI1JIBBg6dKlXH755fTv39+GlmsgonnmOQW4UkTOCF0hIt2BK4F3YhVYKsvNbUdaWvgBitPScsjNbZvgiIxfVJVhw4Zx4403AljibECiKXk+iBs5abqITAUWesuPxI2ytBa4P5bBpar9WvXm228fDLtOJI1WrXonOCLjl7/85S/MmTOH9957z27VG5iIS56qug44HpiOS5YjvNdZwFTgBFVdE48gU01GRj5Hdvkn6el5O0ugaWk5pKfncWSXf9apssiknqKiIj788EOmTZtmjeAboDoNDCIi+7Cr2dIyVd0c06gSLB6jKgFUVhZTWDiFkpKV5Oa2pVWr3pY4G4l3332XE0880YYNTB6+1rbv5CXLeTGOpcHJyMirU626SW1vvvkm1157LR9++CEdOnTwOxwTJ1ElTxFJB/oDZwL74dp1fuaVRM8B3lVVm4ojSpWV21lXOIWSkhXk5rZjv1a9yciIbsxPkxxmzpzJNddcw7Rp0yxxNnARJ08RyQX+i3vuWYwbPb66XedW4GHgn8CdMY6xQSsqKmDhot+jGiAQKCUtLYdvv32QI7v8k2bNuvkdnonSggULeOONNzj66KP9DsXEWTRNle4FugHnAR0IeoagqlXABKBnLINr6Cort7Nw0e+pqire2S40ECilqqqYhYt+T2VlbX0STDL54osvmDlzJrfddhsnnXSS3+GYBIgmeV4EjFbVSUC47jPLgHaxCKqxiKQnkkl+y5Yto1evXmzYsMHvUEwCRZM821D7BG8lQNP6hdO4WE+k1PfTTz9x5plncvfdd3PppZf6HY5JoGiS50bggFrWdwZW1y+cxsV6IqW+8vJybr/9dq655hq/QzEJFk3yfBe4yqs4+hkRaQ/8HpgWq8AahLJtMP9lmHGPey/b9rPV+7XqjUj4r8B6IiW3bdu2cdttt9GmTRtLnI1UNE2V/gIU4Np3/hs3n1EvEekBDAbKgBoHS250Vn4M4y8EDUBFCWTmwvQR0P8/0Pa3wK6eSKG17SJp1hMpie3YsYO+fftyyCGHkJWV5Xc4xidR9TASka645ki/Dlm1GLhcVWt7Jpq0Yt7DqGwbjDwUyrfvvi4rH4Z/Ddm72nFaT6TUUVVVxfnnn09OTg7jx4+3gT5Sh789jFR1PtBFRA4HDvMC+lZVP4t1YClt8QRX4gxHA7BkAhx9xc5F1hMpdaSlpXHZZZdx3nnnWeJs5CJKniKSj6tpf1pVn1TVxbjSpgln03J3qx5ORQlsXJ7YeEy9qSq33nor5557Lpdcconf4ZgkEFGFkapuB1oAYe5DzW6ad3DPOMPJzIUW1m0v1dxzzz3MmjWLLl26+B2KSRLR1Lb/D9fDyOzJ4edDDbXoSBp0Pj+x8Zh6GT16NK+++irTpk1j77339jsckySiSZ53ABeLyFVio7rWLrupq1XPyt9VAs3MdT/3/8/PKotMclNVzjrrLGbMmEGrVjbFs9klmtkzZwFtcV0wNwHf4XoVBVNV7R7LABMhXuN5UrbdVQ5tXO5u1Tufb4kzhbzxxhtMnDiRcePG+R2KqT9fa9s74Np2rvJ+3i/WwTQ42fk/q1U3qeO///0vQ4YMYfr06X6HYpJUxMlTVdvFMQ5jksaPP/5I//79efPNNznqqKP8DsckqTqNJG9MQ1VWVsaBBx7IvHnzaNeund/hmCQWTYURACKSLSI9RWSI9+opIk3iEZwxibRs2TIOO+ww1qxZY4nT7FG003BcATyBG0G++gGsAkUiMlxVX4pteMYkxk8//USPHj0YMWIErVu39jsckwKimYbjEuAlXIXR48CX3qrOuIFBXhCRUlV9NdZBGhNvgwcPZsiQIfzxj3/0OxSTIqJpqrQIyASOU9WtIev2Bj4BylQ14i4Y4sZjuxG4BtcEaj3wGnC3qkY1B4U3VN5ioD3wjKpeH+m+cWuqZJLetm3bSE9Pp6qqiqZNbSzvBizmTZWieebZCXgxNHECqOoW4EXgl1Ge/2+4xwBfAkOB14EbgLelpoEua3YfsG+U+5hGrLS0lHPOOYdRo0ZZ4jRRi+aZ59o9rFdgXaQHE5HOuIQ5QVUvCFr+PfD/gEuBVyI81tHATcBtwMhIY0hGxRXFTPt+Giu3raRt07b0at+LvEwbni7WKioquPjii2ndujU33HCD3+GYFBRN6e4l3Ejyu3WREZG9gKtwpc9I9cMVpZ8MWT4G13NpQCQH8eaSH4MbxX5CFOdPOgvWLaD7a915ZN4jvLj4RR6Z9wjdX+vOgnUL/A6twZk6dSqqytixY21oOVMn0ZQ85wJ9gC9E5Flgqbf8MGAIsAGYKyInB++kqnNqON4xuFk4Pw3ZfoeILPTWR2IYcChwwZ42TGbFFcVcO/NaioOmGy6tdJPDXTvzWmZdPIvcmkZqMhFTVRYvXsy5555L7969LXGaOosmec4I+vcjuNt02PUgtm3INuJtU9NvZxtgg6qWhVn3E3C8iGSpanlNAXlzJ/0FuE9VV4hIuz1exa59BwGDAA4++OBId4ubad9PIxB2RmcIEGDaimmcf4iNxlRfd911FzNmzODjjz+2xGnqJZrkeVWMz52Lm/conB1B29SYPIHngeW4SqeoqOpoYDS42vZo94+1ldtW7ixphiqtLGXV1lVh15nIjRw5kjfeeIM5c+aQlhZ1/xBjfiaavu0vx/jcJUBNY3w1CdomLBEZAPQATlbVihjHlnBtm7YlJyMnbALNycjh4L38Lx2nstLSUmbOnMl///tf9t3XGmWY+vPzz+9qoKWIZIdZdwDulj5sqdPb5wngHWCtiHQUkY64RwcAe3vLmsUh7rjo1b4XaTV8HWmk0atdrwRH1HC89957VFVVMXXqVA466CC/wzENhJ/Jc553/mODF3r95I/ETXNckxxcm87ewLdBr9ne+gHez1fHMuB4ysvM49kzniUvI4+cjBzAlTjzMtxyqyyqm+nTp3PJJZewcuVKv0MxDYyfoyq9CozAtc+cG7T8j7hnneOrF4jIL4BMVa2u4S8GLgpzzH2BZ3HNll4APo951HF09H5HM+viWUxbMY1VW1dx8F4H06tdL0ucdfTRRx8xYMAAJk6cSOfOnf0OxzQwviVPVf1CRJ4BrheRCbhb8MNwPYze5+cN5N/F3ZKLt28F8J/QYwbVtn+nqrutTwW5mblWqx4jixYt4l//+hcnnHCC36GYBsjv8TxvAlbgmgz1xrUVfRrXt72Gic+Nqd23337Ll19+yZAhQ/wOxTRgvrbXUNUqVR2pqp1UNVtVD1DVm72pjoO3a6eqe+zYr6orVFWiGRTENCw//vgjZ555JuvXr/c7FNPA1Sl5ejXZJ3ijKRmTFNavX0+PHj247rrruPrqlKkrNCkqquQpIn1E5Dvga2AO0NVb3kpElonIhXGI0ZiIVFZWct1113HLLbf4HYppBCJOniJyKvAmbtrhvxA0Pp6qFuKmIr40tuEZs2elpaUMHz6cpk2bcv319sTGJEY0Jc+7gUXAb4Bnwqz/GDg6FkEZE6mKigouuugi1q5dS26uNekyiRNN8jwGGF9LLfiPwP71D8mYyKgqAwcORER46aWXrL+6SahomiqlUfNAHgAtqX0QD2NiSkS48MIL6dWrF5mZmX6HYxqZaJLnV8BJuB484fTB3dabOLFR5ne55557OPbYYznvvPP8DsU0UtEkzxeA/yciM4G3vGXqTbz2MPBb4IoYx2c8C9Yt4NqZ1xIgQGllKTkZOTw27zGePeNZjt6vcT1qfuyxx3jttdcYOnSo36GYRizi2TMBRORfwGXAVqApbrbLFrgBj19U1T/EI8h4S/bZM4sriun+WvefjTJfLS8jr1GNMv9///d//OlPf2Lu3LkceOCBfodjUoevs2eiqgNw0128i5uGYxOuT/pFqZo4U0Eko8w3BqpK9+7dmTlzpiVO47uo+7ar6pu49p4mQWyUeZg2bRrPPfcckyZNssGMTVLwe2AQE4HGPsr8hx9+yBVXXMHEiRP9DsWYnSJOniJy9x42UaAUWAXM9nodmRjo1b4Xj817LOy6hj7K/MaNG7ngggsYN24cxx9/vN/hGLNTxBVGIhJg9xkzq4UurwAeV9U/1zvCBEj2CiMIX9ueRlqDrm3fsWMHTZo0YdWqVUkxw6lJaTGvMIrmtv1w4GVcQ/mncIODgJsz/UbvWEOBg4CbgTtEZJWqjopduI1XXUaZr9pezNap71CxciWZbduy11lnk56fGu1Cf/jhB0499VSmT59Ox44d/Q7HmN1EU/L8G9ANOFVVq0LWZeDmD/pUVW/2fi4AAqqa9MWiVCh5Rqtk/nx+GHQNGgigpaVITg6SlsZBo0eR27Wr3+HVqrCwkJNPPplBgwZx8803+x2OaRh8bap0KfBaaOIEUNVK4DVvm+CfO8UiSBOdqu3F/DDoGgLFxWipq2TS0lICxbuWJ7Phw4dz0UUXWeI0SS2a2/a9vVdt65sF/byBXc9CTQJtnfoOGgjfLlQDAbZOnUqzC5Nv6NXS0lLKy8t57rnnyMtLjccLpvGKpuS5CLhWRNqGrvAmXrsWWBi0uBOwpj7BmbqpWLlyZ4kzlJaWUr4y+dqFlpeXc+GFF/LEE0+Qn5+PSMzvsoyJqWhKnncA04GvRGQi8I23vBPQF5eI+wGISDbQH5gcs0hNxDLbtkVycsImUMnJIattctVcV1VVceWVV5Kens6dd97pdzjGRCTi5Kmq74vIGcAT7D5ifAFwi6rO8bYt80qoFTGL1ERsr7POpvDhR8I+M5G0NPY666yEx1SbDz74gMLCQqZMmWJDy5mUEdXAIDt3EmkFtPd+XKGq62IaVYJZbbt/Fi1aRJcuXQgEAjaYsYknX9t57uT1HrIeRD6rrR1nbteuHDLnfbZOnUr5ylVktT2Yvc46i7Qkqoh59NFHGTt2LAsWLCArK8vvcIyJSl1Lnvm4mvXdigqqmny1EXuQiiXPVClZ1mT06NE89NBDfPDBBxxwwAF+h2MaPn+HpBORS0VkMbAFWAl8H+Zl4izV23FWVlYyefJkZsyYYYnTpKxoph7+HfAK7lZ/FC6T/xt4HVcxNB+4L/YhmlCRtONMVnPmzGHr1q289dZb1u3SpLRoSp634OYxOhI3DTHAP1X1Uly3zU78vJ2niZNUbMcJMHfuXC644AK+++47v0Mxpt6iSZ5HAC+r6g7YOax5OoCqLgZGA3+KbXgmnOp2nOEkYztOgM8++4wLLriAV155hWOOOcbvcIypt2iSZzqw0ft3dbEnuLvm17iRl0yc7XXW2UgNzXqSsR0nwJdffsnzzz9Pjx49/A7FmJiIpqnSj0BbAFUtFZFCoCvwH299JyC5ayoaiPT8PA4aParG2vZkao60atUqPvjgA/r37+93KMbEVDTJ8yPgDHY973wLuElESnEl2OuAt2MbXgNStg0WT4BNy6F5Bzj8fMhuWufDpUI7zsLCQnr06MHgwYP9DsWYmItmPM9jgPOA+72S577ADNyzUIAlwNmq+kNcIo2juLfzXPkxjL8QNAAVJZCZC5IG/f8DbX8bv/P6qKioiNNOO41zzjmH++6zRhjGdzFv51mnRvI/O4DIEUAV8JWqhm8/k+TimjzLtsHIQ6F8++7rsvJh+NeQnR+fc/to8+bNjB07lhtuuMFGSDLJwJ9G8iKSJyJ3i0jP0HWq+rmqLknVxBl3iye4Emc4GoAlExIbT5yVl5czfPhwVJUbb7zREqdpsCJ65qmqxSIyArg+zvE0PJuWu1v1cCpKYOPyxMYTR1VVVVx++eXs2LGDpk3r/jzXmFQQTYXRd8D+8QqkwWrewT3jDJdAM3OhRYfExxQn119/PevXr+edd96xoeVMgxdNO89ngT+KSIt4BdMgHX6+qxwKR9Kg8/mJjSeO+vTpw6RJk2jSpInfoRgTd9GUPLcBm4CvReRl4Ftgt+KUqo6NUWwNQ3ZTV6teU217A6gseuSRRzjooIO47LLL/A7FmISJpqlSJBVCqqrp9Qsp8RIyJF3Zdlc5tHG5u1XvfH6DSJzPP/88jz76KHPnzrURkkwy83Uw5NNiffJGJTsfjr7C7yhiasqUKTzwwAO8//77ljhNo1Pvdp4NQSoOhuw3VWXbtm2sWbOGTp06+R2OMXvi72DIO6MQyRaRA0TE5k5ohObMmUP37t1p2rSpJU7TaEU7kvzRIjILV3m0CjjRW95KRN71Ztc0DdiCBQu48MILGTFihDWAN41aNCPJHwnMBX4B/KxG3ZsQLge4MpbBmeRSXFxM3759GTVqFGecYX8nTeMWTYXRfcBq4CigCfD7kPXvAhfHKC6TZEpLS8nLy+Pjjz/mwAMP9DscY3wXzW37ScAYVd0OhKtlWgW0iUlUJqmsW7eOI488ks8++8wSpzGeaJJnE9ysmTXZq56xmCRUVFREz5496devH0cddZTf4RiTNKJJnt/hRo6vyenAl/ULxySbu+66i1NOOYV77rnH71CMSSrRPPN8BbhLRF4DPvOWKYCIDAd6ATfGNrzGJVBWSemiDVRsLCWzRQ45XVqSlh3NVxQ75eXlbN26lUceeYQmTZpYzboxIaL5n/k40AOYDizFJc6/eSPK748bVf7ZmEfYSJSt2MKGF5eAKloeQLLSKJqynJZXdSa73d57PkAMVVVVMWDAANq0acOTTz6Z0HMbkyoivm1X1XJc8rwFN3vmDuCXwAbgNqCPDYhcN4GySja8uAQtq0LL3Ueo5QG0rIoNLy4hUFaVsFhUlcGDB7Nx40YefvjhhJ3XmFQT1T2hqlYCf/NeJkZKF22AmrrJqlL6+XryjknMUKoLFy5k6dKlvPPOOza0nDG1iKaR/LkiknIjJqWCio2lO0ucobQ8QMWG0oTEsWDBAo466ijef/99GwnemD2IprZ9IrBaRP4mIjFpsyIiaSIyTESWisgOEflBREaKyB7nzxWRX4rIfSLyPxFZLyLbRGShiPw5kv2TSWaLHCQr/FchWWlktsyJewzPPfccF110EcXFxaSl1WnIA2MalWj+lwwBluFq1AtE5HMRGS4i9bmf/BvwBK6J01DgdeAG4G2RmoZf3+n3wDBcE6r7gFuBr4EHgI9EJP4ZJ0ZyurSEmmqzRcg5Yt+4nv+VV17hwQcfZMaMGeQl0bzvxiSzaCqMRqnqCUBHXILKBR4DfhCRKSJysYhkR3o8EemMS5gTVPV8VR2jqjcDN+PGDr10D4f4D3CgqvZX1adV9XlVvQR4EDeX/B8ijcVvadkZtLyqM5KdvrMEKllpSHY6La/qTFp2/J6WqCqTJk1i2rRpdOjQcOZTMibe6jWep4icBFwBXIjrYbRFVZtHuO8DwJ+Bk1V1btDyJsBG4H1VPbsOMf0a+BwYpaqDI9knWcbzDJRVUfr5eio2lJLZMoecI/aNa+L8+OOPadeuHa1bt47bOYxJEr6OJL8bVZ0rIvOBAuARIJoGiccAAeDTkGPuEJGF3vq6qO58va6O+/smLTs9YbXqBQUF9O3bl9dff92SpzF1UOeaARE5Q0TG4pLUs0AF8EwUh2gDbFDVsjDrfgJaRjvYstca4C6gEtcjqrZtB4lIgYgUrF+/PprTpLyvvvqKc845h9GjR3PKKaf4HY4xKSmqkqeIHIYbs7M/LvlVAu8ALwNTVLUiisPlAuESJ7gG+NXblEdxzCeB3wIjVPXr2jZU1dHAaHC37VGcI+V99913PProo/zud7/zOxRjUlbEyVNECnBjeQowH3eb/m9V3VjHc5cArWpY1yRom0jjux+4Hhitqg/VMaYGbe3atUyePJmrr77a71CMSXnR3La3xvVvP1xVj1HVv4cmzmhq23EDK7esYZ8DcLf0EZU6ReRe4E7gRSCiSqLGZvPmzfTs2ZPVq1f7HYoxDUI0yfMgVb1dVXcbdk5EuorIs7iEGKl53vmPDTlWE+BIXCXUHnmJ8x7co4Or1aYD3U1xcTG9e/fm9NNP56677vI7HGMahGjaef6s/6CINBeRG7ya8U9xJb5oal5exY3MdFPI8j/innWODzrXL0Tk0NADiMjduMQ5Dvi9DUxSs4svvpiRI0fa0HLGxEjU7TxFpCeud8+5QBbwDfBv4A1VXRLlsZ7GPad8E1fxdBiuh9GHwOnVyVBEVgBtVVWC9r0O+Dtu+o+7cM2egq1T1RmRxJGodp7lOypZVlBIUWEJzVrl0rFbK7KaxG+8zsrKSu644w6GDx9uzZFMY+dPO08RaYdLmFfi2lFuwPXwuQz4s6pOqOP5bwJWAIOA3t5xnwbujqAUWd0O9GDcLXuo93FjjCaF1cuKmPz0IlSVyvIAGVlpfPD6t/QZ2oU2HZvF/HyqyjXXXMOqVato3jyifgvGmCjUWvIUkf64pHkKUAVMxiWqd4C2wLfAhfVInkkh3iXP8h2VvHT7h1SEGZczMzudgY+cEPMS6O23386cOXOYMWMG+fn5MT22MSko5iXPPT3zHIdLkjcBbVT1AlV9yxvX00RoWUEhNf2RUlWWzS+M+TnPPPNMpkyZYonTmDjZU3GnDGgH9AU2i8gEVU3M4JINSFFhCZU1jNdZWR5gS2HEzVn36Nlnn0VEGDJkSMyOaYzZ3Z5Knq1xpc4WuFLoWhF5QUROJg7F4IaqWatcMmoYrzMjK429W+XG5Dzjx4/noYceolevXjE5njGmZrUmT1Ut8hrDHw10A/4FnAe8B3yAa2qU2NnJUlDHbq1qbCIkInTsWlNHq8jNmTOH4cOHM23aNNq3b1/v4xljahdNO88FqnodrjR6OVDdLOkf3gjud3pjdJoQWU0y6DO0C5nZ6TtLoBlZaWRmp9NnaJd6VxYFAgGOOeYY3n33XTp3tq/AmESo73ie7djVhOkgIKCq/kw0Xg8Jbec5v5AthSXs3SqXjl3r385z3rx53HDDDcydO5eMjJT76I1JlKQbz3MFcLeI3ANUN55vtLZXVjGpsIjlJWV0yM2mb6tm5GfsGsw4q0kGvzqhTczO9+WXX3LOOecwZswYS5zGJFi9Sp4NRSxKnp8Ubaf/58sJqFISUHLThDQRxh/Rgd80i31zofLycjp37sw999zDgAEDYn58YxqY5Cp5Gmd7ZRX9P1/O9qpdzZFKAgoo/T9fzqLjO5OXEbvpNEpKSsjNzeX999+nTZvYlWSNMZGzOWZjYFJhEYEaSvABVSYVFsXsXJs2beK4445j9uzZljiN8ZElzxhYXlLmlTR3VxJQvi+tacD86Gzfvp3evXvTo0cPmz7DGJ9Z8oyBDrnZ5KaFf6SSmya0z4lmjOiaPfLII/zqV7/i8ccft6HljPGZVRhR/wqj7ZVVHPnRkp8986yWn55W72eelZWVbNiwgX322Yf09HSrWTcmegkfGMREID8jnfFHdCA/PW1nCTQ3TchPT2P8ER3qlTgDgQCDBg3iT3/6E9nZ2ZY4jUkS9j8xRn7TLJ9Fx3dmUmER35eW0T7HtfOsT+JUVW655RaWLl3KjBlJMzSpMQZLnjGVl5HOZW1axOx4y5Yt46OPPmLq1Knk5eXF7LjGmPqz2/YkVVBQQMeOHfnoo4/YZ599/A7HGBPCkmcUtpdV8n+fruLhqV/xf5+uYntZfMaEHjduHOeddx6bN28mLc2+ImOSkd22R2jeik0MfPFTVKGkvIrcrHTun/IlL111LMe0i90cQZMmTeK2225j1qxZNveQMUnMijUR2F5WycAXP6W4rIqScjcPUUl5FcVlVd7y2JVAJ02axNtvv81hhx0Ws2MaY2LPSp4RmLxoNTU1h1WFyZ+v5pJjDq7XOQoKCmjevDn//Oc/63UcY0xiWMkzAis2Fu8scYYqKa9ixYb6zUG0ePFi+vTpw9KlS+t1HGNM4ljyjEC7FnnkZoVvr5mblU67lnWfg2j58uX06tWLkSNHcvbZZ9f5OMaYxLLkGYE+XdpQU1dyEehzRN1HN/rhhx+466676N+/f52PYYxJPEueEcjPzuClq44lLzt9Zwk0NyudvOx0b3n0j443bdrE008/zcknn8w111wT65CNMXFmFUYROqZdcz4dcQaTP1/Nig0ltGuZS58j2tQpcW7fvp2zzz6bk046KQ6RGmMSwZJnFPKyM+pdq75jxw5+97vfcfjhh/Poo4/a0HLGpCi7bU8wEaFPnz6MGjXKEqcxKcySZ4IEAgFuv/12Vq9ezU033UR6euzmNDLGJJ4lzwRQVW6++WY+/PBDWrVq5Xc4xpgYsGeeCfDXv/6V2bNnM3v2bBtazpgGwkqeCXDaaacxffp0mjVr5ncoxpgYsZJnHI0dO5affvqJP/3pT36HYoyJMUuecTJx4kRuv/123nvvPb9DMcbEgSXPOJg/fz6DBg1i6tSpHHrooX6HY4yJA0ueMRYIBDjiiCOYNWsWhx9+uN/hGGPixCqMYmjx4sV069aNqqoqS5zGNHCWPGOkemi5W2+9lSZNmvgdjjEmzix5xkAgEOC8887jzjvvpF+/fn6HY4xJAHvmWU/FxcXk5uYybdo0Wrdu7Xc4xpgEsZJnPWzbto3TTjuNt956yxKnMY2MJc86qh5a7qijjuLcc8/1OxxjTIJZ8qyjZ599ln333Zdnn33WhpYzphGyZ55RCgQCrFmzhhtvvJGqqiobWs6YRsqSZxRUlZtuuokff/yRCRMmWOI0phGz5BmFe++9l7lz51p/dWOMPfOM1OrVq5k6dSrTpk2zoeWMMZY8IzFv3jxat27NJ598wn777ed3OMaYJGDJcw8mTJjAueeey5o1a6xW3Rizkz3zrMXMmTMZPHgw06dPp02bNn6HY4xJIlbyrMXbb7/NG2+8wVFHHeV3KMaYJGMlzzC++OILRISnnnrK71CMMUnKSp4hli1bRq9evfjqq6/8DsUYk8QseQb56aefOPPMM7nnnnu46KKL/A7HGJPELHkGWbt2LTfeeCODBg3yOxRjTJKzZ55BunbtSteuXf0OwxiTAqzkaYwxdWDJ0xhj6qDR3raLyCCg+uFmmYgs9jMen7QENvgdhA8a63VD4732xaoa0yltRVVjebyUJCIFqtrN7zgSza678Wms1x6P67bbdmOMqQNLnsYYUweWPJ3RfgfgE7vuxqexXnvMr9ueeRpjTB1YydMYY+rAkqcxxtRBg0yeIpImIsNEZKmI7BCRH0RkpIjkJWJ/v9QnbhH5pYjcJyL/E5H1IrJNRBaKyJ8b8nWHOVauiCwXERWRv8cj3liKxbWLSHMReVxElnnHWC8i74nISfGMvT5i8H88X0RGiMgX3u/6BhH5SEQGSqRTRqhqg3sBTwEKTAD+CDwBVACzgLR475+K1w08DGwDxgNDgcHAq97xFgE5fl9fIr4v4HHvc1Dg735fW7yvHWgLfA+s934Hfg8MA14ELvX7+uJx3bhC41ygCvgnrrPMTcAn3jEfiSgGvz+EOHyonYEA8EbI8qHeB3NZPPdP4evuBuwdZvkD3v7X+32N8f6+gKOBSuDmVEiesbh2L4n8ALT2+3oSdd3Ab73t/hayPAtYDhRFEkdDvG3vBwjwZMjyMUAJMCDO+/ulXnGraoGqbgmz6lXvPaZd22IoJt+XiKR7+0zDlWZSQb2uXUROBk4EHlXVNSKSKSK58Qg0xur7ne/lva8OXqiq5biuq8WRBNEQk+cxuL9KnwYvVNUdwEJvfTz390u84j7Qe19X58jiK1bXPQw4FLg+lsHFWX2v/WzvfZWIvA2UAsUi8o2IJGshAep/3Z8CRcBtInKRiBwsIoeKyENAV+DeSIJoiMmzDbBBVcvCrPsJaCkiWXHc3y8xj9srjd2Fu5V9pf4hxkW9r1tE2gN/Ae5T1RWxDzFu6nvtnbz3MUBz4ErcM89yYJyIXBXLYGOoXtetqpuBc4FNwGvASuAr4DrgAlUdE0kQDXFUpVwg3IcKsCNom/I47e+XeMT9JO750AhV/bruocVVLK77edyzridiGFci1Pfam3rv24DTvNtWRGQi7vP4q4i8rKqB2IQbM7H4zrcDi4G3gI9wfzyuA14Rkb6qOmNPQTTEkmcJkF3DuiZB28Rrf7/ENG4RuR93CztaVR+qZ2zxVK/r9m5PewBDVLUixrHFW32/81Lv/d/ViRN2lszeAvZnV+k0mdT3O/81LmHOUNVbVfVNVX0B9/x3LTDGu+uqVUNMnqtxxfZwH+4BuOJ+bX+R6ru/X2IWt4jcC9yJa64yOGYRxkedr9vb5wngHWCtiHQUkY645jsAe3vLmsUh7lio73f+o/e+Nsy6Nd77PvWIL17qe93DcEn29eCFqloCTMF9/+32FERDTJ7zcNd1bPBCEWkCHAkUxHl/v8Qkbi9x3gO8DFytXhuOJFaf684B9gV6A98GvWZ76wd4P18dy4BjqL7feXWFy4Fh1lUvK6xHfPFS3+s+wHsPV7rMCHmvmd9ttuLQBuzX1N4GbEDQsl8Ah9Z1/2R61fe6veV3e9uOJYk7A8TquoFM4MIwryHevlO9n3/p93XG4zvHlSq34kqg+UHLW+OeCX7t9zXG6br/5m13W8jyZrhS7SYgfY9x+P1BxOnDfZpdvQ+uBkbieh/MDk4KwAr396Nu+yfbqz7XjXtYrriaxytwpa7gVw+/ry9e33eY47UjBRrJx+Lacb1rFFd5cjNwh/c7UA6c6ff1xeO6cbflG70EPA73aGoErqeVAtdGFIPfH0KcPth0YDjwNa5W7ifcs638kO1q+oWKaP9ke9XnuoGXvF+cml6z/b6+eH3fYY6XSsmz3tcOnA/8D9c4fBvwX+AEv68tnteNK5G+jCt1V+BK4HOA8yONwcbzNMaYOmiIFUbGGBN3ljyNMaYOLHkaY0wdWPI0xpg6sORpjDF1YMnTGGPqwJKnMcbUgSVPE1ci8pKIpFRjYhE5UkTeFZHN3kRw9/odUzLxJklTETnV71j81BDH80wK3i/WeyGLi3E9Isbieq9UJTisuBCRgUAzVX3S51DqTUQygDdw/d7vwo04/rmfMZnkZD2M4iQoef4bN+SZ4EbAHoib7mGMqg7yKbyYEpHZQDtVbRdmXSZukIUdoeuSkYj8EvcHbriqptrgyAnhjXWZCZRr8g2UnDB22x5/C1T1X6o6TlUfAX6DG7nlahHZr6adRKRpTeuSgTj5e9pOVStSJXF69vfeN/kaRYLU5fdMVatUdUdjTpxgyTPhVHUr8DGuJNoBQERWiMhsETlKRKaLyBaCbhVF5GQRmSEiW0SkVEQWiMgfQo/tHWOFiHQQkUne9ltF5E0R6RBm+zwReUhEvhORMhFZKyJjRaRtyHanes+4BorIdSLyJW66g1tEZAVwCtDW26b6daq3b9hnniJyhBfXRhHZISJfishtoSN4V+8vInuLyHMiUuht/6GI/CbSz11E2onIOBFZ513rdyLyVwmaLdIrQb/v/fhi0LW0q+W4zUXkb97xdnjXM19EbvXWtxKRchEZX8P+z4hIoPocInKvd85OXnw/evEuEpGzazjGJSLygYhsE5ESEflERC4Ms516n2d3b/vtwNtB64eIyNfe+b4VkevDPd+s6ZmniGSLyAgRWeJ9FkUi8raIHBWyXZqI3CQin3sxb/XO+4K4O5WUYM88E0xEBOjo/bghaNXBwCzc6NZvAPne9ucAb+JG+x6JG/XmUuAfItJBVf8ccoo83LBcnwB/Ag4BrgWOE5GjVHWtd9xMYDpwAvAf79iH4MayPFNEuqnqjyHHvglogZswbC1uvu+FwENAS9wI3dW+quUz6IZLUhXAM96xzgEeAboA/cPsNh1YD9znxXAzMEVE2qvqtprO5Z2vLW7g372BZ3EDHJ+K+3xOEJHuqloJPAh8iBuebDRuTnO889bkdeBk3DxIn+MGWD7MO/5jqlooIm8B54tIM1UtCoqrCXAZMFN3n3juZdzn8zhuPvGbgIki8svgbUXkAeDPuCmT78INs3Ye8LqIXK+qz4QctxtwAe47fDnoOLcDDwMLvM8lF7h1D9e+k/f7NA04HjfM299xn/cfgQ9F5GRVrR6k+M+47/Ft73OrAtrjJmXL9q47+fk9tFRDfeH+8yhugOGWuBHLj8D90irwcdC2K7xlV4ccIx03tmIR0CZoeRbuP3kVcEjQ8tnecZ4MOc553vLng5b90Vv2aMi2vb3l48JcyyagVZhrnQ2sqOFzeIndh7/7EDcj5xFBywQ3k6EC3UP3B54NOcZF3vJrIvguxnvbnh2y/DFv+R/CXOvACI67d7jYwmx3JmHGicT9kVDg4qBl93rLJuPVSXjLj/GWPxS07Ghv2V/DnHMibpi1pkHLqocXPCNk2+a4+Yw+B5oELd8f2OLtc2rQ8oFhlg3zlvUMOfZewCqChjTEJegv/f4/Wt+X7wE01FfQf8LQVxUwCdgvaNsVuMFZ00OOcay3zxNhjt/XW3dL0LLZ3rL9w2y/FFgb9PM7Xiz7hNn2M+8/XlrItTxZw7XOJsLkCbTyjjUhzLZdCBlHk13J85CQbVt4yx/fw/eQhiutLwizrrn3GUwO870NjOA7zsI9vpiPqzCraTvBzUY5P2T5LNzdR1bQsnu98+82+LR3Hf8J+nkkrqTZCfcHOvj1e+84ZwZtr8DCMMe9xFs3JMy6Z4ksec7H3W2ExtESeAH3xzLH2/Y9XFI+0c//o/V92W17/I3G3doprqnSN6oarjLiO9296VJ7731JmO2rl4U+yyxS79Y8xFfA70QkT1WLvWOvVjdTYrhjH4n7xQ+ew+abMNtGq7Zr+gqXDHZ7PotLPjup6kb3BIQWezjfvrhHILudT1U3iciaGs63R6paLiI3AU8B33vPgmcBE1X13aDtVET+ATwoIkeq6kJxz6BPBZ7S8JOVLQ+zbCM/v97DcIl5aS1hhlZKhvsOq7+TcNNLRzrl9GG4Rxa13ea3xD3qGYErGc8VkdW4P75TcH8YknFyxbAsecbft6o6M4LtknE641C+xRjmD0s1SWggIVT1eRGZhHvccQpuzqPrReRVVb00aNN/An8B/oCba+f3uNj/UcOhI7lewf1RPquW7UP/aMTrOxTgC9yz6JqsB1DVj0XkF0BP4DTvdRlwp4icWEPhIulY8kxu1aWPzmHW/Spkm2rNRGT/MKXPw4BCr9RZvV+v0EqMoGNv5ecVWrWJprHw9957uGs6FHebHa7UVVfrcbe7u51PRPbBTXa2sD4nUNU1uCT4D6+1wDign4iMVNV53jZrReRtoL+I3IG79f1EVcOVwCP1LdALWKWqNVbQRWCF994JV3IOFum87d/iSvmzNIImTKq6HVcx+gaAiFyLqzz8A+5ZdNKzpkrJbQHuYftVIlLd/rC6ZvNWXNKaFGa/O4J/EJHzcP8JJgYtnoj7/kO3PQs4Cngrkv8Enu3APl5LglqpaiHwEXCOiBwedF7B1fKCa10QE941vA0cJSK9QlbfgfsM6nQ+EckNburkna+KXc3MmofsMgY3Y+XzuOlvayp1Rmqc9/5XCWni5cVXYzviEDNw8wAN8VoAVO+/P+FbPoQzFlfBFLbkGRyLiLQMs8kC7z30M0taVvJMYqpaJSLX4/5zzxOR0bhS1CXAcbha1m9DdtuAaxbTBvcsqbqp0jpcZUS1l4Argdu9NoZzcE2oqrcdEUWo/wP6AH8XkY9wt5CzvEQZzo24pkpzRaS6qVIf3G3cK8HPC2NkBNAD19TnWWAZrnnRJbjrfrmWfWvzS+B9EXkTN/vkZlwJfwiuhD03ZPvpuNYTA3B/cP6vjucFQFXniet3fy+wUERex3XAaA10Bc7GVWrt6TgbReQvwF9xzYr+hWuqNAj3jLQbe767eAr3GT8mIqfjSrBbcU3wuuMq1k7ztv1KRP6Ha05XHe8g3Iyd9fpMEsrvGquG+mJXre0tEWy7glpmp8Q9S5uB+2XcgasN/0OY7WZ7x+qAK5FuxSXbSUDHMNvn4dpoLsf94hbiSjNta7iWgTXEl4urUV2HS5w7a2IJ01TJW94FV/rdhCv1fAXcxu4tDsLu761T4KUIv4/23rUVete6HJcscqO51pBtW+DmAF+Ia05WikvMTwKta9jnLu/4L9Sw/l5vfbtIf09wz1unB32WP+DmnB8czeeFm376G+8Y3wLXs2su9GODthsY/B0HLc8AbgDm4SpHi73jjOfntf534P5oFQbF+zpwdKL/n9bnZX3bGxCppY+5SQ4ichuuM8Dxqvqx3/HsiYg8jUuirTV8K45Gy5JnA2LJM7mJG7Hpa6BYVY/wO55gItJEQ8YgEJHWuGZQq1T11/5ElrzsmacxcSYi7YHf4jo2dAD6+RtRWKeKyGPABOBHoB2uF1o+IZWKxrHkaUz8nQK8iKvMu09Vk7FSZBnwHS5htsA9Wy/AdQeNpJ1yo2O37cYYUwfWztMYY+rAkqcxxtSBJU9jjKkDS57GGFMHljyNMaYOLHkaY0wd/H80C2iUHU7ZxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "# for antagonism predictions\n",
    "for cl in keys:\n",
    "    ycl = y[np.isin(combs, pr.predicted[cl]['comb'].values)].argmax(axis=1)\n",
    "    syn_rate = np.sum(ycl == 2) / ycl.size\n",
    "    plt.scatter(syn_rate, pr.avprec[cl][2], marker='o', \n",
    "             label=cl, s=50)\n",
    "    plt.xlim((0,0.8))\n",
    "    plt.ylim((0,0.8))\n",
    "plt.plot([0.01, 1], [0.01, 1], 'k--', lw=1)\n",
    "plt.xlabel('Proportion of synergies')\n",
    "plt.ylabel('Average precision')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.get_major_ticks()[0].label1.set_visible(False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Ecoli-AP-syn-vs-rate.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"calib\"></a> \n",
    "## Probability calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "def build_nn(dropout=0.2, nodes=32, layers=3, learning_rate_deep=0.001):\n",
    "    model = Sequential()\n",
    "    for i in range(layers):\n",
    "        #With BN\n",
    "        #model.add(Dense(self.nodes, activation=\"linear\", use_bias=\"False\"))\n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(Activation(\"relu\"))\n",
    "        #model.add(Dropout(self.dropout))\n",
    "        #Without BN\n",
    "        model.add(Dense(nodes, activation=\"relu\"))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Dense(3, activation=\"softmax\"))\n",
    "                \n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate_deep)#, beta_1=self.beta_1, beta_2=self.beta_2)\n",
    "        model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = opt,  metrics = [\"accuracy\"]) #other option loss = \"binary_crossentropy\"\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#clf = OneVsRestClassifier(RandomForestClassifier(bootstrap=True,\n",
    "#                                                max_features='sqrt',\n",
    "#                                                **param_dict,\n",
    "#                                                random_state=2305,\n",
    "#                                              n_jobs=-1))\n",
    "keras_clf = OneVsRestClassifier(tf.keras.wrappers.scikit_learn.KerasClassifier(build_nn, epochs=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_onehot, y, test_size=0.2,\n",
    "                                                    random_state=2305,\n",
    "                                                    stratify=np.argmax(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 877us/step - loss: 0.7189 - accuracy: 0.6869\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 782us/step - loss: 0.5509 - accuracy: 0.7162\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 744us/step - loss: 0.4898 - accuracy: 0.7792\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 754us/step - loss: 0.5112 - accuracy: 0.7715\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.8095\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 926us/step - loss: 0.4541 - accuracy: 0.7813\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 789us/step - loss: 0.4336 - accuracy: 0.7889\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 783us/step - loss: 0.4630 - accuracy: 0.7763\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 745us/step - loss: 0.3919 - accuracy: 0.8322\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 715us/step - loss: 0.4237 - accuracy: 0.7989\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 729us/step - loss: 0.3688 - accuracy: 0.8390\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 922us/step - loss: 0.3906 - accuracy: 0.8291\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 941us/step - loss: 0.3570 - accuracy: 0.8556\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 792us/step - loss: 0.3636 - accuracy: 0.8336\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 0.3398 - accuracy: 0.8452\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 740us/step - loss: 0.3638 - accuracy: 0.8514\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 736us/step - loss: 0.3224 - accuracy: 0.8584\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 749us/step - loss: 0.3309 - accuracy: 0.8721\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 875us/step - loss: 0.2997 - accuracy: 0.8741\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 930us/step - loss: 0.2903 - accuracy: 0.8767\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 0.3144 - accuracy: 0.8803\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 764us/step - loss: 0.2861 - accuracy: 0.8923\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 753us/step - loss: 0.2705 - accuracy: 0.8825\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 729us/step - loss: 0.2909 - accuracy: 0.8843\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 745us/step - loss: 0.2579 - accuracy: 0.9020\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9213\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 949us/step - loss: 0.2362 - accuracy: 0.9193\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8900\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.2377 - accuracy: 0.9163\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 800us/step - loss: 0.2461 - accuracy: 0.9107\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.2091 - accuracy: 0.9165\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 758us/step - loss: 0.2008 - accuracy: 0.9319\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 732us/step - loss: 0.2110 - accuracy: 0.9335\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 734us/step - loss: 0.1968 - accuracy: 0.9228\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 954us/step - loss: 0.2076 - accuracy: 0.9100\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 982us/step - loss: 0.1947 - accuracy: 0.9233\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9410\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 792us/step - loss: 0.1567 - accuracy: 0.9476\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 783us/step - loss: 0.1834 - accuracy: 0.9359\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 764us/step - loss: 0.1757 - accuracy: 0.9342\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 743us/step - loss: 0.1708 - accuracy: 0.9496\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 710us/step - loss: 0.1704 - accuracy: 0.9320\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 912us/step - loss: 0.1691 - accuracy: 0.9475\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 813us/step - loss: 0.1529 - accuracy: 0.9439\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 875us/step - loss: 0.1584 - accuracy: 0.9389\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 792us/step - loss: 0.1589 - accuracy: 0.9454\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 757us/step - loss: 0.1631 - accuracy: 0.9417\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 747us/step - loss: 0.1455 - accuracy: 0.9455\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 727us/step - loss: 0.1449 - accuracy: 0.9580\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 749us/step - loss: 0.1274 - accuracy: 0.9646\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 940us/step - loss: 0.1459 - accuracy: 0.9598\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 853us/step - loss: 0.1574 - accuracy: 0.9481\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 969us/step - loss: 0.1322 - accuracy: 0.9597\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9528\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 985us/step - loss: 0.1358 - accuracy: 0.9577\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 940us/step - loss: 0.1337 - accuracy: 0.9437\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 845us/step - loss: 0.1298 - accuracy: 0.9625\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 925us/step - loss: 0.1313 - accuracy: 0.9467\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 784us/step - loss: 0.1168 - accuracy: 0.9633\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 769us/step - loss: 0.1139 - accuracy: 0.9643\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 738us/step - loss: 0.1108 - accuracy: 0.9654\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 723us/step - loss: 0.1445 - accuracy: 0.9483\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 715us/step - loss: 0.0943 - accuracy: 0.9689\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 713us/step - loss: 0.1166 - accuracy: 0.9613\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 714us/step - loss: 0.1054 - accuracy: 0.9693\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.1015 - accuracy: 0.9752\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 924us/step - loss: 0.0986 - accuracy: 0.9667\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 955us/step - loss: 0.1224 - accuracy: 0.9592\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.1124 - accuracy: 0.9657\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 803us/step - loss: 0.1002 - accuracy: 0.9659\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 768us/step - loss: 0.0967 - accuracy: 0.9703\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 738us/step - loss: 0.0960 - accuracy: 0.9651\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 719us/step - loss: 0.1174 - accuracy: 0.9519\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 880us/step - loss: 0.0999 - accuracy: 0.9643\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 752us/step - loss: 0.0867 - accuracy: 0.9744\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 888us/step - loss: 0.1029 - accuracy: 0.9667\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 796us/step - loss: 0.1219 - accuracy: 0.9476\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 757us/step - loss: 0.0894 - accuracy: 0.9770\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 743us/step - loss: 0.0724 - accuracy: 0.9782\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 711us/step - loss: 0.0865 - accuracy: 0.9713\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 881us/step - loss: 0.0800 - accuracy: 0.9751\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 776us/step - loss: 0.0758 - accuracy: 0.9823\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 746us/step - loss: 0.0864 - accuracy: 0.9740\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 738us/step - loss: 0.0877 - accuracy: 0.9763\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 728us/step - loss: 0.0612 - accuracy: 0.9850\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 727us/step - loss: 0.0818 - accuracy: 0.9766\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 779us/step - loss: 0.0721 - accuracy: 0.9791\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 888us/step - loss: 0.0714 - accuracy: 0.9802\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.0563 - accuracy: 0.9876\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 830us/step - loss: 0.0813 - accuracy: 0.9831\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 865us/step - loss: 0.0727 - accuracy: 0.9711\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0755 - accuracy: 0.9784\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0819 - accuracy: 0.9769\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 842us/step - loss: 0.0610 - accuracy: 0.9786\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 804us/step - loss: 0.0754 - accuracy: 0.9769\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 843us/step - loss: 0.0523 - accuracy: 0.9852\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 0.0698 - accuracy: 0.9836\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 0.0872 - accuracy: 0.9675\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 856us/step - loss: 0.0745 - accuracy: 0.9732\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 808us/step - loss: 0.0589 - accuracy: 0.9827\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 806us/step - loss: 0.0661 - accuracy: 0.9765\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 0.1021 - accuracy: 0.9568\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 828us/step - loss: 0.0746 - accuracy: 0.9752\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0648 - accuracy: 0.9833\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0793 - accuracy: 0.9742\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.0673 - accuracy: 0.9777\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 804us/step - loss: 0.0601 - accuracy: 0.9786\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 823us/step - loss: 0.0652 - accuracy: 0.9720\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.0661 - accuracy: 0.9813\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 775us/step - loss: 0.0748 - accuracy: 0.9632\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 0.0630 - accuracy: 0.9779\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.0569 - accuracy: 0.9807\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 0.0888 - accuracy: 0.9755\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0691 - accuracy: 0.9781\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0598 - accuracy: 0.9781\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 0.0536 - accuracy: 0.9826\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 808us/step - loss: 0.0486 - accuracy: 0.9850\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 813us/step - loss: 0.0564 - accuracy: 0.9853\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0748 - accuracy: 0.9765\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 0.0424 - accuracy: 0.9878\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 777us/step - loss: 0.0634 - accuracy: 0.9833\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 0.0565 - accuracy: 0.9847\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 838us/step - loss: 0.0367 - accuracy: 0.9922\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0502 - accuracy: 0.9835\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0732 - accuracy: 0.9711\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 0.0632 - accuracy: 0.9829\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0658 - accuracy: 0.9694\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 759us/step - loss: 0.0631 - accuracy: 0.9825\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.0557 - accuracy: 0.9802\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 809us/step - loss: 0.0590 - accuracy: 0.9802\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 853us/step - loss: 0.0537 - accuracy: 0.9806\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0582 - accuracy: 0.9809\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 803us/step - loss: 0.0562 - accuracy: 0.9753\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0441 - accuracy: 0.9834\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 847us/step - loss: 0.0559 - accuracy: 0.9750\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 806us/step - loss: 0.0648 - accuracy: 0.9775\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 830us/step - loss: 0.0463 - accuracy: 0.9834\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.0654 - accuracy: 0.9720\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 782us/step - loss: 0.0590 - accuracy: 0.9716\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0630 - accuracy: 0.9783\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 801us/step - loss: 0.0572 - accuracy: 0.9737\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0787 - accuracy: 0.9697\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 851us/step - loss: 0.0639 - accuracy: 0.9877\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0570 - accuracy: 0.9848\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 784us/step - loss: 0.0622 - accuracy: 0.9791\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 0.0422 - accuracy: 0.9853\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 794us/step - loss: 0.0449 - accuracy: 0.9855\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.0529 - accuracy: 0.9813\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 853us/step - loss: 0.0397 - accuracy: 0.9899\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 797us/step - loss: 0.0399 - accuracy: 0.9921\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 780us/step - loss: 0.0438 - accuracy: 0.9814\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.0584 - accuracy: 0.9758\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 786us/step - loss: 0.0472 - accuracy: 0.9784\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 765us/step - loss: 0.0615 - accuracy: 0.9768\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 777us/step - loss: 0.0455 - accuracy: 0.9792\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 753us/step - loss: 0.0381 - accuracy: 0.9842\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 787us/step - loss: 0.0657 - accuracy: 0.9778\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0415 - accuracy: 0.9844\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 766us/step - loss: 0.0363 - accuracy: 0.9860\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 793us/step - loss: 0.0563 - accuracy: 0.9844\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 802us/step - loss: 0.0483 - accuracy: 0.9778\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 801us/step - loss: 0.0283 - accuracy: 0.9919\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0285 - accuracy: 0.9936\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0190 - accuracy: 0.9918\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.0641 - accuracy: 0.9819\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0331 - accuracy: 0.9890\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 809us/step - loss: 0.0425 - accuracy: 0.9839\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.0408 - accuracy: 0.9840\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 854us/step - loss: 0.0375 - accuracy: 0.9837\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.0432 - accuracy: 0.9832\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 0.0316 - accuracy: 0.9889\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 0.0425 - accuracy: 0.9898\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0303 - accuracy: 0.9899\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 847us/step - loss: 0.0293 - accuracy: 0.9891\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 0.0389 - accuracy: 0.9894\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 802us/step - loss: 0.0269 - accuracy: 0.9948\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 754us/step - loss: 0.0462 - accuracy: 0.9786\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 743us/step - loss: 0.0487 - accuracy: 0.9809\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 838us/step - loss: 0.0523 - accuracy: 0.9830\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 991us/step - loss: 0.0374 - accuracy: 0.9878\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.0504 - accuracy: 0.9842\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 850us/step - loss: 0.0321 - accuracy: 0.9951\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 800us/step - loss: 0.0461 - accuracy: 0.9807\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0302 - accuracy: 0.9874\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0409 - accuracy: 0.9884\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.0232 - accuracy: 0.9945\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 850us/step - loss: 0.0349 - accuracy: 0.9857\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 798us/step - loss: 0.0373 - accuracy: 0.9911\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 786us/step - loss: 0.0525 - accuracy: 0.9805\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 800us/step - loss: 0.0340 - accuracy: 0.9909\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 777us/step - loss: 0.0289 - accuracy: 0.9894\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 747us/step - loss: 0.0416 - accuracy: 0.9857\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 919us/step - loss: 0.0582 - accuracy: 0.9833\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0523 - accuracy: 0.9762\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0448 - accuracy: 0.9835\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 853us/step - loss: 0.0360 - accuracy: 0.9848\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 832us/step - loss: 0.0575 - accuracy: 0.9796\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0434 - accuracy: 0.9768\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 808us/step - loss: 0.0326 - accuracy: 0.9884\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0212 - accuracy: 0.9944\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 774us/step - loss: 0.6288 - accuracy: 0.7232\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 723us/step - loss: 0.4187 - accuracy: 0.8326\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 861us/step - loss: 0.3492 - accuracy: 0.8659\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.3268 - accuracy: 0.8728\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 769us/step - loss: 0.3105 - accuracy: 0.8679\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 787us/step - loss: 0.2956 - accuracy: 0.8742\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 749us/step - loss: 0.2963 - accuracy: 0.8781\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 747us/step - loss: 0.2880 - accuracy: 0.8874\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 790us/step - loss: 0.2922 - accuracy: 0.8725\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 961us/step - loss: 0.2826 - accuracy: 0.8755\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 840us/step - loss: 0.2495 - accuracy: 0.9001\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 839us/step - loss: 0.2518 - accuracy: 0.9022\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.2359 - accuracy: 0.9100\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.2228 - accuracy: 0.8991\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.2072 - accuracy: 0.9259\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 811us/step - loss: 0.2309 - accuracy: 0.9018\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 789us/step - loss: 0.1898 - accuracy: 0.9207\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.2220 - accuracy: 0.8937\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 806us/step - loss: 0.2051 - accuracy: 0.9342\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.1977 - accuracy: 0.9277\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 828us/step - loss: 0.1836 - accuracy: 0.9351\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.1654 - accuracy: 0.9328\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 809us/step - loss: 0.1802 - accuracy: 0.9217\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 813us/step - loss: 0.1781 - accuracy: 0.9367\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.1491 - accuracy: 0.9559\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.1325 - accuracy: 0.9530\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.1517 - accuracy: 0.9389\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 809us/step - loss: 0.1484 - accuracy: 0.9545\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 791us/step - loss: 0.1326 - accuracy: 0.9535\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 762us/step - loss: 0.1344 - accuracy: 0.9637\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 740us/step - loss: 0.1357 - accuracy: 0.9578\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.1206 - accuracy: 0.9514\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 787us/step - loss: 0.1348 - accuracy: 0.9459\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 918us/step - loss: 0.1408 - accuracy: 0.9489\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 843us/step - loss: 0.1125 - accuracy: 0.9582\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.1100 - accuracy: 0.9622\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.1041 - accuracy: 0.9639\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 809us/step - loss: 0.1064 - accuracy: 0.9601\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.1229 - accuracy: 0.9599\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 771us/step - loss: 0.0916 - accuracy: 0.9627\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 832us/step - loss: 0.0920 - accuracy: 0.9743\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 770us/step - loss: 0.1172 - accuracy: 0.9501\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 828us/step - loss: 0.0912 - accuracy: 0.9707\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 852us/step - loss: 0.0856 - accuracy: 0.9711\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 842us/step - loss: 0.0798 - accuracy: 0.9747\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0894 - accuracy: 0.9681\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.0994 - accuracy: 0.9589\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 848us/step - loss: 0.0825 - accuracy: 0.9822\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0852 - accuracy: 0.9724\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.0844 - accuracy: 0.9775\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.0775 - accuracy: 0.9759\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 0.0895 - accuracy: 0.9760\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.0675 - accuracy: 0.9832\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 832us/step - loss: 0.0901 - accuracy: 0.9640\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0887 - accuracy: 0.9741\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 906us/step - loss: 0.0649 - accuracy: 0.9739\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0746 - accuracy: 0.9724\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 808us/step - loss: 0.0592 - accuracy: 0.9828\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0680 - accuracy: 0.9761\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0661 - accuracy: 0.9774\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 830us/step - loss: 0.0609 - accuracy: 0.9840\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.0603 - accuracy: 0.9790\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.0482 - accuracy: 0.9861\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0478 - accuracy: 0.9941\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 0.0516 - accuracy: 0.9833\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 0.0503 - accuracy: 0.9927\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0448 - accuracy: 0.9911\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0400 - accuracy: 0.9901\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.0569 - accuracy: 0.9838\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0413 - accuracy: 0.9894\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.0600 - accuracy: 0.9776\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 0.0501 - accuracy: 0.9862\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 799us/step - loss: 0.0502 - accuracy: 0.9860\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0494 - accuracy: 0.9841\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 0.0441 - accuracy: 0.9914\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.0487 - accuracy: 0.9795\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 780us/step - loss: 0.0372 - accuracy: 0.9913\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.0307 - accuracy: 0.9909\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0541 - accuracy: 0.9859\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0350 - accuracy: 0.9922\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0381 - accuracy: 0.9845\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0619 - accuracy: 0.9788\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 801us/step - loss: 0.0273 - accuracy: 0.9947\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 838us/step - loss: 0.0305 - accuracy: 0.9931\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.0306 - accuracy: 0.9915\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.0354 - accuracy: 0.9922\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0293 - accuracy: 0.9909\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.0292 - accuracy: 0.9960\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 0.0267 - accuracy: 0.9953\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 849us/step - loss: 0.0483 - accuracy: 0.9816\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 845us/step - loss: 0.0293 - accuracy: 0.9937\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 862us/step - loss: 0.0274 - accuracy: 0.9958\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 849us/step - loss: 0.0324 - accuracy: 0.9945\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 832us/step - loss: 0.0329 - accuracy: 0.9895\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 831us/step - loss: 0.0365 - accuracy: 0.9919\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 850us/step - loss: 0.0369 - accuracy: 0.9945\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.0348 - accuracy: 0.9794\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 949us/step - loss: 0.0250 - accuracy: 0.9974\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 844us/step - loss: 0.0229 - accuracy: 0.9967\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 0.0255 - accuracy: 0.9935\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 842us/step - loss: 0.0195 - accuracy: 0.9959\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 832us/step - loss: 0.0288 - accuracy: 0.9965\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 823us/step - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 771us/step - loss: 0.0371 - accuracy: 0.9879\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 804us/step - loss: 0.0230 - accuracy: 0.9933\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 776us/step - loss: 0.0200 - accuracy: 0.9994\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 780us/step - loss: 0.0365 - accuracy: 0.9858\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 779us/step - loss: 0.0360 - accuracy: 0.9911\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0271 - accuracy: 0.9924\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.0183 - accuracy: 0.9959\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.0170 - accuracy: 0.9961\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.0273 - accuracy: 0.9940\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 801us/step - loss: 0.0227 - accuracy: 0.9933\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 0.0268 - accuracy: 0.9976\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 831us/step - loss: 0.0215 - accuracy: 0.9949\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.0258 - accuracy: 0.9972\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 823us/step - loss: 0.0320 - accuracy: 0.9899\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 839us/step - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 861us/step - loss: 0.0155 - accuracy: 0.9962\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9932\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9914\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9964\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9912\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9943\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9914\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9956\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.9923\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.9947\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9943\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9982\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9967\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 963us/step - loss: 0.0159 - accuracy: 0.9947\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9957\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9935\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.9986\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.9963\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9917\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9934\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9979\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9967\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.9936\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 921us/step - loss: 0.0230 - accuracy: 0.9901\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9968\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 980us/step - loss: 0.0196 - accuracy: 0.9974\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.0164 - accuracy: 0.9949\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 951us/step - loss: 0.0192 - accuracy: 0.9976\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.0232 - accuracy: 0.9898\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 880us/step - loss: 0.0236 - accuracy: 0.9931\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 860us/step - loss: 0.0326 - accuracy: 0.9911\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 808us/step - loss: 0.0130 - accuracy: 0.9980\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 830us/step - loss: 0.0268 - accuracy: 0.9879\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 831us/step - loss: 0.0329 - accuracy: 0.9913\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 840us/step - loss: 0.0187 - accuracy: 0.9909\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0163 - accuracy: 0.9996\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 826us/step - loss: 0.0231 - accuracy: 0.9954\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 826us/step - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0170 - accuracy: 0.9985\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0188 - accuracy: 0.9893\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0215 - accuracy: 0.9899\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 803us/step - loss: 0.0139 - accuracy: 0.9975\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0165 - accuracy: 0.9935\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.0098 - accuracy: 0.9990\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 0.0138 - accuracy: 0.9985\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 838us/step - loss: 0.0241 - accuracy: 0.9922\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 796us/step - loss: 0.0153 - accuracy: 0.9941\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 804us/step - loss: 0.0109 - accuracy: 0.9994\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 808us/step - loss: 0.0059 - accuracy: 0.9999\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 762us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 764us/step - loss: 0.0064 - accuracy: 0.9994\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 787us/step - loss: 0.0094 - accuracy: 0.9986\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 807us/step - loss: 0.0093 - accuracy: 0.9996\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 989us/step - loss: 0.0145 - accuracy: 0.9935\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 840us/step - loss: 0.0100 - accuracy: 0.9967\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 806us/step - loss: 0.0083 - accuracy: 0.9962\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 798us/step - loss: 0.0132 - accuracy: 0.9991\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 764us/step - loss: 0.0109 - accuracy: 0.9960\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 754us/step - loss: 0.0145 - accuracy: 0.9943\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 785us/step - loss: 0.0192 - accuracy: 0.9943\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 873us/step - loss: 0.0206 - accuracy: 0.9951\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 871us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.0079 - accuracy: 0.9978\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 783us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 764us/step - loss: 0.0192 - accuracy: 0.9957\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 736us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 778us/step - loss: 0.0119 - accuracy: 0.9970\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 858us/step - loss: 0.0231 - accuracy: 0.9938\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 865us/step - loss: 0.0125 - accuracy: 0.9960\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 831us/step - loss: 0.0184 - accuracy: 0.9937\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.0098 - accuracy: 0.9983\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 809us/step - loss: 0.0100 - accuracy: 0.9960\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 771us/step - loss: 0.0164 - accuracy: 0.9921\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 769us/step - loss: 0.0124 - accuracy: 0.9988\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 727us/step - loss: 0.0106 - accuracy: 0.9962\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 729us/step - loss: 0.0345 - accuracy: 0.9949\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 795us/step - loss: 0.0158 - accuracy: 0.9943\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 796us/step - loss: 0.5411 - accuracy: 0.7889\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 736us/step - loss: 0.3786 - accuracy: 0.8822\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 747us/step - loss: 0.3284 - accuracy: 0.8838\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 744us/step - loss: 0.2996 - accuracy: 0.8909\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 909us/step - loss: 0.3139 - accuracy: 0.8690\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 902us/step - loss: 0.2893 - accuracy: 0.8841\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.2756 - accuracy: 0.8866\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.2808 - accuracy: 0.8934\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 841us/step - loss: 0.2875 - accuracy: 0.8915\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 831us/step - loss: 0.2933 - accuracy: 0.8971\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.2523 - accuracy: 0.8908\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 858us/step - loss: 0.2516 - accuracy: 0.9124\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 806us/step - loss: 0.2072 - accuracy: 0.9219\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.2295 - accuracy: 0.9153\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 873us/step - loss: 0.2019 - accuracy: 0.9240\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 844us/step - loss: 0.2130 - accuracy: 0.9227\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 877us/step - loss: 0.2227 - accuracy: 0.9057\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 983us/step - loss: 0.2127 - accuracy: 0.9205\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.9371\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9245\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 830us/step - loss: 0.1889 - accuracy: 0.9287\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 0.1898 - accuracy: 0.9325\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 873us/step - loss: 0.1675 - accuracy: 0.9386\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 811us/step - loss: 0.1637 - accuracy: 0.9424\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 861us/step - loss: 0.1687 - accuracy: 0.9470\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 892us/step - loss: 0.1727 - accuracy: 0.9321\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 876us/step - loss: 0.1263 - accuracy: 0.9576\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 936us/step - loss: 0.1331 - accuracy: 0.9609\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9543\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 995us/step - loss: 0.1356 - accuracy: 0.9489\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.9646\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 932us/step - loss: 0.1310 - accuracy: 0.9595\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 962us/step - loss: 0.1216 - accuracy: 0.9611\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 855us/step - loss: 0.1302 - accuracy: 0.9450\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 847us/step - loss: 0.1100 - accuracy: 0.9619\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 847us/step - loss: 0.1241 - accuracy: 0.9501\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 865us/step - loss: 0.1142 - accuracy: 0.9690\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.1308 - accuracy: 0.9458\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 889us/step - loss: 0.1200 - accuracy: 0.9584\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9522\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 845us/step - loss: 0.1131 - accuracy: 0.9577\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 939us/step - loss: 0.1164 - accuracy: 0.9494\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 889us/step - loss: 0.0918 - accuracy: 0.9677\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 878us/step - loss: 0.0896 - accuracy: 0.9733\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 901us/step - loss: 0.0830 - accuracy: 0.9692\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 904us/step - loss: 0.0989 - accuracy: 0.9677\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 851us/step - loss: 0.0939 - accuracy: 0.9697\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 854us/step - loss: 0.0732 - accuracy: 0.9795\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 863us/step - loss: 0.0866 - accuracy: 0.9636\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 0.0833 - accuracy: 0.9763\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 803us/step - loss: 0.0950 - accuracy: 0.9623\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 876us/step - loss: 0.0651 - accuracy: 0.9795\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9820\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 858us/step - loss: 0.0725 - accuracy: 0.9740\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 939us/step - loss: 0.0810 - accuracy: 0.9811\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 873us/step - loss: 0.0864 - accuracy: 0.9656\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 862us/step - loss: 0.0708 - accuracy: 0.9732\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 867us/step - loss: 0.0619 - accuracy: 0.9842\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 861us/step - loss: 0.0647 - accuracy: 0.9814\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 847us/step - loss: 0.0594 - accuracy: 0.9824\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 868us/step - loss: 0.0571 - accuracy: 0.9823\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 840us/step - loss: 0.0714 - accuracy: 0.9711\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 889us/step - loss: 0.0632 - accuracy: 0.9756\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 900us/step - loss: 0.0491 - accuracy: 0.9896\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 950us/step - loss: 0.0614 - accuracy: 0.9804\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 818us/step - loss: 0.0649 - accuracy: 0.9807\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0554 - accuracy: 0.9841\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 842us/step - loss: 0.0510 - accuracy: 0.9801\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 868us/step - loss: 0.0547 - accuracy: 0.9846\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 844us/step - loss: 0.0453 - accuracy: 0.9861\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 853us/step - loss: 0.0395 - accuracy: 0.9883\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 811us/step - loss: 0.0455 - accuracy: 0.9938\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 795us/step - loss: 0.0464 - accuracy: 0.9881\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 806us/step - loss: 0.0554 - accuracy: 0.9862\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 785us/step - loss: 0.0508 - accuracy: 0.9872\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 766us/step - loss: 0.0336 - accuracy: 0.9940\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 770us/step - loss: 0.0395 - accuracy: 0.9878\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 951us/step - loss: 0.0482 - accuracy: 0.9862\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 854us/step - loss: 0.0406 - accuracy: 0.9891\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 824us/step - loss: 0.0398 - accuracy: 0.9908\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0389 - accuracy: 0.9939\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.0374 - accuracy: 0.9862\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0436 - accuracy: 0.9882\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0500 - accuracy: 0.9822\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 826us/step - loss: 0.0305 - accuracy: 0.9892\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 0.0335 - accuracy: 0.9901\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 836us/step - loss: 0.0416 - accuracy: 0.9836\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0418 - accuracy: 0.9862\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0289 - accuracy: 0.9893\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.0371 - accuracy: 0.9879\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 838us/step - loss: 0.0384 - accuracy: 0.9905\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 786us/step - loss: 0.0248 - accuracy: 0.9971\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 760us/step - loss: 0.0243 - accuracy: 0.9929\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 774us/step - loss: 0.0232 - accuracy: 0.9961\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 767us/step - loss: 0.0360 - accuracy: 0.9872\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 788us/step - loss: 0.0326 - accuracy: 0.9947\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 927us/step - loss: 0.0379 - accuracy: 0.9861\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 909us/step - loss: 0.0278 - accuracy: 0.9902\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 842us/step - loss: 0.0339 - accuracy: 0.9860\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 854us/step - loss: 0.0568 - accuracy: 0.9763\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0318 - accuracy: 0.9915\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 839us/step - loss: 0.0348 - accuracy: 0.9907\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 849us/step - loss: 0.0203 - accuracy: 0.9975\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0257 - accuracy: 0.9955\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0297 - accuracy: 0.9912\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0225 - accuracy: 0.9929\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0340 - accuracy: 0.9890\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 809us/step - loss: 0.0355 - accuracy: 0.9887\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 843us/step - loss: 0.0307 - accuracy: 0.9940\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 834us/step - loss: 0.0231 - accuracy: 0.9961\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 843us/step - loss: 0.0205 - accuracy: 0.9956\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 854us/step - loss: 0.0354 - accuracy: 0.9862\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.0271 - accuracy: 0.9927\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.0380 - accuracy: 0.9861\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 775us/step - loss: 0.0254 - accuracy: 0.9865\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 759us/step - loss: 0.0258 - accuracy: 0.9915\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 765us/step - loss: 0.0249 - accuracy: 0.9927\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 940us/step - loss: 0.0128 - accuracy: 0.9992\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 850us/step - loss: 0.0195 - accuracy: 0.9947\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0291 - accuracy: 0.9855\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 853us/step - loss: 0.0254 - accuracy: 0.9930\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0192 - accuracy: 0.9964\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0183 - accuracy: 0.9987\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 864us/step - loss: 0.0218 - accuracy: 0.9949\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0208 - accuracy: 0.9899\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0259 - accuracy: 0.9896\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 822us/step - loss: 0.0318 - accuracy: 0.9900\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 797us/step - loss: 0.0324 - accuracy: 0.9917\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 798us/step - loss: 0.0283 - accuracy: 0.9884\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0178 - accuracy: 0.9963\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0177 - accuracy: 0.9950\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.0134 - accuracy: 0.9970\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 839us/step - loss: 0.0169 - accuracy: 0.9959\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 0.0211 - accuracy: 0.9957\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0194 - accuracy: 0.9988\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 796us/step - loss: 0.0113 - accuracy: 0.9981\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 813us/step - loss: 0.0365 - accuracy: 0.9912\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 810us/step - loss: 0.0198 - accuracy: 0.9976\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 792us/step - loss: 0.0132 - accuracy: 0.9975\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 789us/step - loss: 0.0130 - accuracy: 0.9991\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 798us/step - loss: 0.0115 - accuracy: 0.9969\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0174 - accuracy: 0.9992\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 785us/step - loss: 0.0161 - accuracy: 0.9945\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 803us/step - loss: 0.0210 - accuracy: 0.9982\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 807us/step - loss: 0.0130 - accuracy: 0.9974\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 777us/step - loss: 0.0121 - accuracy: 0.9979\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 778us/step - loss: 0.0282 - accuracy: 0.9873\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 787us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 755us/step - loss: 0.0232 - accuracy: 0.9953\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 779us/step - loss: 0.0125 - accuracy: 0.9994\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 793us/step - loss: 0.0141 - accuracy: 0.9923\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 799us/step - loss: 0.0117 - accuracy: 0.9989\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.0109 - accuracy: 0.9950\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 815us/step - loss: 0.0224 - accuracy: 0.9928\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 777us/step - loss: 0.0134 - accuracy: 0.9996\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 804us/step - loss: 0.0214 - accuracy: 0.9939\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 784us/step - loss: 0.0278 - accuracy: 0.9882\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 811us/step - loss: 0.0295 - accuracy: 0.9865\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 846us/step - loss: 0.0189 - accuracy: 0.9926\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 770us/step - loss: 0.0149 - accuracy: 0.9944\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 791us/step - loss: 0.0160 - accuracy: 0.9960\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 774us/step - loss: 0.0174 - accuracy: 0.9962\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 755us/step - loss: 0.0260 - accuracy: 0.9909\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 742us/step - loss: 0.0261 - accuracy: 0.9907\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 742us/step - loss: 0.0253 - accuracy: 0.9885\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 812us/step - loss: 0.0134 - accuracy: 0.9943\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 993us/step - loss: 0.0247 - accuracy: 0.9876\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 849us/step - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 960us/step - loss: 0.0197 - accuracy: 0.9900\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 0.0107 - accuracy: 0.9984\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 858us/step - loss: 0.0202 - accuracy: 0.9938\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 837us/step - loss: 0.0193 - accuracy: 0.9945\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 800us/step - loss: 0.0194 - accuracy: 0.9930\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.0126 - accuracy: 0.9962\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 0.0101 - accuracy: 0.9977\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0128 - accuracy: 0.9960\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 830us/step - loss: 0.0300 - accuracy: 0.9841\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0185 - accuracy: 0.9915\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 824us/step - loss: 0.0164 - accuracy: 0.9925\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 843us/step - loss: 0.0092 - accuracy: 0.9979\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 830us/step - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 827us/step - loss: 0.0118 - accuracy: 0.9952\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 832us/step - loss: 0.0173 - accuracy: 0.9927\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 833us/step - loss: 0.0122 - accuracy: 0.9983\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 831us/step - loss: 0.0118 - accuracy: 0.9948\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 825us/step - loss: 0.0121 - accuracy: 0.9965\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 828us/step - loss: 0.0313 - accuracy: 0.9905\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 808us/step - loss: 0.0179 - accuracy: 0.9958\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 820us/step - loss: 0.0140 - accuracy: 0.9964\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 819us/step - loss: 0.0185 - accuracy: 0.9948\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 831us/step - loss: 0.0183 - accuracy: 0.9926\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 813us/step - loss: 0.0157 - accuracy: 0.9969\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 814us/step - loss: 0.0180 - accuracy: 0.9928\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 821us/step - loss: 0.0152 - accuracy: 0.9957\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 829us/step - loss: 0.0157 - accuracy: 0.9974\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 806us/step - loss: 0.0137 - accuracy: 0.9985\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 842us/step - loss: 0.0175 - accuracy: 0.9937\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 835us/step - loss: 0.0087 - accuracy: 0.9981\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 816us/step - loss: 0.0099 - accuracy: 0.9983\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 817us/step - loss: 0.0144 - accuracy: 0.9939\n"
     ]
    }
   ],
   "source": [
    "#clf = clf.fit(X_train, y_train)\n",
    "clf= keras_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c792cfd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "probas_ = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot precision-recall for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "thresh = dict()\n",
    "average_precision = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val[:, i], probas_[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    precision[i], recall[i], thresh[i] = precision_recall_curve(y_val[:, i],\n",
    "                                                        probas_[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val[:, i], probas_[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9c739e2220>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "class_names = ['none', 'antagonism', 'synergy']\n",
    "colors = cycle(['#808080','#FFCC33', '#009999'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y_ = f_score * x / (2 * x - f_score)\n",
    "    plt.plot(x[y_ >= 0], y_[y_ >= 0], color='gray', alpha=0.2,\n",
    "             label='iso-F1 curves')\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y_[45] + 0.02))\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label='Precision-recall of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "fraction_of_positives = dict()\n",
    "mean_predicted_value = dict()\n",
    "for i in range(n_classes):\n",
    "    proba_val = clf.predict_proba(X_val)[:, i]\n",
    "    fraction_of_positives[i], mean_predicted_value[i] = calibration_curve(y_val[:,i],\n",
    "                                                                proba_val,\n",
    "                                                                n_bins=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00509713, 0.26705122, 0.44835931, 0.59294522, 0.74089634,\n",
       "       0.9373042 ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_predicted_value[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9c78870250>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "plt.plot(mean_predicted_value[0], fraction_of_positives[0], 's-', label='none')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot(mean_predicted_value[1], fraction_of_positives[1], 's-', label='antagonism')\n",
    "plt.plot(mean_predicted_value[2], fraction_of_positives[2], 's-', label='synergy')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Uncalibrated probabilities')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.8684 - accuracy: 0.5720\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.5671 - accuracy: 0.7360\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7452\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7553\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.4716 - accuracy: 0.7986\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.4585 - accuracy: 0.8106\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8008\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.8152\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8399\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.4230 - accuracy: 0.7955\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.3716 - accuracy: 0.8395\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.8389\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8445\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8407\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.3720 - accuracy: 0.8591\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8419\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8513\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8288\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8763\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8768\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.3078 - accuracy: 0.8786\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8614\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8361\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.3006 - accuracy: 0.8874\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 987us/step - loss: 0.3216 - accuracy: 0.8544\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.3473 - accuracy: 0.8525\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8727\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.3136 - accuracy: 0.8659\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2818 - accuracy: 0.8825\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.2933 - accuracy: 0.8750\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.8833\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.2535 - accuracy: 0.9044\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2521 - accuracy: 0.9216\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.9088\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.2632 - accuracy: 0.9064\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8827\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.2669 - accuracy: 0.8923\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.9079\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.2186 - accuracy: 0.9232\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9091\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.2422 - accuracy: 0.9107\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.2499 - accuracy: 0.8971\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.2226 - accuracy: 0.9214\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.2085 - accuracy: 0.9186\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.2420 - accuracy: 0.9128\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.9127\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.2134 - accuracy: 0.9107\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9091\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.2082 - accuracy: 0.9188\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.9318\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2115 - accuracy: 0.9250\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9022\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1993 - accuracy: 0.9245\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9322\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.2069 - accuracy: 0.9379\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9420\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1946 - accuracy: 0.9307\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.1973 - accuracy: 0.9189\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.1837 - accuracy: 0.9240\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.1770 - accuracy: 0.9273\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.1669 - accuracy: 0.9377\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.1609 - accuracy: 0.9456\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1582 - accuracy: 0.9341\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1832 - accuracy: 0.9352\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1600 - accuracy: 0.9505\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1528 - accuracy: 0.9533\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.1517 - accuracy: 0.9438\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.1505 - accuracy: 0.9408\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1658 - accuracy: 0.9445\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1625 - accuracy: 0.9329\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.1291 - accuracy: 0.9611\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.1511 - accuracy: 0.9505\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1676 - accuracy: 0.9366\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1458 - accuracy: 0.9445\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1465 - accuracy: 0.9492\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1550 - accuracy: 0.9563\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.1088 - accuracy: 0.9706\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.1689 - accuracy: 0.9332\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.1210 - accuracy: 0.9496\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1346 - accuracy: 0.9542\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1147 - accuracy: 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.1204 - accuracy: 0.9631\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.1194 - accuracy: 0.9644\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1620 - accuracy: 0.9446\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.1191 - accuracy: 0.9612\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1065 - accuracy: 0.9590\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1303 - accuracy: 0.9534\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1377 - accuracy: 0.9410\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.1842 - accuracy: 0.9162\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1362 - accuracy: 0.9603\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.1263 - accuracy: 0.9500\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1269 - accuracy: 0.9598\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1559 - accuracy: 0.9517\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1374 - accuracy: 0.9528\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1288 - accuracy: 0.9493\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0993 - accuracy: 0.9657\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0790 - accuracy: 0.9780\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.1032 - accuracy: 0.9708\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.1172 - accuracy: 0.9532\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0973 - accuracy: 0.9628\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0781 - accuracy: 0.9767\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.1034 - accuracy: 0.9575\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.1091 - accuracy: 0.9544\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1084 - accuracy: 0.9605\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0840 - accuracy: 0.9646\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0844 - accuracy: 0.9815\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.0766 - accuracy: 0.9785\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0944 - accuracy: 0.9677\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0944 - accuracy: 0.9718\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0846 - accuracy: 0.9696\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0883 - accuracy: 0.9641\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1020 - accuracy: 0.9651\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0961 - accuracy: 0.9649\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0799 - accuracy: 0.9694\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.1114 - accuracy: 0.9517\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1006 - accuracy: 0.9498\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.1064 - accuracy: 0.9701\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.1060 - accuracy: 0.9565\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0860 - accuracy: 0.9697\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0810 - accuracy: 0.9677\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0655 - accuracy: 0.9894\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0783 - accuracy: 0.9689\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0836 - accuracy: 0.9736\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0693 - accuracy: 0.9770\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0819 - accuracy: 0.9729\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0942 - accuracy: 0.9593\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1146 - accuracy: 0.9462\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0858 - accuracy: 0.9667\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0733 - accuracy: 0.9666\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0636 - accuracy: 0.9885\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0826 - accuracy: 0.9721\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0822 - accuracy: 0.9637\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0624 - accuracy: 0.9823\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0677 - accuracy: 0.9727\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0551 - accuracy: 0.9835\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.0635 - accuracy: 0.9789\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0480 - accuracy: 0.9877\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0660 - accuracy: 0.9749\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0555 - accuracy: 0.9858\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0688 - accuracy: 0.9797\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0798 - accuracy: 0.9661\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0762 - accuracy: 0.9703\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0667 - accuracy: 0.9715\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0568 - accuracy: 0.9825\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0990 - accuracy: 0.9699\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1013 - accuracy: 0.9581\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0903 - accuracy: 0.9623\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0801 - accuracy: 0.9670\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0681 - accuracy: 0.9761\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0687 - accuracy: 0.9747\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0757 - accuracy: 0.9707\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0689 - accuracy: 0.9630\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0931 - accuracy: 0.9545\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0473 - accuracy: 0.9859\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0509 - accuracy: 0.9863\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0600 - accuracy: 0.9783\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0553 - accuracy: 0.9828\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0808 - accuracy: 0.9672\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0647 - accuracy: 0.9787\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0557 - accuracy: 0.9834\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 832us/step - loss: 0.0542 - accuracy: 0.9829\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0720 - accuracy: 0.9720\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0622 - accuracy: 0.9766\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0689 - accuracy: 0.9696\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0615 - accuracy: 0.9802\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.0544 - accuracy: 0.9774\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0528 - accuracy: 0.9816\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0438 - accuracy: 0.9891\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0461 - accuracy: 0.9901\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0578 - accuracy: 0.9778\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0446 - accuracy: 0.9843\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0426 - accuracy: 0.9887\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0475 - accuracy: 0.9863\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0562 - accuracy: 0.9695\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0630 - accuracy: 0.9691\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0431 - accuracy: 0.9898\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0492 - accuracy: 0.9752\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0447 - accuracy: 0.9885\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0588 - accuracy: 0.9796\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0509 - accuracy: 0.9769\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0527 - accuracy: 0.9892\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0590 - accuracy: 0.9747\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0458 - accuracy: 0.9840\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0677 - accuracy: 0.9665\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0579 - accuracy: 0.9786\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0337 - accuracy: 0.9855\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0379 - accuracy: 0.9803\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0566 - accuracy: 0.9809\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0364 - accuracy: 0.9907\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0490 - accuracy: 0.9876\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0426 - accuracy: 0.9869\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0480 - accuracy: 0.9863\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0410 - accuracy: 0.9888\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0494 - accuracy: 0.9817\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0677 - accuracy: 0.9759\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0344 - accuracy: 0.9866\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0577 - accuracy: 0.9727\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0539 - accuracy: 0.9821\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0564 - accuracy: 0.9737\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0793 - accuracy: 0.9535\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 834us/step - loss: 0.7198 - accuracy: 0.6747\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 725us/step - loss: 0.5326 - accuracy: 0.7307\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.4808 - accuracy: 0.7910\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.4722 - accuracy: 0.7830\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4575 - accuracy: 0.7898\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.4434 - accuracy: 0.8037\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4373 - accuracy: 0.8190\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.4268 - accuracy: 0.7997\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.4546 - accuracy: 0.7908\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3907 - accuracy: 0.8292\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.4049 - accuracy: 0.8070\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.3577 - accuracy: 0.8639\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.3475 - accuracy: 0.8689\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.3549 - accuracy: 0.8459\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.3249 - accuracy: 0.8543\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.3081 - accuracy: 0.8619\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.3047 - accuracy: 0.8891\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.3127 - accuracy: 0.8689\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.2977 - accuracy: 0.8974\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.3016 - accuracy: 0.8767\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.2726 - accuracy: 0.8987\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.2729 - accuracy: 0.9073\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.2592 - accuracy: 0.8970\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.2997 - accuracy: 0.8843\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.2705 - accuracy: 0.8678\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.2542 - accuracy: 0.9125\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.2376 - accuracy: 0.9150\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.2695 - accuracy: 0.8852\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.2835 - accuracy: 0.8970\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.2314 - accuracy: 0.9004\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.2226 - accuracy: 0.9202\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.2096 - accuracy: 0.9228\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.2146 - accuracy: 0.9305\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.2175 - accuracy: 0.9151\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1982 - accuracy: 0.9236\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.2061 - accuracy: 0.9046\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1679 - accuracy: 0.9445\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1908 - accuracy: 0.9291\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.1853 - accuracy: 0.9280\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1719 - accuracy: 0.9441\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1869 - accuracy: 0.9274\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1787 - accuracy: 0.9426\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.1499 - accuracy: 0.9543\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1788 - accuracy: 0.9293\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.1710 - accuracy: 0.9349\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.1513 - accuracy: 0.9555\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.1617 - accuracy: 0.9238\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1432 - accuracy: 0.9560\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.1266 - accuracy: 0.9539\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1317 - accuracy: 0.9730\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.1317 - accuracy: 0.9487\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1429 - accuracy: 0.9521\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1398 - accuracy: 0.9481\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.1366 - accuracy: 0.9460\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1572 - accuracy: 0.9430\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1194 - accuracy: 0.9674\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1090 - accuracy: 0.9664\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1216 - accuracy: 0.9689\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1134 - accuracy: 0.9651\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1149 - accuracy: 0.9641\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1043 - accuracy: 0.9737\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1018 - accuracy: 0.9642\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1008 - accuracy: 0.9629\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1021 - accuracy: 0.9599\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0967 - accuracy: 0.9780\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1001 - accuracy: 0.9728\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.1282 - accuracy: 0.9468\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0900 - accuracy: 0.9699\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1525 - accuracy: 0.9449\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1045 - accuracy: 0.9691\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0731 - accuracy: 0.9746\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.1186 - accuracy: 0.9661\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0955 - accuracy: 0.9655\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0936 - accuracy: 0.9559\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.1000 - accuracy: 0.9636\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0987 - accuracy: 0.9714\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0860 - accuracy: 0.9701\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.0914 - accuracy: 0.9696\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.0907 - accuracy: 0.9703\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0760 - accuracy: 0.9820\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 832us/step - loss: 0.0777 - accuracy: 0.9744\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0871 - accuracy: 0.9663\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0850 - accuracy: 0.9774\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0779 - accuracy: 0.9717\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0695 - accuracy: 0.9840\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0777 - accuracy: 0.9749\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0839 - accuracy: 0.9701\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0733 - accuracy: 0.9756\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0728 - accuracy: 0.9820\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0925 - accuracy: 0.9681\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0600 - accuracy: 0.9873\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0628 - accuracy: 0.9770\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0505 - accuracy: 0.9889\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0666 - accuracy: 0.9847\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0630 - accuracy: 0.9868\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0628 - accuracy: 0.9771\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0605 - accuracy: 0.9840\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0552 - accuracy: 0.9840\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0559 - accuracy: 0.9851\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0640 - accuracy: 0.9750\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0520 - accuracy: 0.9876\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0576 - accuracy: 0.9906\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0429 - accuracy: 0.9911\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0561 - accuracy: 0.9814\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0541 - accuracy: 0.9866\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0640 - accuracy: 0.9828\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0546 - accuracy: 0.9777\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0607 - accuracy: 0.9779\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9902\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9873\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9817\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9836\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0440 - accuracy: 0.9883\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0639 - accuracy: 0.9773\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9777\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9854\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9766\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9909\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9736\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0540 - accuracy: 0.9830\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0588 - accuracy: 0.9747\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0441 - accuracy: 0.9846\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0405 - accuracy: 0.9876\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.0479 - accuracy: 0.9799\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0449 - accuracy: 0.9865\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0468 - accuracy: 0.9833\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0506 - accuracy: 0.9841\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0324 - accuracy: 0.9951\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0503 - accuracy: 0.9919\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0404 - accuracy: 0.9914\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0532 - accuracy: 0.9835\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0479 - accuracy: 0.9754\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0393 - accuracy: 0.9918\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0442 - accuracy: 0.9909\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0300 - accuracy: 0.9927\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0332 - accuracy: 0.9899\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0455 - accuracy: 0.9826\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0377 - accuracy: 0.9865\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9754\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9897\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9916\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9924\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9847\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9926\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9911\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9910\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9919\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.0167 - accuracy: 0.9985\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9926\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9788\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0349 - accuracy: 0.9887\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9863\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9893\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9834\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0656 - accuracy: 0.9778\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9677\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9809\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9892\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9873\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9905\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9939\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0386 - accuracy: 0.9874\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9906\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9980\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9958\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0226 - accuracy: 0.9909\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9645\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9813\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9888\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9826\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9801\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9933\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9853\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9989\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9908\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9851\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9897\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9817\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0346 - accuracy: 0.9924\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9955\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9952\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9836\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9976\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.0190 - accuracy: 0.9959\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9886\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9833\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9943\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0233 - accuracy: 0.9932\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9852\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0291 - accuracy: 0.9939\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0292 - accuracy: 0.9851\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0684 - accuracy: 0.9781\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0463 - accuracy: 0.9803\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0212 - accuracy: 0.9970\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0254 - accuracy: 0.9945\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0186 - accuracy: 0.9958\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0275 - accuracy: 0.9882\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0180 - accuracy: 0.9944\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 809us/step - loss: 0.8524 - accuracy: 0.5837\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 773us/step - loss: 0.5601 - accuracy: 0.7427\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.5210 - accuracy: 0.7409\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.5085 - accuracy: 0.7614\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7601\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.4595 - accuracy: 0.7803\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8010\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.4332 - accuracy: 0.8169\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.8036\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8196\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8192\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8486\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8477\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8620\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8551\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8588\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8726\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8795\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.8952\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8641\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.8815\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.8953\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.9015\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.8947\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2522 - accuracy: 0.9231\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.8933\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9070\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.9194\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.2210 - accuracy: 0.9244\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.9131\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.2230 - accuracy: 0.9380\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.2233 - accuracy: 0.9253\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.9058\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.2060 - accuracy: 0.9385\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.1814 - accuracy: 0.9377\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.2335 - accuracy: 0.9043\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9434\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.2147 - accuracy: 0.9160\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.2459 - accuracy: 0.8948\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1855 - accuracy: 0.9216\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.1825 - accuracy: 0.9505\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1557 - accuracy: 0.9474\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.1660 - accuracy: 0.9544\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9610\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9495\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.9458\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9580\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9606\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9568\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9565\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9420\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9656\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9697\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9484\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9614\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9578\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9645\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9539\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.9700\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9682\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9672\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9711\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9629\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.9693\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9747\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9653\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9589\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9679\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9687\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.1149 - accuracy: 0.9620\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1149 - accuracy: 0.9586\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.1133 - accuracy: 0.9567\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0889 - accuracy: 0.9769\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0813 - accuracy: 0.9786\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0782 - accuracy: 0.9874\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0962 - accuracy: 0.9617\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0826 - accuracy: 0.9752\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0898 - accuracy: 0.9630\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 782us/step - loss: 0.0941 - accuracy: 0.9679\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.0805 - accuracy: 0.9809\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0956 - accuracy: 0.9684\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 793us/step - loss: 0.0779 - accuracy: 0.9748\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0748 - accuracy: 0.9828\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 775us/step - loss: 0.0745 - accuracy: 0.9751\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0701 - accuracy: 0.9822\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0760 - accuracy: 0.9746\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.0585 - accuracy: 0.9912\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0906 - accuracy: 0.9660\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0675 - accuracy: 0.9778\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0602 - accuracy: 0.9795\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0714 - accuracy: 0.9756\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0720 - accuracy: 0.9775\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0682 - accuracy: 0.9847\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0764 - accuracy: 0.9704\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0706 - accuracy: 0.9775\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0603 - accuracy: 0.9806\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0724 - accuracy: 0.9829\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0669 - accuracy: 0.9867\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0637 - accuracy: 0.9804\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0654 - accuracy: 0.9753\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0792 - accuracy: 0.9694\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0573 - accuracy: 0.9886\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.0751 - accuracy: 0.9712\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 776us/step - loss: 0.0569 - accuracy: 0.9727\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.0618 - accuracy: 0.9797\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 753us/step - loss: 0.0687 - accuracy: 0.9743\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 792us/step - loss: 0.0676 - accuracy: 0.9762\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0588 - accuracy: 0.9836\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9812\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0535 - accuracy: 0.9771\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0544 - accuracy: 0.9899\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0623 - accuracy: 0.9838\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0400 - accuracy: 0.9929\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0758 - accuracy: 0.9837\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0539 - accuracy: 0.9827\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1031 - accuracy: 0.9643\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0885 - accuracy: 0.9748\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0791 - accuracy: 0.9783\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0628 - accuracy: 0.9843\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0683 - accuracy: 0.9705\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0509 - accuracy: 0.9871\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0785 - accuracy: 0.9731\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0626 - accuracy: 0.9776\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0791 - accuracy: 0.9778\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0347 - accuracy: 0.9882\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0362 - accuracy: 0.9951\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0528 - accuracy: 0.9829\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 788us/step - loss: 0.0492 - accuracy: 0.9874\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 747us/step - loss: 0.0354 - accuracy: 0.9950\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0590 - accuracy: 0.9848\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0486 - accuracy: 0.9823\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0620 - accuracy: 0.9831\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0513 - accuracy: 0.9812\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0369 - accuracy: 0.9894\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0382 - accuracy: 0.9840\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0543 - accuracy: 0.9847\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0407 - accuracy: 0.9875\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0397 - accuracy: 0.9889\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.0436 - accuracy: 0.9870\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0757 - accuracy: 0.9679\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0465 - accuracy: 0.9870\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 791us/step - loss: 0.0296 - accuracy: 0.9922\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.0407 - accuracy: 0.9948\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 775us/step - loss: 0.0302 - accuracy: 0.9946\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 781us/step - loss: 0.0484 - accuracy: 0.9834\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 774us/step - loss: 0.0402 - accuracy: 0.9870\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0390 - accuracy: 0.9877\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0396 - accuracy: 0.9901\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0358 - accuracy: 0.9890\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0475 - accuracy: 0.9868\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 786us/step - loss: 0.0409 - accuracy: 0.9881\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 777us/step - loss: 0.0451 - accuracy: 0.9847\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 764us/step - loss: 0.0751 - accuracy: 0.9637\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 778us/step - loss: 0.0718 - accuracy: 0.9725\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0498 - accuracy: 0.9862\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0468 - accuracy: 0.9807\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0592 - accuracy: 0.9771\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.0514 - accuracy: 0.9822\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 792us/step - loss: 0.0385 - accuracy: 0.9889\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 795us/step - loss: 0.0275 - accuracy: 0.9907\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 781us/step - loss: 0.0335 - accuracy: 0.9886\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.0237 - accuracy: 0.9963\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.0311 - accuracy: 0.9939\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0324 - accuracy: 0.9903\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0273 - accuracy: 0.9921\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0422 - accuracy: 0.9879\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0312 - accuracy: 0.9882\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0264 - accuracy: 0.9924\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0377 - accuracy: 0.9829\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0397 - accuracy: 0.9910\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0412 - accuracy: 0.9875\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0537 - accuracy: 0.9822\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0486 - accuracy: 0.9813\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0421 - accuracy: 0.9914\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1274 - accuracy: 0.9485\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1041 - accuracy: 0.9661\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0823 - accuracy: 0.9722\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0449 - accuracy: 0.9857\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0525 - accuracy: 0.9794\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0663 - accuracy: 0.9767\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1088 - accuracy: 0.9679\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0868 - accuracy: 0.9691\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0738 - accuracy: 0.9705\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0978 - accuracy: 0.9697\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0522 - accuracy: 0.9734\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0669 - accuracy: 0.9767\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0628 - accuracy: 0.9761\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0519 - accuracy: 0.9792\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0609 - accuracy: 0.9723\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0423 - accuracy: 0.9865\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0543 - accuracy: 0.9876\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0686 - accuracy: 0.9750\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0552 - accuracy: 0.9780\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0420 - accuracy: 0.9859\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0719 - accuracy: 0.9696\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0649 - accuracy: 0.9738\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0679 - accuracy: 0.9701\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0211 - accuracy: 0.9955\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0422 - accuracy: 0.9882\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0497 - accuracy: 0.9817\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 839us/step - loss: 0.7762 - accuracy: 0.5932\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 742us/step - loss: 0.5624 - accuracy: 0.7295\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.4922 - accuracy: 0.7732\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.4901 - accuracy: 0.7784\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.4794 - accuracy: 0.7854\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.4558 - accuracy: 0.7931\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.4509 - accuracy: 0.7831\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.4341 - accuracy: 0.8112\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.4244 - accuracy: 0.7935\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8366\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.3760 - accuracy: 0.8442\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.3920 - accuracy: 0.8368\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8398\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8336\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8348\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.3414 - accuracy: 0.8567\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8774\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3432 - accuracy: 0.8509\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8903\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8794\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8849\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.9030\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.2960 - accuracy: 0.8773\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.8943\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8814\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2905 - accuracy: 0.8704\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8841\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.9052\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.8951\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9072\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.8878\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9310\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9312\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9310\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9211\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.2016 - accuracy: 0.9260\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.9447\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.2006 - accuracy: 0.9326\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.9015\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.2176 - accuracy: 0.9229\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.9174\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9397\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9429\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9385\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.1976 - accuracy: 0.9315\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9402\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.9470\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.9332\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9458\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9333\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9487\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1580 - accuracy: 0.9355\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9451\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9650\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.1384 - accuracy: 0.9566\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9598\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.9543\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9510\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9591\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9608\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9687\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9677\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1115 - accuracy: 0.9690\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9558\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.1257 - accuracy: 0.9605\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1308 - accuracy: 0.9556\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9570\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.0977 - accuracy: 0.9773\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9650\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9704\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.9720\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9546\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9607\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9668\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9698\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9817\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9725\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9706\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9716\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9792\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9736\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9820\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9702\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9818\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9662\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9863\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.0956 - accuracy: 0.9644\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9681\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9842\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9807\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9807\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9542\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0819 - accuracy: 0.9708\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9841\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0728 - accuracy: 0.9764\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9776\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0814 - accuracy: 0.9681\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0584 - accuracy: 0.9836\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0582 - accuracy: 0.9831\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0617 - accuracy: 0.9784\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0521 - accuracy: 0.9850\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0818 - accuracy: 0.9767\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0619 - accuracy: 0.9712\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0580 - accuracy: 0.9836\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0805 - accuracy: 0.9836\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0647 - accuracy: 0.9833\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1077 - accuracy: 0.9618\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0637 - accuracy: 0.9782\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0591 - accuracy: 0.9810\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0674 - accuracy: 0.9772\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0798 - accuracy: 0.9686\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0639 - accuracy: 0.9803\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0579 - accuracy: 0.9813\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9777\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9853\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9803\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9891\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0611 - accuracy: 0.9838\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9816\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9890\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9854\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0614 - accuracy: 0.9796\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0468 - accuracy: 0.9867\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0616 - accuracy: 0.9878\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9935\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0537 - accuracy: 0.9883\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0643 - accuracy: 0.9861\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0491 - accuracy: 0.9874\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0629 - accuracy: 0.9724\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0697 - accuracy: 0.9810\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0860 - accuracy: 0.9701\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0647 - accuracy: 0.9744\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0494 - accuracy: 0.9865\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9731\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9611\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9833\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9759\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9740\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.9673\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 979us/step - loss: 0.1011 - accuracy: 0.9509\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9496\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9647\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9681\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9685\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9757\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9765\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9740\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9840\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9823\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9833\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9777\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9912\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0808 - accuracy: 0.9702\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0578 - accuracy: 0.9795\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9747\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9829\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9789\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9879\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9812\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9818\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9812\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9814\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9877\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9907\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0350 - accuracy: 0.9911\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9904\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9906\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9843\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9905\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9793\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0492 - accuracy: 0.9882\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9896\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9923\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9857\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9896\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9912\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9667\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0591 - accuracy: 0.9787\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9865\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9840\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0401 - accuracy: 0.9902\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9940\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9890\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9865\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9962\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9824\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9902\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9822\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9839\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9836\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9949\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9844\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9964\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9942\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9905\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9739\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0663 - accuracy: 0.9856\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9800\n",
      "WARNING:tensorflow:5 out of the last 80 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c78cd7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.6772 - accuracy: 0.6452\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.5048 - accuracy: 0.7675\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.4790 - accuracy: 0.7789\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.5035 - accuracy: 0.7566\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4561 - accuracy: 0.7936\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.4244 - accuracy: 0.8055\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.4200 - accuracy: 0.8112\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.3985 - accuracy: 0.8180\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.4312 - accuracy: 0.8088\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.4007 - accuracy: 0.8279\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.3713 - accuracy: 0.8150\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.3735 - accuracy: 0.8421\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.3779 - accuracy: 0.8303\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.3453 - accuracy: 0.8462\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.3071 - accuracy: 0.8710\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.3346 - accuracy: 0.8540\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.3601 - accuracy: 0.8542\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.3124 - accuracy: 0.8800\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.3174 - accuracy: 0.8624\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.3267 - accuracy: 0.8536\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.3159 - accuracy: 0.8696\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.3037 - accuracy: 0.8803\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.2678 - accuracy: 0.8836\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.2853 - accuracy: 0.8827\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.2971 - accuracy: 0.8699\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.2864 - accuracy: 0.8889\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.2309 - accuracy: 0.9102\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.2958 - accuracy: 0.8679\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.2590 - accuracy: 0.8921\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.2522 - accuracy: 0.8951\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.2340 - accuracy: 0.9083\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.2676 - accuracy: 0.8818\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.2284 - accuracy: 0.9091\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.2264 - accuracy: 0.8962\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.2276 - accuracy: 0.9093\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.2227 - accuracy: 0.9019\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.2164 - accuracy: 0.9262\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1916 - accuracy: 0.9247\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1852 - accuracy: 0.9292\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1814 - accuracy: 0.9302\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1929 - accuracy: 0.9223\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1969 - accuracy: 0.9201\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1839 - accuracy: 0.9278\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1659 - accuracy: 0.9418\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1606 - accuracy: 0.9492\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.1860 - accuracy: 0.9320\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1878 - accuracy: 0.9252\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1623 - accuracy: 0.9416\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1379 - accuracy: 0.9680\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.1638 - accuracy: 0.9515\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1464 - accuracy: 0.9595\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.1545 - accuracy: 0.9448\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1818 - accuracy: 0.9201\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1401 - accuracy: 0.9428\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.1316 - accuracy: 0.9578\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1164 - accuracy: 0.9646\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1359 - accuracy: 0.9432\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1252 - accuracy: 0.9535\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1312 - accuracy: 0.9563\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1493 - accuracy: 0.9430\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1215 - accuracy: 0.9623\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1107 - accuracy: 0.9711\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1024 - accuracy: 0.9791\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0993 - accuracy: 0.9737\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1126 - accuracy: 0.9557\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1080 - accuracy: 0.9584\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1199 - accuracy: 0.9583\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.1421 - accuracy: 0.9415\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1050 - accuracy: 0.9619\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.1159 - accuracy: 0.9629\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.0781 - accuracy: 0.9766\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0938 - accuracy: 0.9723\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0917 - accuracy: 0.9753\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0974 - accuracy: 0.9625\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0973 - accuracy: 0.9758\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1006 - accuracy: 0.9696\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0955 - accuracy: 0.9682\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 793us/step - loss: 0.0940 - accuracy: 0.9674\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.0839 - accuracy: 0.9703\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0974 - accuracy: 0.9610\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 799us/step - loss: 0.0944 - accuracy: 0.9704\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0919 - accuracy: 0.9736\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 791us/step - loss: 0.0831 - accuracy: 0.9711\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0810 - accuracy: 0.9752\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0952 - accuracy: 0.9724\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0925 - accuracy: 0.9759\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0881 - accuracy: 0.9618\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0677 - accuracy: 0.9769\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0796 - accuracy: 0.9721\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0735 - accuracy: 0.9841\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0760 - accuracy: 0.9820\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0800 - accuracy: 0.9659\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0786 - accuracy: 0.9722\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0782 - accuracy: 0.9849\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0581 - accuracy: 0.9801\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0663 - accuracy: 0.9722\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0569 - accuracy: 0.9857\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0735 - accuracy: 0.9765\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0638 - accuracy: 0.9816\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0471 - accuracy: 0.9929\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0592 - accuracy: 0.9837\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0680 - accuracy: 0.9792\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0706 - accuracy: 0.9792\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0753 - accuracy: 0.9704\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0693 - accuracy: 0.9771\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0707 - accuracy: 0.9750\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0665 - accuracy: 0.9908\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0610 - accuracy: 0.9852\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0516 - accuracy: 0.9852\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0635 - accuracy: 0.9874\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0705 - accuracy: 0.9784\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0731 - accuracy: 0.9726\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0755 - accuracy: 0.9748\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0938 - accuracy: 0.9623\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0820 - accuracy: 0.9695\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0474 - accuracy: 0.9882\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0707 - accuracy: 0.9699\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0641 - accuracy: 0.9844\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0606 - accuracy: 0.9844\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0645 - accuracy: 0.9859\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9809\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9781\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9804\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9959\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9893\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0716 - accuracy: 0.9704\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9933\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9897\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9906\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9941\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9858\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9945\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9923\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9918\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9884\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9911\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9869\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0680 - accuracy: 0.9726\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9812\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9894\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9884\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9834\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9822\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9892\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0429 - accuracy: 0.9832\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0437 - accuracy: 0.9902\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9784\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9881\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9812\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9884\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9826\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9926\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9853\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9881\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0415 - accuracy: 0.9874\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9910\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9885\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9897\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.0274 - accuracy: 0.9963\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9983\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9875\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9978\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9820\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9843\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9880\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9940\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9952\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9830\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9889\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9891\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9794\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9848\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0457 - accuracy: 0.9783\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9867\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0235 - accuracy: 0.9885\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0358 - accuracy: 0.9827\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9959\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9863\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.0220 - accuracy: 0.9963\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.0247 - accuracy: 0.9987\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9933\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9767\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9806\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0632 - accuracy: 0.9707\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9852\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9795\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9688\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9783\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9839\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9785\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9822\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9970\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9828\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9964\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9820\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9897\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9858\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9834\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9865\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9832\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c79796af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9670 - accuracy: 0.5651\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.7341\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7142\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7445\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.7369\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7814\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7609\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8090\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8062\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8196\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8121\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4038 - accuracy: 0.8270\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8351\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8308\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8407\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8197\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.8371\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8562\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8483\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8731\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8479\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8560\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8931\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8598\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8583\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8847\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2882 - accuracy: 0.8861\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8860\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.3090 - accuracy: 0.8871\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.8798\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.3243 - accuracy: 0.8656\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.2970 - accuracy: 0.8867\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.3018 - accuracy: 0.8568\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.2453 - accuracy: 0.8935\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.2932 - accuracy: 0.8928\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.2915 - accuracy: 0.8702\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.2687 - accuracy: 0.9002\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.2509 - accuracy: 0.9090\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.2569 - accuracy: 0.8909\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.2195 - accuracy: 0.9140\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.2668 - accuracy: 0.8951\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.2405 - accuracy: 0.9051\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.1817 - accuracy: 0.9586\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.2256 - accuracy: 0.9142\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.2568 - accuracy: 0.9041\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.2458 - accuracy: 0.9112\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.1866 - accuracy: 0.9267\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.2195 - accuracy: 0.9191\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.2217 - accuracy: 0.9150\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.2048 - accuracy: 0.9216\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.3059 - accuracy: 0.8703\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2301 - accuracy: 0.9210\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1923 - accuracy: 0.9386\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1788 - accuracy: 0.9418\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1929 - accuracy: 0.9218\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1765 - accuracy: 0.9416\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.2005 - accuracy: 0.9231\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.1528 - accuracy: 0.9490\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1633 - accuracy: 0.9482\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1601 - accuracy: 0.9448\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1690 - accuracy: 0.9499\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 779us/step - loss: 0.1629 - accuracy: 0.9488\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.1821 - accuracy: 0.9408\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.1458 - accuracy: 0.9589\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.1449 - accuracy: 0.9608\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1511 - accuracy: 0.9469\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1267 - accuracy: 0.9630\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1315 - accuracy: 0.9642\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1578 - accuracy: 0.9544\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.1905 - accuracy: 0.9225\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1369 - accuracy: 0.9589\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 787us/step - loss: 0.1507 - accuracy: 0.9433\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.1312 - accuracy: 0.9603\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.1214 - accuracy: 0.9532\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1131 - accuracy: 0.9599\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1467 - accuracy: 0.9639\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 784us/step - loss: 0.1513 - accuracy: 0.9464\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1336 - accuracy: 0.9488\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 764us/step - loss: 0.1127 - accuracy: 0.9635\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1369 - accuracy: 0.9639\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.1119 - accuracy: 0.9574\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 812us/step - loss: 0.1250 - accuracy: 0.9670\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.1299 - accuracy: 0.9513\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 758us/step - loss: 0.1308 - accuracy: 0.9606\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0772 - accuracy: 0.9851\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1071 - accuracy: 0.9698\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1113 - accuracy: 0.9701\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1245 - accuracy: 0.9648\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1131 - accuracy: 0.9672\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0996 - accuracy: 0.9720\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1052 - accuracy: 0.9669\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0989 - accuracy: 0.9693\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1518 - accuracy: 0.9503\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1135 - accuracy: 0.9592\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.1097 - accuracy: 0.9604\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1070 - accuracy: 0.9637\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1048 - accuracy: 0.9600\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1125 - accuracy: 0.9663\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1081 - accuracy: 0.9728\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1146 - accuracy: 0.9681\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1013 - accuracy: 0.9708\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1161 - accuracy: 0.9573\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0892 - accuracy: 0.9744\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1000 - accuracy: 0.9567\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0775 - accuracy: 0.9772\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0878 - accuracy: 0.9662\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0898 - accuracy: 0.9732\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0936 - accuracy: 0.9697\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1017 - accuracy: 0.9708\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0960 - accuracy: 0.9609\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0967 - accuracy: 0.9693\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0949 - accuracy: 0.9744\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0873 - accuracy: 0.9677\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0808 - accuracy: 0.9707\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0930 - accuracy: 0.9714\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0742 - accuracy: 0.9815\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1189 - accuracy: 0.9630\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1198 - accuracy: 0.9592\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0835 - accuracy: 0.9788\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0784 - accuracy: 0.9750\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0740 - accuracy: 0.9755\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0785 - accuracy: 0.9687\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0763 - accuracy: 0.9820\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0763 - accuracy: 0.9801\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0641 - accuracy: 0.9796\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0549 - accuracy: 0.9819\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.0912 - accuracy: 0.9724\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1424 - accuracy: 0.9548\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0789 - accuracy: 0.9767\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0753 - accuracy: 0.9804\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0772 - accuracy: 0.9711\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0729 - accuracy: 0.9738\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0574 - accuracy: 0.9868\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0793 - accuracy: 0.9773\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0593 - accuracy: 0.9783\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0689 - accuracy: 0.9796\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0502 - accuracy: 0.9864\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0490 - accuracy: 0.9859\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.0756 - accuracy: 0.9683\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0627 - accuracy: 0.9830\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0592 - accuracy: 0.9807\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0580 - accuracy: 0.9828\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0547 - accuracy: 0.9793\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0571 - accuracy: 0.9804\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0579 - accuracy: 0.9798\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0756 - accuracy: 0.9674\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0576 - accuracy: 0.9787\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0831 - accuracy: 0.9773\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.0912 - accuracy: 0.9632\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0544 - accuracy: 0.9831\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0623 - accuracy: 0.9785\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.0742 - accuracy: 0.9744\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0395 - accuracy: 0.9874\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 769us/step - loss: 0.0696 - accuracy: 0.9776\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0680 - accuracy: 0.9684\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0498 - accuracy: 0.9903\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.0668 - accuracy: 0.9795\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0537 - accuracy: 0.9877\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.0614 - accuracy: 0.9787\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.0696 - accuracy: 0.9777\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 805us/step - loss: 0.0549 - accuracy: 0.9833\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.0678 - accuracy: 0.9756\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0677 - accuracy: 0.9739\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0662 - accuracy: 0.9793\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0534 - accuracy: 0.9868\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0666 - accuracy: 0.9759\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1790 - accuracy: 0.9279\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1004 - accuracy: 0.9675\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.1207 - accuracy: 0.9483\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.1196 - accuracy: 0.9545\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1114 - accuracy: 0.9561\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0956 - accuracy: 0.9703\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0974 - accuracy: 0.9739\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0616 - accuracy: 0.9802\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0815 - accuracy: 0.9802\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0835 - accuracy: 0.9718\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0817 - accuracy: 0.9750\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0835 - accuracy: 0.9735\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0613 - accuracy: 0.9892\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0819 - accuracy: 0.9731\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0791 - accuracy: 0.9690\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0943 - accuracy: 0.9701\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0617 - accuracy: 0.9797\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0872 - accuracy: 0.9715\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0932 - accuracy: 0.9771\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0893 - accuracy: 0.9666\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0706 - accuracy: 0.9772\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0869 - accuracy: 0.9726\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0677 - accuracy: 0.9861\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1087 - accuracy: 0.9613\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1507 - accuracy: 0.9528\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1364 - accuracy: 0.9535\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1214 - accuracy: 0.9656\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0798 - accuracy: 0.9657\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0736 - accuracy: 0.9781\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0834 - accuracy: 0.9745\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0801 - accuracy: 0.9728\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0643 - accuracy: 0.9815\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0712 - accuracy: 0.9795\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0513 - accuracy: 0.9836\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c780c5ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 798us/step - loss: 0.6495 - accuracy: 0.7050\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 754us/step - loss: 0.5038 - accuracy: 0.7723\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.4782 - accuracy: 0.7850\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.4748 - accuracy: 0.7890\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4787 - accuracy: 0.7786\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.4041 - accuracy: 0.8285\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.4353 - accuracy: 0.8223\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.4162 - accuracy: 0.8177\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.3867 - accuracy: 0.8495\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.3782 - accuracy: 0.8353\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.3645 - accuracy: 0.8366\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.3603 - accuracy: 0.8585\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.3594 - accuracy: 0.8479\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.3475 - accuracy: 0.8458\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.3354 - accuracy: 0.8742\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.3687 - accuracy: 0.8478\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.3253 - accuracy: 0.8631\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.3130 - accuracy: 0.8746\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.2956 - accuracy: 0.8817\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.2943 - accuracy: 0.8899\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.2929 - accuracy: 0.8781\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2691 - accuracy: 0.8985\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.2702 - accuracy: 0.8971\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.2792 - accuracy: 0.8893\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.2672 - accuracy: 0.8947\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.2480 - accuracy: 0.8966\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.2611 - accuracy: 0.8969\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.2159 - accuracy: 0.9266\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.2205 - accuracy: 0.9077\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.2219 - accuracy: 0.9339\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.2117 - accuracy: 0.9105\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.2171 - accuracy: 0.9129\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.2556 - accuracy: 0.9100\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1832 - accuracy: 0.9498\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.1993 - accuracy: 0.9236\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1873 - accuracy: 0.9250\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1841 - accuracy: 0.9426\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.1938 - accuracy: 0.9379\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1788 - accuracy: 0.9454\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1770 - accuracy: 0.9394\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.2002 - accuracy: 0.9313\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.2015 - accuracy: 0.9304\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1808 - accuracy: 0.9346\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.1475 - accuracy: 0.9431\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1592 - accuracy: 0.9515\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1496 - accuracy: 0.9603\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1434 - accuracy: 0.9527\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1480 - accuracy: 0.9442\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1390 - accuracy: 0.9568\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1340 - accuracy: 0.9584\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1297 - accuracy: 0.9673\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1484 - accuracy: 0.9529\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1576 - accuracy: 0.9448\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1529 - accuracy: 0.9648\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1155 - accuracy: 0.9713\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1099 - accuracy: 0.9598\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1376 - accuracy: 0.9487\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1133 - accuracy: 0.9568\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.1257 - accuracy: 0.9484\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1278 - accuracy: 0.9556\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.0955 - accuracy: 0.9676\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1141 - accuracy: 0.9541\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1132 - accuracy: 0.9543\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.1101 - accuracy: 0.9605\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1037 - accuracy: 0.9642\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1039 - accuracy: 0.9577\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.1098 - accuracy: 0.9639\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0950 - accuracy: 0.9688\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0667 - accuracy: 0.9849\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0769 - accuracy: 0.9817\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.1201 - accuracy: 0.9539\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.0975 - accuracy: 0.9592\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0949 - accuracy: 0.9626\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1040 - accuracy: 0.9773\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0966 - accuracy: 0.9629\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1012 - accuracy: 0.9657\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.1174 - accuracy: 0.9677\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0873 - accuracy: 0.9772\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0860 - accuracy: 0.9759\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9843\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9723\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9774\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9766\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.9790\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9421\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9774\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9758\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9680\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9753\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9757\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9651\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9886\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9836\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9697\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9610\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9806\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9830\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0674 - accuracy: 0.9855\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9880\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9708\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9734\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9948\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9799\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9835\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9908\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9758\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9890\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9887\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9729\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9834\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9886\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9872\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9592\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0777 - accuracy: 0.9632\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9698\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0627 - accuracy: 0.9764\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0639 - accuracy: 0.9787\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9794\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9803\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9822\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9794\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9736\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9842\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0427 - accuracy: 0.9853\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0407 - accuracy: 0.9901\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9898\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0313 - accuracy: 0.9962\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0399 - accuracy: 0.9902\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0399 - accuracy: 0.9892\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0558 - accuracy: 0.9754\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0388 - accuracy: 0.9913\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0352 - accuracy: 0.9927\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0482 - accuracy: 0.9836\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0365 - accuracy: 0.9885\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0788 - accuracy: 0.9672\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0436 - accuracy: 0.9938\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0558 - accuracy: 0.9801\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0569 - accuracy: 0.9829\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0387 - accuracy: 0.9896\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9838\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0356 - accuracy: 0.9898\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9930\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9904\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9841\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.0338 - accuracy: 0.9902\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9966\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0255 - accuracy: 0.9929\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0436 - accuracy: 0.9872\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0250 - accuracy: 0.9925\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0404 - accuracy: 0.9848\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0396 - accuracy: 0.9945\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0427 - accuracy: 0.9915\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0321 - accuracy: 0.9943\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0448 - accuracy: 0.9838\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0408 - accuracy: 0.9846\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9963\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9943\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9910\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9833\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9816\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9795\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9920\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9861\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9927\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9907\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9951\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9856\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9922\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9934\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9929\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9899\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9939\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9923\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.0381 - accuracy: 0.9918\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.0157 - accuracy: 0.9998\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9817\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9679\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9898\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0236 - accuracy: 0.9938\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0256 - accuracy: 0.9938\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9872\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.0274 - accuracy: 0.9929\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9761\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0328 - accuracy: 0.9916\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.0269 - accuracy: 0.9899\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0185 - accuracy: 0.9940\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0248 - accuracy: 0.9925\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0203 - accuracy: 0.9918\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0330 - accuracy: 0.9853\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0227 - accuracy: 0.9940\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0281 - accuracy: 0.9887\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0189 - accuracy: 0.9914\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.0242 - accuracy: 0.9930\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0253 - accuracy: 0.9934\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0393 - accuracy: 0.9942\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0575 - accuracy: 0.9717\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0392 - accuracy: 0.9850\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0630 - accuracy: 0.9693\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0500 - accuracy: 0.9839\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c780c5790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 872us/step - loss: 0.7234 - accuracy: 0.6355\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.5099 - accuracy: 0.7600\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.5386 - accuracy: 0.7358\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.5193 - accuracy: 0.7649\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7717\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.4613 - accuracy: 0.7794\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.4241 - accuracy: 0.8149\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.4603 - accuracy: 0.7824\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.4339 - accuracy: 0.7973\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.4221 - accuracy: 0.7943\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.4176 - accuracy: 0.8114\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.4077 - accuracy: 0.8149\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4106 - accuracy: 0.8327\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.3619 - accuracy: 0.8407\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.3555 - accuracy: 0.8649\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.3726 - accuracy: 0.8483\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3562 - accuracy: 0.8451\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.3539 - accuracy: 0.8537\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.3779 - accuracy: 0.8425\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.3693 - accuracy: 0.8529\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3113 - accuracy: 0.8734\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8674\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.3317 - accuracy: 0.8542\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.2973 - accuracy: 0.8703\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.3014 - accuracy: 0.8885\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.3078 - accuracy: 0.8783\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.3130 - accuracy: 0.8641\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2729 - accuracy: 0.8968\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.2681 - accuracy: 0.9061\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.2803 - accuracy: 0.8758\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.2767 - accuracy: 0.8919\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.2690 - accuracy: 0.8989\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.2680 - accuracy: 0.8946\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.2280 - accuracy: 0.9184\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.2992 - accuracy: 0.8773\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.2370 - accuracy: 0.9023\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.2758 - accuracy: 0.8739\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.2848 - accuracy: 0.8857\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.2373 - accuracy: 0.9023\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.2505 - accuracy: 0.8915\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.2303 - accuracy: 0.9137\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.2250 - accuracy: 0.8957\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1971 - accuracy: 0.9401\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.2013 - accuracy: 0.9205\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.1719 - accuracy: 0.9424\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1998 - accuracy: 0.9330\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1976 - accuracy: 0.9355\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.2028 - accuracy: 0.9154\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.2011 - accuracy: 0.9198\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.1780 - accuracy: 0.9402\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.1715 - accuracy: 0.9416\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.1683 - accuracy: 0.9506\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.1498 - accuracy: 0.9464\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1717 - accuracy: 0.9374\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1570 - accuracy: 0.9524\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.1679 - accuracy: 0.9476\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1780 - accuracy: 0.9348\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.1641 - accuracy: 0.9430\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1879 - accuracy: 0.9299\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.1611 - accuracy: 0.9477\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1208 - accuracy: 0.9583\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1712 - accuracy: 0.9392\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.1515 - accuracy: 0.9516\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.1653 - accuracy: 0.9319\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.1279 - accuracy: 0.9622\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1488 - accuracy: 0.9479\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1363 - accuracy: 0.9534\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1084 - accuracy: 0.9592\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.1075 - accuracy: 0.9675\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.1241 - accuracy: 0.9566\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1164 - accuracy: 0.9628\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.1273 - accuracy: 0.9510\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1156 - accuracy: 0.9748\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1565 - accuracy: 0.9368\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1096 - accuracy: 0.9588\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1256 - accuracy: 0.9494\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.1102 - accuracy: 0.9670\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1038 - accuracy: 0.9672\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1111 - accuracy: 0.9665\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1122 - accuracy: 0.9613\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 953us/step - loss: 0.1154 - accuracy: 0.9662\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0954 - accuracy: 0.9769\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0993 - accuracy: 0.9733\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.1267 - accuracy: 0.9587\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.1023 - accuracy: 0.9692\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0854 - accuracy: 0.9757\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0937 - accuracy: 0.9717\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0915 - accuracy: 0.9647\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9666\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0945 - accuracy: 0.9673\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.1027 - accuracy: 0.9629\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0874 - accuracy: 0.9710\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0974 - accuracy: 0.9646\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0782 - accuracy: 0.9832\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0759 - accuracy: 0.9702\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0823 - accuracy: 0.9813\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1090 - accuracy: 0.9554\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0912 - accuracy: 0.9747\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0688 - accuracy: 0.9692\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0666 - accuracy: 0.9870\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0701 - accuracy: 0.9690\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0772 - accuracy: 0.9761\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0629 - accuracy: 0.9816\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0997 - accuracy: 0.9565\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0870 - accuracy: 0.9731\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0636 - accuracy: 0.9821\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.1018 - accuracy: 0.9593\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0788 - accuracy: 0.9686\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0985 - accuracy: 0.9611\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0703 - accuracy: 0.9782\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9724\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.0625 - accuracy: 0.9823\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0608 - accuracy: 0.9812\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0639 - accuracy: 0.9768\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0676 - accuracy: 0.9797\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0642 - accuracy: 0.9729\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0572 - accuracy: 0.9883\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0687 - accuracy: 0.9883\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0783 - accuracy: 0.9724\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0666 - accuracy: 0.9861\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0521 - accuracy: 0.9862\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0683 - accuracy: 0.9797\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0870 - accuracy: 0.9591\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0632 - accuracy: 0.9852\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0623 - accuracy: 0.9774\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0678 - accuracy: 0.9783\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0580 - accuracy: 0.9756\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 978us/step - loss: 0.0620 - accuracy: 0.9745\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0535 - accuracy: 0.9883\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0445 - accuracy: 0.9887\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0645 - accuracy: 0.9785\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0520 - accuracy: 0.9773\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0449 - accuracy: 0.9884\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0654 - accuracy: 0.9745\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0454 - accuracy: 0.9852\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0625 - accuracy: 0.9706\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0753 - accuracy: 0.9701\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0493 - accuracy: 0.9851\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0532 - accuracy: 0.9827\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0536 - accuracy: 0.9846\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0648 - accuracy: 0.9775\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0654 - accuracy: 0.9758\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0599 - accuracy: 0.9766\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0515 - accuracy: 0.9886\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0597 - accuracy: 0.9851\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0532 - accuracy: 0.9835\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0445 - accuracy: 0.9875\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0452 - accuracy: 0.9854\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0532 - accuracy: 0.9801\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0597 - accuracy: 0.9720\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.0509 - accuracy: 0.9858\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0456 - accuracy: 0.9822\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0479 - accuracy: 0.9830\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0517 - accuracy: 0.9925\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0493 - accuracy: 0.9791\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0421 - accuracy: 0.9959\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0488 - accuracy: 0.9840\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0650 - accuracy: 0.9760\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0303 - accuracy: 0.9925\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 908us/step - loss: 0.0307 - accuracy: 0.9924\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0344 - accuracy: 0.9892\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0644 - accuracy: 0.9782\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.0531 - accuracy: 0.9798\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0566 - accuracy: 0.9739\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0509 - accuracy: 0.9863\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0410 - accuracy: 0.9839\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0450 - accuracy: 0.9871\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0495 - accuracy: 0.9887\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0353 - accuracy: 0.9924\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0297 - accuracy: 0.9910\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0335 - accuracy: 0.9883\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0311 - accuracy: 0.9894\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0362 - accuracy: 0.9847\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0606 - accuracy: 0.9823\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0362 - accuracy: 0.9939\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0304 - accuracy: 0.9931\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0313 - accuracy: 0.9965\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0367 - accuracy: 0.9881\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0318 - accuracy: 0.9875\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0321 - accuracy: 0.9918\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0276 - accuracy: 0.9909\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0396 - accuracy: 0.9912\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0431 - accuracy: 0.9909\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0347 - accuracy: 0.9912\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0381 - accuracy: 0.9849\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0393 - accuracy: 0.9901\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0460 - accuracy: 0.9766\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0497 - accuracy: 0.9838\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0295 - accuracy: 0.9922\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0381 - accuracy: 0.9925\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0297 - accuracy: 0.9924\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0454 - accuracy: 0.9791\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0489 - accuracy: 0.9850\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0345 - accuracy: 0.9950\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0424 - accuracy: 0.9881\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0399 - accuracy: 0.9803\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0275 - accuracy: 0.9901\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0342 - accuracy: 0.9869\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0452 - accuracy: 0.9813\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0245 - accuracy: 0.9953\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c78809f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 865us/step - loss: 0.7658 - accuracy: 0.6297\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 741us/step - loss: 0.5227 - accuracy: 0.7776\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7454\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.4959 - accuracy: 0.7651\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7943\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.4506 - accuracy: 0.7884\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.4169 - accuracy: 0.8120\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.4292 - accuracy: 0.8219\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.4169 - accuracy: 0.8280\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.3943 - accuracy: 0.8445\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.3679 - accuracy: 0.8408\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.4170 - accuracy: 0.8313\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.3657 - accuracy: 0.8587\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.3683 - accuracy: 0.8504\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.3565 - accuracy: 0.8487\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.3472 - accuracy: 0.8423\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.3341 - accuracy: 0.8540\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.3219 - accuracy: 0.8775\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.3298 - accuracy: 0.8683\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.2973 - accuracy: 0.8773\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.2996 - accuracy: 0.8974\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.3039 - accuracy: 0.8955\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.2987 - accuracy: 0.8849\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.2703 - accuracy: 0.8931\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.2536 - accuracy: 0.9106\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.2742 - accuracy: 0.8965\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.2916 - accuracy: 0.8840\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.2692 - accuracy: 0.9015\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.2442 - accuracy: 0.9095\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.2495 - accuracy: 0.9075\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1994 - accuracy: 0.9285\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.2522 - accuracy: 0.8901\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2366 - accuracy: 0.8956\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.2300 - accuracy: 0.9045\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.2084 - accuracy: 0.9247\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.1997 - accuracy: 0.9306\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.2115 - accuracy: 0.9263\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.2206 - accuracy: 0.9091\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1950 - accuracy: 0.9357\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.1986 - accuracy: 0.9271\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.2305 - accuracy: 0.9045\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.1828 - accuracy: 0.9394\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.1968 - accuracy: 0.9183\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.1882 - accuracy: 0.9341\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.1773 - accuracy: 0.9295\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1839 - accuracy: 0.9356\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1755 - accuracy: 0.9391\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.1727 - accuracy: 0.9532\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1605 - accuracy: 0.9431\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1598 - accuracy: 0.9490\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.1498 - accuracy: 0.9552\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1488 - accuracy: 0.9589\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1503 - accuracy: 0.9563\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1532 - accuracy: 0.9393\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.1262 - accuracy: 0.9586\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.1472 - accuracy: 0.9598\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1376 - accuracy: 0.9456\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.1541 - accuracy: 0.9569\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.1350 - accuracy: 0.9443\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9601\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9436\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9641\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9623\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9636\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9261\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9492\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1411 - accuracy: 0.9498\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.1669 - accuracy: 0.9488\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9488\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.1049 - accuracy: 0.9598\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1392 - accuracy: 0.9640\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.1002 - accuracy: 0.9674\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1144 - accuracy: 0.9729\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0873 - accuracy: 0.9707\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.1065 - accuracy: 0.9715\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.9543\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9636\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9592\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.1032 - accuracy: 0.9595\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.1176 - accuracy: 0.9650\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9707\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0982 - accuracy: 0.9625\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.0872 - accuracy: 0.9681\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9765\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.0789 - accuracy: 0.9761\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9664\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.1005 - accuracy: 0.9693\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0789 - accuracy: 0.9828\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0953 - accuracy: 0.9692\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0738 - accuracy: 0.9725\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 753us/step - loss: 0.0829 - accuracy: 0.9676\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 709us/step - loss: 0.0850 - accuracy: 0.9659\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 697us/step - loss: 0.0972 - accuracy: 0.9679\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 717us/step - loss: 0.0844 - accuracy: 0.9798\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 704us/step - loss: 0.0710 - accuracy: 0.9730\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0646 - accuracy: 0.9845\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 716us/step - loss: 0.0688 - accuracy: 0.9793\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 726us/step - loss: 0.0822 - accuracy: 0.9681\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 709us/step - loss: 0.0699 - accuracy: 0.9825\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9851\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9777\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9865\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9671\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9694\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0742 - accuracy: 0.9848\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9822\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9681\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9760\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0590 - accuracy: 0.9751\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9839\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0668 - accuracy: 0.9809\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0681 - accuracy: 0.9857\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9624\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0728 - accuracy: 0.9751\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0658 - accuracy: 0.9834\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0580 - accuracy: 0.9797\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9773\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0639 - accuracy: 0.9822\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0561 - accuracy: 0.9874\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 979us/step - loss: 0.0576 - accuracy: 0.9819\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0454 - accuracy: 0.9867\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0570 - accuracy: 0.9807\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0592 - accuracy: 0.9803\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9741\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0531 - accuracy: 0.9840\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9832\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9864\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0411 - accuracy: 0.9897\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0591 - accuracy: 0.9789\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0454 - accuracy: 0.9841\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0460 - accuracy: 0.9870\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9887\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0448 - accuracy: 0.9859\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0397 - accuracy: 0.9910\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0580 - accuracy: 0.9876\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0625 - accuracy: 0.9733\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0522 - accuracy: 0.9840\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0668 - accuracy: 0.9771\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9920\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0480 - accuracy: 0.9877\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9855\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9874\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0358 - accuracy: 0.9913\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0496 - accuracy: 0.9878\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.0375 - accuracy: 0.9909\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0401 - accuracy: 0.9870\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0370 - accuracy: 0.9948\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0411 - accuracy: 0.9854\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0568 - accuracy: 0.9827\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.0438 - accuracy: 0.9778\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0327 - accuracy: 0.9913\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.0366 - accuracy: 0.9913\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0470 - accuracy: 0.9830\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0374 - accuracy: 0.9909\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0364 - accuracy: 0.9915\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0409 - accuracy: 0.9876\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0370 - accuracy: 0.9895\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0493 - accuracy: 0.9828\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 978us/step - loss: 0.0634 - accuracy: 0.9810\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.0481 - accuracy: 0.9858\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 965us/step - loss: 0.0657 - accuracy: 0.9727\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0427 - accuracy: 0.9851\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0350 - accuracy: 0.9950\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9927\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9908\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0380 - accuracy: 0.9936\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9801\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0516 - accuracy: 0.9842\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0550 - accuracy: 0.9794\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0424 - accuracy: 0.9851\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0644 - accuracy: 0.9750\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9886\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0386 - accuracy: 0.9896\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0274 - accuracy: 0.9917\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0285 - accuracy: 0.9934\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0229 - accuracy: 0.9938\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.0304 - accuracy: 0.9925\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0268 - accuracy: 0.9937\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0322 - accuracy: 0.9866\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0342 - accuracy: 0.9882\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.0524 - accuracy: 0.9817\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0474 - accuracy: 0.9843\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9826\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9905\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0400 - accuracy: 0.9810\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0300 - accuracy: 0.9873\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0377 - accuracy: 0.9852\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0409 - accuracy: 0.9869\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.0414 - accuracy: 0.9867\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0510 - accuracy: 0.9812\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.0400 - accuracy: 0.9851\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9907\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0326 - accuracy: 0.9923\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9973\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0320 - accuracy: 0.9924\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9888\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9928\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9870\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0342 - accuracy: 0.9866\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73f844c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8305 - accuracy: 0.5861\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.5752 - accuracy: 0.7200\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.5249 - accuracy: 0.7577\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7747\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7809\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7616\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.4760 - accuracy: 0.7671\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7853\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.4234 - accuracy: 0.8210\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.4309 - accuracy: 0.8092\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.8233\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.3949 - accuracy: 0.8228\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.4258 - accuracy: 0.8144\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.4275 - accuracy: 0.8071\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8492\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.3828 - accuracy: 0.8429\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.3584 - accuracy: 0.8431\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8365\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.3678 - accuracy: 0.8430\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.3617 - accuracy: 0.8472\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.3315 - accuracy: 0.8605\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.3184 - accuracy: 0.8639\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.3165 - accuracy: 0.8828\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.3288 - accuracy: 0.8403\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.3177 - accuracy: 0.8734\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8948\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8686\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.2666 - accuracy: 0.8988\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.3009 - accuracy: 0.8784\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.3078 - accuracy: 0.8576\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.2624 - accuracy: 0.8993\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.2413 - accuracy: 0.8942\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.2361 - accuracy: 0.9155\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.2659 - accuracy: 0.8991\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.2729 - accuracy: 0.9133\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.2633 - accuracy: 0.8762\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.2362 - accuracy: 0.9043\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.2440 - accuracy: 0.9062\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1819 - accuracy: 0.9432\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.2006 - accuracy: 0.9289\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.2365 - accuracy: 0.9149\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.2196 - accuracy: 0.9101\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.1973 - accuracy: 0.9452\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.1915 - accuracy: 0.9310\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.2125 - accuracy: 0.9236\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.9433\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.1954 - accuracy: 0.9171\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9560\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.2191 - accuracy: 0.9327\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.1719 - accuracy: 0.9467\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1901 - accuracy: 0.9375\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.2053 - accuracy: 0.9236\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1776 - accuracy: 0.9423\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.1501 - accuracy: 0.9559\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1659 - accuracy: 0.9405\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1810 - accuracy: 0.9352\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.1623 - accuracy: 0.9446\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.1546 - accuracy: 0.9489\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1586 - accuracy: 0.9509\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1551 - accuracy: 0.9514\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.1385 - accuracy: 0.9581\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1324 - accuracy: 0.9661\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1435 - accuracy: 0.9604\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1289 - accuracy: 0.9529\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1584 - accuracy: 0.9276\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1385 - accuracy: 0.9585\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1291 - accuracy: 0.9609\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 980us/step - loss: 0.1210 - accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.1223 - accuracy: 0.9537\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.1128 - accuracy: 0.9658\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.1473 - accuracy: 0.9455\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1337 - accuracy: 0.9644\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1327 - accuracy: 0.9549\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1406 - accuracy: 0.9473\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1108 - accuracy: 0.9660\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1035 - accuracy: 0.9721\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.1274 - accuracy: 0.9675\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.1316 - accuracy: 0.9537\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1117 - accuracy: 0.9646\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0899 - accuracy: 0.9680\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 935us/step - loss: 0.1227 - accuracy: 0.9578\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1210 - accuracy: 0.9666\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0851 - accuracy: 0.9717\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.1166 - accuracy: 0.9722\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.1003 - accuracy: 0.9660\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9800\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.0889 - accuracy: 0.9777\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9581\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.1018 - accuracy: 0.9610\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.1010 - accuracy: 0.9652\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0880 - accuracy: 0.9698\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0878 - accuracy: 0.9755\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.1011 - accuracy: 0.9651\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9669\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9753\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0941 - accuracy: 0.9719\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.1024 - accuracy: 0.9578\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0972 - accuracy: 0.9618\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0849 - accuracy: 0.9715\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.1022 - accuracy: 0.9680\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9608\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0711 - accuracy: 0.9756\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9862\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.9752\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9824\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.0794 - accuracy: 0.9756\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9807\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0641 - accuracy: 0.9823\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0790 - accuracy: 0.9713\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0689 - accuracy: 0.9759\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0924 - accuracy: 0.9677\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0779 - accuracy: 0.9763\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0525 - accuracy: 0.9903\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0443 - accuracy: 0.9885\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0676 - accuracy: 0.9799\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0460 - accuracy: 0.9899\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0822 - accuracy: 0.9688\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0840 - accuracy: 0.9739\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0759 - accuracy: 0.9775\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0512 - accuracy: 0.9900\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0568 - accuracy: 0.9852\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0471 - accuracy: 0.9842\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0680 - accuracy: 0.9730\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0685 - accuracy: 0.9722\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0714 - accuracy: 0.9713\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0667 - accuracy: 0.9759\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0589 - accuracy: 0.9820\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9697\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0724 - accuracy: 0.9720\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0548 - accuracy: 0.9844\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0589 - accuracy: 0.9837\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0617 - accuracy: 0.9810\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0695 - accuracy: 0.9857\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0769 - accuracy: 0.9658\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0603 - accuracy: 0.9790\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0583 - accuracy: 0.9900\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0668 - accuracy: 0.9762\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0616 - accuracy: 0.9748\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0694 - accuracy: 0.9668\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0750 - accuracy: 0.9783\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0539 - accuracy: 0.9840\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0771 - accuracy: 0.9779\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0502 - accuracy: 0.9783\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0531 - accuracy: 0.9866\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0475 - accuracy: 0.9863\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0510 - accuracy: 0.9860\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0548 - accuracy: 0.9818\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0393 - accuracy: 0.9843\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0663 - accuracy: 0.9722\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.0386 - accuracy: 0.9897\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0450 - accuracy: 0.9869\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0476 - accuracy: 0.9822\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0504 - accuracy: 0.9867\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0476 - accuracy: 0.9850\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0648 - accuracy: 0.9677\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0455 - accuracy: 0.9902\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0479 - accuracy: 0.9866\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0394 - accuracy: 0.9865\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0499 - accuracy: 0.9789\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0441 - accuracy: 0.9838\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 925us/step - loss: 0.0573 - accuracy: 0.9763\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0432 - accuracy: 0.9883\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0382 - accuracy: 0.9909\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.0516 - accuracy: 0.9897\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9846\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0391 - accuracy: 0.9888\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0452 - accuracy: 0.9784\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9842\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.0364 - accuracy: 0.9901\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0469 - accuracy: 0.9793\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0460 - accuracy: 0.9872\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0388 - accuracy: 0.9912\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0436 - accuracy: 0.9848\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0557 - accuracy: 0.9752\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0455 - accuracy: 0.9818\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0405 - accuracy: 0.9861\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0453 - accuracy: 0.9875\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.0421 - accuracy: 0.9841\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9853\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9905\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9919\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9898\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9916\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 980us/step - loss: 0.0367 - accuracy: 0.9901\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9838\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0334 - accuracy: 0.9920\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0355 - accuracy: 0.9925\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0569 - accuracy: 0.9760\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0400 - accuracy: 0.9842\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0541 - accuracy: 0.9811\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0238 - accuracy: 0.9970\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.0318 - accuracy: 0.9839\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9932\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0296 - accuracy: 0.9925\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9853\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0253 - accuracy: 0.9986\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0497 - accuracy: 0.9872\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0218 - accuracy: 0.9973\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0259 - accuracy: 0.9903\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c796a7940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.8046 - accuracy: 0.6284\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.4093 - accuracy: 0.8283\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.3812 - accuracy: 0.8307\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.3679 - accuracy: 0.8579\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.3326 - accuracy: 0.8663\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.3332 - accuracy: 0.8409\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.3220 - accuracy: 0.8673\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.9001\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.8826\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.8622\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2575 - accuracy: 0.9071\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.2954 - accuracy: 0.8750\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.2832 - accuracy: 0.8973\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.2389 - accuracy: 0.8999\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.2278 - accuracy: 0.9130\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.2405 - accuracy: 0.8981\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9208\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.9172\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9045\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9055\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.9070\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9245\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.2096 - accuracy: 0.9048\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.1958 - accuracy: 0.9083\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.1856 - accuracy: 0.9326\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.1956 - accuracy: 0.9212\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 978us/step - loss: 0.1782 - accuracy: 0.9228\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.1708 - accuracy: 0.9415\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.1746 - accuracy: 0.9494\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1650 - accuracy: 0.9373\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.2254 - accuracy: 0.9133\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1911 - accuracy: 0.9141\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9340\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9444\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.1462 - accuracy: 0.9515\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.1381 - accuracy: 0.9385\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.1647 - accuracy: 0.9280\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.1373 - accuracy: 0.9500\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1374 - accuracy: 0.9374\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.1182 - accuracy: 0.9521\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.1219 - accuracy: 0.9711\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.1102 - accuracy: 0.9618\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.1196 - accuracy: 0.9652\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.1218 - accuracy: 0.9580\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.1255 - accuracy: 0.9606\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9576\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.1314 - accuracy: 0.9452\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.1278 - accuracy: 0.9558\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1176 - accuracy: 0.9664\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0868 - accuracy: 0.9772\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.1224 - accuracy: 0.9532\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0917 - accuracy: 0.9738\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0917 - accuracy: 0.9719\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.1053 - accuracy: 0.9715\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0771 - accuracy: 0.9725\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0932 - accuracy: 0.9679\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1093 - accuracy: 0.9660\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1074 - accuracy: 0.9586\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.1003 - accuracy: 0.9632\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0869 - accuracy: 0.9692\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0857 - accuracy: 0.9717\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0913 - accuracy: 0.9666\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0742 - accuracy: 0.9700\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0975 - accuracy: 0.9633\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0836 - accuracy: 0.9747\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0968 - accuracy: 0.9594\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0820 - accuracy: 0.9769\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0711 - accuracy: 0.9864\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.0592 - accuracy: 0.9805\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0711 - accuracy: 0.9882\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0644 - accuracy: 0.9775\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0639 - accuracy: 0.9856\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0722 - accuracy: 0.9788\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0642 - accuracy: 0.9779\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0745 - accuracy: 0.9796\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.0732 - accuracy: 0.9702\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0663 - accuracy: 0.9845\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0617 - accuracy: 0.9876\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0493 - accuracy: 0.9926\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0763 - accuracy: 0.9763\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9749\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9743\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9816\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9698\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9856\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9798\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0719 - accuracy: 0.9736\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9812\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.0482 - accuracy: 0.9801\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9912\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9891\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9883\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9864\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9961\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9938\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0507 - accuracy: 0.9823\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9905\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0460 - accuracy: 0.9834\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0462 - accuracy: 0.9873\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0322 - accuracy: 0.9912\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0399 - accuracy: 0.9885\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9836\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9930\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9921\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0424 - accuracy: 0.9917\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 979us/step - loss: 0.0291 - accuracy: 0.9930\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0477 - accuracy: 0.9834\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0303 - accuracy: 0.9951\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.0339 - accuracy: 0.9906\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0295 - accuracy: 0.9931\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0593 - accuracy: 0.9776\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9886\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0545 - accuracy: 0.9766\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9897\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9979\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9921\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9979\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9863\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9827\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9927\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9877\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9933\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9858\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9820\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9928\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9933\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9974\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9884\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9961\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9896\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0225 - accuracy: 0.9981\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0241 - accuracy: 0.9944\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.0299 - accuracy: 0.9916\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.0285 - accuracy: 0.9915\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0250 - accuracy: 0.9939\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0319 - accuracy: 0.9883\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0248 - accuracy: 0.9947\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.0262 - accuracy: 0.9936\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9971\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9919\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9955\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9937\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9928\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9978\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9855\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9906\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9957\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9821\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9970\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0257 - accuracy: 0.9932\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0267 - accuracy: 0.9946\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0171 - accuracy: 0.9958\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0246 - accuracy: 0.9906\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0197 - accuracy: 0.9968\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0210 - accuracy: 0.9939\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0282 - accuracy: 0.9902\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0265 - accuracy: 0.9904\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 909us/step - loss: 0.0443 - accuracy: 0.9920\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0241 - accuracy: 0.9981\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0169 - accuracy: 0.9978\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0258 - accuracy: 0.9882\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0269 - accuracy: 0.9946\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9958\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 0.9994\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.0135 - accuracy: 0.9958\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0241 - accuracy: 0.9915\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9938\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9920\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9948\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.0251 - accuracy: 0.9918\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0225 - accuracy: 0.9974\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9972\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0145 - accuracy: 0.9987\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0221 - accuracy: 0.9984\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9861\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9960\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0128 - accuracy: 0.9973\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0199 - accuracy: 0.9961\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0184 - accuracy: 0.9968\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0164 - accuracy: 0.9953\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9964\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0127 - accuracy: 0.9950\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9910\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0127 - accuracy: 0.9966\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.0236 - accuracy: 0.9898\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 987us/step - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9982\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9878\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9968\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0187 - accuracy: 0.9959\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.0215 - accuracy: 0.9938\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9946\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9970\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.9969\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0157 - accuracy: 0.9957\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9933\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 807us/step - loss: 0.5979 - accuracy: 0.7585\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.4328 - accuracy: 0.8274\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.3228 - accuracy: 0.8497\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.3307 - accuracy: 0.8676\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.3308 - accuracy: 0.8920\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.3026 - accuracy: 0.8864\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.3091 - accuracy: 0.8551\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.2832 - accuracy: 0.8853\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.2632 - accuracy: 0.8843\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.2786 - accuracy: 0.8854\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.8999\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.2219 - accuracy: 0.9081\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9141\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.8928\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.8951\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9043\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.9187\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.8981\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9010\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9326\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9216\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9155\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9368\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.1894 - accuracy: 0.9310\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9305\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.9343\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9433\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9474\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.9671\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9575\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9334\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9598\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9501\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.1254 - accuracy: 0.9567\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9663\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9342\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9406\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9736\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9693\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9538\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9681\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.9704\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9679\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9695\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9691\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0772 - accuracy: 0.9755\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9744\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9650\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9823\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9728\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0660 - accuracy: 0.9786\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9818\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.0675 - accuracy: 0.9882\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9855\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0714 - accuracy: 0.9755\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9807\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0903 - accuracy: 0.9697\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.0637 - accuracy: 0.9799\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0553 - accuracy: 0.9772\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0486 - accuracy: 0.9875\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0555 - accuracy: 0.9862\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0565 - accuracy: 0.9807\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9918\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0521 - accuracy: 0.9777\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9889\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0426 - accuracy: 0.9936\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9922\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9955\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9912\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9860\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0902 - accuracy: 0.9693\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9834\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0554 - accuracy: 0.9784\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0357 - accuracy: 0.9862\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0359 - accuracy: 0.9979\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0363 - accuracy: 0.9887\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0439 - accuracy: 0.9866\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0379 - accuracy: 0.9947\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0322 - accuracy: 0.9908\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0452 - accuracy: 0.9885\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0482 - accuracy: 0.9845\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 931us/step - loss: 0.0351 - accuracy: 0.9916\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.0326 - accuracy: 0.9982\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0369 - accuracy: 0.9919\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0449 - accuracy: 0.9833\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0424 - accuracy: 0.9847\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0380 - accuracy: 0.9911\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9930\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9954\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9930\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9921\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9853\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0237 - accuracy: 0.9983\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9984\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9985\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9937\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9947\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9894\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.0180 - accuracy: 0.9988\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0243 - accuracy: 0.9943\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0202 - accuracy: 0.9983\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9919\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9973\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9803\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0837 - accuracy: 0.9741\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9843\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9860\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0276 - accuracy: 0.9912\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9932\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0311 - accuracy: 0.9892\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0272 - accuracy: 0.9895\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0306 - accuracy: 0.9937\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9923\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9983\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0178 - accuracy: 0.9964\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9956\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0258 - accuracy: 0.9917\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0246 - accuracy: 0.9917\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0201 - accuracy: 0.9963\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0258 - accuracy: 0.9941\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0168 - accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9982\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9947\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0307 - accuracy: 0.9891\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9992\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0166 - accuracy: 0.9973\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0179 - accuracy: 0.9964\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0129 - accuracy: 0.9990\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9963\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0270 - accuracy: 0.9932\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9955\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9955\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0174 - accuracy: 0.9958\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0269 - accuracy: 0.9875\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0283 - accuracy: 0.9913\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0879 - accuracy: 0.9680\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0580 - accuracy: 0.9770\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0366 - accuracy: 0.9851\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0206 - accuracy: 0.9966\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0349 - accuracy: 0.9843\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0139 - accuracy: 0.9994\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0171 - accuracy: 0.9954\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0186 - accuracy: 0.9971\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9928\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0249 - accuracy: 0.9929\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0238 - accuracy: 0.9959\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0285 - accuracy: 0.9918\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0479 - accuracy: 0.9827\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0336 - accuracy: 0.9917\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0505 - accuracy: 0.9897\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.0312 - accuracy: 0.9857\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0274 - accuracy: 0.9934\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0323 - accuracy: 0.9867\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0203 - accuracy: 0.9964\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0118 - accuracy: 0.9990\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0235 - accuracy: 0.9918\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9934\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9847\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0937 - accuracy: 0.9656\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9935\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 956us/step - loss: 0.0364 - accuracy: 0.9851\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0171 - accuracy: 0.9974\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0135 - accuracy: 0.9965\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0233 - accuracy: 0.9887\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9978\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0138 - accuracy: 0.9956\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.0342 - accuracy: 0.9846\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0316 - accuracy: 0.9911\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0156 - accuracy: 0.9959\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0134 - accuracy: 0.9957\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0177 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9942\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0128 - accuracy: 0.9977\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9921\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9914\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0171 - accuracy: 0.9951\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0239 - accuracy: 0.9945\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9957\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.0247 - accuracy: 0.9899\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0136 - accuracy: 0.9960\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0163 - accuracy: 0.9982\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0257 - accuracy: 0.9910\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0265 - accuracy: 0.9898\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0303 - accuracy: 0.9836\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0244 - accuracy: 0.9958\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0140 - accuracy: 0.9972\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0155 - accuracy: 0.9984\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.0176 - accuracy: 0.9962\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0183 - accuracy: 0.9928\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0209 - accuracy: 0.9896\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.0294 - accuracy: 0.9867\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0129 - accuracy: 0.9984\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0123 - accuracy: 0.9975\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9973\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0169 - accuracy: 0.9939\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0108 - accuracy: 0.9959\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0187 - accuracy: 0.9971\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 847us/step - loss: 0.6040 - accuracy: 0.7898\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.3843 - accuracy: 0.8508\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.4374 - accuracy: 0.7971\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.3314 - accuracy: 0.8684\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.3273 - accuracy: 0.8866\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.3467 - accuracy: 0.8671\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.3095 - accuracy: 0.8777\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.2852 - accuracy: 0.8834\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.2958 - accuracy: 0.8828\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.2616 - accuracy: 0.9140\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.2531 - accuracy: 0.9018\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.2678 - accuracy: 0.8849\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.2412 - accuracy: 0.9086\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.2362 - accuracy: 0.9156\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.2300 - accuracy: 0.8968\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.2476 - accuracy: 0.8903\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.2128 - accuracy: 0.9203\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.2073 - accuracy: 0.9245\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1819 - accuracy: 0.9371\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9030\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2057 - accuracy: 0.9114\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.9350\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.1943 - accuracy: 0.9138\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1595 - accuracy: 0.9529\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.1656 - accuracy: 0.9439\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.1794 - accuracy: 0.9300\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1562 - accuracy: 0.9479\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9474\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.1402 - accuracy: 0.9490\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.1525 - accuracy: 0.9463\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.1309 - accuracy: 0.9635\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.1527 - accuracy: 0.9396\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1236 - accuracy: 0.9629\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.1347 - accuracy: 0.9426\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.1233 - accuracy: 0.9614\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.1184 - accuracy: 0.9720\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.1123 - accuracy: 0.9624\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.1104 - accuracy: 0.9617\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1160 - accuracy: 0.9651\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1094 - accuracy: 0.9647\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.1011 - accuracy: 0.9625\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0955 - accuracy: 0.9693\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0990 - accuracy: 0.9640\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.1038 - accuracy: 0.9766\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0953 - accuracy: 0.9627\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0957 - accuracy: 0.9678\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0952 - accuracy: 0.9648\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0943 - accuracy: 0.9625\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0881 - accuracy: 0.9723\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.0777 - accuracy: 0.9739\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0716 - accuracy: 0.9773\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0816 - accuracy: 0.9666\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1424 - accuracy: 0.9341\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1122 - accuracy: 0.9604\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0764 - accuracy: 0.9748\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.0971 - accuracy: 0.9716\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0947 - accuracy: 0.9661\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0733 - accuracy: 0.9734\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0747 - accuracy: 0.9763\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0853 - accuracy: 0.9735\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0896 - accuracy: 0.9821\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0766 - accuracy: 0.9724\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0607 - accuracy: 0.9750\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0620 - accuracy: 0.9801\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0786 - accuracy: 0.9666\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0485 - accuracy: 0.9818\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0416 - accuracy: 0.9893\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.0457 - accuracy: 0.9917\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0484 - accuracy: 0.9803\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0553 - accuracy: 0.9909\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0446 - accuracy: 0.9817\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0572 - accuracy: 0.9751\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0623 - accuracy: 0.9827\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0693 - accuracy: 0.9701\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0645 - accuracy: 0.9759\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.0554 - accuracy: 0.9771\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0565 - accuracy: 0.9757\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0592 - accuracy: 0.9744\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0528 - accuracy: 0.9847\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0490 - accuracy: 0.9865\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 895us/step - loss: 0.0480 - accuracy: 0.9838\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0383 - accuracy: 0.9921\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0449 - accuracy: 0.9880\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0354 - accuracy: 0.9913\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0432 - accuracy: 0.9871\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0411 - accuracy: 0.9871\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0461 - accuracy: 0.9823\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0323 - accuracy: 0.9963\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0304 - accuracy: 0.9933\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0321 - accuracy: 0.9910\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0339 - accuracy: 0.9859\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0360 - accuracy: 0.9917\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0342 - accuracy: 0.9910\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0271 - accuracy: 0.9911\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9947\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.0361 - accuracy: 0.9921\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0310 - accuracy: 0.9921\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0541 - accuracy: 0.9915\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0354 - accuracy: 0.9972\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0322 - accuracy: 0.9955\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0351 - accuracy: 0.9938\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.0222 - accuracy: 0.9957\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0218 - accuracy: 0.9963\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0244 - accuracy: 0.9965\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0514 - accuracy: 0.9794\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0479 - accuracy: 0.9870\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0436 - accuracy: 0.9893\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0405 - accuracy: 0.9881\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.0314 - accuracy: 0.9926\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0211 - accuracy: 0.9991\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0339 - accuracy: 0.9844\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0290 - accuracy: 0.9907\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0432 - accuracy: 0.9888\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.0278 - accuracy: 0.9964\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0357 - accuracy: 0.9872\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0409 - accuracy: 0.9856\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.0232 - accuracy: 0.9940\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0179 - accuracy: 0.9958\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0313 - accuracy: 0.9940\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0266 - accuracy: 0.9967\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0257 - accuracy: 0.9919\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0254 - accuracy: 0.9919\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0295 - accuracy: 0.9906\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0242 - accuracy: 0.9948\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0187 - accuracy: 0.9954\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0346 - accuracy: 0.9856\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0213 - accuracy: 0.9951\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0321 - accuracy: 0.9918\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0208 - accuracy: 0.9915\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0305 - accuracy: 0.9837\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0297 - accuracy: 0.9852\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0182 - accuracy: 0.9928\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0182 - accuracy: 0.9970\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0142 - accuracy: 0.9964\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0167 - accuracy: 0.9993\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0213 - accuracy: 0.9907\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0299 - accuracy: 0.9873\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0257 - accuracy: 0.9936\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0153 - accuracy: 0.9980\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0263 - accuracy: 0.9949\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0295 - accuracy: 0.9893\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0195 - accuracy: 0.9964\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0267 - accuracy: 0.9882\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0178 - accuracy: 0.9954\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0216 - accuracy: 0.9955\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0235 - accuracy: 0.9911\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0143 - accuracy: 0.9962\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0243 - accuracy: 0.9945\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0185 - accuracy: 0.9901\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0216 - accuracy: 0.9952\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0263 - accuracy: 0.9878\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0200 - accuracy: 0.9948\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0274 - accuracy: 0.9868\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0133 - accuracy: 0.9968\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0139 - accuracy: 0.9951\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0072 - accuracy: 0.9992\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0219 - accuracy: 0.9915\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0257 - accuracy: 0.9945\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 975us/step - loss: 0.0204 - accuracy: 0.9938\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0135 - accuracy: 0.9971\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0253 - accuracy: 0.9895\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0131 - accuracy: 0.9966\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0150 - accuracy: 0.9944\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0372 - accuracy: 0.9833\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9982\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9960\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 0.9990\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9967\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9942\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9969\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9928\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9979\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9914\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9953\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0137 - accuracy: 0.9998\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9973\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9966\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0084 - accuracy: 0.9981\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0263 - accuracy: 0.9891\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0163 - accuracy: 0.9996\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0256 - accuracy: 0.9869\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0358 - accuracy: 0.9895\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0139 - accuracy: 0.9965\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0180 - accuracy: 0.9963\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0171 - accuracy: 0.9922\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0270 - accuracy: 0.9890\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0145 - accuracy: 0.9970\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0303 - accuracy: 0.9883\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0137 - accuracy: 0.9969\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0173 - accuracy: 0.9938\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0107 - accuracy: 0.9961\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0235 - accuracy: 0.9882\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0139 - accuracy: 0.9969\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0122 - accuracy: 0.9950\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.0130 - accuracy: 0.9988\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0245 - accuracy: 0.9896\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 810us/step - loss: 0.6505 - accuracy: 0.7397\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.4014 - accuracy: 0.8196\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.3646 - accuracy: 0.8429\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.3511 - accuracy: 0.8512\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.3643 - accuracy: 0.8403\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.3262 - accuracy: 0.8665\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8813\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.2715 - accuracy: 0.8744\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.3252 - accuracy: 0.8411\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.2730 - accuracy: 0.8871\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.2674 - accuracy: 0.8699\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.2564 - accuracy: 0.8841\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.2342 - accuracy: 0.9089\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.2388 - accuracy: 0.9045\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.2384 - accuracy: 0.8982\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.2243 - accuracy: 0.9112\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.9158\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.2047 - accuracy: 0.9242\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.1983 - accuracy: 0.9200\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1897 - accuracy: 0.9290\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1992 - accuracy: 0.9175\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.2027 - accuracy: 0.9228\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1752 - accuracy: 0.9318\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9159\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.1805 - accuracy: 0.9175\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.1604 - accuracy: 0.9385\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.1775 - accuracy: 0.9317\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.1466 - accuracy: 0.9489\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.2128 - accuracy: 0.8963\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1335 - accuracy: 0.9526\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.1558 - accuracy: 0.9403\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.1860 - accuracy: 0.9310\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1422 - accuracy: 0.9415\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.1101 - accuracy: 0.9672\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1429 - accuracy: 0.9418\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1112 - accuracy: 0.9555\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.1125 - accuracy: 0.9670\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1341 - accuracy: 0.9392\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.1199 - accuracy: 0.9502\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.1199 - accuracy: 0.9570\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1320 - accuracy: 0.9551\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.1089 - accuracy: 0.9594\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.1334 - accuracy: 0.9607\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1259 - accuracy: 0.9493\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.1240 - accuracy: 0.9557\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1145 - accuracy: 0.9512\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0993 - accuracy: 0.9660\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0904 - accuracy: 0.9671\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0796 - accuracy: 0.9656\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0815 - accuracy: 0.9784\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0848 - accuracy: 0.9734\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9845\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9764\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.9786\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9788\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9769\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9635\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9768\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0966 - accuracy: 0.9613\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0624 - accuracy: 0.9907\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0729 - accuracy: 0.9720\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0752 - accuracy: 0.9742\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0680 - accuracy: 0.9739\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0808 - accuracy: 0.9721\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0717 - accuracy: 0.9763\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0579 - accuracy: 0.9803\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0648 - accuracy: 0.9802\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0724 - accuracy: 0.9765\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0537 - accuracy: 0.9823\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9868\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0683 - accuracy: 0.9753\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0597 - accuracy: 0.9744\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0519 - accuracy: 0.9858\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0688 - accuracy: 0.9756\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.1052 - accuracy: 0.9687\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0744 - accuracy: 0.9746\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0498 - accuracy: 0.9829\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0541 - accuracy: 0.9763\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0480 - accuracy: 0.9807\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0513 - accuracy: 0.9756\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 921us/step - loss: 0.0603 - accuracy: 0.9804\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9827\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9886\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9923\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9947\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9924\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0363 - accuracy: 0.9960\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0339 - accuracy: 0.9933\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0334 - accuracy: 0.9910\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0382 - accuracy: 0.9898\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0599 - accuracy: 0.9754\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0764 - accuracy: 0.9675\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0496 - accuracy: 0.9840\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0550 - accuracy: 0.9836\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0421 - accuracy: 0.9887\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0326 - accuracy: 0.9913\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0535 - accuracy: 0.9852\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0493 - accuracy: 0.9876\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0195 - accuracy: 0.9997\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0464 - accuracy: 0.9833\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0453 - accuracy: 0.9893\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.0285 - accuracy: 0.9964\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0411 - accuracy: 0.9894\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0301 - accuracy: 0.9896\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0356 - accuracy: 0.9850\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0409 - accuracy: 0.9821\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0326 - accuracy: 0.9920\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0235 - accuracy: 0.9950\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0582 - accuracy: 0.9851\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0265 - accuracy: 0.9903\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0314 - accuracy: 0.9959\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0229 - accuracy: 0.9941\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0241 - accuracy: 0.9954\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0200 - accuracy: 0.9927\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0248 - accuracy: 0.9936\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0321 - accuracy: 0.9924\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0260 - accuracy: 0.9937\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0253 - accuracy: 0.9961\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0355 - accuracy: 0.9916\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0255 - accuracy: 0.9937\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0410 - accuracy: 0.9886\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0267 - accuracy: 0.9941\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0314 - accuracy: 0.9910\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0489 - accuracy: 0.9876\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0365 - accuracy: 0.9841\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0440 - accuracy: 0.9798\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0266 - accuracy: 0.9894\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0211 - accuracy: 0.9964\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9891\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0153 - accuracy: 0.9974\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9943\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9978\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9955\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9960\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9745\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9873\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0307 - accuracy: 0.9924\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9909\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9686\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9918\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9830\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0346 - accuracy: 0.9873\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9878\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9962\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9964\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0222 - accuracy: 0.9946\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9985\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0260 - accuracy: 0.9892\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.0378 - accuracy: 0.9891\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 978us/step - loss: 0.0351 - accuracy: 0.9900\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9932\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0315 - accuracy: 0.9919\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0248 - accuracy: 0.9922\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0202 - accuracy: 0.9939\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0171 - accuracy: 0.9959\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0178 - accuracy: 0.9938\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0374 - accuracy: 0.9887\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 884us/step - loss: 0.0153 - accuracy: 0.9943\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0191 - accuracy: 0.9942\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0293 - accuracy: 0.9882\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0143 - accuracy: 0.9985\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0194 - accuracy: 0.9964\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0178 - accuracy: 0.9957\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0137 - accuracy: 0.9980\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0269 - accuracy: 0.9903\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0150 - accuracy: 0.9975\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0160 - accuracy: 0.9982\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0130 - accuracy: 0.9976\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0336 - accuracy: 0.9903\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0186 - accuracy: 0.9905\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0169 - accuracy: 0.9993\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0188 - accuracy: 0.9948\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0163 - accuracy: 0.9944\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0200 - accuracy: 0.9922\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0375 - accuracy: 0.9819\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0155 - accuracy: 0.9987\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0226 - accuracy: 0.9909\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0225 - accuracy: 0.9914\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0158 - accuracy: 0.9935\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0161 - accuracy: 0.9953\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0155 - accuracy: 0.9975\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0086 - accuracy: 0.9984\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0123 - accuracy: 0.9970\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0444 - accuracy: 0.9805\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0375 - accuracy: 0.9902\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0285 - accuracy: 0.9953\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0287 - accuracy: 0.9914\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0145 - accuracy: 0.9968\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0127 - accuracy: 0.9974\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0166 - accuracy: 0.9922\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0201 - accuracy: 0.9973\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0178 - accuracy: 0.9925\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0180 - accuracy: 0.9969\n",
      "WARNING:tensorflow:5 out of the last 83 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7538bf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 867us/step - loss: 0.5107 - accuracy: 0.8024\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.3778 - accuracy: 0.8335\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.3406 - accuracy: 0.8607\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.3432 - accuracy: 0.8555\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8618\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8573\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8747\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8856\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.9109\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.9045\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.9048\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9009\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.2577 - accuracy: 0.8921\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.2164 - accuracy: 0.9065\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2688 - accuracy: 0.9002\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 980us/step - loss: 0.1929 - accuracy: 0.9284\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.9148\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.2007 - accuracy: 0.9309\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.2340 - accuracy: 0.9081\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.1852 - accuracy: 0.9187\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.1986 - accuracy: 0.9178\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.1817 - accuracy: 0.9350\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1669 - accuracy: 0.9377\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1967 - accuracy: 0.9177\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9398\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.1742 - accuracy: 0.9403\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.1978 - accuracy: 0.9179\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9495\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.1424 - accuracy: 0.9438\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9498\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.1259 - accuracy: 0.9551\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1407 - accuracy: 0.9529\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.1311 - accuracy: 0.9546\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.1256 - accuracy: 0.9665\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.1432 - accuracy: 0.9441\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0973 - accuracy: 0.9564\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1145 - accuracy: 0.9639\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.1267 - accuracy: 0.9459\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1175 - accuracy: 0.9662\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1153 - accuracy: 0.9580\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.1050 - accuracy: 0.9632\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0945 - accuracy: 0.9667\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0974 - accuracy: 0.9684\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0953 - accuracy: 0.9743\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0789 - accuracy: 0.9818\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 987us/step - loss: 0.0867 - accuracy: 0.9658\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9633\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0792 - accuracy: 0.9756\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0763 - accuracy: 0.9800\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9745\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0866 - accuracy: 0.9686\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0805 - accuracy: 0.9859\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0747 - accuracy: 0.9818\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0747 - accuracy: 0.9800\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0652 - accuracy: 0.9748\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0590 - accuracy: 0.9842\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9801\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9744\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9756\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9639\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0709 - accuracy: 0.9771\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9784\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0495 - accuracy: 0.9841\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0476 - accuracy: 0.9874\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9871\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9886\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9884\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0556 - accuracy: 0.9852\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0566 - accuracy: 0.9886\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0357 - accuracy: 0.9938\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0382 - accuracy: 0.9853\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0413 - accuracy: 0.9848\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9860\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9950\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0359 - accuracy: 0.9959\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 978us/step - loss: 0.0401 - accuracy: 0.9960\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0454 - accuracy: 0.9884\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9898\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0433 - accuracy: 0.9897\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9892\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 918us/step - loss: 0.0286 - accuracy: 0.9967\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9889\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0410 - accuracy: 0.9904\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9903\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9832\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9912\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0201 - accuracy: 0.9980\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9961\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0245 - accuracy: 0.9906\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9878\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0265 - accuracy: 0.9959\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0334 - accuracy: 0.9904\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0641 - accuracy: 0.9732\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9837\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0312 - accuracy: 0.9942\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9916\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0266 - accuracy: 0.9918\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0358 - accuracy: 0.9942\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0222 - accuracy: 0.9917\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0229 - accuracy: 0.9971\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9957\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0264 - accuracy: 0.9948\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0323 - accuracy: 0.9909\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0274 - accuracy: 0.9924\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0182 - accuracy: 0.9933\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.0311 - accuracy: 0.9883\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9900\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0234 - accuracy: 0.9966\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0411 - accuracy: 0.9807\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0191 - accuracy: 0.9996\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0202 - accuracy: 0.9959\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0152 - accuracy: 0.9991\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0147 - accuracy: 0.9989\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0283 - accuracy: 0.9906\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9932\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0170 - accuracy: 0.9983\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0224 - accuracy: 0.9829\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0252 - accuracy: 0.9910\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0181 - accuracy: 0.9959\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0210 - accuracy: 0.9885\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0341 - accuracy: 0.9837\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0202 - accuracy: 0.9954\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0221 - accuracy: 0.9952\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0327 - accuracy: 0.9937\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.0250 - accuracy: 0.9937\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0149 - accuracy: 0.9975\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9865\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9965\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9993\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0368 - accuracy: 0.9909\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0318 - accuracy: 0.9839\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0277 - accuracy: 0.9958\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0262 - accuracy: 0.9908\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0182 - accuracy: 0.9980\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0203 - accuracy: 0.9990\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9980\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0177 - accuracy: 0.9964\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0288 - accuracy: 0.9931\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0170 - accuracy: 0.9928\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0165 - accuracy: 0.9934\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0123 - accuracy: 0.9980\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0115 - accuracy: 0.9958\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0125 - accuracy: 0.9967\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0185 - accuracy: 0.9929\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0103 - accuracy: 0.9978\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0089 - accuracy: 0.9984\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0170 - accuracy: 0.9956\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0128 - accuracy: 0.9955\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0125 - accuracy: 0.9975\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0275 - accuracy: 0.9922\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.0132 - accuracy: 0.9973\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0151 - accuracy: 0.9975\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0178 - accuracy: 0.9910\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0300 - accuracy: 0.9916\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0147 - accuracy: 0.9964\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0147 - accuracy: 0.9978\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 893us/step - loss: 0.0085 - accuracy: 0.9991\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.0175 - accuracy: 0.9928\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0143 - accuracy: 0.9985\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9983\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0183 - accuracy: 0.9947\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9984\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9911\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0095 - accuracy: 0.9981\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0066 - accuracy: 0.9996\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0073 - accuracy: 0.9992\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0084 - accuracy: 0.9996\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.0115 - accuracy: 0.9984\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9998\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0187 - accuracy: 0.9931\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0114 - accuracy: 0.9989\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0066 - accuracy: 0.9990\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0097 - accuracy: 0.9992\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0082 - accuracy: 0.9993\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9949\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9961\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9960\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0367 - accuracy: 0.9848\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0252 - accuracy: 0.9919\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0111 - accuracy: 0.9971\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9874\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0062 - accuracy: 0.9990\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0076 - accuracy: 0.9983\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.0355 - accuracy: 0.9951\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0170 - accuracy: 0.9943\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0073 - accuracy: 0.9989\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9948\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0170 - accuracy: 0.9919\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0246 - accuracy: 0.9931\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c76b9fdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 885us/step - loss: 0.6333 - accuracy: 0.7601\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.3931 - accuracy: 0.8329\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.3685 - accuracy: 0.8349\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8487\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8630\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8711\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.2517 - accuracy: 0.8942\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2797 - accuracy: 0.8801\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.2473 - accuracy: 0.8990\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.2615 - accuracy: 0.8830\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.2863 - accuracy: 0.8837\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.2314 - accuracy: 0.8934\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9094\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.2441 - accuracy: 0.8825\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.2160 - accuracy: 0.9260\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.2145 - accuracy: 0.9145\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.9144\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.2109 - accuracy: 0.9143\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.9331\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.1892 - accuracy: 0.9265\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.2012 - accuracy: 0.9152\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.2306 - accuracy: 0.9076\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9354\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.1667 - accuracy: 0.9400\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1830 - accuracy: 0.9412\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.1551 - accuracy: 0.9399\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9345\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9314\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.1459 - accuracy: 0.9508\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.1234 - accuracy: 0.9637\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9545\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.1420 - accuracy: 0.9589\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.1234 - accuracy: 0.9433\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.1116 - accuracy: 0.9686\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.1347 - accuracy: 0.9399\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.1132 - accuracy: 0.9714\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9533\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9563\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.1025 - accuracy: 0.9676\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1111 - accuracy: 0.9649\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.1045 - accuracy: 0.9619\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.0971 - accuracy: 0.9615\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0760 - accuracy: 0.9812\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9645\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0788 - accuracy: 0.9694\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0876 - accuracy: 0.9715\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0731 - accuracy: 0.9819\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0825 - accuracy: 0.9793\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0738 - accuracy: 0.9723\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0715 - accuracy: 0.9793\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.0793 - accuracy: 0.9740\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0730 - accuracy: 0.9769\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0497 - accuracy: 0.9877\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0702 - accuracy: 0.9813\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0747 - accuracy: 0.9745\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0712 - accuracy: 0.9784\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0685 - accuracy: 0.9835\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0806 - accuracy: 0.9705\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0777 - accuracy: 0.9729\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9765\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0483 - accuracy: 0.9881\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0499 - accuracy: 0.9914\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0598 - accuracy: 0.9761\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0615 - accuracy: 0.9808\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0589 - accuracy: 0.9803\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0532 - accuracy: 0.9823\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0588 - accuracy: 0.9905\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0472 - accuracy: 0.9828\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9848\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0388 - accuracy: 0.9902\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0375 - accuracy: 0.9972\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.0475 - accuracy: 0.9840\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0442 - accuracy: 0.9817\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0442 - accuracy: 0.9899\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0347 - accuracy: 0.9926\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9893\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9807\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9897\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0310 - accuracy: 0.9946\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0435 - accuracy: 0.9789\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 911us/step - loss: 0.1012 - accuracy: 0.9625\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0639 - accuracy: 0.9841\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0695 - accuracy: 0.9770\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0475 - accuracy: 0.9802\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0416 - accuracy: 0.9920\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9940\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9835\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0512 - accuracy: 0.9798\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0618 - accuracy: 0.9874\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0411 - accuracy: 0.9907\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0367 - accuracy: 0.9824\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0434 - accuracy: 0.9804\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0194 - accuracy: 0.9973\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9976\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0346 - accuracy: 0.9886\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9899\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.0198 - accuracy: 0.9961\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0273 - accuracy: 0.9914\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0324 - accuracy: 0.9925\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0313 - accuracy: 0.9882\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9902\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0267 - accuracy: 0.9952\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0252 - accuracy: 0.9981\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9900\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9987\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0244 - accuracy: 0.9902\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0222 - accuracy: 0.9947\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0389 - accuracy: 0.9867\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0234 - accuracy: 0.9940\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9857\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9944\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0210 - accuracy: 0.9961\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0240 - accuracy: 0.9909\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0238 - accuracy: 0.9961\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0211 - accuracy: 0.9975\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0156 - accuracy: 0.9941\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0122 - accuracy: 0.9985\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0155 - accuracy: 0.9974\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0234 - accuracy: 0.9947\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0170 - accuracy: 0.9991\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0222 - accuracy: 0.9924\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0194 - accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0241 - accuracy: 0.9946\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0218 - accuracy: 0.9964\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0250 - accuracy: 0.9889\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0225 - accuracy: 0.9964\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0327 - accuracy: 0.9838\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0223 - accuracy: 0.9963\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0158 - accuracy: 0.9978\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9981\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0204 - accuracy: 0.9932\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9989\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0268 - accuracy: 0.9866\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0164 - accuracy: 0.9961\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0232 - accuracy: 0.9945\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0101 - accuracy: 0.9978\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0162 - accuracy: 0.9982\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.0143 - accuracy: 0.9986\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0196 - accuracy: 0.9942\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 979us/step - loss: 0.0107 - accuracy: 0.9974\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0229 - accuracy: 0.9902\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.0147 - accuracy: 0.9942\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9983\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0100 - accuracy: 0.9989\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.0142 - accuracy: 0.9972\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0177 - accuracy: 0.9991\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0098 - accuracy: 0.9998\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0141 - accuracy: 0.9995\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9978\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9975\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9943\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0115 - accuracy: 0.9971\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9947\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9912\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9981\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9622\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0499 - accuracy: 0.9844\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.0359 - accuracy: 0.9912\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0431 - accuracy: 0.9821\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0323 - accuracy: 0.9883\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0208 - accuracy: 0.9952\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0237 - accuracy: 0.9927\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0207 - accuracy: 0.9972\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0253 - accuracy: 0.9896\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.9998\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0208 - accuracy: 0.9986\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9934\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 987us/step - loss: 0.0376 - accuracy: 0.9845\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9984\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0255 - accuracy: 0.9896\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9934\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9884\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9969\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0203 - accuracy: 0.9963\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9975\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0110 - accuracy: 0.9990\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.0127 - accuracy: 0.9958\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0110 - accuracy: 0.9981\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0131 - accuracy: 0.9970\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0164 - accuracy: 0.9955\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0079 - accuracy: 0.9990\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0155 - accuracy: 0.9957\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0094 - accuracy: 0.9966\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0143 - accuracy: 0.9990\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0099 - accuracy: 0.9978\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0084 - accuracy: 0.9974\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0120 - accuracy: 0.9969\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c79256790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.7564\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.4322 - accuracy: 0.8403\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8771\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.3258 - accuracy: 0.8518\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.3764 - accuracy: 0.8367\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.3294 - accuracy: 0.8558\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.8763\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8932\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8911\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9073\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.2352 - accuracy: 0.9153\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.2283 - accuracy: 0.9129\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 987us/step - loss: 0.2478 - accuracy: 0.8885\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.1963 - accuracy: 0.9301\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.2125 - accuracy: 0.9081\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.2083 - accuracy: 0.9223\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.2076 - accuracy: 0.9161\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.1906 - accuracy: 0.9186\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.1710 - accuracy: 0.9420\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.1737 - accuracy: 0.9344\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9395\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.2011 - accuracy: 0.9277\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.1735 - accuracy: 0.9166\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.1438 - accuracy: 0.9598\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.1792 - accuracy: 0.9272\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.1684 - accuracy: 0.9337\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9310\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9678\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.1383 - accuracy: 0.9541\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.9335\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1435 - accuracy: 0.9531\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.1258 - accuracy: 0.9557\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.1033 - accuracy: 0.9707\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1134 - accuracy: 0.9613\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.1108 - accuracy: 0.9570\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9525\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0941 - accuracy: 0.9623\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9720\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9697\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1021 - accuracy: 0.9574\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9791\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9792\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0732 - accuracy: 0.9734\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0802 - accuracy: 0.9737\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0823 - accuracy: 0.9667\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0860 - accuracy: 0.9725\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0933 - accuracy: 0.9641\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0823 - accuracy: 0.9757\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0714 - accuracy: 0.9808\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0780 - accuracy: 0.9753\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0798 - accuracy: 0.9701\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0984 - accuracy: 0.9597\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0714 - accuracy: 0.9827\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.0864 - accuracy: 0.9821\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0763 - accuracy: 0.9747\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0628 - accuracy: 0.9834\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0619 - accuracy: 0.9823\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0599 - accuracy: 0.9827\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0620 - accuracy: 0.9784\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0580 - accuracy: 0.9907\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9759\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9688\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0502 - accuracy: 0.9888\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0541 - accuracy: 0.9824\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0420 - accuracy: 0.9950\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.0464 - accuracy: 0.9915\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0465 - accuracy: 0.9918\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0444 - accuracy: 0.9892\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0478 - accuracy: 0.9889\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0416 - accuracy: 0.9912\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0490 - accuracy: 0.9870\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0391 - accuracy: 0.9910\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0336 - accuracy: 0.9959\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0338 - accuracy: 0.9981\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0586 - accuracy: 0.9772\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0447 - accuracy: 0.9861\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0492 - accuracy: 0.9893\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0496 - accuracy: 0.9897\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0366 - accuracy: 0.9922\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 936us/step - loss: 0.0347 - accuracy: 0.9928\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.0586 - accuracy: 0.9740\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9679\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9832\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.0564 - accuracy: 0.9829\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0461 - accuracy: 0.9811\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0479 - accuracy: 0.9826\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0321 - accuracy: 0.9955\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0611 - accuracy: 0.9762\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0426 - accuracy: 0.9841\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0406 - accuracy: 0.9838\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0254 - accuracy: 0.9934\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0242 - accuracy: 0.9919\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0234 - accuracy: 0.9934\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0231 - accuracy: 0.9949\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0360 - accuracy: 0.9863\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0232 - accuracy: 0.9949\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0251 - accuracy: 0.9956\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9977\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0203 - accuracy: 0.9962\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9956\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9989\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9853\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9945\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9932\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9973\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9958\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0248 - accuracy: 0.9911\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0212 - accuracy: 0.9931\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0125 - accuracy: 0.9986\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0135 - accuracy: 0.9994\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0150 - accuracy: 0.9990\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0211 - accuracy: 0.9963\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0140 - accuracy: 0.9988\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0130 - accuracy: 0.9978\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9938\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0133 - accuracy: 0.9986\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0164 - accuracy: 0.9970\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9952\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.0175 - accuracy: 0.9948\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0188 - accuracy: 0.9890\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.0171 - accuracy: 0.9960\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0209 - accuracy: 0.9936\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0177 - accuracy: 0.9974\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0237 - accuracy: 0.9919\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0166 - accuracy: 0.9960\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0234 - accuracy: 0.9951\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0194 - accuracy: 0.9971\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0145 - accuracy: 0.9980\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0143 - accuracy: 0.9993\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0202 - accuracy: 0.9979\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0265 - accuracy: 0.9940\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0306 - accuracy: 0.9888\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0250 - accuracy: 0.9960\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0212 - accuracy: 0.9928\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0094 - accuracy: 0.9988\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0166 - accuracy: 0.9960\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0132 - accuracy: 0.9994\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0141 - accuracy: 0.9945\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0208 - accuracy: 0.9952\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9994\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9973\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9956\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9979\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0432 - accuracy: 0.9816\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0306 - accuracy: 0.9868\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0153 - accuracy: 0.9943\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.0250 - accuracy: 0.9916\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 745us/step - loss: 0.0089 - accuracy: 0.9998\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0249 - accuracy: 0.9944\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 785us/step - loss: 0.0165 - accuracy: 0.9929\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0225 - accuracy: 0.9900\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0156 - accuracy: 0.9954\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0105 - accuracy: 0.9997\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 869us/step - loss: 0.0176 - accuracy: 0.9927\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0179 - accuracy: 0.9964\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0203 - accuracy: 0.9928\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0105 - accuracy: 0.9992\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0106 - accuracy: 0.9985\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0266 - accuracy: 0.9897\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0081 - accuracy: 0.9987\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.0147 - accuracy: 0.9965\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0216 - accuracy: 0.9951\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0154 - accuracy: 0.9938\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0110 - accuracy: 0.9976\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.0199 - accuracy: 0.9951\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9938\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 0.9995\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0072 - accuracy: 0.9994\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9955\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9978\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9893\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9988\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9986\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9919\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9996\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9922\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9881\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9880\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9919\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9890\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0173 - accuracy: 0.9950\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9894\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9924\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0079 - accuracy: 0.9978\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.0108 - accuracy: 0.9990\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0092 - accuracy: 0.9975\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0140 - accuracy: 0.9950\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0136 - accuracy: 0.9967\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0054 - accuracy: 0.9993\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7760a3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 853us/step - loss: 0.9691 - accuracy: 0.5883\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 740us/step - loss: 0.4497 - accuracy: 0.8495\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.4039 - accuracy: 0.8221\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.3776 - accuracy: 0.8483\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.3412 - accuracy: 0.8497\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.3387 - accuracy: 0.8450\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.3163 - accuracy: 0.8563\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.3106 - accuracy: 0.8707\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.2922 - accuracy: 0.8832\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.2912 - accuracy: 0.8765\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.2964 - accuracy: 0.8683\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.2636 - accuracy: 0.8900\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.2539 - accuracy: 0.8891\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.2915 - accuracy: 0.8660\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.2579 - accuracy: 0.8782\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.3163 - accuracy: 0.8685\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.2641 - accuracy: 0.8809\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.2561 - accuracy: 0.8973\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.2350 - accuracy: 0.9002\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.2356 - accuracy: 0.8828\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.2307 - accuracy: 0.8951\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.2009 - accuracy: 0.9182\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.2240 - accuracy: 0.9239\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.1979 - accuracy: 0.9162\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1891 - accuracy: 0.9328\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1945 - accuracy: 0.9221\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.1886 - accuracy: 0.9129\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.1819 - accuracy: 0.9253\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.1668 - accuracy: 0.9388\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1810 - accuracy: 0.9337\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.1402 - accuracy: 0.9434\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.1615 - accuracy: 0.9448\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1976 - accuracy: 0.9165\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.1543 - accuracy: 0.9409\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.1341 - accuracy: 0.9449\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.1488 - accuracy: 0.9433\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1453 - accuracy: 0.9491\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.1346 - accuracy: 0.9507\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.1197 - accuracy: 0.9580\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.1527 - accuracy: 0.9308\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9662\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9577\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9613\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.9669\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9669\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9730\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.1454 - accuracy: 0.9479\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9542\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9560\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0844 - accuracy: 0.9746\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9520\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9660\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9696\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.0979 - accuracy: 0.9677\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.0861 - accuracy: 0.9794\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9898\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9479\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0900 - accuracy: 0.9704\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9752\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9684\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0764 - accuracy: 0.9704\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0883 - accuracy: 0.9741\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0765 - accuracy: 0.9710\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0720 - accuracy: 0.9856\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0742 - accuracy: 0.9798\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0555 - accuracy: 0.9941\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0677 - accuracy: 0.9730\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0796 - accuracy: 0.9754\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0757 - accuracy: 0.9784\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0637 - accuracy: 0.9692\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0772 - accuracy: 0.9699\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0563 - accuracy: 0.9953\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0724 - accuracy: 0.9728\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0644 - accuracy: 0.9808\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0598 - accuracy: 0.9768\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0552 - accuracy: 0.9845\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0432 - accuracy: 0.9895\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0472 - accuracy: 0.9863\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0378 - accuracy: 0.9911\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0602 - accuracy: 0.9815\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 861us/step - loss: 0.0570 - accuracy: 0.9884\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0329 - accuracy: 0.9961\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0435 - accuracy: 0.9910\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0440 - accuracy: 0.9867\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0775 - accuracy: 0.9757\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0515 - accuracy: 0.9937\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9786\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9832\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9903\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.0443 - accuracy: 0.9880\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9878\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0424 - accuracy: 0.9974\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9860\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0340 - accuracy: 0.9929\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9924\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0375 - accuracy: 0.9875\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9951\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9920\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0318 - accuracy: 0.9941\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0398 - accuracy: 0.9845\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9903\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9882\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0469 - accuracy: 0.9880\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.0365 - accuracy: 0.9882\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9889\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0396 - accuracy: 0.9852\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9920\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.0509 - accuracy: 0.9763\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0389 - accuracy: 0.9914\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0317 - accuracy: 0.9954\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9846\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0295 - accuracy: 0.9973\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9966\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9921\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0325 - accuracy: 0.9911\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9993\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9934\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9937\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.0288 - accuracy: 0.9964\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0469 - accuracy: 0.9798\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0277 - accuracy: 0.9922\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.0403 - accuracy: 0.9860\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0345 - accuracy: 0.9903\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0286 - accuracy: 0.9981\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0368 - accuracy: 0.9877\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0540 - accuracy: 0.9724\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0389 - accuracy: 0.9882\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0334 - accuracy: 0.9928\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0225 - accuracy: 0.9936\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0167 - accuracy: 0.9961\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0257 - accuracy: 0.9911\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0368 - accuracy: 0.9919\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0226 - accuracy: 0.9944\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0340 - accuracy: 0.9933\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0358 - accuracy: 0.9890\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0460 - accuracy: 0.9861\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0375 - accuracy: 0.9924\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0436 - accuracy: 0.9887\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0353 - accuracy: 0.9840\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.0217 - accuracy: 0.9979\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0185 - accuracy: 0.9985\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0307 - accuracy: 0.9897\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0286 - accuracy: 0.9914\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0274 - accuracy: 0.9921\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0200 - accuracy: 0.9955\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0248 - accuracy: 0.9940\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0297 - accuracy: 0.9890\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0201 - accuracy: 0.9952\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0282 - accuracy: 0.9885\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0277 - accuracy: 0.9920\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0203 - accuracy: 0.9961\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0257 - accuracy: 0.9880\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0241 - accuracy: 0.9931\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0141 - accuracy: 0.9975\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0149 - accuracy: 0.9970\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0253 - accuracy: 0.9944\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0173 - accuracy: 0.9903\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0233 - accuracy: 0.9960\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0206 - accuracy: 0.9944\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0228 - accuracy: 0.9957\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 873us/step - loss: 0.0201 - accuracy: 0.9958\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0172 - accuracy: 0.9970\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0168 - accuracy: 0.9935\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0275 - accuracy: 0.9948\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0275 - accuracy: 0.9907\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0265 - accuracy: 0.9897\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0187 - accuracy: 0.9948\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0139 - accuracy: 0.9959\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0234 - accuracy: 0.9905\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0319 - accuracy: 0.9890\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0156 - accuracy: 0.9991\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0286 - accuracy: 0.9893\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 970us/step - loss: 0.0177 - accuracy: 0.9959\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0170 - accuracy: 0.9966\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0175 - accuracy: 0.9953\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0174 - accuracy: 0.9933\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0163 - accuracy: 0.9985\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0177 - accuracy: 0.9963\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0208 - accuracy: 0.9988\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0335 - accuracy: 0.9901\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0176 - accuracy: 0.9943\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0155 - accuracy: 0.9985\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0241 - accuracy: 0.9876\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.0185 - accuracy: 0.9939\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0140 - accuracy: 0.9971\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9901\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9955\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9998\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.0128 - accuracy: 0.9948\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9943\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0139 - accuracy: 0.9964\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9938\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9973\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9973\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.9987\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9992\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.0148 - accuracy: 0.9938\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9962\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c78cd7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.5842 - accuracy: 0.8152\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.3902 - accuracy: 0.8474\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.3671 - accuracy: 0.8472\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.3847 - accuracy: 0.8333\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.3259 - accuracy: 0.8897\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.2896 - accuracy: 0.8853\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.3373 - accuracy: 0.8516\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.2927 - accuracy: 0.8658\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.2498 - accuracy: 0.8964\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.2604 - accuracy: 0.9179\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.2689 - accuracy: 0.8886\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.2293 - accuracy: 0.8983\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.2290 - accuracy: 0.9157\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.2473 - accuracy: 0.9140\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.2116 - accuracy: 0.9138\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.2048 - accuracy: 0.9190\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.2282 - accuracy: 0.9061\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1820 - accuracy: 0.9317\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1962 - accuracy: 0.9219\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1928 - accuracy: 0.9272\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1685 - accuracy: 0.9319\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1634 - accuracy: 0.9412\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1744 - accuracy: 0.9195\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1896 - accuracy: 0.9322\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.1630 - accuracy: 0.9357\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.1542 - accuracy: 0.9391\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1419 - accuracy: 0.9513\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1430 - accuracy: 0.9487\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1366 - accuracy: 0.9568\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1318 - accuracy: 0.9598\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1789 - accuracy: 0.9394\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1528 - accuracy: 0.9385\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1627 - accuracy: 0.9473\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1158 - accuracy: 0.9724\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.1311 - accuracy: 0.9572\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1175 - accuracy: 0.9583\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.1097 - accuracy: 0.9580\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1107 - accuracy: 0.9615\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1120 - accuracy: 0.9633\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1150 - accuracy: 0.9437\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1232 - accuracy: 0.9556\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1064 - accuracy: 0.9746\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1233 - accuracy: 0.9591\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1193 - accuracy: 0.9553\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0996 - accuracy: 0.9686\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0820 - accuracy: 0.9698\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0974 - accuracy: 0.9602\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.0746 - accuracy: 0.9824\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0815 - accuracy: 0.9815\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0701 - accuracy: 0.9816\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0850 - accuracy: 0.9754\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0777 - accuracy: 0.9832\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0723 - accuracy: 0.9808\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1007 - accuracy: 0.9573\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0875 - accuracy: 0.9758\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0793 - accuracy: 0.9715\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0647 - accuracy: 0.9844\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0535 - accuracy: 0.9848\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0610 - accuracy: 0.9815\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0592 - accuracy: 0.9880\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0481 - accuracy: 0.9924\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0596 - accuracy: 0.9835\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0581 - accuracy: 0.9799\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0577 - accuracy: 0.9870\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0549 - accuracy: 0.9861\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0571 - accuracy: 0.9877\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0635 - accuracy: 0.9810\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.0487 - accuracy: 0.9913\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.0609 - accuracy: 0.9876\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0613 - accuracy: 0.9866\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.0555 - accuracy: 0.9844\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0976 - accuracy: 0.9692\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0805 - accuracy: 0.9690\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0444 - accuracy: 0.9917\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0456 - accuracy: 0.9874\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0411 - accuracy: 0.9911\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0365 - accuracy: 0.9931\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0352 - accuracy: 0.9951\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0392 - accuracy: 0.9930\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0497 - accuracy: 0.9887\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 827us/step - loss: 0.0515 - accuracy: 0.9835\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0369 - accuracy: 0.9885\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0359 - accuracy: 0.9914\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0449 - accuracy: 0.9895\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0498 - accuracy: 0.9825\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0345 - accuracy: 0.9932\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0382 - accuracy: 0.9956\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0427 - accuracy: 0.9914\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0475 - accuracy: 0.9874\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0352 - accuracy: 0.9932\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0248 - accuracy: 0.9976\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0336 - accuracy: 0.9910\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0358 - accuracy: 0.9929\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0407 - accuracy: 0.9906\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0323 - accuracy: 0.9940\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0327 - accuracy: 0.9931\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0299 - accuracy: 0.9898\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0419 - accuracy: 0.9887\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0413 - accuracy: 0.9905\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0316 - accuracy: 0.9900\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0309 - accuracy: 0.9946\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0202 - accuracy: 0.9990\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0233 - accuracy: 0.9927\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0276 - accuracy: 0.9906\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0283 - accuracy: 0.9956\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0208 - accuracy: 0.9953\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0217 - accuracy: 0.9983\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0247 - accuracy: 0.9996\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0329 - accuracy: 0.9903\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0260 - accuracy: 0.9934\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0226 - accuracy: 0.9943\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0331 - accuracy: 0.9891\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0186 - accuracy: 0.9959\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0217 - accuracy: 0.9918\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0162 - accuracy: 0.9988\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0307 - accuracy: 0.9910\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0159 - accuracy: 0.9986\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0207 - accuracy: 0.9947\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0198 - accuracy: 0.9965\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0254 - accuracy: 0.9936\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0186 - accuracy: 0.9998\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0269 - accuracy: 0.9905\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0159 - accuracy: 0.9981\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0286 - accuracy: 0.9909\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0315 - accuracy: 0.9926\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0423 - accuracy: 0.9876\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0437 - accuracy: 0.9840\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0383 - accuracy: 0.9877\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0428 - accuracy: 0.9824\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0288 - accuracy: 0.9874\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0326 - accuracy: 0.9872\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0346 - accuracy: 0.9935\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0220 - accuracy: 0.9943\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0207 - accuracy: 0.9959\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0159 - accuracy: 0.9967\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0270 - accuracy: 0.9831\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0148 - accuracy: 0.9970\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0526 - accuracy: 0.9864\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0454 - accuracy: 0.9749\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0232 - accuracy: 0.9974\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0208 - accuracy: 0.9929\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0218 - accuracy: 0.9913\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0181 - accuracy: 0.9961\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0286 - accuracy: 0.9899\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0228 - accuracy: 0.9934\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0151 - accuracy: 0.9991\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0340 - accuracy: 0.9886\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0220 - accuracy: 0.9937\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9942\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9888\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9963\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9975\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9862\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9998\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9978\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9964\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0179 - accuracy: 0.9977\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9940\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9967\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9913\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9963\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9901\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9926\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9995\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9935\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9949\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9870\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.0181 - accuracy: 0.9924\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9948\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 0.0175 - accuracy: 0.9930\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.9991\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9987\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9956\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.0104 - accuracy: 0.9967\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0181 - accuracy: 0.9940\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0143 - accuracy: 0.9973\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0153 - accuracy: 0.9957\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0132 - accuracy: 0.9940\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0101 - accuracy: 0.9979\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0149 - accuracy: 0.9969\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0093 - accuracy: 0.9968\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0176 - accuracy: 0.9935\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0153 - accuracy: 0.9966\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0142 - accuracy: 0.9981\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0121 - accuracy: 0.9986\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0116 - accuracy: 0.9989\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0135 - accuracy: 0.9943\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0118 - accuracy: 0.9977\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0124 - accuracy: 0.9988\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0269 - accuracy: 0.9926\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0354 - accuracy: 0.9841\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0265 - accuracy: 0.9952\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0079 - accuracy: 0.9997\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9976\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7b7a63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7611 - accuracy: 0.6939\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8305\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8572\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8726\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8632\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3038 - accuracy: 0.8592\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8845\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.2849 - accuracy: 0.8807\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.2700 - accuracy: 0.8878\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8840\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.8661\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.2821 - accuracy: 0.8813\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.2368 - accuracy: 0.8960\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.2587 - accuracy: 0.8919\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.2461 - accuracy: 0.8991\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.2339 - accuracy: 0.9153\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.2044 - accuracy: 0.9267\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 965us/step - loss: 0.2086 - accuracy: 0.9226\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.2026 - accuracy: 0.9037\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1908 - accuracy: 0.9299\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.2006 - accuracy: 0.9141\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.1698 - accuracy: 0.9421\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.1971 - accuracy: 0.9104\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.1817 - accuracy: 0.9325\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.1669 - accuracy: 0.9413\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.1675 - accuracy: 0.9279\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.1500 - accuracy: 0.9447\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.1878 - accuracy: 0.9421\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1681 - accuracy: 0.9257\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1450 - accuracy: 0.9464\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.1472 - accuracy: 0.9497\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.1257 - accuracy: 0.9535\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.1275 - accuracy: 0.9617\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1380 - accuracy: 0.9474\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.1285 - accuracy: 0.9599\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.1633 - accuracy: 0.9335\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.1556 - accuracy: 0.9434\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1046 - accuracy: 0.9671\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 989us/step - loss: 0.1018 - accuracy: 0.9635\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.1093 - accuracy: 0.9623\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9649\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9504\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.9512\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9634\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9603\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9650\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9543\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9467\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9512\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9701\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9703\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0936 - accuracy: 0.9729\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0856 - accuracy: 0.9675\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9756\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9876\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9736\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0756 - accuracy: 0.9673\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9570\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9653\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9674\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.9751\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9749\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9909\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9697\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0876 - accuracy: 0.9591\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0599 - accuracy: 0.9820\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0661 - accuracy: 0.9757\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0562 - accuracy: 0.9855\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0502 - accuracy: 0.9902\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0496 - accuracy: 0.9891\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0489 - accuracy: 0.9828\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0578 - accuracy: 0.9842\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0599 - accuracy: 0.9822\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0618 - accuracy: 0.9799\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0535 - accuracy: 0.9776\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0445 - accuracy: 0.9867\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0371 - accuracy: 0.9897\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0726 - accuracy: 0.9704\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 782us/step - loss: 0.0456 - accuracy: 0.9870\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.0406 - accuracy: 0.9948\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 792us/step - loss: 0.0401 - accuracy: 0.9923\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 827us/step - loss: 0.0453 - accuracy: 0.9826\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0494 - accuracy: 0.9880\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0385 - accuracy: 0.9903\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0324 - accuracy: 0.9942\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0500 - accuracy: 0.9808\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0636 - accuracy: 0.9751\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0437 - accuracy: 0.9773\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0372 - accuracy: 0.9879\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0361 - accuracy: 0.9929\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0314 - accuracy: 0.9955\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0361 - accuracy: 0.9943\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0541 - accuracy: 0.9766\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0328 - accuracy: 0.9916\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0438 - accuracy: 0.9885\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0293 - accuracy: 0.9902\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0385 - accuracy: 0.9911\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0431 - accuracy: 0.9882\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0304 - accuracy: 0.9956\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0375 - accuracy: 0.9903\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0342 - accuracy: 0.9897\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0369 - accuracy: 0.9913\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0264 - accuracy: 0.9923\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0423 - accuracy: 0.9888\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0290 - accuracy: 0.9941\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0259 - accuracy: 0.9973\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0191 - accuracy: 0.9991\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0234 - accuracy: 0.9934\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0262 - accuracy: 0.9965\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0297 - accuracy: 0.9985\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0406 - accuracy: 0.9863\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0231 - accuracy: 0.9905\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0232 - accuracy: 0.9940\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0270 - accuracy: 0.9957\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0336 - accuracy: 0.9931\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0429 - accuracy: 0.9905\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0370 - accuracy: 0.9849\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0301 - accuracy: 0.9932\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0264 - accuracy: 0.9951\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0248 - accuracy: 0.9930\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0261 - accuracy: 0.9904\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0373 - accuracy: 0.9938\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0340 - accuracy: 0.9857\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0386 - accuracy: 0.9840\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0329 - accuracy: 0.9852\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0223 - accuracy: 0.9970\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9902\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0188 - accuracy: 0.9963\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0378 - accuracy: 0.9850\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0340 - accuracy: 0.9854\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0183 - accuracy: 0.9981\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0177 - accuracy: 0.9928\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0253 - accuracy: 0.9932\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0213 - accuracy: 0.9968\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0700 - accuracy: 0.9720\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0327 - accuracy: 0.9893\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0241 - accuracy: 0.9913\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0256 - accuracy: 0.9899\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0152 - accuracy: 0.9977\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0179 - accuracy: 0.9929\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0278 - accuracy: 0.9912\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0521 - accuracy: 0.9751\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0291 - accuracy: 0.9930\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0307 - accuracy: 0.9888\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0261 - accuracy: 0.9922\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0500 - accuracy: 0.9816\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0575 - accuracy: 0.9743\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0275 - accuracy: 0.9961\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0281 - accuracy: 0.9930\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0217 - accuracy: 0.9939\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0165 - accuracy: 0.9934\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0256 - accuracy: 0.9907\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0240 - accuracy: 0.9958\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0271 - accuracy: 0.9874\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0195 - accuracy: 0.9978\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0211 - accuracy: 0.9967\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0127 - accuracy: 0.9977\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0211 - accuracy: 0.9931\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0223 - accuracy: 0.9933\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.0220 - accuracy: 0.9946\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 809us/step - loss: 0.0155 - accuracy: 0.9969\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0196 - accuracy: 0.9932\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0195 - accuracy: 0.9938\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 778us/step - loss: 0.0165 - accuracy: 0.9975\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0096 - accuracy: 0.9988\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0107 - accuracy: 0.9995\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0172 - accuracy: 0.9953\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0110 - accuracy: 0.9998\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0151 - accuracy: 0.9944\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0152 - accuracy: 0.9954\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0105 - accuracy: 0.9985\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0144 - accuracy: 0.9986\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0160 - accuracy: 0.9958\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0128 - accuracy: 0.9933\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0253 - accuracy: 0.9937\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0156 - accuracy: 0.9974\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0161 - accuracy: 0.9970\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0189 - accuracy: 0.9957\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0096 - accuracy: 0.9991\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0133 - accuracy: 0.9961\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0091 - accuracy: 0.9985\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0117 - accuracy: 0.9966\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0091 - accuracy: 0.9994\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0162 - accuracy: 0.9947\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0167 - accuracy: 0.9953\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0096 - accuracy: 0.9982\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 747us/step - loss: 0.0082 - accuracy: 0.9993\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 684us/step - loss: 0.0109 - accuracy: 0.9960\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 687us/step - loss: 0.0127 - accuracy: 0.9943\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 701us/step - loss: 0.0175 - accuracy: 0.9906\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 683us/step - loss: 0.0119 - accuracy: 0.9967\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 660us/step - loss: 0.0204 - accuracy: 0.9919\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 702us/step - loss: 0.0204 - accuracy: 0.9898\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 689us/step - loss: 0.0202 - accuracy: 0.9917\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 697us/step - loss: 0.0160 - accuracy: 0.9969\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 737us/step - loss: 0.0165 - accuracy: 0.9963\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 697us/step - loss: 0.0125 - accuracy: 0.9986\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c739d4700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.7351\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.8648\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8817\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8470\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8706\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8740\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8680\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8821\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8875\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.8948\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8978\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.8974\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.2615 - accuracy: 0.9105\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.9155\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8960\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9091\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9015\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.9305\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9162\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9082\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9083\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9285\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 0.9102\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1655 - accuracy: 0.9295\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9330\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9320\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9341\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1735 - accuracy: 0.9292\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9340\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9335\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1673 - accuracy: 0.9240\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9527\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9399\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9383\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9478\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 990us/step - loss: 0.1408 - accuracy: 0.9454\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.1142 - accuracy: 0.9579\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9498\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9509\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9405\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 998us/step - loss: 0.1231 - accuracy: 0.9569\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9595\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9496\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9540\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9527\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9415\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9683\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9396\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9609\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9547\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9593\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9652\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9716\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9721\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9572\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.0988 - accuracy: 0.9667\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9834\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0841 - accuracy: 0.9647\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9754\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9704\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9589\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9753\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9707\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9846\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9706\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9721\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9665\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9756\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9770\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9742\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9836\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9824\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9788\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9719\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9794\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9903\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9809\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9787\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9869\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9962\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9828\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9720\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9847\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9874\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9847\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9905\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9856\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9919\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9881\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9794\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9766\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0467 - accuracy: 0.9903\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9916\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9923\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9898\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9845\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9943\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9933\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9913\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9869\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9940\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9919\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9917\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9890\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9935\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 0.9830\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0402 - accuracy: 0.9850\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.0331 - accuracy: 0.9961\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0430 - accuracy: 0.9865\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0303 - accuracy: 0.9947\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0253 - accuracy: 0.9937\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0217 - accuracy: 0.9996\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0268 - accuracy: 0.9918\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0289 - accuracy: 0.9968\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0285 - accuracy: 0.9918\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0248 - accuracy: 0.9990\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9843\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9910\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9978\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9780\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9955\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.0449 - accuracy: 0.9879\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9979\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0256 - accuracy: 0.9963\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9817\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0296 - accuracy: 0.9928\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0525 - accuracy: 0.9784\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0224 - accuracy: 0.9950\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0292 - accuracy: 0.9929\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0302 - accuracy: 0.9870\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0204 - accuracy: 0.9982\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0322 - accuracy: 0.9903\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0212 - accuracy: 0.9974\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0244 - accuracy: 0.9914\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0257 - accuracy: 0.9960\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0214 - accuracy: 0.9977\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0129 - accuracy: 0.9989\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0261 - accuracy: 0.9960\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0161 - accuracy: 0.9938\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0217 - accuracy: 0.9951\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0380 - accuracy: 0.9937\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0525 - accuracy: 0.9783\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0466 - accuracy: 0.9847\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0489 - accuracy: 0.9762\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0540 - accuracy: 0.9812\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0339 - accuracy: 0.9911\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0281 - accuracy: 0.9916\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0198 - accuracy: 0.9992\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 962us/step - loss: 0.0151 - accuracy: 0.9993\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0385 - accuracy: 0.9856\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9867\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.0230 - accuracy: 0.9948\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0201 - accuracy: 0.9945\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0188 - accuracy: 0.9979\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0228 - accuracy: 0.9959\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0198 - accuracy: 0.9985\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9739\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0311 - accuracy: 0.9823\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9960\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0234 - accuracy: 0.9943\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0282 - accuracy: 0.9916\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 837us/step - loss: 0.0159 - accuracy: 0.9984\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.0244 - accuracy: 0.9948\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 982us/step - loss: 0.0147 - accuracy: 0.9989\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9925\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9908\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9971\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.0146 - accuracy: 0.9971\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9965\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0186 - accuracy: 0.9924\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0142 - accuracy: 0.9983\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0280 - accuracy: 0.9941\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0347 - accuracy: 0.9881\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0197 - accuracy: 0.9966\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0168 - accuracy: 0.9989\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0202 - accuracy: 0.9906\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0325 - accuracy: 0.9921\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0444 - accuracy: 0.9800\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0303 - accuracy: 0.9982\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0202 - accuracy: 0.9969\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0242 - accuracy: 0.9934\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0303 - accuracy: 0.9892\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0276 - accuracy: 0.9915\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0219 - accuracy: 0.9935\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0152 - accuracy: 0.9994\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0281 - accuracy: 0.9924\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0253 - accuracy: 0.9922\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0217 - accuracy: 0.9969\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0213 - accuracy: 0.9964\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0089 - accuracy: 0.9979\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0107 - accuracy: 0.9989\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9970\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.9983\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9902\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9942\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9948\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 824us/step - loss: 0.6024 - accuracy: 0.7706\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.3824 - accuracy: 0.8783\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.3182 - accuracy: 0.8773\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.3450 - accuracy: 0.8762\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.3211 - accuracy: 0.8817\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.2865 - accuracy: 0.8886\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.2916 - accuracy: 0.8849\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.2789 - accuracy: 0.8847\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.2909 - accuracy: 0.8865\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.2658 - accuracy: 0.8835\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.2223 - accuracy: 0.9088\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.2329 - accuracy: 0.9040\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.2503 - accuracy: 0.8971\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.2352 - accuracy: 0.9002\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.2155 - accuracy: 0.9268\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.2190 - accuracy: 0.9110\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.2236 - accuracy: 0.9063\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.2134 - accuracy: 0.9200\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1948 - accuracy: 0.9361\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.2019 - accuracy: 0.9225\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1796 - accuracy: 0.9397\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1827 - accuracy: 0.9203\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.1677 - accuracy: 0.9289\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1656 - accuracy: 0.9392\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1420 - accuracy: 0.9511\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1514 - accuracy: 0.9460\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.1451 - accuracy: 0.9573\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1625 - accuracy: 0.9450\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1330 - accuracy: 0.9617\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1520 - accuracy: 0.9375\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1174 - accuracy: 0.9524\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.1401 - accuracy: 0.9624\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.1275 - accuracy: 0.9493\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1263 - accuracy: 0.9622\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.1083 - accuracy: 0.9692\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1024 - accuracy: 0.9637\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1046 - accuracy: 0.9626\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.1254 - accuracy: 0.9472\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0980 - accuracy: 0.9672\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0933 - accuracy: 0.9577\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.1073 - accuracy: 0.9644\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0954 - accuracy: 0.9676\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0729 - accuracy: 0.9787\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0934 - accuracy: 0.9527\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0804 - accuracy: 0.9736\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0783 - accuracy: 0.9765\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0827 - accuracy: 0.9761\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0827 - accuracy: 0.9672\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1254 - accuracy: 0.9613\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0891 - accuracy: 0.9670\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0817 - accuracy: 0.9712\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0638 - accuracy: 0.9812\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0640 - accuracy: 0.9798\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0866 - accuracy: 0.9670\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.1121 - accuracy: 0.9536\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0809 - accuracy: 0.9684\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0913 - accuracy: 0.9712\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0645 - accuracy: 0.9845\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.0617 - accuracy: 0.9860\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.0426 - accuracy: 0.9931\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0658 - accuracy: 0.9840\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0725 - accuracy: 0.9831\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0704 - accuracy: 0.9841\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0494 - accuracy: 0.9885\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0685 - accuracy: 0.9625\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0657 - accuracy: 0.9873\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0513 - accuracy: 0.9928\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0434 - accuracy: 0.9890\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0416 - accuracy: 0.9885\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0658 - accuracy: 0.9793\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.0558 - accuracy: 0.9791\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0487 - accuracy: 0.9865\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0312 - accuracy: 0.9967\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0299 - accuracy: 0.9955\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0391 - accuracy: 0.9914\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.0476 - accuracy: 0.9805\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0255 - accuracy: 0.9977\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0296 - accuracy: 0.9936\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0486 - accuracy: 0.9823\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.0407 - accuracy: 0.9885\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 816us/step - loss: 0.0334 - accuracy: 0.9880\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 801us/step - loss: 0.0263 - accuracy: 0.9919\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.0285 - accuracy: 0.9898\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0300 - accuracy: 0.9926\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0525 - accuracy: 0.9779\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0317 - accuracy: 0.9893\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0309 - accuracy: 0.9926\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0285 - accuracy: 0.9887\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0331 - accuracy: 0.9929\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0326 - accuracy: 0.9935\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0207 - accuracy: 0.9996\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0160 - accuracy: 0.9978\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0241 - accuracy: 0.9966\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0320 - accuracy: 0.9927\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0268 - accuracy: 0.9913\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0256 - accuracy: 0.9944\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0187 - accuracy: 0.9965\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0187 - accuracy: 0.9990\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0235 - accuracy: 0.9940\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0201 - accuracy: 0.9994\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.0187 - accuracy: 0.9955\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.0246 - accuracy: 0.9937\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0287 - accuracy: 0.9919\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0265 - accuracy: 0.9896\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0259 - accuracy: 0.9910\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0303 - accuracy: 0.9918\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0305 - accuracy: 0.9947\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0220 - accuracy: 0.9966\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0239 - accuracy: 0.9941\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0227 - accuracy: 0.9924\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0237 - accuracy: 0.9940\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0204 - accuracy: 0.9954\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0211 - accuracy: 0.9969\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0248 - accuracy: 0.9930\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0147 - accuracy: 0.9985\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0184 - accuracy: 0.9943\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0153 - accuracy: 0.9986\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0217 - accuracy: 0.9904\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0177 - accuracy: 0.9955\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0135 - accuracy: 0.9995\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0153 - accuracy: 0.9935\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0244 - accuracy: 0.9921\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0130 - accuracy: 0.9977\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0137 - accuracy: 0.9987\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0130 - accuracy: 0.9977\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0140 - accuracy: 0.9960\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0102 - accuracy: 0.9988\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0148 - accuracy: 0.9976\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0142 - accuracy: 0.9982\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0104 - accuracy: 0.9993\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0132 - accuracy: 0.9986\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0113 - accuracy: 0.9982\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0174 - accuracy: 0.9961\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0109 - accuracy: 0.9994\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0093 - accuracy: 0.9996\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.0139 - accuracy: 0.9952\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0099 - accuracy: 0.9961\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0147 - accuracy: 0.9975\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0172 - accuracy: 0.9942\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0117 - accuracy: 0.9950\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0105 - accuracy: 0.9993\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0147 - accuracy: 0.9964\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0181 - accuracy: 0.9920\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0157 - accuracy: 0.9980\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 795us/step - loss: 0.0249 - accuracy: 0.9918\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0222 - accuracy: 0.9923\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0219 - accuracy: 0.9933\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0262 - accuracy: 0.9894\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0163 - accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0175 - accuracy: 0.9934\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0206 - accuracy: 0.9970\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0107 - accuracy: 0.9988\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0169 - accuracy: 0.9914\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0129 - accuracy: 0.9975\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0135 - accuracy: 0.9966\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0121 - accuracy: 0.9968\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 814us/step - loss: 0.0201 - accuracy: 0.9933\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 780us/step - loss: 0.0257 - accuracy: 0.9914\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0184 - accuracy: 0.9935\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0088 - accuracy: 0.9996\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0190 - accuracy: 0.9946\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0183 - accuracy: 0.9912\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0232 - accuracy: 0.9904\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0113 - accuracy: 0.9992\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0130 - accuracy: 0.9940\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0083 - accuracy: 0.9980\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0157 - accuracy: 0.9927\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0182 - accuracy: 0.9950\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0111 - accuracy: 0.9979\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0094 - accuracy: 0.9961\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0072 - accuracy: 0.9991\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0212 - accuracy: 0.9915\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0181 - accuracy: 0.9944\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9989\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0103 - accuracy: 0.9982\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0076 - accuracy: 0.9967\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0089 - accuracy: 0.9978\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0064 - accuracy: 0.9992\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0094 - accuracy: 0.9975\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0084 - accuracy: 0.9981\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0125 - accuracy: 0.9990\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0072 - accuracy: 0.9986\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0112 - accuracy: 0.9953\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0087 - accuracy: 0.9949\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0092 - accuracy: 0.9958\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 0.9973\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 0.9986\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.8271\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8838\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.3308 - accuracy: 0.8860\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8897\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8903\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2712 - accuracy: 0.8964\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.8762\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8959\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.2820 - accuracy: 0.8837\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.2637 - accuracy: 0.8999\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.2446 - accuracy: 0.8991\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.2648 - accuracy: 0.8808\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.2011 - accuracy: 0.9231\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.2214 - accuracy: 0.9129\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.2204 - accuracy: 0.9065\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.2207 - accuracy: 0.9061\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1911 - accuracy: 0.9133\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1922 - accuracy: 0.9417\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.1678 - accuracy: 0.9312\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.1760 - accuracy: 0.9337\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.1944 - accuracy: 0.9177\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1766 - accuracy: 0.9225\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1484 - accuracy: 0.9501\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1532 - accuracy: 0.9420\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.1408 - accuracy: 0.9417\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1585 - accuracy: 0.9413\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1479 - accuracy: 0.9351\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1583 - accuracy: 0.9265\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1337 - accuracy: 0.9453\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.1244 - accuracy: 0.9500\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.1231 - accuracy: 0.9495\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1005 - accuracy: 0.9624\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0888 - accuracy: 0.9673\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1029 - accuracy: 0.9628\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1010 - accuracy: 0.9567\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0910 - accuracy: 0.9728\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1183 - accuracy: 0.9540\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0882 - accuracy: 0.9710\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.1026 - accuracy: 0.9671\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0909 - accuracy: 0.9614\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.1148 - accuracy: 0.9581\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0875 - accuracy: 0.9666\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.0866 - accuracy: 0.9775\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0808 - accuracy: 0.9754\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0962 - accuracy: 0.9679\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0875 - accuracy: 0.9696\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0858 - accuracy: 0.9711\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0663 - accuracy: 0.9777\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0704 - accuracy: 0.9868\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0810 - accuracy: 0.9845\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0764 - accuracy: 0.9797\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0709 - accuracy: 0.9772\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0576 - accuracy: 0.9883\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0431 - accuracy: 0.9872\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0429 - accuracy: 0.9926\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.0595 - accuracy: 0.9805\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0642 - accuracy: 0.9780\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0571 - accuracy: 0.9831\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0518 - accuracy: 0.9779\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0613 - accuracy: 0.9915\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0688 - accuracy: 0.9720\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 795us/step - loss: 0.0523 - accuracy: 0.9872\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0837 - accuracy: 0.9590\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.0776 - accuracy: 0.9706\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0614 - accuracy: 0.9761\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0546 - accuracy: 0.9819\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0404 - accuracy: 0.9915\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.0326 - accuracy: 0.9933\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0402 - accuracy: 0.9874\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0444 - accuracy: 0.9909\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0410 - accuracy: 0.9892\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.0555 - accuracy: 0.9769\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.0375 - accuracy: 0.9937\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0423 - accuracy: 0.9891\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0390 - accuracy: 0.9900\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0502 - accuracy: 0.9845\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.0343 - accuracy: 0.9922\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.0301 - accuracy: 0.9935\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.0380 - accuracy: 0.9889\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0352 - accuracy: 0.9944\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 818us/step - loss: 0.0321 - accuracy: 0.9890\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0253 - accuracy: 0.9950\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.0230 - accuracy: 0.9963\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0337 - accuracy: 0.9899\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0330 - accuracy: 0.9923\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0352 - accuracy: 0.9862\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0259 - accuracy: 0.9969\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0366 - accuracy: 0.9924\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0360 - accuracy: 0.9910\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0362 - accuracy: 0.9829\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0353 - accuracy: 0.9865\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9957\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9943\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9889\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9951\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9948\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9940\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9966\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9965\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9905\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9965\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9930\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 979us/step - loss: 0.0213 - accuracy: 0.9961\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9973\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0464 - accuracy: 0.9786\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0383 - accuracy: 0.9853\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0242 - accuracy: 0.9959\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0242 - accuracy: 0.9914\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0171 - accuracy: 0.9976\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9986\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9960\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9978\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.0257 - accuracy: 0.9929\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0269 - accuracy: 0.9913\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.0223 - accuracy: 0.9928\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0164 - accuracy: 0.9944\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0137 - accuracy: 0.9987\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0266 - accuracy: 0.9950\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0236 - accuracy: 0.9891\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 807us/step - loss: 0.0163 - accuracy: 0.9980\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.0174 - accuracy: 0.9934\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0217 - accuracy: 0.9945\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0140 - accuracy: 0.9998\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0141 - accuracy: 0.9995\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 799us/step - loss: 0.0196 - accuracy: 0.9980\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0220 - accuracy: 0.9901\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0139 - accuracy: 0.9952\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.0115 - accuracy: 0.9980\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0174 - accuracy: 0.9982\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0304 - accuracy: 0.9869\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0232 - accuracy: 0.9927\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0162 - accuracy: 0.9972\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0171 - accuracy: 0.9972\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0112 - accuracy: 0.9989\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.0210 - accuracy: 0.9898\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0153 - accuracy: 0.9992\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 784us/step - loss: 0.0205 - accuracy: 0.9870\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.0123 - accuracy: 0.9997\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0235 - accuracy: 0.9896\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.0083 - accuracy: 0.9992\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0112 - accuracy: 0.9974\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0201 - accuracy: 0.9961\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 772us/step - loss: 0.0134 - accuracy: 0.9978\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.0156 - accuracy: 0.9966\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.0095 - accuracy: 0.9984\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 779us/step - loss: 0.0240 - accuracy: 0.9949\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0255 - accuracy: 0.9920\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0181 - accuracy: 0.9997\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.0111 - accuracy: 0.9993\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0123 - accuracy: 0.9961\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9886\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9976\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 853us/step - loss: 0.0103 - accuracy: 0.9990\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9906\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9978\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9973\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9899\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9929\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9974\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9961\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.0157 - accuracy: 0.9921\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.0149 - accuracy: 0.9955\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9973\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9998\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9894\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9969\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9861\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0194 - accuracy: 0.9948\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9842\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0397 - accuracy: 0.9839\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0169 - accuracy: 0.9954\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0136 - accuracy: 0.9991\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0068 - accuracy: 0.9996\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0128 - accuracy: 0.9941\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0084 - accuracy: 0.9997\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0115 - accuracy: 0.9949\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0254 - accuracy: 0.9936\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0129 - accuracy: 0.9977\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0152 - accuracy: 0.9938\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0096 - accuracy: 0.9985\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.0209 - accuracy: 0.9855\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0290 - accuracy: 0.9898\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0267 - accuracy: 0.9931\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0107 - accuracy: 0.9974\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0205 - accuracy: 0.9916\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0079 - accuracy: 0.9993\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0063 - accuracy: 0.9996\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0138 - accuracy: 0.9965\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0070 - accuracy: 0.9990\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0102 - accuracy: 0.9956\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 770us/step - loss: 0.5402 - accuracy: 0.8500\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.3537 - accuracy: 0.8846\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.3603 - accuracy: 0.8732\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.3273 - accuracy: 0.8844\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.2888 - accuracy: 0.8926\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.2714 - accuracy: 0.9029\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.2967 - accuracy: 0.8901\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.8894\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.9040\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.9144\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.8826\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9217\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.2374 - accuracy: 0.9092\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2297 - accuracy: 0.9094\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1738 - accuracy: 0.9232\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9050\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9003\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.9279\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.1851 - accuracy: 0.9319\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9352\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9313\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.9413\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9441\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9441\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9432\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9452\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.1523 - accuracy: 0.9373\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9475\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9442\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9602\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9634\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9501\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9562\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9498\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9533\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9703\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9666\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9756\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9637\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1132 - accuracy: 0.9626\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0990 - accuracy: 0.9573\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.0785 - accuracy: 0.9674\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0771 - accuracy: 0.9764\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1165 - accuracy: 0.9572\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1176 - accuracy: 0.9528\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0761 - accuracy: 0.9789\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.0776 - accuracy: 0.9725\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9788\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9746\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.0767 - accuracy: 0.9640\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9716\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9770\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0797 - accuracy: 0.9689\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9766\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9894\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9897\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.0575 - accuracy: 0.9852\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9794\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9948\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9871\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9794\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9762\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9741\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 992us/step - loss: 0.0498 - accuracy: 0.9819\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9814\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9872\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9760\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9920\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9764\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9903\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9904\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9917\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9891\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9800\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9851\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9844\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9887\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0313 - accuracy: 0.9921\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0294 - accuracy: 0.9980\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0363 - accuracy: 0.9847\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0283 - accuracy: 0.9970\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9845\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9910\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9952\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9791\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9930\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9945\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9903\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9722\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9915\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9919\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9958\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9945\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9923\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 978us/step - loss: 0.0279 - accuracy: 0.9912\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9848\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9906\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9893\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9914\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9984\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9766\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9878\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9817\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9874\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9974\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9889\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 986us/step - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0251 - accuracy: 0.9938\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0205 - accuracy: 0.9957\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0997 - accuracy: 0.9617\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0546 - accuracy: 0.9855\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0273 - accuracy: 0.9947\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0397 - accuracy: 0.9887\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0403 - accuracy: 0.9840\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0337 - accuracy: 0.9915\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0616 - accuracy: 0.9831\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0435 - accuracy: 0.9860\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0419 - accuracy: 0.9839\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0375 - accuracy: 0.9865\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0299 - accuracy: 0.9885\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0225 - accuracy: 0.9984\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0408 - accuracy: 0.9830\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0220 - accuracy: 0.9996\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.0159 - accuracy: 0.9984\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.0236 - accuracy: 0.9918\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0359 - accuracy: 0.9848\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0363 - accuracy: 0.9887\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0393 - accuracy: 0.9860\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.0345 - accuracy: 0.9885\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0286 - accuracy: 0.9970\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0359 - accuracy: 0.9814\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0262 - accuracy: 0.9887\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0199 - accuracy: 0.9957\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0143 - accuracy: 0.9988\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 0.9958\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0167 - accuracy: 0.9968\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9987\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9951\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9908\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9905\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9955\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9962\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0149 - accuracy: 0.9976\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9990\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9983\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9901\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9966\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0121 - accuracy: 0.9964\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9978\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9980\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9910\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9922\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9978\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 0.9996\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9971\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9938\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9890\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 0.9951\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9958\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9960\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9883\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9900\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0102 - accuracy: 0.9960\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0120 - accuracy: 0.9996\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0121 - accuracy: 0.9989\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0296 - accuracy: 0.9845\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.0211 - accuracy: 0.9955\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0167 - accuracy: 0.9972\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9961\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9816\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9801\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9906\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.9939\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9847\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9961\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9927\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9839\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9911\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9927\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9967\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9806\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9961\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9903\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9910\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9901\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9973\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9995\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9865\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9892\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9981\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9916\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9946\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9953\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9978\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9971\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9930\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9901\n",
      "WARNING:tensorflow:5 out of the last 83 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c75b58040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 888us/step - loss: 0.7196 - accuracy: 0.7326\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.3413 - accuracy: 0.8894\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.3610 - accuracy: 0.8708\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8719\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.3238 - accuracy: 0.8800\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8916\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8809\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8849\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.9016\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8787\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2741 - accuracy: 0.8835\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.8854\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2621 - accuracy: 0.8981\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8977\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2610 - accuracy: 0.8942\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9084\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.9334\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.9084\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.9096\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.9335\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9276\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9340\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9123\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.9174\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9115\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.9213\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.9192\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9311\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 994us/step - loss: 0.1707 - accuracy: 0.9225\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 966us/step - loss: 0.1608 - accuracy: 0.9401\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9357\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.1659 - accuracy: 0.9274\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.1465 - accuracy: 0.9501\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.1342 - accuracy: 0.9616\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1407 - accuracy: 0.9475\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1344 - accuracy: 0.9593\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1300 - accuracy: 0.9539\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.1399 - accuracy: 0.9610\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.1544 - accuracy: 0.9284\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.1566 - accuracy: 0.9391\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1143 - accuracy: 0.9574\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1283 - accuracy: 0.9609\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1275 - accuracy: 0.9620\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1164 - accuracy: 0.9605\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0984 - accuracy: 0.9641\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.1194 - accuracy: 0.9545\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1140 - accuracy: 0.9556\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1005 - accuracy: 0.9715\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0949 - accuracy: 0.9701\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0762 - accuracy: 0.9745\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.1066 - accuracy: 0.9638\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0924 - accuracy: 0.9627\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0819 - accuracy: 0.9773\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0905 - accuracy: 0.9725\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0871 - accuracy: 0.9663\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0766 - accuracy: 0.9690\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0956 - accuracy: 0.9776\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0843 - accuracy: 0.9710\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0761 - accuracy: 0.9803\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.9689\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9727\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9816\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9755\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9900\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9757\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9807\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9818\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0628 - accuracy: 0.9826\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9803\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9772\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9890\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0494 - accuracy: 0.9838\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9845\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 0.9834\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9756\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0470 - accuracy: 0.9885\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9749\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9859\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0675 - accuracy: 0.9777\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9898\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9847\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9923\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9871\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.0393 - accuracy: 0.9843\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0476 - accuracy: 0.9802\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.0423 - accuracy: 0.9865\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.0472 - accuracy: 0.9872\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0535 - accuracy: 0.9851\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0371 - accuracy: 0.9913\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0368 - accuracy: 0.9927\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0331 - accuracy: 0.9978\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0410 - accuracy: 0.9874\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0422 - accuracy: 0.9868\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0405 - accuracy: 0.9884\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0320 - accuracy: 0.9942\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0326 - accuracy: 0.9915\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0486 - accuracy: 0.9847\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0361 - accuracy: 0.9915\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0334 - accuracy: 0.9886\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0482 - accuracy: 0.9894\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0265 - accuracy: 0.9973\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0274 - accuracy: 0.9960\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0344 - accuracy: 0.9875\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0368 - accuracy: 0.9854\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0428 - accuracy: 0.9917\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0332 - accuracy: 0.9891\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9907\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9929\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9949\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9968\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9877\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9984\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9934\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0410 - accuracy: 0.9939\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9838\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9853\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9925\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9975\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9995\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9977\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9944\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9885\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9855\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9962\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9947\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9962\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9965\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9975\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9747\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0337 - accuracy: 0.9902\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9926\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9982\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9896\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0244 - accuracy: 0.9966\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.0222 - accuracy: 0.9956\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9919\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0166 - accuracy: 0.9916\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0385 - accuracy: 0.9921\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0212 - accuracy: 0.9952\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0293 - accuracy: 0.9895\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0302 - accuracy: 0.9933\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0188 - accuracy: 0.9947\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0209 - accuracy: 0.9925\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0143 - accuracy: 0.9958\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0165 - accuracy: 0.9972\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.0240 - accuracy: 0.9976\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0291 - accuracy: 0.9825\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0174 - accuracy: 0.9984\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0226 - accuracy: 0.9990\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0156 - accuracy: 0.9997\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0201 - accuracy: 0.9977\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0204 - accuracy: 0.9895\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0736 - accuracy: 0.9646\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0538 - accuracy: 0.9775\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0405 - accuracy: 0.9907\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0301 - accuracy: 0.9905\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9931\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9970\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9940\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9876\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0371 - accuracy: 0.9865\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9883\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9849\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9928\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0240 - accuracy: 0.9923\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9955\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9948\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.9974\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.0164 - accuracy: 0.9967\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9902\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9983\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9946\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9966\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9926\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9978\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.9941\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9951\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.0176 - accuracy: 0.9942\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9926\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0080 - accuracy: 0.9983\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0106 - accuracy: 0.9980\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 0.9980\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9959\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9840\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9779\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9840\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9933\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9939\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9919\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9964\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.9983\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9979\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c780724c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 773us/step - loss: 0.7765 - accuracy: 0.7095\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.3929 - accuracy: 0.8630\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8743\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.3425 - accuracy: 0.8774\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.3135 - accuracy: 0.8856\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8841\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.2951 - accuracy: 0.8759\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.2798 - accuracy: 0.8887\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.2307 - accuracy: 0.9048\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.2684 - accuracy: 0.8961\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.2334 - accuracy: 0.9108\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.2429 - accuracy: 0.9116\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.1918 - accuracy: 0.9253\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.2159 - accuracy: 0.9210\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.2456 - accuracy: 0.9062\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.2148 - accuracy: 0.9115\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.2022 - accuracy: 0.9239\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.2011 - accuracy: 0.9177\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1763 - accuracy: 0.9298\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1951 - accuracy: 0.9202\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1953 - accuracy: 0.9328\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.1881 - accuracy: 0.9209\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.1603 - accuracy: 0.9384\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1541 - accuracy: 0.9505\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1406 - accuracy: 0.9616\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.1502 - accuracy: 0.9423\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1468 - accuracy: 0.9392\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.1560 - accuracy: 0.9486\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.1501 - accuracy: 0.9442\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1292 - accuracy: 0.9526\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.1297 - accuracy: 0.9588\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.1565 - accuracy: 0.9368\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.1210 - accuracy: 0.9639\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1216 - accuracy: 0.9637\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.1207 - accuracy: 0.9634\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.1048 - accuracy: 0.9626\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.1357 - accuracy: 0.9544\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1234 - accuracy: 0.9524\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0845 - accuracy: 0.9719\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0974 - accuracy: 0.9664\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.1167 - accuracy: 0.9560\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.0941 - accuracy: 0.9623\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0969 - accuracy: 0.9752\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0946 - accuracy: 0.9692\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0733 - accuracy: 0.9745\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0787 - accuracy: 0.9676\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0885 - accuracy: 0.9679\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0827 - accuracy: 0.9715\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1019 - accuracy: 0.9649\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0794 - accuracy: 0.9721\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0863 - accuracy: 0.9671\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0739 - accuracy: 0.9800\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0789 - accuracy: 0.9723\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0837 - accuracy: 0.9708\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0828 - accuracy: 0.9702\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0699 - accuracy: 0.9756\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0577 - accuracy: 0.9813\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0800 - accuracy: 0.9715\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0753 - accuracy: 0.9823\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0601 - accuracy: 0.9809\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0684 - accuracy: 0.9706\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0515 - accuracy: 0.9822\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0592 - accuracy: 0.9744\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0689 - accuracy: 0.9770\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0465 - accuracy: 0.9852\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0504 - accuracy: 0.9913\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0555 - accuracy: 0.9821\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0439 - accuracy: 0.9895\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0451 - accuracy: 0.9837\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0607 - accuracy: 0.9768\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0550 - accuracy: 0.9816\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0553 - accuracy: 0.9839\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0418 - accuracy: 0.9881\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0386 - accuracy: 0.9897\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0498 - accuracy: 0.9803\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0478 - accuracy: 0.9872\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0369 - accuracy: 0.9873\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0539 - accuracy: 0.9879\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0404 - accuracy: 0.9884\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.0576 - accuracy: 0.9759\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 878us/step - loss: 0.0434 - accuracy: 0.9852\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0372 - accuracy: 0.9911\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0552 - accuracy: 0.9773\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0400 - accuracy: 0.9895\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0355 - accuracy: 0.9940\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0559 - accuracy: 0.9786\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.0437 - accuracy: 0.9847\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0963 - accuracy: 0.9696\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9837\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0378 - accuracy: 0.9921\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0456 - accuracy: 0.9810\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0256 - accuracy: 0.9986\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0410 - accuracy: 0.9794\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0218 - accuracy: 0.9941\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0465 - accuracy: 0.9745\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0416 - accuracy: 0.9844\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0329 - accuracy: 0.9941\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0394 - accuracy: 0.9897\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0353 - accuracy: 0.9887\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0409 - accuracy: 0.9909\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0294 - accuracy: 0.9955\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0169 - accuracy: 0.9984\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0308 - accuracy: 0.9850\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0270 - accuracy: 0.9949\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0247 - accuracy: 0.9902\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0256 - accuracy: 0.9883\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0265 - accuracy: 0.9919\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0280 - accuracy: 0.9912\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.0246 - accuracy: 0.9934\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0230 - accuracy: 0.9962\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0316 - accuracy: 0.9923\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.0250 - accuracy: 0.9951\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0233 - accuracy: 0.9943\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0277 - accuracy: 0.9913\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0221 - accuracy: 0.9926\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0279 - accuracy: 0.9921\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0204 - accuracy: 0.9964\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0201 - accuracy: 0.9959\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0264 - accuracy: 0.9954\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0283 - accuracy: 0.9829\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0205 - accuracy: 0.9953\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0149 - accuracy: 0.9964\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0160 - accuracy: 0.9986\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0161 - accuracy: 0.9998\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0202 - accuracy: 0.9967\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0131 - accuracy: 0.9994\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0317 - accuracy: 0.9850\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0137 - accuracy: 0.9981\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0222 - accuracy: 0.9915\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0142 - accuracy: 0.9960\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0271 - accuracy: 0.9868\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0163 - accuracy: 0.9983\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0216 - accuracy: 0.9938\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0121 - accuracy: 0.9992\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0183 - accuracy: 0.9983\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0109 - accuracy: 0.9960\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0131 - accuracy: 0.9993\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0163 - accuracy: 0.9913\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0223 - accuracy: 0.9943\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0279 - accuracy: 0.9885\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0184 - accuracy: 0.9979\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0223 - accuracy: 0.9915\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0151 - accuracy: 0.9988\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0100 - accuracy: 0.9981\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0301 - accuracy: 0.9860\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0492 - accuracy: 0.9779\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0176 - accuracy: 0.9937\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0116 - accuracy: 0.9948\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0166 - accuracy: 0.9975\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0096 - accuracy: 0.9990\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0163 - accuracy: 0.9927\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0228 - accuracy: 0.9931\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0118 - accuracy: 0.9961\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0119 - accuracy: 0.9969\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0163 - accuracy: 0.9937\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.0161 - accuracy: 0.9980\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 827us/step - loss: 0.0131 - accuracy: 0.9973\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0163 - accuracy: 0.9976\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0096 - accuracy: 0.9980\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0124 - accuracy: 0.9946\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0128 - accuracy: 0.9971\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0058 - accuracy: 0.9993\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0124 - accuracy: 0.9975\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0169 - accuracy: 0.9967\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0209 - accuracy: 0.9929\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0107 - accuracy: 0.9975\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0139 - accuracy: 0.9930\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0230 - accuracy: 0.9901\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0105 - accuracy: 0.9991\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0111 - accuracy: 0.9964\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0090 - accuracy: 0.9988\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0094 - accuracy: 0.9956\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0174 - accuracy: 0.9937\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0289 - accuracy: 0.9882\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0173 - accuracy: 0.9938\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0141 - accuracy: 0.9968\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0606 - accuracy: 0.9715\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0309 - accuracy: 0.9878\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0225 - accuracy: 0.9895\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0103 - accuracy: 0.9992\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0280 - accuracy: 0.9913\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0185 - accuracy: 0.9938\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0177 - accuracy: 0.9969\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0248 - accuracy: 0.9902\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0266 - accuracy: 0.9843\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0167 - accuracy: 0.9963\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0160 - accuracy: 0.9981\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0151 - accuracy: 0.9980\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0161 - accuracy: 0.9932\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0176 - accuracy: 0.9972\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0194 - accuracy: 0.9954\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0218 - accuracy: 0.9942\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0180 - accuracy: 0.9916\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0483 - accuracy: 0.9860\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0198 - accuracy: 0.9966\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0103 - accuracy: 0.9976\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7873cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 867us/step - loss: 0.4352 - accuracy: 0.8763\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.3650 - accuracy: 0.8835\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.3133 - accuracy: 0.8881\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.3407 - accuracy: 0.8902\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.3273 - accuracy: 0.8793\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.2745 - accuracy: 0.8992\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.2684 - accuracy: 0.8973\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.2700 - accuracy: 0.9077\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.2602 - accuracy: 0.9092\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.2410 - accuracy: 0.9155\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.2187 - accuracy: 0.9209\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.2664 - accuracy: 0.9183\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.2077 - accuracy: 0.9252\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.2004 - accuracy: 0.9222\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1923 - accuracy: 0.9349\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.2108 - accuracy: 0.9334\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.2030 - accuracy: 0.9207\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1781 - accuracy: 0.9366\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.1728 - accuracy: 0.9371\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1753 - accuracy: 0.9378\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.1530 - accuracy: 0.9523\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1783 - accuracy: 0.9321\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1393 - accuracy: 0.9546\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1444 - accuracy: 0.9446\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1647 - accuracy: 0.9455\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.1512 - accuracy: 0.9388\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.1272 - accuracy: 0.9534\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.1157 - accuracy: 0.9695\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.1596 - accuracy: 0.9370\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.1163 - accuracy: 0.9635\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1254 - accuracy: 0.9497\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.1238 - accuracy: 0.9537\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.1042 - accuracy: 0.9718\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.1114 - accuracy: 0.9594\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1076 - accuracy: 0.9649\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0954 - accuracy: 0.9719\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0857 - accuracy: 0.9715\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.1047 - accuracy: 0.9578\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0758 - accuracy: 0.9707\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0745 - accuracy: 0.9808\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0674 - accuracy: 0.9822\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0906 - accuracy: 0.9678\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0971 - accuracy: 0.9744\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0783 - accuracy: 0.9706\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0871 - accuracy: 0.9741\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0906 - accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0757 - accuracy: 0.9719\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0738 - accuracy: 0.9703\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0722 - accuracy: 0.9829\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0609 - accuracy: 0.9820\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0605 - accuracy: 0.9770\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0509 - accuracy: 0.9870\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0481 - accuracy: 0.9842\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0596 - accuracy: 0.9758\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0491 - accuracy: 0.9897\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0469 - accuracy: 0.9863\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0603 - accuracy: 0.9730\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0631 - accuracy: 0.9859\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0588 - accuracy: 0.9812\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0511 - accuracy: 0.9844\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0437 - accuracy: 0.9854\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0386 - accuracy: 0.9920\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0574 - accuracy: 0.9833\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 969us/step - loss: 0.0503 - accuracy: 0.9852\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0582 - accuracy: 0.9815\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0339 - accuracy: 0.9904\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0434 - accuracy: 0.9911\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0384 - accuracy: 0.9936\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0438 - accuracy: 0.9869\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0363 - accuracy: 0.9905\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0372 - accuracy: 0.9888\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0266 - accuracy: 0.9914\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0302 - accuracy: 0.9950\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0376 - accuracy: 0.9880\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0447 - accuracy: 0.9891\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.1090 - accuracy: 0.9474\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.0639 - accuracy: 0.9770\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0388 - accuracy: 0.9813\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0335 - accuracy: 0.9911\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0244 - accuracy: 0.9965\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 834us/step - loss: 0.0242 - accuracy: 0.9947\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0285 - accuracy: 0.9951\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 794us/step - loss: 0.0555 - accuracy: 0.9778\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0427 - accuracy: 0.9837\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0246 - accuracy: 0.9960\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0298 - accuracy: 0.9897\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0282 - accuracy: 0.9878\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0341 - accuracy: 0.9878\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0385 - accuracy: 0.9878\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0204 - accuracy: 0.9968\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0214 - accuracy: 0.9984\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0155 - accuracy: 0.9982\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0154 - accuracy: 0.9977\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0211 - accuracy: 0.9963\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0203 - accuracy: 0.9979\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0251 - accuracy: 0.9939\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0248 - accuracy: 0.9956\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0305 - accuracy: 0.9893\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0240 - accuracy: 0.9931\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0147 - accuracy: 0.9990\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0282 - accuracy: 0.9877\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0291 - accuracy: 0.9937\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0139 - accuracy: 0.9990\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0229 - accuracy: 0.9924\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0444 - accuracy: 0.9778\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0245 - accuracy: 0.9974\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0410 - accuracy: 0.9877\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0203 - accuracy: 0.9961\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0252 - accuracy: 0.9915\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0177 - accuracy: 0.9968\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0195 - accuracy: 0.9920\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0169 - accuracy: 0.9966\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0305 - accuracy: 0.9877\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0227 - accuracy: 0.9971\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0183 - accuracy: 0.9978\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0194 - accuracy: 0.9914\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0150 - accuracy: 0.9965\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0154 - accuracy: 0.9916\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0337 - accuracy: 0.9900\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0355 - accuracy: 0.9882\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0182 - accuracy: 0.9934\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0163 - accuracy: 0.9970\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0155 - accuracy: 0.9934\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0236 - accuracy: 0.9911\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0249 - accuracy: 0.9897\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0234 - accuracy: 0.9942\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0387 - accuracy: 0.9863\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.0272 - accuracy: 0.9867\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0166 - accuracy: 0.9961\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 803us/step - loss: 0.0266 - accuracy: 0.9914\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0164 - accuracy: 0.9969\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0097 - accuracy: 0.9995\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0136 - accuracy: 0.9943\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0145 - accuracy: 0.9989\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0172 - accuracy: 0.9929\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0200 - accuracy: 0.9915\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0078 - accuracy: 0.9993\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.0154 - accuracy: 0.9946\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0118 - accuracy: 0.9970\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0109 - accuracy: 0.9992\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0154 - accuracy: 0.9948\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0107 - accuracy: 0.9975\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0075 - accuracy: 0.9989\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.0082 - accuracy: 0.9969\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9959\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9950\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 932us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0106 - accuracy: 0.9970\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0075 - accuracy: 0.9970\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 987us/step - loss: 0.0111 - accuracy: 0.9957\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0114 - accuracy: 0.9978\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0096 - accuracy: 0.9944\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0163 - accuracy: 0.9942\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0106 - accuracy: 0.9993\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0302 - accuracy: 0.9844\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0108 - accuracy: 0.9985\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0112 - accuracy: 0.9980\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 875us/step - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.0223 - accuracy: 0.9892\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0226 - accuracy: 0.9951\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0157 - accuracy: 0.9991\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0154 - accuracy: 0.9966\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0108 - accuracy: 0.9965\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0134 - accuracy: 0.9955\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0248 - accuracy: 0.9936\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0095 - accuracy: 0.9969\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0106 - accuracy: 0.9953\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0128 - accuracy: 0.9943\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0090 - accuracy: 0.9990\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.0111 - accuracy: 0.9953\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0141 - accuracy: 0.9943\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0072 - accuracy: 0.9959\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0114 - accuracy: 0.9956\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0147 - accuracy: 0.9968\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.0182 - accuracy: 0.9914\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0120 - accuracy: 0.9968\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0174 - accuracy: 0.9964\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0171 - accuracy: 0.9931\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0058 - accuracy: 0.9994\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.0247 - accuracy: 0.9897\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.0085 - accuracy: 0.9996\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0151 - accuracy: 0.9955\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0122 - accuracy: 0.9965\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0080 - accuracy: 0.9980\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0068 - accuracy: 0.9998\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0092 - accuracy: 0.9946\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0062 - accuracy: 0.9984\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0046 - accuracy: 0.9996\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0089 - accuracy: 0.9978\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0081 - accuracy: 0.9984\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0070 - accuracy: 0.9994\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0043 - accuracy: 0.9997\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73f01f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 871us/step - loss: 0.5720 - accuracy: 0.8155\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.3811 - accuracy: 0.8881\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.3317 - accuracy: 0.8849\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.3379 - accuracy: 0.8643\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8774\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.2951 - accuracy: 0.8840\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.2652 - accuracy: 0.8926\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.2652 - accuracy: 0.8923\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.8987\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 968us/step - loss: 0.2626 - accuracy: 0.8973\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.2634 - accuracy: 0.9057\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.2822 - accuracy: 0.8840\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.2720 - accuracy: 0.8940\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.2391 - accuracy: 0.8937\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.2492 - accuracy: 0.9007\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9104\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.2193 - accuracy: 0.9134\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.1904 - accuracy: 0.9273\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.2100 - accuracy: 0.9103\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.1900 - accuracy: 0.9274\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.2147 - accuracy: 0.9211\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.1853 - accuracy: 0.9330\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1969 - accuracy: 0.9301\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1977 - accuracy: 0.9273\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1749 - accuracy: 0.9300\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.1949 - accuracy: 0.9260\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1646 - accuracy: 0.9394\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1753 - accuracy: 0.9218\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.1545 - accuracy: 0.9406\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1737 - accuracy: 0.9380\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.1553 - accuracy: 0.9242\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.1417 - accuracy: 0.9529\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.1318 - accuracy: 0.9604\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.1206 - accuracy: 0.9473\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.1315 - accuracy: 0.9585\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.1551 - accuracy: 0.9487\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.1387 - accuracy: 0.9452\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1249 - accuracy: 0.9599\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.1348 - accuracy: 0.9493\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.1007 - accuracy: 0.9640\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1096 - accuracy: 0.9558\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1080 - accuracy: 0.9627\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1137 - accuracy: 0.9496\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.1136 - accuracy: 0.9628\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.1124 - accuracy: 0.9575\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0917 - accuracy: 0.9667\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.1034 - accuracy: 0.9611\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.1024 - accuracy: 0.9646\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0993 - accuracy: 0.9713\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0979 - accuracy: 0.9735\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0753 - accuracy: 0.9796\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.0960 - accuracy: 0.9713\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0774 - accuracy: 0.9756\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0800 - accuracy: 0.9796\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0784 - accuracy: 0.9730\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0754 - accuracy: 0.9708\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0984 - accuracy: 0.9631\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0969 - accuracy: 0.9647\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0749 - accuracy: 0.9708\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0791 - accuracy: 0.9648\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0614 - accuracy: 0.9830\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0710 - accuracy: 0.9782\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0583 - accuracy: 0.9798\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0650 - accuracy: 0.9880\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0584 - accuracy: 0.9873\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0597 - accuracy: 0.9787\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0806 - accuracy: 0.9777\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0908 - accuracy: 0.9586\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0682 - accuracy: 0.9758\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0541 - accuracy: 0.9789\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0663 - accuracy: 0.9767\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0502 - accuracy: 0.9878\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.0530 - accuracy: 0.9869\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0553 - accuracy: 0.9831\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.0515 - accuracy: 0.9823\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0418 - accuracy: 0.9925\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0401 - accuracy: 0.9921\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0643 - accuracy: 0.9788\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.0487 - accuracy: 0.9878\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0411 - accuracy: 0.9907\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 841us/step - loss: 0.0540 - accuracy: 0.9821\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0453 - accuracy: 0.9872\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.0488 - accuracy: 0.9884\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0386 - accuracy: 0.9956\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0444 - accuracy: 0.9863\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0330 - accuracy: 0.9948\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0447 - accuracy: 0.9913\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0333 - accuracy: 0.9948\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0585 - accuracy: 0.9781\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0374 - accuracy: 0.9847\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0396 - accuracy: 0.9904\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0388 - accuracy: 0.9913\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0406 - accuracy: 0.9880\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0389 - accuracy: 0.9853\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.0271 - accuracy: 0.9974\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0316 - accuracy: 0.9907\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0262 - accuracy: 0.9980\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0442 - accuracy: 0.9898\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0420 - accuracy: 0.9901\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0394 - accuracy: 0.9966\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0396 - accuracy: 0.9892\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.0354 - accuracy: 0.9915\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0448 - accuracy: 0.9827\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0519 - accuracy: 0.9801\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0384 - accuracy: 0.9852\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0231 - accuracy: 0.9945\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0331 - accuracy: 0.9929\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0256 - accuracy: 0.9940\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0356 - accuracy: 0.9849\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0346 - accuracy: 0.9921\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.0409 - accuracy: 0.9892\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0353 - accuracy: 0.9989\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0325 - accuracy: 0.9943\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0292 - accuracy: 0.9928\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.0361 - accuracy: 0.9909\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.0200 - accuracy: 0.9933\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0302 - accuracy: 0.9930\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.0230 - accuracy: 0.9990\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0268 - accuracy: 0.9921\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0274 - accuracy: 0.9932\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0220 - accuracy: 0.9958\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0281 - accuracy: 0.9927\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0216 - accuracy: 0.9962\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0221 - accuracy: 0.9938\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0197 - accuracy: 0.9965\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0234 - accuracy: 0.9944\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0212 - accuracy: 0.9964\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0179 - accuracy: 0.9948\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0236 - accuracy: 0.9953\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0253 - accuracy: 0.9950\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0244 - accuracy: 0.9933\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0250 - accuracy: 0.9945\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0211 - accuracy: 0.9982\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0238 - accuracy: 0.9898\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0196 - accuracy: 0.9958\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0220 - accuracy: 0.9962\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0186 - accuracy: 0.9966\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0183 - accuracy: 0.9985\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0464 - accuracy: 0.9901\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0188 - accuracy: 0.9980\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0256 - accuracy: 0.9843\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0202 - accuracy: 0.9941\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0173 - accuracy: 0.9960\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0261 - accuracy: 0.9885\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0104 - accuracy: 0.9996\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0279 - accuracy: 0.9870\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0248 - accuracy: 0.9939\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0186 - accuracy: 0.9965\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0159 - accuracy: 0.9974\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0153 - accuracy: 0.9970\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0262 - accuracy: 0.9889\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.0395 - accuracy: 0.9825\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0172 - accuracy: 0.9969\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.0177 - accuracy: 0.9968\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.0118 - accuracy: 0.9995\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 802us/step - loss: 0.0209 - accuracy: 0.9942\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0174 - accuracy: 0.9978\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 836us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0206 - accuracy: 0.9963\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0127 - accuracy: 0.9988\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0173 - accuracy: 0.9951\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0127 - accuracy: 0.9985\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0220 - accuracy: 0.9955\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0109 - accuracy: 0.9986\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0163 - accuracy: 0.9951\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0117 - accuracy: 0.9995\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0149 - accuracy: 0.9989\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0128 - accuracy: 0.9974\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0107 - accuracy: 0.9996\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0291 - accuracy: 0.9924\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0138 - accuracy: 0.9929\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0175 - accuracy: 0.9943\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.0158 - accuracy: 0.9949\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0162 - accuracy: 0.9917\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0077 - accuracy: 0.9996\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0159 - accuracy: 0.9963\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0109 - accuracy: 0.9975\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0197 - accuracy: 0.9951\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0217 - accuracy: 0.9955\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0217 - accuracy: 0.9959\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.0180 - accuracy: 0.9942\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0125 - accuracy: 0.9975\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0163 - accuracy: 0.9969\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0088 - accuracy: 0.9998\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.0172 - accuracy: 0.9938\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0235 - accuracy: 0.9936\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9870\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0643 - accuracy: 0.9755\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0165 - accuracy: 0.9985\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0145 - accuracy: 0.9943\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0302 - accuracy: 0.9894\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0285 - accuracy: 0.9909\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0352 - accuracy: 0.9845\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0255 - accuracy: 0.9903\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0100 - accuracy: 0.9992\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c741074c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 856us/step - loss: 0.5337 - accuracy: 0.8165\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.3661 - accuracy: 0.8899\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.3374 - accuracy: 0.8934\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.3149 - accuracy: 0.8905\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.2977 - accuracy: 0.8871\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.3249 - accuracy: 0.8771\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 983us/step - loss: 0.2962 - accuracy: 0.8965\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.2700 - accuracy: 0.9070\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.2759 - accuracy: 0.9082\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.2505 - accuracy: 0.9015\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.2425 - accuracy: 0.9014\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.2456 - accuracy: 0.9089\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.2197 - accuracy: 0.9271\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.2564 - accuracy: 0.9244\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.1910 - accuracy: 0.9252\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.2024 - accuracy: 0.9193\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.2161 - accuracy: 0.9123\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 978us/step - loss: 0.1856 - accuracy: 0.9396\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.9146\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.9384\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.1605 - accuracy: 0.9414\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.1570 - accuracy: 0.9377\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.1631 - accuracy: 0.9344\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.1509 - accuracy: 0.9382\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1695 - accuracy: 0.9449\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1358 - accuracy: 0.9500\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.1389 - accuracy: 0.9513\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1221 - accuracy: 0.9571\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.1521 - accuracy: 0.9422\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.1395 - accuracy: 0.9536\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.1246 - accuracy: 0.9547\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.1159 - accuracy: 0.9600\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.1402 - accuracy: 0.9491\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.1520 - accuracy: 0.9416\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.1302 - accuracy: 0.9432\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.1207 - accuracy: 0.9532\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1068 - accuracy: 0.9712\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0938 - accuracy: 0.9697\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.1217 - accuracy: 0.9518\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0840 - accuracy: 0.9784\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0806 - accuracy: 0.9684\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0766 - accuracy: 0.9730\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.1010 - accuracy: 0.9689\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0891 - accuracy: 0.9716\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.0896 - accuracy: 0.9680\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0895 - accuracy: 0.9661\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.0971 - accuracy: 0.9651\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0955 - accuracy: 0.9589\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0727 - accuracy: 0.9801\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.0757 - accuracy: 0.9716\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0807 - accuracy: 0.9792\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0669 - accuracy: 0.9799\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0698 - accuracy: 0.9770\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0667 - accuracy: 0.9781\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0626 - accuracy: 0.9743\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.0790 - accuracy: 0.9724\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0659 - accuracy: 0.9793\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0574 - accuracy: 0.9859\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0666 - accuracy: 0.9784\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0618 - accuracy: 0.9838\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0583 - accuracy: 0.9776\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0467 - accuracy: 0.9836\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0707 - accuracy: 0.9793\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0870 - accuracy: 0.9641\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0486 - accuracy: 0.9887\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0798 - accuracy: 0.9693\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0858 - accuracy: 0.9675\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.0805 - accuracy: 0.9635\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0638 - accuracy: 0.9789\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0448 - accuracy: 0.9780\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.0409 - accuracy: 0.9902\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0461 - accuracy: 0.9816\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0462 - accuracy: 0.9835\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0360 - accuracy: 0.9882\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0410 - accuracy: 0.9838\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0602 - accuracy: 0.9878\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0467 - accuracy: 0.9815\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0507 - accuracy: 0.9912\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0450 - accuracy: 0.9845\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.0297 - accuracy: 0.9927\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 846us/step - loss: 0.0401 - accuracy: 0.9838\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.0403 - accuracy: 0.9894\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0324 - accuracy: 0.9921\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.0381 - accuracy: 0.9914\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0539 - accuracy: 0.9789\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0380 - accuracy: 0.9855\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0412 - accuracy: 0.9905\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.0367 - accuracy: 0.9885\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0420 - accuracy: 0.9745\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0408 - accuracy: 0.9863\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0718 - accuracy: 0.9778\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.0332 - accuracy: 0.9904\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0331 - accuracy: 0.9913\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0467 - accuracy: 0.9844\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0237 - accuracy: 0.9950\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0196 - accuracy: 0.9942\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.0389 - accuracy: 0.9849\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0348 - accuracy: 0.9886\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0333 - accuracy: 0.9927\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0301 - accuracy: 0.9869\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0262 - accuracy: 0.9907\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0218 - accuracy: 0.9942\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0304 - accuracy: 0.9932\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0251 - accuracy: 0.9899\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0220 - accuracy: 0.9989\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0228 - accuracy: 0.9953\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0261 - accuracy: 0.9902\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0201 - accuracy: 0.9959\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0335 - accuracy: 0.9869\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.0340 - accuracy: 0.9874\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0322 - accuracy: 0.9945\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0176 - accuracy: 0.9977\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0314 - accuracy: 0.9879\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0326 - accuracy: 0.9869\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0185 - accuracy: 0.9949\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0352 - accuracy: 0.9872\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0323 - accuracy: 0.9891\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0216 - accuracy: 0.9955\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0277 - accuracy: 0.9872\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0666 - accuracy: 0.9856\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0564 - accuracy: 0.9778\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0616 - accuracy: 0.9733\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0413 - accuracy: 0.9889\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0611 - accuracy: 0.9799\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0349 - accuracy: 0.9880\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0380 - accuracy: 0.9922\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0503 - accuracy: 0.9764\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0493 - accuracy: 0.9820\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.0270 - accuracy: 0.9930\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.0388 - accuracy: 0.9851\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.0488 - accuracy: 0.9819\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0335 - accuracy: 0.9853\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0342 - accuracy: 0.9906\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0480 - accuracy: 0.9767\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0421 - accuracy: 0.9863\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0437 - accuracy: 0.9829\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0443 - accuracy: 0.9873\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0299 - accuracy: 0.9917\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.0223 - accuracy: 0.9926\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0240 - accuracy: 0.9943\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0517 - accuracy: 0.9774\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0321 - accuracy: 0.9924\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0203 - accuracy: 0.9933\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0136 - accuracy: 0.9964\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0213 - accuracy: 0.9965\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0185 - accuracy: 0.9931\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 787us/step - loss: 0.0187 - accuracy: 0.9951\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0247 - accuracy: 0.9850\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.0299 - accuracy: 0.9859\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0256 - accuracy: 0.9896\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0171 - accuracy: 0.9954\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.0189 - accuracy: 0.9961\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 792us/step - loss: 0.0254 - accuracy: 0.9941\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0274 - accuracy: 0.9933\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.0173 - accuracy: 0.9955\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.0220 - accuracy: 0.9922\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0321 - accuracy: 0.9903\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 808us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.0136 - accuracy: 0.9978\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0186 - accuracy: 0.9922\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.0250 - accuracy: 0.9884\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0126 - accuracy: 0.9999\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.0402 - accuracy: 0.9838\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.0245 - accuracy: 0.9950\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0181 - accuracy: 0.9924\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0116 - accuracy: 0.9981\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0263 - accuracy: 0.9885\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0184 - accuracy: 0.9913\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0119 - accuracy: 0.9980\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0171 - accuracy: 0.9956\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0153 - accuracy: 0.9961\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.0370 - accuracy: 0.9843\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0129 - accuracy: 0.9974\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9975\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0169 - accuracy: 0.9974\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9911\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0236 - accuracy: 0.9863\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0247 - accuracy: 0.9921\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0150 - accuracy: 0.9937\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0292 - accuracy: 0.9835\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 961us/step - loss: 0.0235 - accuracy: 0.9927\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0630 - accuracy: 0.9724\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0586 - accuracy: 0.9762\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0294 - accuracy: 0.9923\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0490 - accuracy: 0.9794\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0469 - accuracy: 0.9804\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0387 - accuracy: 0.9797\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.0275 - accuracy: 0.9893\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.0479 - accuracy: 0.9871\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0188 - accuracy: 0.9937\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.0331 - accuracy: 0.9909\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0193 - accuracy: 0.9963\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.0225 - accuracy: 0.9951\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0203 - accuracy: 0.9941\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c73f019d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 860us/step - loss: 0.6171 - accuracy: 0.7429\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 731us/step - loss: 0.3621 - accuracy: 0.8767\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.3405 - accuracy: 0.8868\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.2949 - accuracy: 0.8902\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.3122 - accuracy: 0.8831\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.3054 - accuracy: 0.8920\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.2472 - accuracy: 0.9149\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.2649 - accuracy: 0.9014\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.2886 - accuracy: 0.8834\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.2454 - accuracy: 0.8987\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.2745 - accuracy: 0.8879\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.2659 - accuracy: 0.9057\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.2466 - accuracy: 0.9016\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.2290 - accuracy: 0.9057\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9069\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.2032 - accuracy: 0.9267\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.2115 - accuracy: 0.9158\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1999 - accuracy: 0.9112\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.1900 - accuracy: 0.9317\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.1754 - accuracy: 0.9400\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.1708 - accuracy: 0.9479\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.2117 - accuracy: 0.9183\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.1607 - accuracy: 0.9393\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.1590 - accuracy: 0.9308\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.1512 - accuracy: 0.9446\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.1714 - accuracy: 0.9411\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.1614 - accuracy: 0.9464\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.1592 - accuracy: 0.9356\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.1458 - accuracy: 0.9449\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.1441 - accuracy: 0.9369\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.1299 - accuracy: 0.9558\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.1416 - accuracy: 0.9498\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.1463 - accuracy: 0.9520\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.1263 - accuracy: 0.9552\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.1115 - accuracy: 0.9648\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.1329 - accuracy: 0.9357\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.1505 - accuracy: 0.9452\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.1181 - accuracy: 0.9572\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.1235 - accuracy: 0.9522\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.1121 - accuracy: 0.9486\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.1214 - accuracy: 0.9640\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.1274 - accuracy: 0.9622\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0968 - accuracy: 0.9615\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.0977 - accuracy: 0.9712\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.1017 - accuracy: 0.9703\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.0988 - accuracy: 0.9749\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.0667 - accuracy: 0.9840\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0743 - accuracy: 0.9718\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0946 - accuracy: 0.9609\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.0782 - accuracy: 0.9759\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 821us/step - loss: 0.0782 - accuracy: 0.9716\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0735 - accuracy: 0.9700\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.0865 - accuracy: 0.9748\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.0847 - accuracy: 0.9639\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.0771 - accuracy: 0.9712\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.0620 - accuracy: 0.9825\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0711 - accuracy: 0.9809\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 914us/step - loss: 0.0535 - accuracy: 0.9841\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.0513 - accuracy: 0.9858\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0756 - accuracy: 0.9863\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.0689 - accuracy: 0.9696\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.0711 - accuracy: 0.9791\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.0620 - accuracy: 0.9778\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.0515 - accuracy: 0.9873\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.0475 - accuracy: 0.9849\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0524 - accuracy: 0.9841\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.0597 - accuracy: 0.9758\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0560 - accuracy: 0.9716\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0653 - accuracy: 0.9735\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0665 - accuracy: 0.9789\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0572 - accuracy: 0.9786\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 927us/step - loss: 0.0533 - accuracy: 0.9857\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.0441 - accuracy: 0.9894\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.0559 - accuracy: 0.9834\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.0492 - accuracy: 0.9814\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0629 - accuracy: 0.9764\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0400 - accuracy: 0.9938\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.0491 - accuracy: 0.9868\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0460 - accuracy: 0.9885\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.0369 - accuracy: 0.9929\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 884us/step - loss: 0.0670 - accuracy: 0.9691\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.0589 - accuracy: 0.9791\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0401 - accuracy: 0.9857\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0359 - accuracy: 0.9906\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.0847 - accuracy: 0.9743\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0538 - accuracy: 0.9842\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.0614 - accuracy: 0.9717\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.0389 - accuracy: 0.9864\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0677 - accuracy: 0.9656\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0483 - accuracy: 0.9869\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0351 - accuracy: 0.9883\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.0411 - accuracy: 0.9875\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 955us/step - loss: 0.0349 - accuracy: 0.9946\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0469 - accuracy: 0.9822\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0391 - accuracy: 0.9897\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.0347 - accuracy: 0.9953\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9842\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9975\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9857\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9935\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9776\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0314 - accuracy: 0.9912\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9955\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0320 - accuracy: 0.9897\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.0190 - accuracy: 0.9963\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0213 - accuracy: 0.9936\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.0348 - accuracy: 0.9893\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.0328 - accuracy: 0.9916\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.0185 - accuracy: 0.9957\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.0243 - accuracy: 0.9924\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.0256 - accuracy: 0.9917\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.0219 - accuracy: 0.9950\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.0406 - accuracy: 0.9949\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.0297 - accuracy: 0.9938\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.0450 - accuracy: 0.9828\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9842\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9932\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.0229 - accuracy: 0.9932\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0333 - accuracy: 0.9881\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.0170 - accuracy: 0.9982\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.0344 - accuracy: 0.9839\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9911\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 943us/step - loss: 0.0387 - accuracy: 0.9816\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.0195 - accuracy: 0.9917\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.0175 - accuracy: 0.9948\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0184 - accuracy: 0.9967\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.0306 - accuracy: 0.9936\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.0181 - accuracy: 0.9978\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.0251 - accuracy: 0.9913\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0188 - accuracy: 0.9956\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.0237 - accuracy: 0.9897\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0192 - accuracy: 0.9948\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.0255 - accuracy: 0.9951\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.0277 - accuracy: 0.9882\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0326 - accuracy: 0.9937\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.0167 - accuracy: 0.9986\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.0095 - accuracy: 0.9997\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 993us/step - loss: 0.0278 - accuracy: 0.9902\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0290 - accuracy: 0.9960\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.0214 - accuracy: 0.9956\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0255 - accuracy: 0.9945\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0140 - accuracy: 0.9980\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.0157 - accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.0275 - accuracy: 0.9869\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.0276 - accuracy: 0.9973\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.0162 - accuracy: 0.9950\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.0216 - accuracy: 0.9923\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0245 - accuracy: 0.9942\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 918us/step - loss: 0.0254 - accuracy: 0.9936\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.0121 - accuracy: 0.9992\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9970\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9875\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0594 - accuracy: 0.9734\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9975\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9926\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9924\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9904\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 981us/step - loss: 0.0131 - accuracy: 0.9971\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.0149 - accuracy: 0.9948\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9946\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 999us/step - loss: 0.0202 - accuracy: 0.9963\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9949\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 954us/step - loss: 0.0151 - accuracy: 0.9981\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 976us/step - loss: 0.0325 - accuracy: 0.9880\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 945us/step - loss: 0.0226 - accuracy: 0.9958\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 996us/step - loss: 0.0279 - accuracy: 0.9926\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9942\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 991us/step - loss: 0.0144 - accuracy: 0.9966\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9805\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.0230 - accuracy: 0.9925\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.0161 - accuracy: 0.9978\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0140 - accuracy: 0.9970\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 977us/step - loss: 0.0153 - accuracy: 0.9966\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 960us/step - loss: 0.0185 - accuracy: 0.9940\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9800\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9927\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 985us/step - loss: 0.0255 - accuracy: 0.9983\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 959us/step - loss: 0.0308 - accuracy: 0.9831\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.0249 - accuracy: 0.9911\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.0277 - accuracy: 0.9942\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.0287 - accuracy: 0.9925\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.0272 - accuracy: 0.9899\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.0313 - accuracy: 0.9934\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0361 - accuracy: 0.9880\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 824us/step - loss: 0.0544 - accuracy: 0.9856\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.0330 - accuracy: 0.9838\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 940us/step - loss: 0.0208 - accuracy: 0.9951\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.0168 - accuracy: 0.9952\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.0219 - accuracy: 0.9943\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.0203 - accuracy: 0.9931\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 963us/step - loss: 0.0229 - accuracy: 0.9937\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0204 - accuracy: 0.9922\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9977\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c7c59ad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "fraction_of_positives = dict()\n",
    "mean_predicted_value = dict()\n",
    "for i in range(n_classes):\n",
    "    #proba_val = clf.predict_proba(X_val)[:, i]\n",
    "#    clf_calib = CalibratedClassifierCV(clf.estimators_[i], cv=10, method='isotonic')\n",
    "    clf_calib = CalibratedClassifierCV(clf, cv=10, method='isotonic')\n",
    "    proba_val = clf_calib.fit(X_train, y_train[:,i]).predict_proba(X_val)[:,1]\n",
    "    fraction_of_positives[i], mean_predicted_value[i] = calibration_curve(y_val[:,i],\n",
    "                                                                proba_val,\n",
    "                                                                n_bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9c73e15c70>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "plt.plot(mean_predicted_value[0], fraction_of_positives[0], 's-', label='none')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot(mean_predicted_value[1], fraction_of_positives[1], 's-', label='antagonism')\n",
    "plt.plot(mean_predicted_value[2], fraction_of_positives[2], 's-', label='synergy')\n",
    "plt.title('Calibrated probabilities')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow probability calibration doesn't work for synergy prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test\"></a> \n",
    "## Generate Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs = pd.read_csv('../data/chemgenetics/nichols_testset_signed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs = X_drugs.iloc[:,np.where(np.isin(X_drugs.columns, gene_subset))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 350)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drugs = X_drugs.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "combs_test = list(itertools.combinations(test_drugs, 2))\n",
    "combs_test = np.array([i[0]+\"_\"+i[1] for i in combs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame([utl.get_comb_feat_signed(X_drugs, c) for c in combs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACRA_-2</th>\n",
       "      <th>ACRA_-1</th>\n",
       "      <th>ACRA_0</th>\n",
       "      <th>ACRA_1</th>\n",
       "      <th>ACRA_2</th>\n",
       "      <th>ACRA_3</th>\n",
       "      <th>ACRB_-2</th>\n",
       "      <th>ACRB_-1</th>\n",
       "      <th>ACRB_0</th>\n",
       "      <th>ACRB_1</th>\n",
       "      <th>ACRB_2</th>\n",
       "      <th>ACRB_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACRA_-2  ACRA_-1  ACRA_0  ACRA_1  ACRA_2  ACRA_3  ACRB_-2  ACRB_-1  ACRB_0  \\\n",
       "0        0        1       0       0       0       0        0        1       0   \n",
       "1        1        0       0       0       0       0        1        0       0   \n",
       "2        0        1       0       0       0       0        1        0       0   \n",
       "3        0        1       0       0       0       0        0        1       0   \n",
       "4        1        0       0       0       0       0        1        0       0   \n",
       "5        0        1       0       0       0       0        0        1       0   \n",
       "6        1        0       0       0       0       0        0        1       0   \n",
       "7        0        1       0       0       0       0        0        1       0   \n",
       "8        0        1       0       0       0       0        0        1       0   \n",
       "9        0        1       0       0       0       0        0        1       0   \n",
       "\n",
       "   ACRB_1  ACRB_2  ACRB_3  \n",
       "0       0       0       0  \n",
       "1       0       0       0  \n",
       "2       0       0       0  \n",
       "3       0       0       0  \n",
       "4       0       0       0  \n",
       "5       0       0       0  \n",
       "6       0       0       0  \n",
       "7       0       0       0  \n",
       "8       0       0       0  \n",
       "9       0       0       0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[:10,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad some columns (as some are all zeros in the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 1179)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pad = np.setdiff1d(X_onehot.columns, X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_pad:\n",
    "    X_test[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.loc[:,np.isin(X_test.columns, X_onehot.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[X_onehot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(X_test.columns == X_onehot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "31/31 [==============================] - 0s 942us/step - loss: 0.7658 - accuracy: 0.6452\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.7144\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7506\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7984\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7719\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8160\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 876us/step - loss: 0.4370 - accuracy: 0.7964\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 974us/step - loss: 0.4485 - accuracy: 0.7998\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8068\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8139\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8228\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 979us/step - loss: 0.4323 - accuracy: 0.8081\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 979us/step - loss: 0.4039 - accuracy: 0.8229\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 985us/step - loss: 0.3358 - accuracy: 0.8727\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 989us/step - loss: 0.3866 - accuracy: 0.8485\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8722\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 995us/step - loss: 0.3351 - accuracy: 0.8702\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 999us/step - loss: 0.3200 - accuracy: 0.8754\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8773\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8636\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 978us/step - loss: 0.3170 - accuracy: 0.8748\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 956us/step - loss: 0.2833 - accuracy: 0.8932\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 988us/step - loss: 0.2854 - accuracy: 0.8925\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8919\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8923\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.9186\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9054\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.9076\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.9006\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 966us/step - loss: 0.2483 - accuracy: 0.9163\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 895us/step - loss: 0.2134 - accuracy: 0.9184\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 986us/step - loss: 0.2058 - accuracy: 0.9243\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9304\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9180\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.9178\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9337\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.9196\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9384\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9068\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9241\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 984us/step - loss: 0.2041 - accuracy: 0.9147\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 990us/step - loss: 0.1768 - accuracy: 0.9389\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 980us/step - loss: 0.1712 - accuracy: 0.9403\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 993us/step - loss: 0.1869 - accuracy: 0.9319\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 988us/step - loss: 0.1632 - accuracy: 0.9449\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9447\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 977us/step - loss: 0.1379 - accuracy: 0.9593\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 968us/step - loss: 0.1938 - accuracy: 0.9233\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 976us/step - loss: 0.1817 - accuracy: 0.9284\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 976us/step - loss: 0.1546 - accuracy: 0.9376\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 994us/step - loss: 0.1569 - accuracy: 0.9442\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.9540\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9611\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.9580\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.9231\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 923us/step - loss: 0.1311 - accuracy: 0.9655\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 859us/step - loss: 0.1395 - accuracy: 0.9591\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 853us/step - loss: 0.1466 - accuracy: 0.9525\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 858us/step - loss: 0.1302 - accuracy: 0.9561\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 856us/step - loss: 0.1286 - accuracy: 0.9669\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 882us/step - loss: 0.1447 - accuracy: 0.9438\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.1129 - accuracy: 0.9578\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 874us/step - loss: 0.1359 - accuracy: 0.9561\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 845us/step - loss: 0.1119 - accuracy: 0.9580\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 796us/step - loss: 0.1032 - accuracy: 0.9656\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 847us/step - loss: 0.1220 - accuracy: 0.9596\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 826us/step - loss: 0.1292 - accuracy: 0.9607\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 768us/step - loss: 0.1131 - accuracy: 0.9677\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 790us/step - loss: 0.0952 - accuracy: 0.9703\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 794us/step - loss: 0.0990 - accuracy: 0.9756\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 820us/step - loss: 0.1199 - accuracy: 0.9537\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 811us/step - loss: 0.1121 - accuracy: 0.9527\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 799us/step - loss: 0.0981 - accuracy: 0.9686\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 776us/step - loss: 0.1019 - accuracy: 0.9665\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 787us/step - loss: 0.1007 - accuracy: 0.9618\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 804us/step - loss: 0.1091 - accuracy: 0.9590\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 802us/step - loss: 0.1146 - accuracy: 0.9574\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 822us/step - loss: 0.0932 - accuracy: 0.9647\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 787us/step - loss: 0.0947 - accuracy: 0.9745\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 818us/step - loss: 0.0824 - accuracy: 0.9800\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 800us/step - loss: 0.0868 - accuracy: 0.9698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0906 - accuracy: 0.9731\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0841 - accuracy: 0.9642\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 806us/step - loss: 0.0762 - accuracy: 0.9741\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 819us/step - loss: 0.1081 - accuracy: 0.9630\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 841us/step - loss: 0.0903 - accuracy: 0.9721\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 804us/step - loss: 0.0762 - accuracy: 0.9721\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 822us/step - loss: 0.0907 - accuracy: 0.9735\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 829us/step - loss: 0.0963 - accuracy: 0.9652\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 818us/step - loss: 0.0769 - accuracy: 0.9730\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 823us/step - loss: 0.0811 - accuracy: 0.9688\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 875us/step - loss: 0.0810 - accuracy: 0.9748\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9772\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9723\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9766\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9753\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9706\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 919us/step - loss: 0.0928 - accuracy: 0.9617\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9862\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9730\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9797\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 954us/step - loss: 0.0584 - accuracy: 0.9817\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9680\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0660 - accuracy: 0.9842\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9735\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9767\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9791\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9834\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9843\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9789\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 0.9812\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9771\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9792\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 992us/step - loss: 0.0549 - accuracy: 0.9781\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9732\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9808\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 838us/step - loss: 0.0517 - accuracy: 0.9817\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 751us/step - loss: 0.0550 - accuracy: 0.9776\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 668us/step - loss: 0.0648 - accuracy: 0.9708\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 680us/step - loss: 0.0632 - accuracy: 0.9780\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 653us/step - loss: 0.0697 - accuracy: 0.9728\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 663us/step - loss: 0.0530 - accuracy: 0.9828\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 647us/step - loss: 0.0628 - accuracy: 0.9708\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 653us/step - loss: 0.0457 - accuracy: 0.9865\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 782us/step - loss: 0.0639 - accuracy: 0.9738\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 710us/step - loss: 0.0527 - accuracy: 0.9832\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 870us/step - loss: 0.0596 - accuracy: 0.9786\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 863us/step - loss: 0.0661 - accuracy: 0.9805\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 806us/step - loss: 0.0485 - accuracy: 0.9809\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 839us/step - loss: 0.0594 - accuracy: 0.9745\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 813us/step - loss: 0.0519 - accuracy: 0.9799\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 799us/step - loss: 0.0575 - accuracy: 0.9801\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 802us/step - loss: 0.0524 - accuracy: 0.9816\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 826us/step - loss: 0.0595 - accuracy: 0.9789\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 801us/step - loss: 0.0462 - accuracy: 0.9876\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 798us/step - loss: 0.0485 - accuracy: 0.9767\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0505 - accuracy: 0.9806\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 800us/step - loss: 0.0680 - accuracy: 0.9729\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.0356 - accuracy: 0.9869\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.0432 - accuracy: 0.9838\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 826us/step - loss: 0.0415 - accuracy: 0.9848\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 807us/step - loss: 0.0432 - accuracy: 0.9874\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 814us/step - loss: 0.0383 - accuracy: 0.9878\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 819us/step - loss: 0.0505 - accuracy: 0.9811\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.0496 - accuracy: 0.9770\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 807us/step - loss: 0.0541 - accuracy: 0.9819\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 782us/step - loss: 0.0452 - accuracy: 0.9840\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 813us/step - loss: 0.0632 - accuracy: 0.9686\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 806us/step - loss: 0.0457 - accuracy: 0.9831\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0424 - accuracy: 0.9856\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 835us/step - loss: 0.0470 - accuracy: 0.9811\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 765us/step - loss: 0.0533 - accuracy: 0.9759\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 839us/step - loss: 0.0544 - accuracy: 0.9818\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0428 - accuracy: 0.9831\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 825us/step - loss: 0.0479 - accuracy: 0.9779\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 825us/step - loss: 0.0403 - accuracy: 0.9863\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 809us/step - loss: 0.0836 - accuracy: 0.9654\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 807us/step - loss: 0.0466 - accuracy: 0.9867\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 786us/step - loss: 0.0509 - accuracy: 0.9807\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 830us/step - loss: 0.0593 - accuracy: 0.9791\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 789us/step - loss: 0.0361 - accuracy: 0.9877\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 845us/step - loss: 0.0683 - accuracy: 0.9703\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0528 - accuracy: 0.9828\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 816us/step - loss: 0.0445 - accuracy: 0.9837\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 806us/step - loss: 0.0370 - accuracy: 0.9865\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 807us/step - loss: 0.0384 - accuracy: 0.9867\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0245 - accuracy: 0.9931\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 836us/step - loss: 0.0369 - accuracy: 0.9858\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 791us/step - loss: 0.0428 - accuracy: 0.9829\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0426 - accuracy: 0.9825\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 825us/step - loss: 0.0363 - accuracy: 0.9872\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 810us/step - loss: 0.0456 - accuracy: 0.9893\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 804us/step - loss: 0.0465 - accuracy: 0.9838\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 808us/step - loss: 0.0379 - accuracy: 0.9876\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 809us/step - loss: 0.0486 - accuracy: 0.9790\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 806us/step - loss: 0.0342 - accuracy: 0.9868\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 822us/step - loss: 0.0273 - accuracy: 0.9921\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 818us/step - loss: 0.0310 - accuracy: 0.9885\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 842us/step - loss: 0.0390 - accuracy: 0.9865\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 792us/step - loss: 0.0542 - accuracy: 0.9823\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 821us/step - loss: 0.0426 - accuracy: 0.9804\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 833us/step - loss: 0.0354 - accuracy: 0.9934\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 798us/step - loss: 0.0333 - accuracy: 0.9875\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 811us/step - loss: 0.0382 - accuracy: 0.9816\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 816us/step - loss: 0.0250 - accuracy: 0.9898\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 795us/step - loss: 0.0468 - accuracy: 0.9818\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 830us/step - loss: 0.0464 - accuracy: 0.9811\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 792us/step - loss: 0.0284 - accuracy: 0.9908\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 823us/step - loss: 0.0461 - accuracy: 0.9820\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 804us/step - loss: 0.0353 - accuracy: 0.9875\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 831us/step - loss: 0.0365 - accuracy: 0.9909\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 795us/step - loss: 0.0382 - accuracy: 0.9863\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 856us/step - loss: 0.0482 - accuracy: 0.9797\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 797us/step - loss: 0.0563 - accuracy: 0.9811\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 830us/step - loss: 0.0296 - accuracy: 0.9903\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 803us/step - loss: 0.0467 - accuracy: 0.9773\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 854us/step - loss: 0.0480 - accuracy: 0.9812\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 814us/step - loss: 0.0537 - accuracy: 0.9772\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 851us/step - loss: 0.0286 - accuracy: 0.9899\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 894us/step - loss: 0.0336 - accuracy: 0.9834\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 0s 808us/step - loss: 0.6006 - accuracy: 0.7567\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 890us/step - loss: 0.3776 - accuracy: 0.8506\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 883us/step - loss: 0.3532 - accuracy: 0.8587\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 842us/step - loss: 0.3561 - accuracy: 0.8545\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 835us/step - loss: 0.3105 - accuracy: 0.8773\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.3131 - accuracy: 0.8719\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 851us/step - loss: 0.2977 - accuracy: 0.8750\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 844us/step - loss: 0.2800 - accuracy: 0.8814\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 894us/step - loss: 0.2693 - accuracy: 0.8891\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.8957\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8857\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2686 - accuracy: 0.8890\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.8998\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9142\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9068\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9090\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9050\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 995us/step - loss: 0.1897 - accuracy: 0.9213\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9148\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9214\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.9308\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9413\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 996us/step - loss: 0.1814 - accuracy: 0.9356\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9348\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9344\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9390\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9474\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 941us/step - loss: 0.1404 - accuracy: 0.9453\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 885us/step - loss: 0.1463 - accuracy: 0.9391\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 889us/step - loss: 0.1263 - accuracy: 0.9547\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 841us/step - loss: 0.1285 - accuracy: 0.9525\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 855us/step - loss: 0.1260 - accuracy: 0.9536\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 861us/step - loss: 0.1236 - accuracy: 0.9562\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 976us/step - loss: 0.1112 - accuracy: 0.9624\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1409 - accuracy: 0.9344\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 975us/step - loss: 0.1202 - accuracy: 0.9573\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.9564\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9668\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9522\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9570\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9695\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 993us/step - loss: 0.0998 - accuracy: 0.9695\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9651\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9601\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9729\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0992 - accuracy: 0.9625\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9519\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 995us/step - loss: 0.0767 - accuracy: 0.9728\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9809\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9610\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9628\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9795\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 992us/step - loss: 0.0737 - accuracy: 0.9804\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 994us/step - loss: 0.0768 - accuracy: 0.9702\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 930us/step - loss: 0.0850 - accuracy: 0.9619\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 853us/step - loss: 0.0566 - accuracy: 0.9818\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 942us/step - loss: 0.0591 - accuracy: 0.9823\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 810us/step - loss: 0.0603 - accuracy: 0.9751\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 826us/step - loss: 0.0650 - accuracy: 0.9757\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 812us/step - loss: 0.0737 - accuracy: 0.9750\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 825us/step - loss: 0.0677 - accuracy: 0.9771\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 838us/step - loss: 0.0499 - accuracy: 0.9814\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 909us/step - loss: 0.0532 - accuracy: 0.9841\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 981us/step - loss: 0.0558 - accuracy: 0.9766\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9722\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9954\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9877\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9830\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9825\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9900\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9825\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9720\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9897\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9876\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9804\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9860\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9930\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9848\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9853\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9874\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9865\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9896\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9859\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9888\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.0375 - accuracy: 0.9931\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9923\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 862us/step - loss: 0.0422 - accuracy: 0.9872\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 888us/step - loss: 0.0246 - accuracy: 0.9928\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 899us/step - loss: 0.0572 - accuracy: 0.9842\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.0460 - accuracy: 0.9851\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 826us/step - loss: 0.0503 - accuracy: 0.9767\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 933us/step - loss: 0.0348 - accuracy: 0.9960\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 838us/step - loss: 0.0392 - accuracy: 0.9958\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 849us/step - loss: 0.0356 - accuracy: 0.9914\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 867us/step - loss: 0.0353 - accuracy: 0.9876\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 877us/step - loss: 0.0396 - accuracy: 0.9904\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 863us/step - loss: 0.0377 - accuracy: 0.9872\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0306 - accuracy: 0.9960\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 924us/step - loss: 0.0333 - accuracy: 0.9887\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 875us/step - loss: 0.0423 - accuracy: 0.9892\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 873us/step - loss: 0.0264 - accuracy: 0.9939\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.0320 - accuracy: 0.9896\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 938us/step - loss: 0.0333 - accuracy: 0.9895\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 864us/step - loss: 0.0206 - accuracy: 0.9943\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 897us/step - loss: 0.0248 - accuracy: 0.9945\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 841us/step - loss: 0.0362 - accuracy: 0.9917\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 826us/step - loss: 0.0360 - accuracy: 0.9856\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9886\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 880us/step - loss: 0.0259 - accuracy: 0.9939\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 848us/step - loss: 0.0286 - accuracy: 0.9889\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 929us/step - loss: 0.0189 - accuracy: 0.9936\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 856us/step - loss: 0.0329 - accuracy: 0.9872\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 880us/step - loss: 0.0274 - accuracy: 0.9934\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 880us/step - loss: 0.0294 - accuracy: 0.9870\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 883us/step - loss: 0.0282 - accuracy: 0.9884\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 865us/step - loss: 0.0259 - accuracy: 0.9891\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 860us/step - loss: 0.0313 - accuracy: 0.9804\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 893us/step - loss: 0.0307 - accuracy: 0.9914\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9933\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9760\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9895\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9952\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9875\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9940\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9865\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9957\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9913\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9890\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9891\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9935\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 949us/step - loss: 0.0213 - accuracy: 0.9941\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9972\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 920us/step - loss: 0.0373 - accuracy: 0.9901\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9949\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9937\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 959us/step - loss: 0.0243 - accuracy: 0.9923\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9903\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 902us/step - loss: 0.0297 - accuracy: 0.9906\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 859us/step - loss: 0.0478 - accuracy: 0.9887\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 903us/step - loss: 0.0443 - accuracy: 0.9905\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 859us/step - loss: 0.0275 - accuracy: 0.9920\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.0268 - accuracy: 0.9935\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 890us/step - loss: 0.0239 - accuracy: 0.9883\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 825us/step - loss: 0.0128 - accuracy: 0.9986\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 869us/step - loss: 0.0215 - accuracy: 0.9953\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 887us/step - loss: 0.0198 - accuracy: 0.9928\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 861us/step - loss: 0.0260 - accuracy: 0.9955\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 965us/step - loss: 0.0196 - accuracy: 0.9914\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9916\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9933\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9967\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9942\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9886\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9930\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9959\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9936\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9953\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9969\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9890\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9901\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9876\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9962\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9931\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9969\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9978\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9943\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 0.9970\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 834us/step - loss: 0.0201 - accuracy: 0.9937\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 946us/step - loss: 0.0146 - accuracy: 0.9976\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.0206 - accuracy: 0.9917\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 881us/step - loss: 0.0204 - accuracy: 0.9928\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 845us/step - loss: 0.0166 - accuracy: 0.9969\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 854us/step - loss: 0.0240 - accuracy: 0.9928\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 823us/step - loss: 0.0226 - accuracy: 0.9899\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0216 - accuracy: 0.9926\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 816us/step - loss: 0.0198 - accuracy: 0.9914\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 835us/step - loss: 0.0229 - accuracy: 0.9872\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 811us/step - loss: 0.0175 - accuracy: 0.9954\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 827us/step - loss: 0.0229 - accuracy: 0.9910\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 796us/step - loss: 0.0344 - accuracy: 0.9855\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 847us/step - loss: 0.0256 - accuracy: 0.9895\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 844us/step - loss: 0.0277 - accuracy: 0.9869\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 813us/step - loss: 0.0223 - accuracy: 0.9913\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 857us/step - loss: 0.0250 - accuracy: 0.9880\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 854us/step - loss: 0.0147 - accuracy: 0.9975\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 881us/step - loss: 0.0139 - accuracy: 0.9974\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 874us/step - loss: 0.0110 - accuracy: 0.9967\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.0148 - accuracy: 0.9965\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 859us/step - loss: 0.0067 - accuracy: 0.9994\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 823us/step - loss: 0.0193 - accuracy: 0.9910\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 849us/step - loss: 0.0195 - accuracy: 0.9938\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 787us/step - loss: 0.0114 - accuracy: 0.9975\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 844us/step - loss: 0.0262 - accuracy: 0.9887\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 820us/step - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 810us/step - loss: 0.0272 - accuracy: 0.9900\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 822us/step - loss: 0.0116 - accuracy: 0.9981\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 856us/step - loss: 0.0078 - accuracy: 0.9985\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 852us/step - loss: 0.0185 - accuracy: 0.9921\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 864us/step - loss: 0.0160 - accuracy: 0.9946\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7810\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3053 - accuracy: 0.8872\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8632\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.8975\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 931us/step - loss: 0.3156 - accuracy: 0.8910\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 933us/step - loss: 0.2716 - accuracy: 0.8924\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 888us/step - loss: 0.2598 - accuracy: 0.8982\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 912us/step - loss: 0.2925 - accuracy: 0.8797\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 893us/step - loss: 0.2793 - accuracy: 0.8972\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 838us/step - loss: 0.2422 - accuracy: 0.9043\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 851us/step - loss: 0.2293 - accuracy: 0.9097\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 843us/step - loss: 0.2378 - accuracy: 0.9000\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 868us/step - loss: 0.1968 - accuracy: 0.9311\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 863us/step - loss: 0.2221 - accuracy: 0.9168\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 924us/step - loss: 0.2132 - accuracy: 0.9287\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 966us/step - loss: 0.2206 - accuracy: 0.9277\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 954us/step - loss: 0.1996 - accuracy: 0.9211\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 877us/step - loss: 0.1806 - accuracy: 0.9257\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 846us/step - loss: 0.1909 - accuracy: 0.9376\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9403\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.9229\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 861us/step - loss: 0.1865 - accuracy: 0.9274\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 865us/step - loss: 0.1619 - accuracy: 0.9506\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 890us/step - loss: 0.1485 - accuracy: 0.9517\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 821us/step - loss: 0.1662 - accuracy: 0.9385\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 856us/step - loss: 0.1471 - accuracy: 0.9418\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 857us/step - loss: 0.1326 - accuracy: 0.9494\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 835us/step - loss: 0.1434 - accuracy: 0.9434\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 836us/step - loss: 0.1400 - accuracy: 0.9606\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 833us/step - loss: 0.1246 - accuracy: 0.9557\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 800us/step - loss: 0.1163 - accuracy: 0.9586\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 830us/step - loss: 0.1182 - accuracy: 0.9612\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 828us/step - loss: 0.1061 - accuracy: 0.9658\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 948us/step - loss: 0.1085 - accuracy: 0.9697\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 833us/step - loss: 0.1102 - accuracy: 0.9717\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 835us/step - loss: 0.0998 - accuracy: 0.9732\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.1109 - accuracy: 0.9649\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 834us/step - loss: 0.0830 - accuracy: 0.9724\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 803us/step - loss: 0.0977 - accuracy: 0.9663\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 810us/step - loss: 0.0926 - accuracy: 0.9721\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 802us/step - loss: 0.0967 - accuracy: 0.9603\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 823us/step - loss: 0.0909 - accuracy: 0.9705\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 833us/step - loss: 0.0769 - accuracy: 0.9748\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 848us/step - loss: 0.0831 - accuracy: 0.9672\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 812us/step - loss: 0.0859 - accuracy: 0.9738\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 822us/step - loss: 0.0799 - accuracy: 0.9736\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 834us/step - loss: 0.0925 - accuracy: 0.9649\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 867us/step - loss: 0.0732 - accuracy: 0.9783\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0730 - accuracy: 0.9812\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 841us/step - loss: 0.0829 - accuracy: 0.9818\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 845us/step - loss: 0.0632 - accuracy: 0.9815\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 932us/step - loss: 0.0589 - accuracy: 0.9792\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 860us/step - loss: 0.0751 - accuracy: 0.9736\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9653\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 916us/step - loss: 0.0700 - accuracy: 0.9715\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 935us/step - loss: 0.0880 - accuracy: 0.9703\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 943us/step - loss: 0.0691 - accuracy: 0.9787\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 834us/step - loss: 0.0617 - accuracy: 0.9763\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 837us/step - loss: 0.0669 - accuracy: 0.9702\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 904us/step - loss: 0.0495 - accuracy: 0.9816\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 930us/step - loss: 0.0551 - accuracy: 0.9822\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 837us/step - loss: 0.0533 - accuracy: 0.9808\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 820us/step - loss: 0.0569 - accuracy: 0.9865\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 821us/step - loss: 0.0498 - accuracy: 0.9823\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 838us/step - loss: 0.0590 - accuracy: 0.9872\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.0462 - accuracy: 0.9854\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 916us/step - loss: 0.0513 - accuracy: 0.9850\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 979us/step - loss: 0.0432 - accuracy: 0.9863\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 860us/step - loss: 0.0550 - accuracy: 0.9809\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 913us/step - loss: 0.0463 - accuracy: 0.9821\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 818us/step - loss: 0.0447 - accuracy: 0.9888\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 846us/step - loss: 0.0514 - accuracy: 0.9885\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0440 - accuracy: 0.9830\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0491 - accuracy: 0.9854\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 837us/step - loss: 0.0451 - accuracy: 0.9843\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 847us/step - loss: 0.0376 - accuracy: 0.9920\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 879us/step - loss: 0.0636 - accuracy: 0.9744\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 855us/step - loss: 0.0423 - accuracy: 0.9849\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 926us/step - loss: 0.0337 - accuracy: 0.9872\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 849us/step - loss: 0.0316 - accuracy: 0.9932\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 841us/step - loss: 0.0404 - accuracy: 0.9828\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 847us/step - loss: 0.0426 - accuracy: 0.9790\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 843us/step - loss: 0.0437 - accuracy: 0.9881\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 963us/step - loss: 0.0390 - accuracy: 0.9906\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9882\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9835\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9927\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 838us/step - loss: 0.0339 - accuracy: 0.9923\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 854us/step - loss: 0.0356 - accuracy: 0.9863\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 849us/step - loss: 0.0336 - accuracy: 0.9892\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 900us/step - loss: 0.0317 - accuracy: 0.9882\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 880us/step - loss: 0.0387 - accuracy: 0.9853\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 849us/step - loss: 0.0397 - accuracy: 0.9875\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 957us/step - loss: 0.0530 - accuracy: 0.9821\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 872us/step - loss: 0.0401 - accuracy: 0.9890\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 876us/step - loss: 0.0427 - accuracy: 0.9800\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 816us/step - loss: 0.0291 - accuracy: 0.9933\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 886us/step - loss: 0.0306 - accuracy: 0.9912\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 929us/step - loss: 0.0314 - accuracy: 0.9920\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 844us/step - loss: 0.0213 - accuracy: 0.9960\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 827us/step - loss: 0.0288 - accuracy: 0.9885\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 935us/step - loss: 0.0455 - accuracy: 0.9835\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 950us/step - loss: 0.0281 - accuracy: 0.9931\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 878us/step - loss: 0.0482 - accuracy: 0.9765\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 865us/step - loss: 0.0237 - accuracy: 0.9919\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 813us/step - loss: 0.0435 - accuracy: 0.9830\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 836us/step - loss: 0.0350 - accuracy: 0.9804\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 800us/step - loss: 0.0332 - accuracy: 0.9834\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 839us/step - loss: 0.0132 - accuracy: 0.9991\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 828us/step - loss: 0.0177 - accuracy: 0.9943\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 834us/step - loss: 0.0234 - accuracy: 0.9936\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 820us/step - loss: 0.0323 - accuracy: 0.9900\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 814us/step - loss: 0.0277 - accuracy: 0.9911\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0314 - accuracy: 0.9883\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.0276 - accuracy: 0.9964\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 841us/step - loss: 0.0196 - accuracy: 0.9946\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 848us/step - loss: 0.0412 - accuracy: 0.9887\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 804us/step - loss: 0.0351 - accuracy: 0.9807\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 806us/step - loss: 0.0222 - accuracy: 0.9967\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 824us/step - loss: 0.0146 - accuracy: 0.9992\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 834us/step - loss: 0.0298 - accuracy: 0.9893\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 884us/step - loss: 0.0442 - accuracy: 0.9840\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.0404 - accuracy: 0.9787\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 885us/step - loss: 0.0330 - accuracy: 0.9904\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 831us/step - loss: 0.0220 - accuracy: 0.9918\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 817us/step - loss: 0.0288 - accuracy: 0.9889\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 827us/step - loss: 0.0311 - accuracy: 0.9840\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 833us/step - loss: 0.0198 - accuracy: 0.9913\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 792us/step - loss: 0.0241 - accuracy: 0.9923\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 790us/step - loss: 0.0246 - accuracy: 0.9907\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 838us/step - loss: 0.0220 - accuracy: 0.9953\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 791us/step - loss: 0.0270 - accuracy: 0.9915\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 804us/step - loss: 0.0338 - accuracy: 0.9876\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 820us/step - loss: 0.0514 - accuracy: 0.9778\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 803us/step - loss: 0.0232 - accuracy: 0.9944\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 787us/step - loss: 0.0189 - accuracy: 0.9967\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 815us/step - loss: 0.0259 - accuracy: 0.9916\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 800us/step - loss: 0.0236 - accuracy: 0.9907\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 804us/step - loss: 0.0223 - accuracy: 0.9879\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 968us/step - loss: 0.0291 - accuracy: 0.9885\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 861us/step - loss: 0.0284 - accuracy: 0.9887\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 845us/step - loss: 0.0374 - accuracy: 0.9825\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 798us/step - loss: 0.0185 - accuracy: 0.9958\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 829us/step - loss: 0.0264 - accuracy: 0.9909\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 854us/step - loss: 0.0170 - accuracy: 0.9976\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 886us/step - loss: 0.0327 - accuracy: 0.9804\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 836us/step - loss: 0.0333 - accuracy: 0.9856\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 840us/step - loss: 0.0331 - accuracy: 0.9851\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 903us/step - loss: 0.0340 - accuracy: 0.9899\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 874us/step - loss: 0.0363 - accuracy: 0.9857\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 859us/step - loss: 0.0239 - accuracy: 0.9927\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 803us/step - loss: 0.0432 - accuracy: 0.9853\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 862us/step - loss: 0.0252 - accuracy: 0.9957\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 922us/step - loss: 0.0182 - accuracy: 0.9965\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 823us/step - loss: 0.0170 - accuracy: 0.9959\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 856us/step - loss: 0.0232 - accuracy: 0.9949\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 892us/step - loss: 0.0242 - accuracy: 0.9952\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 872us/step - loss: 0.0087 - accuracy: 0.9985\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 837us/step - loss: 0.0154 - accuracy: 0.9970\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 810us/step - loss: 0.0267 - accuracy: 0.9909\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 830us/step - loss: 0.0165 - accuracy: 0.9978\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9857\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 982us/step - loss: 0.0118 - accuracy: 0.9946\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9878\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 0.9898\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 927us/step - loss: 0.0222 - accuracy: 0.9869\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9891\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 926us/step - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 999us/step - loss: 0.0125 - accuracy: 0.9956\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 963us/step - loss: 0.0114 - accuracy: 0.9992\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 955us/step - loss: 0.0139 - accuracy: 0.9965\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 956us/step - loss: 0.0110 - accuracy: 0.9979\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9864\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 937us/step - loss: 0.0167 - accuracy: 0.9938\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9939\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9960\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 955us/step - loss: 0.0171 - accuracy: 0.9942\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9896\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9866\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 986us/step - loss: 0.0276 - accuracy: 0.9892\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 892us/step - loss: 0.0157 - accuracy: 0.9950\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 879us/step - loss: 0.0331 - accuracy: 0.9843\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 855us/step - loss: 0.0272 - accuracy: 0.9887\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 882us/step - loss: 0.0154 - accuracy: 0.9924\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 922us/step - loss: 0.0154 - accuracy: 0.9935\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 858us/step - loss: 0.0299 - accuracy: 0.9894\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 848us/step - loss: 0.0206 - accuracy: 0.9923\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 833us/step - loss: 0.0198 - accuracy: 0.9946\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 831us/step - loss: 0.0077 - accuracy: 0.9981\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 846us/step - loss: 0.0170 - accuracy: 0.9915\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 920us/step - loss: 0.0112 - accuracy: 0.9970\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 920us/step - loss: 0.0217 - accuracy: 0.9905\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 829us/step - loss: 0.0137 - accuracy: 0.9952\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 852us/step - loss: 0.0142 - accuracy: 0.9953\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 873us/step - loss: 0.0161 - accuracy: 0.9940\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 883us/step - loss: 0.0086 - accuracy: 0.9989\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 820us/step - loss: 0.0129 - accuracy: 0.9962\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 878us/step - loss: 0.0067 - accuracy: 0.9994\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 850us/step - loss: 0.0138 - accuracy: 0.9931\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 892us/step - loss: 0.0087 - accuracy: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# without probability calibration\n",
    "y_test_proba = clf.fit(X_onehot, y).predict_proba(X_test)\n",
    "antag = combs_test[y_test_proba[:,1] > antag_thresh]\n",
    "syn = combs_test[y_test_proba[:,2] > syn_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Actinomycin D_Carbenicillin', 'Actinomycin D_Chlorpromazine',\n",
       "       'Ampicillin_Dibucaine', 'Azidothymidine_Chlorpromazine',\n",
       "       'Bicyclomycin_Sds', 'Bile_Chlorpromazine',\n",
       "       'Carbenicillin_Chlorpromazine', 'Carbenicillin_Cholate',\n",
       "       'Cecropinb_Norfloxacin', 'Cecropinb_Sds',\n",
       "       'Ceftazidime_Deoxycholate', 'Ceftazidime_Dibucaine',\n",
       "       'Ceftazidime_Sds', 'Chir090_Chlorpromazine',\n",
       "       'Chlorpromazine_Ethidiumbromide', 'Chlorpromazine_Norfloxacin',\n",
       "       'Chlorpromazine_Sds', 'Chlorpromazine_Taurocholate',\n",
       "       'Chlorpromazine_Tetracycline', 'Chlorpromazine_Uv',\n",
       "       'Deoxycholate_Sds', 'Methotrexate_Norfloxacin', 'Methotrexate_Sds',\n",
       "       'Nigericin_Norfloxacin', 'Nigericin_Sds', 'Norfloxacin_Sds',\n",
       "       'Pms_Sds', 'Sds_Tetracycline', 'Streptomycin_Tetracycline'],\n",
       "      dtype='<U31')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(antag, syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Actinomycin D_Deoxycholate', 'Actinomycin D_Ethanol',\n",
       "       'Ampicillin_Cefoxitin', 'Azidothymidine_Ethanol',\n",
       "       'Azidothymidine_Sds', 'Cefoxitin_Ceftazidime',\n",
       "       'Cefoxitin_Taurocholate', 'Cefoxitin_Vancomycin',\n",
       "       'Ceftazidime_Radicicol', 'Chlorpromazine_Nalidixicacid',\n",
       "       'Chlorpromazine_Peroxide', 'Chlorpromazine_Vancomycin',\n",
       "       'Cholate_Norfloxacin', 'Cholate_Radicicol', 'Deoxycholate_Ethanol',\n",
       "       'Deoxycholate_Nalidixicacid', 'Epinephrine_Peroxide',\n",
       "       'Epinephrine_Taurocholate', 'Isoniazid_Peroxide',\n",
       "       'Nalidixicacid_Streptonigrin', 'Radicicol_Taurocholate',\n",
       "       'Taurocholate_Vancomycin'], dtype='<U31')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(syn, antag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Actinomycin D_Taurocholate', 'Sds_Sulfamethizole'], dtype='<U31')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(antag, syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr = pd.DataFrame(y_test_proba, index=combs_test,\n",
    "             columns=['none', 'antag', 'synergy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr.to_csv('nichols_test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>none</th>\n",
       "      <th>antag</th>\n",
       "      <th>synergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Deoxycholate_Sds</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>1.415680e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ceftazidime_Dibucaine</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>2.519536e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ceftazidime_Sds</th>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>4.931456e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bicyclomycin_Sds</th>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.999078</td>\n",
       "      <td>2.937713e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norfloxacin_Sds</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.999001</td>\n",
       "      <td>8.375962e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carbenicillin_Cholate</th>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>1.490311e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chlorpromazine_Sds</th>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.997589</td>\n",
       "      <td>2.350738e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chlorpromazine_Taurocholate</th>\n",
       "      <td>0.012932</td>\n",
       "      <td>0.989746</td>\n",
       "      <td>1.591111e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azidothymidine_Chlorpromazine</th>\n",
       "      <td>0.105469</td>\n",
       "      <td>0.988430</td>\n",
       "      <td>2.213059e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Methotrexate_Norfloxacin</th>\n",
       "      <td>0.437550</td>\n",
       "      <td>0.981116</td>\n",
       "      <td>1.569646e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sds_Tetracycline</th>\n",
       "      <td>0.750340</td>\n",
       "      <td>0.976254</td>\n",
       "      <td>1.274645e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ceftazidime_Deoxycholate</th>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.963887</td>\n",
       "      <td>2.009629e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chlorpromazine_Norfloxacin</th>\n",
       "      <td>0.057591</td>\n",
       "      <td>0.956809</td>\n",
       "      <td>2.181856e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cecropinb_Sds</th>\n",
       "      <td>0.210192</td>\n",
       "      <td>0.952221</td>\n",
       "      <td>4.119134e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nigericin_Sds</th>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.947643</td>\n",
       "      <td>2.757183e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sds_Sulfamethizole</th>\n",
       "      <td>0.008359</td>\n",
       "      <td>0.918292</td>\n",
       "      <td>5.152018e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actinomycin D_Chlorpromazine</th>\n",
       "      <td>0.381631</td>\n",
       "      <td>0.909778</td>\n",
       "      <td>1.620909e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bile_Chlorpromazine</th>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.894372</td>\n",
       "      <td>6.621200e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actinomycin D_Carbenicillin</th>\n",
       "      <td>0.507321</td>\n",
       "      <td>0.891677</td>\n",
       "      <td>1.080183e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Methotrexate_Sds</th>\n",
       "      <td>0.190873</td>\n",
       "      <td>0.885107</td>\n",
       "      <td>1.910876e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   none     antag       synergy\n",
       "Deoxycholate_Sds               0.000002  0.999906  1.415680e-04\n",
       "Ceftazidime_Dibucaine          0.000020  0.999878  2.519536e-10\n",
       "Ceftazidime_Sds                0.000117  0.999718  4.931456e-08\n",
       "Bicyclomycin_Sds               0.000165  0.999078  2.937713e-02\n",
       "Norfloxacin_Sds                0.000075  0.999001  8.375962e-04\n",
       "Carbenicillin_Cholate          0.015052  0.998681  1.490311e-11\n",
       "Chlorpromazine_Sds             0.005793  0.997589  2.350738e-01\n",
       "Chlorpromazine_Taurocholate    0.012932  0.989746  1.591111e-02\n",
       "Azidothymidine_Chlorpromazine  0.105469  0.988430  2.213059e-01\n",
       "Methotrexate_Norfloxacin       0.437550  0.981116  1.569646e-05\n",
       "Sds_Tetracycline               0.750340  0.976254  1.274645e-08\n",
       "Ceftazidime_Deoxycholate       0.005818  0.963887  2.009629e-02\n",
       "Chlorpromazine_Norfloxacin     0.057591  0.956809  2.181856e-03\n",
       "Cecropinb_Sds                  0.210192  0.952221  4.119134e-05\n",
       "Nigericin_Sds                  0.012185  0.947643  2.757183e-06\n",
       "Sds_Sulfamethizole             0.008359  0.918292  5.152018e-01\n",
       "Actinomycin D_Chlorpromazine   0.381631  0.909778  1.620909e-02\n",
       "Bile_Chlorpromazine            0.962659  0.894372  6.621200e-10\n",
       "Actinomycin D_Carbenicillin    0.507321  0.891677  1.080183e-09\n",
       "Methotrexate_Sds               0.190873  0.885107  1.910876e-04"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_uncalibr.sort_values('antag', ascending=False).iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>none</th>\n",
       "      <th>antag</th>\n",
       "      <th>synergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nalidixicacid_Streptonigrin</th>\n",
       "      <td>0.753998</td>\n",
       "      <td>1.889142e-17</td>\n",
       "      <td>0.984839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cefoxitin_Ceftazidime</th>\n",
       "      <td>0.400368</td>\n",
       "      <td>9.335238e-13</td>\n",
       "      <td>0.973902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ceftazidime_Radicicol</th>\n",
       "      <td>0.571502</td>\n",
       "      <td>2.626599e-04</td>\n",
       "      <td>0.963931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azidothymidine_Sds</th>\n",
       "      <td>0.145679</td>\n",
       "      <td>3.704839e-06</td>\n",
       "      <td>0.939499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epinephrine_Taurocholate</th>\n",
       "      <td>0.078117</td>\n",
       "      <td>7.855433e-06</td>\n",
       "      <td>0.911133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taurocholate_Vancomycin</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.434091e-04</td>\n",
       "      <td>0.896034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azidothymidine_Ethanol</th>\n",
       "      <td>0.626038</td>\n",
       "      <td>4.617234e-09</td>\n",
       "      <td>0.857221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ampicillin_Cefoxitin</th>\n",
       "      <td>0.902034</td>\n",
       "      <td>7.833438e-18</td>\n",
       "      <td>0.823103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cefoxitin_Vancomycin</th>\n",
       "      <td>0.160119</td>\n",
       "      <td>8.189893e-07</td>\n",
       "      <td>0.810583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radicicol_Taurocholate</th>\n",
       "      <td>0.170094</td>\n",
       "      <td>2.266181e-08</td>\n",
       "      <td>0.807362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholate_Radicicol</th>\n",
       "      <td>0.891728</td>\n",
       "      <td>3.245779e-10</td>\n",
       "      <td>0.785799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chlorpromazine_Peroxide</th>\n",
       "      <td>0.286442</td>\n",
       "      <td>1.428316e-01</td>\n",
       "      <td>0.765273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actinomycin D_Deoxycholate</th>\n",
       "      <td>0.967283</td>\n",
       "      <td>1.391504e-12</td>\n",
       "      <td>0.736351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chlorpromazine_Vancomycin</th>\n",
       "      <td>0.157819</td>\n",
       "      <td>8.854898e-06</td>\n",
       "      <td>0.670266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actinomycin D_Taurocholate</th>\n",
       "      <td>0.000755</td>\n",
       "      <td>6.829776e-01</td>\n",
       "      <td>0.655053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deoxycholate_Ethanol</th>\n",
       "      <td>0.974736</td>\n",
       "      <td>2.881699e-15</td>\n",
       "      <td>0.611171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deoxycholate_Nalidixicacid</th>\n",
       "      <td>0.091965</td>\n",
       "      <td>7.762087e-04</td>\n",
       "      <td>0.587822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actinomycin D_Ethanol</th>\n",
       "      <td>0.948287</td>\n",
       "      <td>3.398377e-13</td>\n",
       "      <td>0.565502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epinephrine_Peroxide</th>\n",
       "      <td>0.645474</td>\n",
       "      <td>7.013668e-11</td>\n",
       "      <td>0.562425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chlorpromazine_Nalidixicacid</th>\n",
       "      <td>0.006815</td>\n",
       "      <td>9.849885e-03</td>\n",
       "      <td>0.534593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  none         antag   synergy\n",
       "Nalidixicacid_Streptonigrin   0.753998  1.889142e-17  0.984839\n",
       "Cefoxitin_Ceftazidime         0.400368  9.335238e-13  0.973902\n",
       "Ceftazidime_Radicicol         0.571502  2.626599e-04  0.963931\n",
       "Azidothymidine_Sds            0.145679  3.704839e-06  0.939499\n",
       "Epinephrine_Taurocholate      0.078117  7.855433e-06  0.911133\n",
       "Taurocholate_Vancomycin       0.000047  1.434091e-04  0.896034\n",
       "Azidothymidine_Ethanol        0.626038  4.617234e-09  0.857221\n",
       "Ampicillin_Cefoxitin          0.902034  7.833438e-18  0.823103\n",
       "Cefoxitin_Vancomycin          0.160119  8.189893e-07  0.810583\n",
       "Radicicol_Taurocholate        0.170094  2.266181e-08  0.807362\n",
       "Cholate_Radicicol             0.891728  3.245779e-10  0.785799\n",
       "Chlorpromazine_Peroxide       0.286442  1.428316e-01  0.765273\n",
       "Actinomycin D_Deoxycholate    0.967283  1.391504e-12  0.736351\n",
       "Chlorpromazine_Vancomycin     0.157819  8.854898e-06  0.670266\n",
       "Actinomycin D_Taurocholate    0.000755  6.829776e-01  0.655053\n",
       "Deoxycholate_Ethanol          0.974736  2.881699e-15  0.611171\n",
       "Deoxycholate_Nalidixicacid    0.091965  7.762087e-04  0.587822\n",
       "Actinomycin D_Ethanol         0.948287  3.398377e-13  0.565502\n",
       "Epinephrine_Peroxide          0.645474  7.013668e-11  0.562425\n",
       "Chlorpromazine_Nalidixicacid  0.006815  9.849885e-03  0.534593"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_uncalibr.sort_values('synergy', ascending=False).iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.7114 - accuracy: 0.6558\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7305\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.5448 - accuracy: 0.7245\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.5035 - accuracy: 0.7692\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.4834 - accuracy: 0.7727\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.4587 - accuracy: 0.7839\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.8137\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8284\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.8163\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8236\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8373\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8382\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8557\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8301\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8362\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.3719 - accuracy: 0.8387\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8672\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8341\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8691\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.8846\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8733\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.9005\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 0.9086\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.8998\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2746 - accuracy: 0.8780\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.8933\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.8968\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2554 - accuracy: 0.8949\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9329\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2606 - accuracy: 0.8900\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8981\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9151\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.9267\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9453\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.1885 - accuracy: 0.9317\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.9311\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9198\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.9189\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9280\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9377\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9565\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.1746 - accuracy: 0.9310\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.9350\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9356\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9594\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1723 - accuracy: 0.9432\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1448 - accuracy: 0.9541\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9402\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9508\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9417\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.9590\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.9468\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9439\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.9516\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9417\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9739\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.1157 - accuracy: 0.9598\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.1265 - accuracy: 0.9591\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.1128 - accuracy: 0.9547\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 808us/step - loss: 0.1136 - accuracy: 0.9621\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.1263 - accuracy: 0.9567\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.1058 - accuracy: 0.9701\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.1236 - accuracy: 0.9549\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.1100 - accuracy: 0.9629\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.1130 - accuracy: 0.9598\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.1021 - accuracy: 0.9594\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0917 - accuracy: 0.9716\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0964 - accuracy: 0.9712\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.1184 - accuracy: 0.9635\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.1005 - accuracy: 0.9613\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0997 - accuracy: 0.9606\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.1069 - accuracy: 0.9521\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0986 - accuracy: 0.9738\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0934 - accuracy: 0.9617\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.1011 - accuracy: 0.9584\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.1062 - accuracy: 0.9567\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0739 - accuracy: 0.9781\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.0922 - accuracy: 0.9639\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0850 - accuracy: 0.9678\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0694 - accuracy: 0.9774\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9745\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9627\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9772\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0745 - accuracy: 0.9761\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0595 - accuracy: 0.9867\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0680 - accuracy: 0.9772\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0587 - accuracy: 0.9826\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0651 - accuracy: 0.9827\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0741 - accuracy: 0.9776\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0652 - accuracy: 0.9745\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0781 - accuracy: 0.9707\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0739 - accuracy: 0.9726\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0709 - accuracy: 0.9811\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0809 - accuracy: 0.9757\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0710 - accuracy: 0.9824\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0671 - accuracy: 0.9782\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0609 - accuracy: 0.9847\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0565 - accuracy: 0.9842\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0586 - accuracy: 0.9837\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9669\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9888\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0695 - accuracy: 0.9799\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9724\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9789\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0732 - accuracy: 0.9777\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0605 - accuracy: 0.9818\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0856 - accuracy: 0.9784\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0668 - accuracy: 0.9803\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0621 - accuracy: 0.9802\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0473 - accuracy: 0.9819\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0748 - accuracy: 0.9760\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0440 - accuracy: 0.9933\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0623 - accuracy: 0.9776\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0395 - accuracy: 0.9914\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0504 - accuracy: 0.9833\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0461 - accuracy: 0.9846\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0394 - accuracy: 0.9920\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0561 - accuracy: 0.9834\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0565 - accuracy: 0.9789\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0416 - accuracy: 0.9869\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0447 - accuracy: 0.9834\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0522 - accuracy: 0.9923\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0424 - accuracy: 0.9851\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0506 - accuracy: 0.9852\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0380 - accuracy: 0.9918\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0625 - accuracy: 0.9812\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0508 - accuracy: 0.9754\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0456 - accuracy: 0.9874\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0575 - accuracy: 0.9790\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9860\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0566 - accuracy: 0.9748\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9920\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9850\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9910\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0663 - accuracy: 0.9758\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0448 - accuracy: 0.9817\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0372 - accuracy: 0.9914\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 797us/step - loss: 0.0382 - accuracy: 0.9905\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 800us/step - loss: 0.0457 - accuracy: 0.9922\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.0382 - accuracy: 0.9877\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0741 - accuracy: 0.9746\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0596 - accuracy: 0.9776\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0513 - accuracy: 0.9837\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0453 - accuracy: 0.9881\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0370 - accuracy: 0.9847\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 802us/step - loss: 0.0442 - accuracy: 0.9814\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0476 - accuracy: 0.9879\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 815us/step - loss: 0.0413 - accuracy: 0.9808\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0531 - accuracy: 0.9817\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0302 - accuracy: 0.9937\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0332 - accuracy: 0.9855\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0420 - accuracy: 0.9910\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0384 - accuracy: 0.9859\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9826\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9883\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9906\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0287 - accuracy: 0.9941\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0462 - accuracy: 0.9819\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9939\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9923\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9867\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9867\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9865\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9924\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9950\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9923\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9915\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9936\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9956\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9857\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9795\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9941\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9855\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0264 - accuracy: 0.9945\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0221 - accuracy: 0.9942\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0338 - accuracy: 0.9853\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0300 - accuracy: 0.9937\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0283 - accuracy: 0.9904\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0374 - accuracy: 0.9814\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0403 - accuracy: 0.9848\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0322 - accuracy: 0.9893\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9885\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9843\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0330 - accuracy: 0.9909\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9952\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9923\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9919\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9908\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9782\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9916\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9890\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0362 - accuracy: 0.9901\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9856\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9882\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9828\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9858\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9901\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 882us/step - loss: 0.8370 - accuracy: 0.6033\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.5862 - accuracy: 0.7083\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.5543 - accuracy: 0.7248\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.4744 - accuracy: 0.7852\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.5007 - accuracy: 0.7701\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.4603 - accuracy: 0.8065\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.4617 - accuracy: 0.8025\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.4655 - accuracy: 0.7939\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.4197 - accuracy: 0.8181\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.4415 - accuracy: 0.8211\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.4129 - accuracy: 0.8140\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.3988 - accuracy: 0.8284\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8515\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8750\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8494\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8654\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.3378 - accuracy: 0.8632\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8811\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8524\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.3131 - accuracy: 0.8657\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.8762\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.2899 - accuracy: 0.8891\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8936\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.2606 - accuracy: 0.9075\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8802\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.2758 - accuracy: 0.8786\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.2508 - accuracy: 0.9068\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9180\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.2617 - accuracy: 0.9038\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.2736 - accuracy: 0.8784\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.2326 - accuracy: 0.9181\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.2429 - accuracy: 0.9078\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9060\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.2040 - accuracy: 0.9297\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9245\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.2434 - accuracy: 0.8921\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.2096 - accuracy: 0.9331\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.2027 - accuracy: 0.9322\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.1666 - accuracy: 0.9431\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.1756 - accuracy: 0.9374\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1853 - accuracy: 0.9442\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.1745 - accuracy: 0.9474\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.1579 - accuracy: 0.9464\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.1617 - accuracy: 0.9400\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.1461 - accuracy: 0.9497\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.1554 - accuracy: 0.9544\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1528 - accuracy: 0.9529\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1424 - accuracy: 0.9460\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.1612 - accuracy: 0.9440\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.1245 - accuracy: 0.9610\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.1369 - accuracy: 0.9605\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.1452 - accuracy: 0.9540\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.1226 - accuracy: 0.9567\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.1398 - accuracy: 0.9485\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.1122 - accuracy: 0.9597\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.1080 - accuracy: 0.9714\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.1281 - accuracy: 0.9514\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.1193 - accuracy: 0.9587\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.1189 - accuracy: 0.9603\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.1170 - accuracy: 0.9613\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.1304 - accuracy: 0.9597\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.1034 - accuracy: 0.9666\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0913 - accuracy: 0.9704\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0972 - accuracy: 0.9687\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.1077 - accuracy: 0.9730\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0939 - accuracy: 0.9626\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.1031 - accuracy: 0.9697\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0865 - accuracy: 0.9744\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.1073 - accuracy: 0.9691\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.1039 - accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.1056 - accuracy: 0.9627\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0808 - accuracy: 0.9727\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0770 - accuracy: 0.9744\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0777 - accuracy: 0.9798\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0801 - accuracy: 0.9748\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0788 - accuracy: 0.9795\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.1129 - accuracy: 0.9552\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0907 - accuracy: 0.9643\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0859 - accuracy: 0.9713\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0721 - accuracy: 0.9851\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 907us/step - loss: 0.0912 - accuracy: 0.9695\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0811 - accuracy: 0.9754\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0712 - accuracy: 0.9759\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0673 - accuracy: 0.9780\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0852 - accuracy: 0.9711\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0737 - accuracy: 0.9720\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.1019 - accuracy: 0.9636\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0641 - accuracy: 0.9791\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0837 - accuracy: 0.9721\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0579 - accuracy: 0.9818\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0758 - accuracy: 0.9717\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0628 - accuracy: 0.9758\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0715 - accuracy: 0.9767\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0905 - accuracy: 0.9618\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0782 - accuracy: 0.9724\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0697 - accuracy: 0.9754\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0451 - accuracy: 0.9932\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0637 - accuracy: 0.9736\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0751 - accuracy: 0.9768\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0577 - accuracy: 0.9765\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0550 - accuracy: 0.9857\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0582 - accuracy: 0.9888\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0609 - accuracy: 0.9810\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0543 - accuracy: 0.9814\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0830 - accuracy: 0.9657\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0564 - accuracy: 0.9859\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0477 - accuracy: 0.9856\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0591 - accuracy: 0.9827\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0502 - accuracy: 0.9852\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0436 - accuracy: 0.9872\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0749 - accuracy: 0.9749\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0721 - accuracy: 0.9790\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0576 - accuracy: 0.9897\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0460 - accuracy: 0.9875\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0539 - accuracy: 0.9881\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0363 - accuracy: 0.9926\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0630 - accuracy: 0.9779\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0602 - accuracy: 0.9736\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0399 - accuracy: 0.9861\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0359 - accuracy: 0.9877\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0376 - accuracy: 0.9902\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0391 - accuracy: 0.9935\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0488 - accuracy: 0.9789\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0498 - accuracy: 0.9865\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0537 - accuracy: 0.9825\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0388 - accuracy: 0.9903\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0473 - accuracy: 0.9874\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0530 - accuracy: 0.9828\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0404 - accuracy: 0.9890\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0446 - accuracy: 0.9846\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0343 - accuracy: 0.9912\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9807\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0559 - accuracy: 0.9805\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0456 - accuracy: 0.9802\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0398 - accuracy: 0.9922\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0498 - accuracy: 0.9812\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0638 - accuracy: 0.9776\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0473 - accuracy: 0.9846\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0466 - accuracy: 0.9840\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 796us/step - loss: 0.0718 - accuracy: 0.9806\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0435 - accuracy: 0.9887\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0386 - accuracy: 0.9885\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0405 - accuracy: 0.9893\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0439 - accuracy: 0.9852\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0431 - accuracy: 0.9782\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0357 - accuracy: 0.9896\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0619 - accuracy: 0.9826\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0396 - accuracy: 0.9878\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0463 - accuracy: 0.9845\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0279 - accuracy: 0.9915\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0398 - accuracy: 0.9885\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0412 - accuracy: 0.9888\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0386 - accuracy: 0.9827\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0590 - accuracy: 0.9808\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0473 - accuracy: 0.9867\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0394 - accuracy: 0.9885\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0233 - accuracy: 0.9936\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0691 - accuracy: 0.9815\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0523 - accuracy: 0.9779\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 870us/step - loss: 0.0420 - accuracy: 0.9789\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0419 - accuracy: 0.9820\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0608 - accuracy: 0.9817\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0319 - accuracy: 0.9897\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0517 - accuracy: 0.9885\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0385 - accuracy: 0.9839\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9925\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9931\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9884\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9860\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9845\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0487 - accuracy: 0.9834\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9847\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0355 - accuracy: 0.9852\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9937\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0384 - accuracy: 0.9896\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0327 - accuracy: 0.9892\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0225 - accuracy: 0.9939\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0426 - accuracy: 0.9811\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9920\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0421 - accuracy: 0.9839\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0281 - accuracy: 0.9886\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9853\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9898\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0388 - accuracy: 0.9826\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9855\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9936\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9792\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9825\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0297 - accuracy: 0.9846\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0237 - accuracy: 0.9963\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0232 - accuracy: 0.9896\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9849\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0249 - accuracy: 0.9918\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0200 - accuracy: 0.9939\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0347 - accuracy: 0.9900\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0228 - accuracy: 0.9967\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0458 - accuracy: 0.9833\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0446 - accuracy: 0.9837\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0410 - accuracy: 0.9876\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0310 - accuracy: 0.9874\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 853us/step - loss: 1.0020 - accuracy: 0.5591\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.5695 - accuracy: 0.7436\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.5715 - accuracy: 0.7180\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.5074 - accuracy: 0.7565\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7682\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.4792 - accuracy: 0.7853\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.4413 - accuracy: 0.8127\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.4210 - accuracy: 0.8180\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.4966 - accuracy: 0.7642\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.4060 - accuracy: 0.8281\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.4252 - accuracy: 0.8191\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.3768 - accuracy: 0.8385\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.3753 - accuracy: 0.8606\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.3613 - accuracy: 0.8563\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.3599 - accuracy: 0.8682\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.3744 - accuracy: 0.8527\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8658\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.3266 - accuracy: 0.8783\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8425\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.2842 - accuracy: 0.9004\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.3034 - accuracy: 0.8940\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.3058 - accuracy: 0.8774\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.3038 - accuracy: 0.8725\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.2648 - accuracy: 0.9066\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.3086 - accuracy: 0.8737\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.2914 - accuracy: 0.8724\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2598 - accuracy: 0.8895\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.2885 - accuracy: 0.8795\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.2737 - accuracy: 0.8971\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.2468 - accuracy: 0.8998\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2536 - accuracy: 0.9111\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.2135 - accuracy: 0.9242\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.2014 - accuracy: 0.9244\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.2070 - accuracy: 0.9259\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.2184 - accuracy: 0.9201\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.2069 - accuracy: 0.9219\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.2197 - accuracy: 0.9160\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.1961 - accuracy: 0.9267\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.2220 - accuracy: 0.9203\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.1994 - accuracy: 0.9344\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1995 - accuracy: 0.9209\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.1631 - accuracy: 0.9369\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.1895 - accuracy: 0.9463\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.1799 - accuracy: 0.9362\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.1737 - accuracy: 0.9491\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.1792 - accuracy: 0.9418\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.1655 - accuracy: 0.9273\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.1609 - accuracy: 0.9412\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.1669 - accuracy: 0.9301\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1847 - accuracy: 0.9297\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.1633 - accuracy: 0.9459\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.1455 - accuracy: 0.9476\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.1419 - accuracy: 0.9492\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.1605 - accuracy: 0.9417\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.1234 - accuracy: 0.9640\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.1388 - accuracy: 0.9584\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.1690 - accuracy: 0.9421\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.1203 - accuracy: 0.9689\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.1248 - accuracy: 0.9558\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.1181 - accuracy: 0.9561\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.1350 - accuracy: 0.9561\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.1265 - accuracy: 0.9660\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.1384 - accuracy: 0.9577\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1336 - accuracy: 0.9415\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.1509 - accuracy: 0.9450\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9637\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.1343 - accuracy: 0.9538\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.1391 - accuracy: 0.9516\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.1302 - accuracy: 0.9620\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.1063 - accuracy: 0.9653\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9665\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0964 - accuracy: 0.9713\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.1056 - accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0894 - accuracy: 0.9795\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.1191 - accuracy: 0.9543\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.1460 - accuracy: 0.9457\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0902 - accuracy: 0.9719\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9642\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.1122 - accuracy: 0.9566\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.1010 - accuracy: 0.9638\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 926us/step - loss: 0.1022 - accuracy: 0.9649\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0915 - accuracy: 0.9648\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0998 - accuracy: 0.9641\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9749\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0801 - accuracy: 0.9768\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0891 - accuracy: 0.9716\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0948 - accuracy: 0.9729\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.1044 - accuracy: 0.9588\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0808 - accuracy: 0.9750\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0635 - accuracy: 0.9789\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0866 - accuracy: 0.9729\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0702 - accuracy: 0.9805\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.9577\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0850 - accuracy: 0.9722\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0864 - accuracy: 0.9695\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0884 - accuracy: 0.9744\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0787 - accuracy: 0.9753\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0923 - accuracy: 0.9627\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0857 - accuracy: 0.9798\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0742 - accuracy: 0.9705\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0772 - accuracy: 0.9751\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0881 - accuracy: 0.9703\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0780 - accuracy: 0.9726\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0744 - accuracy: 0.9738\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0635 - accuracy: 0.9843\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9768\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0784 - accuracy: 0.9684\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0877 - accuracy: 0.9694\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0557 - accuracy: 0.9883\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0706 - accuracy: 0.9793\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0690 - accuracy: 0.9735\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0588 - accuracy: 0.9825\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0757 - accuracy: 0.9696\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0630 - accuracy: 0.9764\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0817 - accuracy: 0.9586\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9777\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0805 - accuracy: 0.9669\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0835 - accuracy: 0.9707\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0906 - accuracy: 0.9581\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0712 - accuracy: 0.9770\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0587 - accuracy: 0.9773\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0632 - accuracy: 0.9752\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0774 - accuracy: 0.9717\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9743\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0707 - accuracy: 0.9783\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0622 - accuracy: 0.9715\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0577 - accuracy: 0.9786\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0834 - accuracy: 0.9697\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0596 - accuracy: 0.9762\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0771 - accuracy: 0.9731\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0632 - accuracy: 0.9783\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0578 - accuracy: 0.9753\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0657 - accuracy: 0.9787\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0563 - accuracy: 0.9767\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0610 - accuracy: 0.9766\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0496 - accuracy: 0.9825\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0559 - accuracy: 0.9841\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0625 - accuracy: 0.9724\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0982 - accuracy: 0.9622\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0625 - accuracy: 0.9743\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0468 - accuracy: 0.9855\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0643 - accuracy: 0.9807\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0649 - accuracy: 0.9706\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0506 - accuracy: 0.9834\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0513 - accuracy: 0.9831\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9894\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0826 - accuracy: 0.9661\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0543 - accuracy: 0.9842\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0741 - accuracy: 0.9667\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0526 - accuracy: 0.9781\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0433 - accuracy: 0.9879\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0552 - accuracy: 0.9809\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9711\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9851\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9842\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9853\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0557 - accuracy: 0.9833\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0576 - accuracy: 0.9799\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0528 - accuracy: 0.9782\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0523 - accuracy: 0.9735\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9810\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0537 - accuracy: 0.9822\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0456 - accuracy: 0.9847\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0405 - accuracy: 0.9856\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0561 - accuracy: 0.9744\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9827\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0414 - accuracy: 0.9802\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0404 - accuracy: 0.9832\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9868\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9934\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9829\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0613 - accuracy: 0.9813\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9853\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9784\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0459 - accuracy: 0.9794\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0367 - accuracy: 0.9882\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0511 - accuracy: 0.9820\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9839\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9850\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9891\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0499 - accuracy: 0.9778\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0547 - accuracy: 0.9848\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0624 - accuracy: 0.9720\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0563 - accuracy: 0.9787\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0421 - accuracy: 0.9925\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9684\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9863\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0460 - accuracy: 0.9840\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0480 - accuracy: 0.9854\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0490 - accuracy: 0.9807\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0483 - accuracy: 0.9839\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0400 - accuracy: 0.9864\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0365 - accuracy: 0.9901\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0341 - accuracy: 0.9883\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9813\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0310 - accuracy: 0.9885\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0310 - accuracy: 0.9928\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9872\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0387 - accuracy: 0.9882\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0353 - accuracy: 0.9872\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 862us/step - loss: 0.8035 - accuracy: 0.6289\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.5498 - accuracy: 0.7439\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.5257 - accuracy: 0.7553\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.5420 - accuracy: 0.7413\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.4713 - accuracy: 0.8001\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.4867 - accuracy: 0.7865\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.4617 - accuracy: 0.7747\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.4633 - accuracy: 0.7944\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.4379 - accuracy: 0.8266\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.4508 - accuracy: 0.8018\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8205\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.4026 - accuracy: 0.8087\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.3829 - accuracy: 0.8442\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.3712 - accuracy: 0.8355\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.3739 - accuracy: 0.8341\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.3490 - accuracy: 0.8541\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.3533 - accuracy: 0.8625\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.3638 - accuracy: 0.8498\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8865\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8314\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8568\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.3352 - accuracy: 0.8658\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.3155 - accuracy: 0.8787\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.2828 - accuracy: 0.8792\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8885\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.2864 - accuracy: 0.8928\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.3026 - accuracy: 0.8874\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.2933 - accuracy: 0.8749\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.2750 - accuracy: 0.8935\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.9025\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9067\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2712 - accuracy: 0.8874\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.2463 - accuracy: 0.8994\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.2469 - accuracy: 0.9109\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.2456 - accuracy: 0.8960\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.2355 - accuracy: 0.9119\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.2248 - accuracy: 0.9051\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9084\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2509 - accuracy: 0.8867\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.2240 - accuracy: 0.9133\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.2352 - accuracy: 0.9051\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.9204\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.1949 - accuracy: 0.9211\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.1753 - accuracy: 0.9400\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.2217 - accuracy: 0.9179\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.9276\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.2069 - accuracy: 0.9301\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9488\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.1987 - accuracy: 0.9239\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.1819 - accuracy: 0.9368\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.1817 - accuracy: 0.9347\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.1905 - accuracy: 0.9311\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.1810 - accuracy: 0.9357\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.1609 - accuracy: 0.9364\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.1906 - accuracy: 0.9225\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.1726 - accuracy: 0.9386\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.1513 - accuracy: 0.9467\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1442 - accuracy: 0.9465\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9393\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.1380 - accuracy: 0.9560\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.1552 - accuracy: 0.9375\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.1547 - accuracy: 0.9361\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.1451 - accuracy: 0.9554\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.1259 - accuracy: 0.9576\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.1437 - accuracy: 0.9511\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.1451 - accuracy: 0.9379\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.1536 - accuracy: 0.9510\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.1307 - accuracy: 0.9583\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9429\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.1401 - accuracy: 0.9519\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.1137 - accuracy: 0.9678\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.1212 - accuracy: 0.9585\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.1393 - accuracy: 0.9516\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.1401 - accuracy: 0.9596\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.1370 - accuracy: 0.9529\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.1144 - accuracy: 0.9628\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.1119 - accuracy: 0.9700\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.1015 - accuracy: 0.9662\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.1126 - accuracy: 0.9643\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.1090 - accuracy: 0.9643\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9531\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.1218 - accuracy: 0.9601\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.9758\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.1221 - accuracy: 0.9488\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.1105 - accuracy: 0.9557\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0986 - accuracy: 0.9692\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.1194 - accuracy: 0.9608\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9357\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.1086 - accuracy: 0.9689\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0963 - accuracy: 0.9639\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9567\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0934 - accuracy: 0.9662\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.9699\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.1026 - accuracy: 0.9582\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.1015 - accuracy: 0.9610\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0954 - accuracy: 0.9618\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0912 - accuracy: 0.9622\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9679\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0880 - accuracy: 0.9624\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0944 - accuracy: 0.9766\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1059 - accuracy: 0.9620\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0895 - accuracy: 0.9641\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0892 - accuracy: 0.9732\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9722\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9605\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0916 - accuracy: 0.9684\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0964 - accuracy: 0.9686\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0791 - accuracy: 0.9752\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0866 - accuracy: 0.9796\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0909 - accuracy: 0.9682\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0752 - accuracy: 0.9691\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0664 - accuracy: 0.9772\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0740 - accuracy: 0.9772\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9723\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0831 - accuracy: 0.9664\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0724 - accuracy: 0.9738\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0681 - accuracy: 0.9751\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0811 - accuracy: 0.9672\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0818 - accuracy: 0.9766\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.1001 - accuracy: 0.9594\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0693 - accuracy: 0.9750\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0932 - accuracy: 0.9692\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9639\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0742 - accuracy: 0.9676\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9748\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0651 - accuracy: 0.9793\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0655 - accuracy: 0.9805\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0728 - accuracy: 0.9742\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0549 - accuracy: 0.9764\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0690 - accuracy: 0.9653\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0780 - accuracy: 0.9601\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0772 - accuracy: 0.9708\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0778 - accuracy: 0.9667\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0849 - accuracy: 0.9552\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0889 - accuracy: 0.9569\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0710 - accuracy: 0.9686\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9842\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0633 - accuracy: 0.9784\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0787 - accuracy: 0.9654\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0685 - accuracy: 0.9745\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0720 - accuracy: 0.9802\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0723 - accuracy: 0.9714\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0434 - accuracy: 0.9858\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0529 - accuracy: 0.9774\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0555 - accuracy: 0.9817\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0528 - accuracy: 0.9740\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0673 - accuracy: 0.9693\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9713\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9752\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9605\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0804 - accuracy: 0.9675\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0687 - accuracy: 0.9767\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0627 - accuracy: 0.9703\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9661\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9744\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.9680\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9847\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0591 - accuracy: 0.9779\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0489 - accuracy: 0.9779\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0538 - accuracy: 0.9732\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 926us/step - loss: 0.0509 - accuracy: 0.9768\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 0.9833\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0655 - accuracy: 0.9731\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0594 - accuracy: 0.9771\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0744 - accuracy: 0.9684\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9761\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9654\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9773\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9626\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9667\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9577\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9668\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9656\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0646 - accuracy: 0.9667\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0524 - accuracy: 0.9816\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0608 - accuracy: 0.9705\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0460 - accuracy: 0.9752\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0618 - accuracy: 0.9693\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0637 - accuracy: 0.9700\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0586 - accuracy: 0.9692\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0720 - accuracy: 0.9653\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0507 - accuracy: 0.9739\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0431 - accuracy: 0.9671\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.9773\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9732\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0540 - accuracy: 0.9761\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0679 - accuracy: 0.9741\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9775\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0555 - accuracy: 0.9694\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0788 - accuracy: 0.9689\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0717 - accuracy: 0.9696\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0384 - accuracy: 0.9856\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0662 - accuracy: 0.9718\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0649 - accuracy: 0.9740\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0697 - accuracy: 0.9698\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0804 - accuracy: 0.9615\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0612 - accuracy: 0.9655\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0842 - accuracy: 0.9747\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0443 - accuracy: 0.9789\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0566 - accuracy: 0.9795\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 828us/step - loss: 0.6566 - accuracy: 0.7018\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.5493 - accuracy: 0.7264\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.5156 - accuracy: 0.7529\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.5244 - accuracy: 0.7515\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.4427 - accuracy: 0.7898\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.4582 - accuracy: 0.7985\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.4400 - accuracy: 0.8050\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.4126 - accuracy: 0.8326\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.3980 - accuracy: 0.8350\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.4022 - accuracy: 0.8163\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.3785 - accuracy: 0.8373\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.3961 - accuracy: 0.8396\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.3680 - accuracy: 0.8388\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.3459 - accuracy: 0.8515\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.3568 - accuracy: 0.8613\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.3754 - accuracy: 0.8473\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.3309 - accuracy: 0.8674\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8807\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8857\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.3466 - accuracy: 0.8426\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.2945 - accuracy: 0.8814\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.2688 - accuracy: 0.9015\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.3076 - accuracy: 0.8710\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.2646 - accuracy: 0.8912\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.2795 - accuracy: 0.8859\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.2721 - accuracy: 0.8973\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9079\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.2535 - accuracy: 0.9076\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.2414 - accuracy: 0.9102\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.2337 - accuracy: 0.8983\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.2434 - accuracy: 0.9239\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.2070 - accuracy: 0.9186\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.2082 - accuracy: 0.9257\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.2075 - accuracy: 0.9316\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.1918 - accuracy: 0.9321\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.2052 - accuracy: 0.9188\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.2067 - accuracy: 0.9180\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.1973 - accuracy: 0.9218\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.9276\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.1778 - accuracy: 0.9295\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.1555 - accuracy: 0.9460\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.1852 - accuracy: 0.9319\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.1903 - accuracy: 0.9312\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.1778 - accuracy: 0.9381\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.1625 - accuracy: 0.9504\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.1579 - accuracy: 0.9513\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.1511 - accuracy: 0.9527\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.1469 - accuracy: 0.9409\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.1355 - accuracy: 0.9549\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.1253 - accuracy: 0.9593\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.1407 - accuracy: 0.9576\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.1151 - accuracy: 0.9685\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.1308 - accuracy: 0.9603\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.1493 - accuracy: 0.9463\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.1199 - accuracy: 0.9675\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.1315 - accuracy: 0.9564\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.1234 - accuracy: 0.9541\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.1345 - accuracy: 0.9591\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.1164 - accuracy: 0.9617\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.1271 - accuracy: 0.9571\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.1010 - accuracy: 0.9698\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.1107 - accuracy: 0.9597\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1144 - accuracy: 0.9652\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.1071 - accuracy: 0.9717\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0997 - accuracy: 0.9668\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0951 - accuracy: 0.9729\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0941 - accuracy: 0.9773\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9672\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0880 - accuracy: 0.9801\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0930 - accuracy: 0.9662\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9682\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0873 - accuracy: 0.9717\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9701\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9710\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9750\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9799\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9641\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9730\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.0929 - accuracy: 0.9660\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0950 - accuracy: 0.9687\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 939us/step - loss: 0.0846 - accuracy: 0.9753\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0762 - accuracy: 0.9742\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0690 - accuracy: 0.9837\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0750 - accuracy: 0.9776\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0839 - accuracy: 0.9694\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0828 - accuracy: 0.9670\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0972 - accuracy: 0.9662\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0658 - accuracy: 0.9789\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0609 - accuracy: 0.9800\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0767 - accuracy: 0.9761\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0514 - accuracy: 0.9904\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0745 - accuracy: 0.9782\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0905 - accuracy: 0.9771\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0524 - accuracy: 0.9824\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0725 - accuracy: 0.9714\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0644 - accuracy: 0.9790\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0596 - accuracy: 0.9864\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0827 - accuracy: 0.9693\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0752 - accuracy: 0.9771\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0552 - accuracy: 0.9849\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0523 - accuracy: 0.9829\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0570 - accuracy: 0.9849\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0553 - accuracy: 0.9825\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0534 - accuracy: 0.9805\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0544 - accuracy: 0.9861\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0568 - accuracy: 0.9793\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0583 - accuracy: 0.9798\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0501 - accuracy: 0.9884\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0564 - accuracy: 0.9766\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0574 - accuracy: 0.9805\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0541 - accuracy: 0.9857\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0325 - accuracy: 0.9902\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0565 - accuracy: 0.9814\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0497 - accuracy: 0.9881\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0458 - accuracy: 0.9884\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0380 - accuracy: 0.9865\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9889\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0388 - accuracy: 0.9919\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0388 - accuracy: 0.9926\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0347 - accuracy: 0.9904\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0459 - accuracy: 0.9896\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0588 - accuracy: 0.9758\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0494 - accuracy: 0.9880\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9819\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0335 - accuracy: 0.9897\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0562 - accuracy: 0.9796\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0486 - accuracy: 0.9855\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0470 - accuracy: 0.9863\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0324 - accuracy: 0.9946\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0352 - accuracy: 0.9941\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0392 - accuracy: 0.9917\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0486 - accuracy: 0.9852\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0337 - accuracy: 0.9848\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0630 - accuracy: 0.9804\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9898\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0337 - accuracy: 0.9961\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0424 - accuracy: 0.9874\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0443 - accuracy: 0.9827\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0439 - accuracy: 0.9835\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0393 - accuracy: 0.9934\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0281 - accuracy: 0.9957\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0407 - accuracy: 0.9804\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0406 - accuracy: 0.9893\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0309 - accuracy: 0.9929\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0426 - accuracy: 0.9801\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0440 - accuracy: 0.9875\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0265 - accuracy: 0.9911\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0394 - accuracy: 0.9868\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0397 - accuracy: 0.9827\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0362 - accuracy: 0.9861\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0388 - accuracy: 0.9855\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0282 - accuracy: 0.9911\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0337 - accuracy: 0.9899\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0364 - accuracy: 0.9887\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0419 - accuracy: 0.9897\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0380 - accuracy: 0.9831\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0374 - accuracy: 0.9833\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0454 - accuracy: 0.9900\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0305 - accuracy: 0.9881\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 957us/step - loss: 0.0432 - accuracy: 0.9837\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0518 - accuracy: 0.9838\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0320 - accuracy: 0.9893\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0338 - accuracy: 0.9867\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0299 - accuracy: 0.9917\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0406 - accuracy: 0.9893\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0373 - accuracy: 0.9904\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0357 - accuracy: 0.9875\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0315 - accuracy: 0.9909\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0314 - accuracy: 0.9864\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0207 - accuracy: 0.9952\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9938\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0395 - accuracy: 0.9895\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0380 - accuracy: 0.9919\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0296 - accuracy: 0.9924\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0276 - accuracy: 0.9941\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0313 - accuracy: 0.9891\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0242 - accuracy: 0.9956\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0479 - accuracy: 0.9816\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0466 - accuracy: 0.9835\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0418 - accuracy: 0.9831\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0239 - accuracy: 0.9916\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0311 - accuracy: 0.9873\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0224 - accuracy: 0.9930\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0379 - accuracy: 0.9911\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0214 - accuracy: 0.9922\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0433 - accuracy: 0.9848\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0258 - accuracy: 0.9923\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0368 - accuracy: 0.9852\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0310 - accuracy: 0.9889\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0178 - accuracy: 0.9949\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0219 - accuracy: 0.9916\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0254 - accuracy: 0.9917\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0420 - accuracy: 0.9898\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0234 - accuracy: 0.9908\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0206 - accuracy: 0.9928\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0294 - accuracy: 0.9922\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0495 - accuracy: 0.9830\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0373 - accuracy: 0.9879\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0275 - accuracy: 0.9888\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0387 - accuracy: 0.9829\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 881us/step - loss: 0.7521 - accuracy: 0.6365\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.5532 - accuracy: 0.7175\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.5008 - accuracy: 0.7452\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.5035 - accuracy: 0.7770\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.4771 - accuracy: 0.7952\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.4467 - accuracy: 0.8058\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.4382 - accuracy: 0.7910\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.4490 - accuracy: 0.7878\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.4201 - accuracy: 0.8078\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.4105 - accuracy: 0.8326\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8293\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.3791 - accuracy: 0.8328\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.3707 - accuracy: 0.8384\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.3860 - accuracy: 0.8374\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.3902 - accuracy: 0.8359\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.3438 - accuracy: 0.8571\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.3174 - accuracy: 0.8737\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.3208 - accuracy: 0.8727\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.3363 - accuracy: 0.8644\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.3100 - accuracy: 0.8650\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.2958 - accuracy: 0.8776\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.2785 - accuracy: 0.8998\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.2629 - accuracy: 0.8987\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.2767 - accuracy: 0.8874\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.2787 - accuracy: 0.8883\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.2652 - accuracy: 0.8820\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.2595 - accuracy: 0.9041\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.2515 - accuracy: 0.9028\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.2425 - accuracy: 0.9062\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.2432 - accuracy: 0.9013\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.2231 - accuracy: 0.9144\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.2358 - accuracy: 0.9177\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.2459 - accuracy: 0.8851\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.2175 - accuracy: 0.9195\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.2291 - accuracy: 0.9050\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.2124 - accuracy: 0.9179\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1918 - accuracy: 0.9297\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.1977 - accuracy: 0.9216\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.1692 - accuracy: 0.9362\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.1916 - accuracy: 0.9247\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.1659 - accuracy: 0.9466\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.1795 - accuracy: 0.9317\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.1798 - accuracy: 0.9336\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.1940 - accuracy: 0.9227\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.1676 - accuracy: 0.9384\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.1824 - accuracy: 0.9309\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.1678 - accuracy: 0.9393\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.1470 - accuracy: 0.9448\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.1414 - accuracy: 0.9519\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.1451 - accuracy: 0.9564\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.1531 - accuracy: 0.9420\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.1433 - accuracy: 0.9470\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.1361 - accuracy: 0.9681\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.1471 - accuracy: 0.9560\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.1676 - accuracy: 0.9285\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.1342 - accuracy: 0.9575\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.1304 - accuracy: 0.9575\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.1739 - accuracy: 0.9462\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.1532 - accuracy: 0.9462\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.1243 - accuracy: 0.9578\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.1193 - accuracy: 0.9561\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.1186 - accuracy: 0.9597\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.1228 - accuracy: 0.9600\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1192 - accuracy: 0.9575\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.1014 - accuracy: 0.9684\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.1216 - accuracy: 0.9592\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.1217 - accuracy: 0.9602\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.1040 - accuracy: 0.9696\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.1057 - accuracy: 0.9537\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.1289 - accuracy: 0.9607\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.1041 - accuracy: 0.9598\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1157 - accuracy: 0.9554\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.1134 - accuracy: 0.9577\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.1031 - accuracy: 0.9585\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0961 - accuracy: 0.9650\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0901 - accuracy: 0.9719\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0890 - accuracy: 0.9664\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0819 - accuracy: 0.9716\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0805 - accuracy: 0.9702\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.1016 - accuracy: 0.9677\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 883us/step - loss: 0.0985 - accuracy: 0.9666\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.1086 - accuracy: 0.9644\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.1011 - accuracy: 0.9612\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9667\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9800\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0959 - accuracy: 0.9593\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0754 - accuracy: 0.9738\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0785 - accuracy: 0.9799\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0650 - accuracy: 0.9797\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0882 - accuracy: 0.9666\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0837 - accuracy: 0.9693\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0723 - accuracy: 0.9811\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0774 - accuracy: 0.9677\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0767 - accuracy: 0.9660\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.1028 - accuracy: 0.9577\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0733 - accuracy: 0.9747\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0719 - accuracy: 0.9772\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0536 - accuracy: 0.9862\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0891 - accuracy: 0.9623\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0622 - accuracy: 0.9904\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1054 - accuracy: 0.9588\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9848\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0784 - accuracy: 0.9684\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0951 - accuracy: 0.9661\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0824 - accuracy: 0.9737\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0618 - accuracy: 0.9772\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0679 - accuracy: 0.9707\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0686 - accuracy: 0.9783\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0812 - accuracy: 0.9788\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1034 - accuracy: 0.9558\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0641 - accuracy: 0.9836\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0645 - accuracy: 0.9825\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0797 - accuracy: 0.9739\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0675 - accuracy: 0.9800\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0601 - accuracy: 0.9785\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0641 - accuracy: 0.9765\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0530 - accuracy: 0.9830\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0524 - accuracy: 0.9939\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0503 - accuracy: 0.9859\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0488 - accuracy: 0.9878\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0808 - accuracy: 0.9729\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0422 - accuracy: 0.9912\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0419 - accuracy: 0.9875\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0379 - accuracy: 0.9916\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0586 - accuracy: 0.9818\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0426 - accuracy: 0.9877\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0407 - accuracy: 0.9918\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0422 - accuracy: 0.9897\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0414 - accuracy: 0.9855\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0407 - accuracy: 0.9916\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0523 - accuracy: 0.9834\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0628 - accuracy: 0.9814\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0502 - accuracy: 0.9852\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0409 - accuracy: 0.9881\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0617 - accuracy: 0.9827\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0577 - accuracy: 0.9768\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0552 - accuracy: 0.9829\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0572 - accuracy: 0.9808\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0481 - accuracy: 0.9861\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0438 - accuracy: 0.9869\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0634 - accuracy: 0.9736\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0519 - accuracy: 0.9837\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0446 - accuracy: 0.9809\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0555 - accuracy: 0.9817\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0553 - accuracy: 0.9794\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0464 - accuracy: 0.9852\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0380 - accuracy: 0.9912\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0541 - accuracy: 0.9810\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0304 - accuracy: 0.9936\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0756 - accuracy: 0.9875\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0386 - accuracy: 0.9821\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0329 - accuracy: 0.9912\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0476 - accuracy: 0.9835\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0460 - accuracy: 0.9856\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0361 - accuracy: 0.9879\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0356 - accuracy: 0.9863\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0366 - accuracy: 0.9921\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0543 - accuracy: 0.9773\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0537 - accuracy: 0.9856\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 905us/step - loss: 0.0524 - accuracy: 0.9825\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0483 - accuracy: 0.9822\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0441 - accuracy: 0.9902\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0366 - accuracy: 0.9916\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0425 - accuracy: 0.9899\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0360 - accuracy: 0.9863\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0421 - accuracy: 0.9848\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0397 - accuracy: 0.9857\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0618 - accuracy: 0.9754\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0446 - accuracy: 0.9837\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0321 - accuracy: 0.9929\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0406 - accuracy: 0.9846\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0332 - accuracy: 0.9903\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0574 - accuracy: 0.9730\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0480 - accuracy: 0.9832\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0290 - accuracy: 0.9954\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0526 - accuracy: 0.9892\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0421 - accuracy: 0.9810\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0315 - accuracy: 0.9927\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0463 - accuracy: 0.9825\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0497 - accuracy: 0.9802\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0476 - accuracy: 0.9840\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0489 - accuracy: 0.9785\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0277 - accuracy: 0.9954\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0436 - accuracy: 0.9829\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0392 - accuracy: 0.9874\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0221 - accuracy: 0.9934\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0324 - accuracy: 0.9858\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0256 - accuracy: 0.9974\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0294 - accuracy: 0.9921\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0305 - accuracy: 0.9938\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0430 - accuracy: 0.9869\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0252 - accuracy: 0.9938\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0363 - accuracy: 0.9874\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0354 - accuracy: 0.9854\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0397 - accuracy: 0.9883\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0222 - accuracy: 0.9933\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0488 - accuracy: 0.9799\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0287 - accuracy: 0.9912\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0463 - accuracy: 0.9870\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0468 - accuracy: 0.9860\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 825us/step - loss: 0.8514 - accuracy: 0.6097\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.7332\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.5183 - accuracy: 0.7401\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.4809 - accuracy: 0.7784\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.5254 - accuracy: 0.7428\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.4565 - accuracy: 0.7872\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.4522 - accuracy: 0.7953\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8257\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.4352 - accuracy: 0.8124\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.4181 - accuracy: 0.8316\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.3633 - accuracy: 0.8450\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.3790 - accuracy: 0.8417\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.3876 - accuracy: 0.8563\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.3638 - accuracy: 0.8378\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.3571 - accuracy: 0.8543\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.3719 - accuracy: 0.8241\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.3547 - accuracy: 0.8652\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.3141 - accuracy: 0.8824\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.3267 - accuracy: 0.8620\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.2957 - accuracy: 0.8898\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.3292 - accuracy: 0.8577\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.3141 - accuracy: 0.8707\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.2869 - accuracy: 0.8862\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.2675 - accuracy: 0.9066\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2704 - accuracy: 0.9000\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.9099\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2726 - accuracy: 0.8976\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.2643 - accuracy: 0.9066\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.2554 - accuracy: 0.8944\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.2204 - accuracy: 0.9254\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.2452 - accuracy: 0.9196\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.2288 - accuracy: 0.9310\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.2269 - accuracy: 0.9146\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9242\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.2135 - accuracy: 0.9213\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.9303\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.2208 - accuracy: 0.9136\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.1980 - accuracy: 0.9379\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.1997 - accuracy: 0.9261\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9329\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1730 - accuracy: 0.9404\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.2054 - accuracy: 0.9173\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.1777 - accuracy: 0.9390\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.9188\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.1917 - accuracy: 0.9268\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.1816 - accuracy: 0.9219\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9599\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.1813 - accuracy: 0.9316\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.1514 - accuracy: 0.9591\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9434\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.1452 - accuracy: 0.9497\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.1404 - accuracy: 0.9483\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.1541 - accuracy: 0.9411\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.1662 - accuracy: 0.9338\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.1477 - accuracy: 0.9421\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9639\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.1421 - accuracy: 0.9493\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.1200 - accuracy: 0.9580\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.1335 - accuracy: 0.9592\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.1311 - accuracy: 0.9529\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.1312 - accuracy: 0.9680\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.1234 - accuracy: 0.9660\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.1074 - accuracy: 0.9691\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9536\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.1235 - accuracy: 0.9697\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.1251 - accuracy: 0.9541\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.1151 - accuracy: 0.9615\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9605\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9625\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.9589\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9539\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9604\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9648\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9756\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9622\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0940 - accuracy: 0.9760\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0917 - accuracy: 0.9720\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9769\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9585\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.1025 - accuracy: 0.9753\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9815\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9740\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9643\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.1243 - accuracy: 0.9600\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9766\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9620\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9760\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0928 - accuracy: 0.9610\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0984 - accuracy: 0.9624\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.9621\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.9800\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0779 - accuracy: 0.9756\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9692\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0807 - accuracy: 0.9818\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0924 - accuracy: 0.9716\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0697 - accuracy: 0.9783\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0792 - accuracy: 0.9725\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0682 - accuracy: 0.9724\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0673 - accuracy: 0.9791\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0764 - accuracy: 0.9765\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0654 - accuracy: 0.9866\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0566 - accuracy: 0.9889\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9811\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0847 - accuracy: 0.9776\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0540 - accuracy: 0.9894\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0766 - accuracy: 0.9766\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0646 - accuracy: 0.9802\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0593 - accuracy: 0.9820\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9810\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0669 - accuracy: 0.9824\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0631 - accuracy: 0.9746\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0800 - accuracy: 0.9714\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0627 - accuracy: 0.9802\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0623 - accuracy: 0.9800\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9752\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0595 - accuracy: 0.9808\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0600 - accuracy: 0.9848\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0680 - accuracy: 0.9739\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0627 - accuracy: 0.9858\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0633 - accuracy: 0.9813\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9794\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.0889 - accuracy: 0.9749\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0653 - accuracy: 0.9755\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0747 - accuracy: 0.9748\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9833\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0642 - accuracy: 0.9771\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.0809 - accuracy: 0.9712\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0646 - accuracy: 0.9759\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9817\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0519 - accuracy: 0.9855\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0491 - accuracy: 0.9850\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0534 - accuracy: 0.9846\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0596 - accuracy: 0.9764\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0436 - accuracy: 0.9834\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0401 - accuracy: 0.9894\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9748\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0509 - accuracy: 0.9875\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9891\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0614 - accuracy: 0.9797\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0377 - accuracy: 0.9911\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0498 - accuracy: 0.9880\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0536 - accuracy: 0.9761\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0439 - accuracy: 0.9848\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0570 - accuracy: 0.9775\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0670 - accuracy: 0.9788\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9827\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0410 - accuracy: 0.9893\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0570 - accuracy: 0.9844\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0539 - accuracy: 0.9800\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0363 - accuracy: 0.9900\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0498 - accuracy: 0.9814\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0426 - accuracy: 0.9883\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0538 - accuracy: 0.9809\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0506 - accuracy: 0.9870\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0549 - accuracy: 0.9836\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0577 - accuracy: 0.9752\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0438 - accuracy: 0.9827\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0339 - accuracy: 0.9900\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0346 - accuracy: 0.9938\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0301 - accuracy: 0.9970\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0269 - accuracy: 0.9932\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 872us/step - loss: 0.0273 - accuracy: 0.9958\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0368 - accuracy: 0.9908\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0441 - accuracy: 0.9910\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9844\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9857\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9852\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9876\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0459 - accuracy: 0.9835\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9888\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0557 - accuracy: 0.9780\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0393 - accuracy: 0.9887\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0561 - accuracy: 0.9815\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0397 - accuracy: 0.9868\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0602 - accuracy: 0.9833\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0320 - accuracy: 0.9935\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0364 - accuracy: 0.9886\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9789\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9858\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9890\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0404 - accuracy: 0.9869\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0343 - accuracy: 0.9873\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0351 - accuracy: 0.9939\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9858\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0383 - accuracy: 0.9902\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0349 - accuracy: 0.9861\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0310 - accuracy: 0.9894\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0361 - accuracy: 0.9920\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0380 - accuracy: 0.9905\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0153 - accuracy: 0.9969\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9876\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0552 - accuracy: 0.9857\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0365 - accuracy: 0.9853\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9940\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0347 - accuracy: 0.9856\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0339 - accuracy: 0.9896\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0303 - accuracy: 0.9907\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0170 - accuracy: 0.9995\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9723\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9814\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 846us/step - loss: 0.9792 - accuracy: 0.4791\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.5816 - accuracy: 0.7173\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.5387 - accuracy: 0.7538\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.5131 - accuracy: 0.7665\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.5118 - accuracy: 0.7438\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7734\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7768\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7768\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7911\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7930\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.8236\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.4378 - accuracy: 0.7907\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.3855 - accuracy: 0.8364\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.3843 - accuracy: 0.8386\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.4120 - accuracy: 0.8173\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8221\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8353\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.3960 - accuracy: 0.8291\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8245\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.4039 - accuracy: 0.8122\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8100\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.3715 - accuracy: 0.8231\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.3559 - accuracy: 0.8456\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.3536 - accuracy: 0.8535\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.3540 - accuracy: 0.8682\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.3254 - accuracy: 0.8708\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.3227 - accuracy: 0.8718\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.3222 - accuracy: 0.8696\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8738\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.3025 - accuracy: 0.8848\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.3032 - accuracy: 0.8858\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8821\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8818\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.3238 - accuracy: 0.8647\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.3003 - accuracy: 0.8702\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.8763\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8929\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.8981\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8721\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2789 - accuracy: 0.9095\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.2538 - accuracy: 0.9026\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.3085 - accuracy: 0.8586\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.2790 - accuracy: 0.8854\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.2497 - accuracy: 0.8970\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9250\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.2496 - accuracy: 0.9070\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.2513 - accuracy: 0.9030\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2650 - accuracy: 0.8947\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.2484 - accuracy: 0.9045\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.2354 - accuracy: 0.9099\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.2223 - accuracy: 0.9171\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.2529 - accuracy: 0.9119\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.2242 - accuracy: 0.9152\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.9220\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.2102 - accuracy: 0.9218\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.2026 - accuracy: 0.9420\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.2272 - accuracy: 0.9092\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.2227 - accuracy: 0.9130\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9285\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9376\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1966 - accuracy: 0.9374\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.2386 - accuracy: 0.9010\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.2003 - accuracy: 0.9302\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.2211 - accuracy: 0.9107\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9268\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.1726 - accuracy: 0.9352\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9156\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.1679 - accuracy: 0.9468\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1733 - accuracy: 0.9274\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.1867 - accuracy: 0.9437\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1756 - accuracy: 0.9348\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.1547 - accuracy: 0.9453\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.1654 - accuracy: 0.9415\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.1781 - accuracy: 0.9240\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.1444 - accuracy: 0.9547\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.1561 - accuracy: 0.9445\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.1688 - accuracy: 0.9333\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.1459 - accuracy: 0.9528\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.1485 - accuracy: 0.9439\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.1672 - accuracy: 0.9379\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9382\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 953us/step - loss: 0.1487 - accuracy: 0.9465\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.9214\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9492\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9341\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9460\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9236\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.1683 - accuracy: 0.9316\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.1290 - accuracy: 0.9514\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.1476 - accuracy: 0.9415\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.1177 - accuracy: 0.9642\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.1139 - accuracy: 0.9595\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1461 - accuracy: 0.9418\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9378\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.1190 - accuracy: 0.9624\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.1200 - accuracy: 0.9429\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.1423 - accuracy: 0.9366\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.1340 - accuracy: 0.9553\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.1158 - accuracy: 0.9610\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.1222 - accuracy: 0.9485\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.1305 - accuracy: 0.9497\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9572\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9583\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.1173 - accuracy: 0.9580\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.1212 - accuracy: 0.9588\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.1052 - accuracy: 0.9647\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.1366 - accuracy: 0.9454\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.1098 - accuracy: 0.9587\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.1194 - accuracy: 0.9541\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9475\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1142 - accuracy: 0.9589\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.1032 - accuracy: 0.9703\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0973 - accuracy: 0.9753\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0999 - accuracy: 0.9679\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0960 - accuracy: 0.9609\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9632\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9592\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1149 - accuracy: 0.9480\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.1024 - accuracy: 0.9622\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.1050 - accuracy: 0.9592\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.1017 - accuracy: 0.9697\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9533\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0955 - accuracy: 0.9617\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0811 - accuracy: 0.9696\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.1016 - accuracy: 0.9545\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0759 - accuracy: 0.9667\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9592\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.1051 - accuracy: 0.9573\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0944 - accuracy: 0.9719\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0956 - accuracy: 0.9597\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0905 - accuracy: 0.9702\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0768 - accuracy: 0.9664\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9678\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9644\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9647\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9724\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.9658\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0875 - accuracy: 0.9637\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0767 - accuracy: 0.9724\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0829 - accuracy: 0.9635\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0935 - accuracy: 0.9570\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0752 - accuracy: 0.9737\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0486 - accuracy: 0.9849\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0757 - accuracy: 0.9740\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0877 - accuracy: 0.9587\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0519 - accuracy: 0.9840\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0631 - accuracy: 0.9824\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0624 - accuracy: 0.9793\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0713 - accuracy: 0.9737\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0647 - accuracy: 0.9710\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0671 - accuracy: 0.9732\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0732 - accuracy: 0.9641\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0781 - accuracy: 0.9720\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0875 - accuracy: 0.9641\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0601 - accuracy: 0.9798\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.1070 - accuracy: 0.9601\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.1007 - accuracy: 0.9657\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0744 - accuracy: 0.9686\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0809 - accuracy: 0.9649\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0767 - accuracy: 0.9715\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0650 - accuracy: 0.9728\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 930us/step - loss: 0.0664 - accuracy: 0.9719\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0843 - accuracy: 0.9681\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9761\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9602\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0546 - accuracy: 0.9781\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0717 - accuracy: 0.9696\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0523 - accuracy: 0.9799\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0710 - accuracy: 0.9724\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0658 - accuracy: 0.9740\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9540\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9600\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9763\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9674\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9804\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0643 - accuracy: 0.9762\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0827 - accuracy: 0.9652\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0729 - accuracy: 0.9689\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0827 - accuracy: 0.9582\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0638 - accuracy: 0.9717\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0709 - accuracy: 0.9730\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0723 - accuracy: 0.9673\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0691 - accuracy: 0.9758\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0738 - accuracy: 0.9602\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0763 - accuracy: 0.9626\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9678\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0796 - accuracy: 0.9513\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0697 - accuracy: 0.9655\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0582 - accuracy: 0.9719\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0556 - accuracy: 0.9744\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0602 - accuracy: 0.9723\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9781\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0689 - accuracy: 0.9723\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0504 - accuracy: 0.9726\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0691 - accuracy: 0.9757\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0788 - accuracy: 0.9608\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0673 - accuracy: 0.9677\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9745\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0510 - accuracy: 0.9807\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0618 - accuracy: 0.9751\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 866us/step - loss: 0.7301 - accuracy: 0.6647\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.5397 - accuracy: 0.7348\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.5019 - accuracy: 0.7600\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.4618 - accuracy: 0.7817\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.4715 - accuracy: 0.7923\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8176\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.7975\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7943\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8335\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.8276\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.8232\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.3579 - accuracy: 0.8575\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.3272 - accuracy: 0.8581\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.3521 - accuracy: 0.8720\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8546\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8541\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.3290 - accuracy: 0.8653\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.2862 - accuracy: 0.8791\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.3159 - accuracy: 0.8742\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.2987 - accuracy: 0.8900\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.3012 - accuracy: 0.8630\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.2941 - accuracy: 0.8903\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.2586 - accuracy: 0.8987\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.2776 - accuracy: 0.8965\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.2788 - accuracy: 0.8953\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.2733 - accuracy: 0.8958\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.2588 - accuracy: 0.8903\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.2468 - accuracy: 0.9087\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.2584 - accuracy: 0.8857\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.2085 - accuracy: 0.9290\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9144\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.8960\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.2276 - accuracy: 0.9143\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.2089 - accuracy: 0.9259\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.2142 - accuracy: 0.9205\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.1789 - accuracy: 0.9437\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.2048 - accuracy: 0.9200\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.1673 - accuracy: 0.9428\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.1908 - accuracy: 0.9291\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.2001 - accuracy: 0.9399\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.1826 - accuracy: 0.9314\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.1690 - accuracy: 0.9373\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.1866 - accuracy: 0.9307\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.1576 - accuracy: 0.9350\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1795 - accuracy: 0.9398\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.1559 - accuracy: 0.9460\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.1723 - accuracy: 0.9377\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.1386 - accuracy: 0.9630\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.1455 - accuracy: 0.9516\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.1591 - accuracy: 0.9394\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.1463 - accuracy: 0.9469\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.1212 - accuracy: 0.9686\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.1307 - accuracy: 0.9556\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.1540 - accuracy: 0.9414\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.1344 - accuracy: 0.9609\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9447\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9588\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9681\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.1180 - accuracy: 0.9712\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9525\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9624\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.1275 - accuracy: 0.9477\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0925 - accuracy: 0.9772\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0910 - accuracy: 0.9695\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9688\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0934 - accuracy: 0.9788\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9734\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.1035 - accuracy: 0.9547\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0896 - accuracy: 0.9656\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0975 - accuracy: 0.9688\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.1068 - accuracy: 0.9538\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0892 - accuracy: 0.9732\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.1017 - accuracy: 0.9649\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0895 - accuracy: 0.9675\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0881 - accuracy: 0.9721\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0809 - accuracy: 0.9732\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0939 - accuracy: 0.9572\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9698\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0648 - accuracy: 0.9782\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0796 - accuracy: 0.9777\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 853us/step - loss: 0.1018 - accuracy: 0.9648\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0781 - accuracy: 0.9705\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0973 - accuracy: 0.9607\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0858 - accuracy: 0.9615\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9683\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0740 - accuracy: 0.9821\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0656 - accuracy: 0.9817\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0757 - accuracy: 0.9739\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0847 - accuracy: 0.9778\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0756 - accuracy: 0.9664\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0761 - accuracy: 0.9698\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0632 - accuracy: 0.9840\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0733 - accuracy: 0.9741\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0666 - accuracy: 0.9796\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0534 - accuracy: 0.9903\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0630 - accuracy: 0.9798\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0457 - accuracy: 0.9831\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0772 - accuracy: 0.9735\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0644 - accuracy: 0.9791\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0659 - accuracy: 0.9801\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0533 - accuracy: 0.9831\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9786\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9812\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0712 - accuracy: 0.9767\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0534 - accuracy: 0.9798\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0580 - accuracy: 0.9786\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0755 - accuracy: 0.9734\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0687 - accuracy: 0.9787\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0517 - accuracy: 0.9867\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0596 - accuracy: 0.9828\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0647 - accuracy: 0.9749\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0649 - accuracy: 0.9804\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0484 - accuracy: 0.9863\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0493 - accuracy: 0.9871\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0547 - accuracy: 0.9833\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0461 - accuracy: 0.9872\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0588 - accuracy: 0.9835\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0696 - accuracy: 0.9734\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0530 - accuracy: 0.9822\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0594 - accuracy: 0.9756\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0645 - accuracy: 0.9808\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0456 - accuracy: 0.9806\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0640 - accuracy: 0.9715\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0417 - accuracy: 0.9918\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0487 - accuracy: 0.9821\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0479 - accuracy: 0.9873\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0507 - accuracy: 0.9859\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0524 - accuracy: 0.9807\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0386 - accuracy: 0.9911\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0418 - accuracy: 0.9837\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0452 - accuracy: 0.9844\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0503 - accuracy: 0.9792\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0499 - accuracy: 0.9841\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0542 - accuracy: 0.9822\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0543 - accuracy: 0.9800\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0294 - accuracy: 0.9924\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0407 - accuracy: 0.9895\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0388 - accuracy: 0.9899\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9857\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0385 - accuracy: 0.9872\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0564 - accuracy: 0.9746\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0617 - accuracy: 0.9751\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0531 - accuracy: 0.9781\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0504 - accuracy: 0.9757\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0448 - accuracy: 0.9788\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0409 - accuracy: 0.9877\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0338 - accuracy: 0.9872\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0330 - accuracy: 0.9884\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0396 - accuracy: 0.9866\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0439 - accuracy: 0.9807\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0302 - accuracy: 0.9920\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0359 - accuracy: 0.9887\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0378 - accuracy: 0.9872\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0317 - accuracy: 0.9810\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0535 - accuracy: 0.9748\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0363 - accuracy: 0.9851\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0422 - accuracy: 0.9892\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0444 - accuracy: 0.9790\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0365 - accuracy: 0.9843\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 848us/step - loss: 0.0314 - accuracy: 0.9903\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0432 - accuracy: 0.9824\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0312 - accuracy: 0.9896\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0342 - accuracy: 0.9866\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0438 - accuracy: 0.9839\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0287 - accuracy: 0.9920\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0416 - accuracy: 0.9857\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0311 - accuracy: 0.9857\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0447 - accuracy: 0.9863\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0400 - accuracy: 0.9820\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0350 - accuracy: 0.9881\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0364 - accuracy: 0.9862\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0355 - accuracy: 0.9883\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0352 - accuracy: 0.9869\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0283 - accuracy: 0.9899\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9803\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0562 - accuracy: 0.9754\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0493 - accuracy: 0.9754\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0729 - accuracy: 0.9681\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0664 - accuracy: 0.9740\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0319 - accuracy: 0.9879\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0235 - accuracy: 0.9908\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0321 - accuracy: 0.9886\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0338 - accuracy: 0.9889\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0415 - accuracy: 0.9894\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0218 - accuracy: 0.9921\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0257 - accuracy: 0.9906\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0315 - accuracy: 0.9814\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0339 - accuracy: 0.9828\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0379 - accuracy: 0.9852\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0402 - accuracy: 0.9830\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0352 - accuracy: 0.9877\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0500 - accuracy: 0.9727\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0297 - accuracy: 0.9881\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0315 - accuracy: 0.9879\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0228 - accuracy: 0.9958\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0580 - accuracy: 0.9821\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0339 - accuracy: 0.9873\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0333 - accuracy: 0.9839\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9912\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9935\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 817us/step - loss: 0.7902 - accuracy: 0.6772\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.6385 - accuracy: 0.7039\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.5598 - accuracy: 0.7191\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.4833 - accuracy: 0.7757\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.4888 - accuracy: 0.7788\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.4664 - accuracy: 0.7505\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.4033 - accuracy: 0.8300\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.4299 - accuracy: 0.8160\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.4228 - accuracy: 0.8211\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8395\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8573\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.3602 - accuracy: 0.8448\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8371\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8735\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.3574 - accuracy: 0.8517\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.3297 - accuracy: 0.8557\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.3054 - accuracy: 0.8567\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.2977 - accuracy: 0.8834\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.3120 - accuracy: 0.8694\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.3017 - accuracy: 0.8672\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.3070 - accuracy: 0.8678\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.2782 - accuracy: 0.8942\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.2774 - accuracy: 0.8878\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.2463 - accuracy: 0.9110\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.2442 - accuracy: 0.9106\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.2420 - accuracy: 0.9146\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.9051\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.2237 - accuracy: 0.9245\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.2097 - accuracy: 0.9199\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.2095 - accuracy: 0.9325\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.2185 - accuracy: 0.9039\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9409\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2019 - accuracy: 0.9385\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.1848 - accuracy: 0.9399\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.1801 - accuracy: 0.9448\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1722 - accuracy: 0.9426\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.1765 - accuracy: 0.9505\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.1743 - accuracy: 0.9418\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.1589 - accuracy: 0.9491\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.1608 - accuracy: 0.9405\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.1556 - accuracy: 0.9544\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.1513 - accuracy: 0.9523\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.1579 - accuracy: 0.9429\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.1564 - accuracy: 0.9513\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9346\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1531 - accuracy: 0.9566\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.1524 - accuracy: 0.9569\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.1144 - accuracy: 0.9673\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1574 - accuracy: 0.9468\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.1377 - accuracy: 0.9564\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.1277 - accuracy: 0.9580\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.1517 - accuracy: 0.9532\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.1106 - accuracy: 0.9686\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.1026 - accuracy: 0.9688\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.1294 - accuracy: 0.9553\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.1026 - accuracy: 0.9706\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9708\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.1054 - accuracy: 0.9651\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.1100 - accuracy: 0.9569\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.1109 - accuracy: 0.9601\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9572\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0962 - accuracy: 0.9775\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.1017 - accuracy: 0.9691\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0912 - accuracy: 0.9769\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.1029 - accuracy: 0.9691\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.1208 - accuracy: 0.9530\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9767\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0859 - accuracy: 0.9690\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0742 - accuracy: 0.9851\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9753\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9696\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0894 - accuracy: 0.9708\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0890 - accuracy: 0.9733\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0821 - accuracy: 0.9754\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9806\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0723 - accuracy: 0.9841\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0722 - accuracy: 0.9839\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0845 - accuracy: 0.9733\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0708 - accuracy: 0.9839\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9770\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9848\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9837\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9675\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0865 - accuracy: 0.9663\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9813\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0700 - accuracy: 0.9820\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0588 - accuracy: 0.9799\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0527 - accuracy: 0.9800\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0564 - accuracy: 0.9785\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0730 - accuracy: 0.9753\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0695 - accuracy: 0.9864\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0578 - accuracy: 0.9839\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0604 - accuracy: 0.9785\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0590 - accuracy: 0.9796\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0625 - accuracy: 0.9848\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0707 - accuracy: 0.9794\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0652 - accuracy: 0.9860\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0452 - accuracy: 0.9910\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0465 - accuracy: 0.9865\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0438 - accuracy: 0.9825\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9892\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9741\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0543 - accuracy: 0.9778\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0406 - accuracy: 0.9918\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0550 - accuracy: 0.9881\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0608 - accuracy: 0.9820\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0432 - accuracy: 0.9846\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0620 - accuracy: 0.9787\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0676 - accuracy: 0.9789\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0485 - accuracy: 0.9900\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0308 - accuracy: 0.9931\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0465 - accuracy: 0.9875\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9897\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0599 - accuracy: 0.9834\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0498 - accuracy: 0.9884\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0691 - accuracy: 0.9753\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0501 - accuracy: 0.9826\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0695 - accuracy: 0.9712\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9788\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9761\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0432 - accuracy: 0.9832\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0535 - accuracy: 0.9839\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0362 - accuracy: 0.9822\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0544 - accuracy: 0.9796\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0496 - accuracy: 0.9804\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0682 - accuracy: 0.9799\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0509 - accuracy: 0.9752\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0427 - accuracy: 0.9889\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0529 - accuracy: 0.9868\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0422 - accuracy: 0.9856\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9761\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0443 - accuracy: 0.9844\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0445 - accuracy: 0.9807\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0376 - accuracy: 0.9880\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0270 - accuracy: 0.9883\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9885\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0391 - accuracy: 0.9892\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0472 - accuracy: 0.9854\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0548 - accuracy: 0.9835\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0519 - accuracy: 0.9824\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0689 - accuracy: 0.9767\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0471 - accuracy: 0.9849\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0387 - accuracy: 0.9861\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0471 - accuracy: 0.9852\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9818\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.0446 - accuracy: 0.9904\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0334 - accuracy: 0.9885\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0340 - accuracy: 0.9894\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0457 - accuracy: 0.9775\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0488 - accuracy: 0.9829\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0343 - accuracy: 0.9885\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0510 - accuracy: 0.9799\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9858\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9920\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0301 - accuracy: 0.9871\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0532 - accuracy: 0.9849\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0311 - accuracy: 0.9915\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9852\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0216 - accuracy: 0.9951\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0390 - accuracy: 0.9892\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9952\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0286 - accuracy: 0.9901\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0400 - accuracy: 0.9824\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0453 - accuracy: 0.9796\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9902\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0367 - accuracy: 0.9919\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0405 - accuracy: 0.9832\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0402 - accuracy: 0.9869\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0361 - accuracy: 0.9840\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0402 - accuracy: 0.9839\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9817\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0475 - accuracy: 0.9856\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0292 - accuracy: 0.9885\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0382 - accuracy: 0.9869\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0307 - accuracy: 0.9878\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9819\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9855\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0408 - accuracy: 0.9811\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0287 - accuracy: 0.9920\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0296 - accuracy: 0.9928\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0374 - accuracy: 0.9821\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0335 - accuracy: 0.9861\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9896\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9849\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0340 - accuracy: 0.9927\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0261 - accuracy: 0.9894\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0170 - accuracy: 0.9933\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0406 - accuracy: 0.9804\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0265 - accuracy: 0.9934\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9940\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0274 - accuracy: 0.9911\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0292 - accuracy: 0.9870\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0260 - accuracy: 0.9920\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0353 - accuracy: 0.9846\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0262 - accuracy: 0.9911\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0264 - accuracy: 0.9918\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0345 - accuracy: 0.9904\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0309 - accuracy: 0.9870\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0313 - accuracy: 0.9931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.7425\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.4036 - accuracy: 0.8406\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8400\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8557\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8762\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.3609 - accuracy: 0.8399\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.3138 - accuracy: 0.8534\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.2818 - accuracy: 0.8797\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.2778 - accuracy: 0.8839\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.2502 - accuracy: 0.8989\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.2961 - accuracy: 0.8629\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8668\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.8802\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.2387 - accuracy: 0.8902\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.2593 - accuracy: 0.9019\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.2484 - accuracy: 0.8951\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9043\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.8914\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9010\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.8931\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9043\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9233\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.1922 - accuracy: 0.9236\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.9094\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.1821 - accuracy: 0.9243\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.2090 - accuracy: 0.9068\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9254\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9317\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.8978\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9365\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.1649 - accuracy: 0.9306\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.1647 - accuracy: 0.9337\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.1685 - accuracy: 0.9346\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.1348 - accuracy: 0.9459\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.1382 - accuracy: 0.9559\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1292 - accuracy: 0.9518\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.1396 - accuracy: 0.9463\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.1343 - accuracy: 0.9556\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.1195 - accuracy: 0.9681\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.1397 - accuracy: 0.9394\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.1184 - accuracy: 0.9620\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.1283 - accuracy: 0.9492\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.1215 - accuracy: 0.9400\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.1089 - accuracy: 0.9562\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.1004 - accuracy: 0.9665\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1225 - accuracy: 0.9563\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.1001 - accuracy: 0.9658\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1137 - accuracy: 0.9562\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0977 - accuracy: 0.9635\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1085 - accuracy: 0.9663\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.1079 - accuracy: 0.9608\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0991 - accuracy: 0.9581\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0923 - accuracy: 0.9755\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0819 - accuracy: 0.9671\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0821 - accuracy: 0.9797\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0941 - accuracy: 0.9694\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0921 - accuracy: 0.9735\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0752 - accuracy: 0.9754\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0937 - accuracy: 0.9639\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0761 - accuracy: 0.9721\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0705 - accuracy: 0.9748\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0871 - accuracy: 0.9708\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0907 - accuracy: 0.9718\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0737 - accuracy: 0.9784\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0736 - accuracy: 0.9776\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9712\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0831 - accuracy: 0.9727\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0697 - accuracy: 0.9831\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0689 - accuracy: 0.9738\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9794\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0788 - accuracy: 0.9770\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0759 - accuracy: 0.9710\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0526 - accuracy: 0.9892\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0679 - accuracy: 0.9831\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0653 - accuracy: 0.9864\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0649 - accuracy: 0.9783\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0524 - accuracy: 0.9887\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0532 - accuracy: 0.9896\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0658 - accuracy: 0.9762\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0660 - accuracy: 0.9760\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 960us/step - loss: 0.0667 - accuracy: 0.9825\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0557 - accuracy: 0.9814\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0466 - accuracy: 0.9872\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9915\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0609 - accuracy: 0.9812\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9883\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9924\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0498 - accuracy: 0.9845\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0401 - accuracy: 0.9888\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0470 - accuracy: 0.9917\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0485 - accuracy: 0.9857\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0502 - accuracy: 0.9828\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0537 - accuracy: 0.9854\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0493 - accuracy: 0.9843\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0384 - accuracy: 0.9930\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0454 - accuracy: 0.9831\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0436 - accuracy: 0.9852\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0392 - accuracy: 0.9886\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9857\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9923\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0447 - accuracy: 0.9917\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0394 - accuracy: 0.9879\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9787\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9800\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0423 - accuracy: 0.9853\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0368 - accuracy: 0.9921\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0415 - accuracy: 0.9881\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0434 - accuracy: 0.9795\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9919\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0337 - accuracy: 0.9880\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0370 - accuracy: 0.9880\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0464 - accuracy: 0.9876\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0275 - accuracy: 0.9933\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0398 - accuracy: 0.9828\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0363 - accuracy: 0.9876\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0288 - accuracy: 0.9955\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9892\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0202 - accuracy: 0.9978\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0306 - accuracy: 0.9928\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0447 - accuracy: 0.9868\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9915\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0349 - accuracy: 0.9872\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0268 - accuracy: 0.9930\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0355 - accuracy: 0.9922\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0363 - accuracy: 0.9930\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0395 - accuracy: 0.9901\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0458 - accuracy: 0.9820\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0237 - accuracy: 0.9948\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0175 - accuracy: 0.9963\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0296 - accuracy: 0.9947\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0349 - accuracy: 0.9923\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0402 - accuracy: 0.9858\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0337 - accuracy: 0.9866\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0305 - accuracy: 0.9937\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0334 - accuracy: 0.9897\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0381 - accuracy: 0.9881\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0419 - accuracy: 0.9880\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0396 - accuracy: 0.9879\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0299 - accuracy: 0.9876\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0313 - accuracy: 0.9858\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0214 - accuracy: 0.9981\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0286 - accuracy: 0.9877\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0286 - accuracy: 0.9934\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0265 - accuracy: 0.9896\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0149 - accuracy: 0.9971\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0313 - accuracy: 0.9885\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0282 - accuracy: 0.9895\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0150 - accuracy: 0.9967\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9841\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0373 - accuracy: 0.9827\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0260 - accuracy: 0.9938\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9885\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0376 - accuracy: 0.9849\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0371 - accuracy: 0.9857\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0242 - accuracy: 0.9917\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0255 - accuracy: 0.9967\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0281 - accuracy: 0.9922\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0287 - accuracy: 0.9938\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 962us/step - loss: 0.0233 - accuracy: 0.9955\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0163 - accuracy: 0.9968\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0303 - accuracy: 0.9896\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9876\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0229 - accuracy: 0.9894\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0112 - accuracy: 0.9998\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9967\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9879\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9875\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9971\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0198 - accuracy: 0.9918\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0175 - accuracy: 0.9972\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0237 - accuracy: 0.9950\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0188 - accuracy: 0.9942\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0156 - accuracy: 0.9989\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0281 - accuracy: 0.9897\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0249 - accuracy: 0.9890\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0194 - accuracy: 0.9934\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0332 - accuracy: 0.9863\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0300 - accuracy: 0.9894\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9852\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.9904\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0290 - accuracy: 0.9889\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9932\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0172 - accuracy: 0.9956\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0258 - accuracy: 0.9881\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0281 - accuracy: 0.9929\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0180 - accuracy: 0.9973\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9877\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.9973\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9885\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0263 - accuracy: 0.9909\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0263 - accuracy: 0.9888\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0149 - accuracy: 0.9970\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0131 - accuracy: 0.9995\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0245 - accuracy: 0.9925\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0153 - accuracy: 0.9979\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0137 - accuracy: 0.9948\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 769us/step - loss: 0.6175 - accuracy: 0.7654\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.3764 - accuracy: 0.8561\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.3664 - accuracy: 0.8534\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.3497 - accuracy: 0.8627\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.3410 - accuracy: 0.8543\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.3251 - accuracy: 0.8553\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.3314 - accuracy: 0.8566\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.3049 - accuracy: 0.8771\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.2936 - accuracy: 0.8838\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.2716 - accuracy: 0.8884\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.8785\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2509 - accuracy: 0.9040\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9153\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9055\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.2357 - accuracy: 0.9010\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.2052 - accuracy: 0.9099\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.1874 - accuracy: 0.9102\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.1977 - accuracy: 0.9251\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1807 - accuracy: 0.9352\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.1896 - accuracy: 0.9141\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.1701 - accuracy: 0.9308\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.1554 - accuracy: 0.9462\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.1669 - accuracy: 0.9324\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.1556 - accuracy: 0.9331\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.1463 - accuracy: 0.9406\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.1428 - accuracy: 0.9593\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.1318 - accuracy: 0.9467\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.1273 - accuracy: 0.9625\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9569\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.1273 - accuracy: 0.9558\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.1055 - accuracy: 0.9634\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.1193 - accuracy: 0.9595\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1062 - accuracy: 0.9629\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.1027 - accuracy: 0.9771\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0994 - accuracy: 0.9727\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0904 - accuracy: 0.9725\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0815 - accuracy: 0.9718\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0907 - accuracy: 0.9637\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.1004 - accuracy: 0.9611\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0836 - accuracy: 0.9682\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1141 - accuracy: 0.9537\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0820 - accuracy: 0.9680\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0896 - accuracy: 0.9720\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0671 - accuracy: 0.9818\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0827 - accuracy: 0.9718\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0652 - accuracy: 0.9831\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0683 - accuracy: 0.9750\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0683 - accuracy: 0.9791\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0604 - accuracy: 0.9787\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0571 - accuracy: 0.9781\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0689 - accuracy: 0.9773\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0647 - accuracy: 0.9768\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0642 - accuracy: 0.9823\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0596 - accuracy: 0.9788\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9925\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0549 - accuracy: 0.9849\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0528 - accuracy: 0.9801\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0564 - accuracy: 0.9774\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0487 - accuracy: 0.9856\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9892\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0498 - accuracy: 0.9830\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0455 - accuracy: 0.9898\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0465 - accuracy: 0.9834\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9899\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9835\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0354 - accuracy: 0.9894\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0447 - accuracy: 0.9879\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0361 - accuracy: 0.9948\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0491 - accuracy: 0.9903\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0382 - accuracy: 0.9961\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0288 - accuracy: 0.9969\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0265 - accuracy: 0.9935\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0318 - accuracy: 0.9909\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0320 - accuracy: 0.9894\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0355 - accuracy: 0.9924\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0239 - accuracy: 0.9994\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0369 - accuracy: 0.9843\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0277 - accuracy: 0.9907\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9865\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9944\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9908\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9917\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9995\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9919\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0303 - accuracy: 0.9916\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9948\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9840\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0285 - accuracy: 0.9963\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9912\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9915\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9851\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0394 - accuracy: 0.9856\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9968\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9885\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9959\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9971\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9969\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9915\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9935\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 0.9971\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0292 - accuracy: 0.9910\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0128 - accuracy: 0.9995\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0329 - accuracy: 0.9890\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0205 - accuracy: 0.9939\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0235 - accuracy: 0.9942\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0254 - accuracy: 0.9923\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0233 - accuracy: 0.9934\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0195 - accuracy: 0.9957\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9982\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9988\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9943\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9952\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9975\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9856\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9940\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9936\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9980\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.9936\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9948\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9932\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9936\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9920\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9892\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9885\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9943\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9881\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9922\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9994\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9987\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9995\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9974\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9980\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9986\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9949\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9991\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9984\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9972\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9945\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9962\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9987\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9976\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9999\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9940\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9903\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9913\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9994\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9941\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9937\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9968\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9978\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9977\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9984\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9948\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9967\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9997\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9902\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9904\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9910\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9914\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9911\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9897\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9947\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9954\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9957\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9978\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.9978\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9816\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9892\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9970\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9934\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9889\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9930\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0138 - accuracy: 0.9968\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9851\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0253 - accuracy: 0.9940\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0140 - accuracy: 0.9968\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0335 - accuracy: 0.9816\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0116 - accuracy: 0.9950\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 0.9928\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9956\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.9988\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0143 - accuracy: 0.9949\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.9995\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0106 - accuracy: 0.9984\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9932\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0078 - accuracy: 0.9977\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0056 - accuracy: 0.9991\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0223 - accuracy: 0.9892\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0129 - accuracy: 0.9939\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0108 - accuracy: 0.9961\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7659 - accuracy: 0.7145\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8479\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8483\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3741 - accuracy: 0.8445\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8547\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8692\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8701\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.3085 - accuracy: 0.8675\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.8731\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.2700 - accuracy: 0.8944\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8570\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.2864 - accuracy: 0.8789\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.2618 - accuracy: 0.8804\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.2656 - accuracy: 0.8879\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.2618 - accuracy: 0.8914\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.8932\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.8969\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9241\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9287\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9225\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9068\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9003\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9249\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.9274\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.9318\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1521 - accuracy: 0.9471\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.1372 - accuracy: 0.9549\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.1599 - accuracy: 0.9341\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.1524 - accuracy: 0.9431\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.1351 - accuracy: 0.9507\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9467\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9430\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9477\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9578\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.9686\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.1368 - accuracy: 0.9501\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.1125 - accuracy: 0.9524\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.1088 - accuracy: 0.9659\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1115 - accuracy: 0.9605\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.1117 - accuracy: 0.9554\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9642\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9594\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.1029 - accuracy: 0.9535\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.1157 - accuracy: 0.9508\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0885 - accuracy: 0.9781\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9678\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0848 - accuracy: 0.9812\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9704\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9609\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0908 - accuracy: 0.9668\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9700\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9767\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9826\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9766\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9771\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9708\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0804 - accuracy: 0.9690\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0713 - accuracy: 0.9768\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0739 - accuracy: 0.9794\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0493 - accuracy: 0.9859\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9791\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0702 - accuracy: 0.9745\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0658 - accuracy: 0.9744\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0530 - accuracy: 0.9805\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0734 - accuracy: 0.9720\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9708\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0464 - accuracy: 0.9871\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0520 - accuracy: 0.9877\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0550 - accuracy: 0.9832\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0528 - accuracy: 0.9842\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0450 - accuracy: 0.9870\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0599 - accuracy: 0.9728\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0487 - accuracy: 0.9828\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0579 - accuracy: 0.9875\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0386 - accuracy: 0.9866\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0518 - accuracy: 0.9886\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0592 - accuracy: 0.9791\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9940\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9884\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9840\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9764\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9864\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9846\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9778\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 0.9852\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9846\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.9848\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9892\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9877\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9885\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9912\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9909\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9850\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0352 - accuracy: 0.9919\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9881\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0306 - accuracy: 0.9939\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0465 - accuracy: 0.9857\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0305 - accuracy: 0.9914\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0378 - accuracy: 0.9874\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0316 - accuracy: 0.9942\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0255 - accuracy: 0.9943\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0381 - accuracy: 0.9854\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0406 - accuracy: 0.9856\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0498 - accuracy: 0.9888\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0504 - accuracy: 0.9916\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0354 - accuracy: 0.9924\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0311 - accuracy: 0.9914\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9965\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9984\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9942\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9862\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9871\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9962\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9767\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0308 - accuracy: 0.9901\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0166 - accuracy: 0.9976\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9969\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0251 - accuracy: 0.9922\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9815\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.0687 - accuracy: 0.9766\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9948\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0287 - accuracy: 0.9938\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9835\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9820\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9816\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9969\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9895\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0256 - accuracy: 0.9905\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9905\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9930\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9977\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9940\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9902\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9957\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0240 - accuracy: 0.9905\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0249 - accuracy: 0.9940\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0162 - accuracy: 0.9993\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9961\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0182 - accuracy: 0.9952\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0226 - accuracy: 0.9945\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0201 - accuracy: 0.9908\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0211 - accuracy: 0.9920\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0184 - accuracy: 0.9963\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0163 - accuracy: 0.9989\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0196 - accuracy: 0.9914\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9799\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0297 - accuracy: 0.9891\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0226 - accuracy: 0.9930\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0189 - accuracy: 0.9952\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0265 - accuracy: 0.9899\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0253 - accuracy: 0.9915\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0213 - accuracy: 0.9963\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0307 - accuracy: 0.9920\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0248 - accuracy: 0.9906\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9975\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0169 - accuracy: 0.9964\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0127 - accuracy: 0.9982\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0222 - accuracy: 0.9954\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0123 - accuracy: 0.9987\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0262 - accuracy: 0.9887\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 886us/step - loss: 0.0197 - accuracy: 0.9937\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0242 - accuracy: 0.9896\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0146 - accuracy: 0.9973\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0269 - accuracy: 0.9874\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0201 - accuracy: 0.9965\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0194 - accuracy: 0.9936\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0187 - accuracy: 0.9940\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0288 - accuracy: 0.9897\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0293 - accuracy: 0.9896\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0263 - accuracy: 0.9914\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 0.9936\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.9941\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9903\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9944\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9932\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9888\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9873\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0198 - accuracy: 0.9929\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0246 - accuracy: 0.9926\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0285 - accuracy: 0.9926\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0441 - accuracy: 0.9766\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0232 - accuracy: 0.9921\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9970\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9941\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9975\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 0.9952\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9852\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9979\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9963\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0184 - accuracy: 0.9920\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0203 - accuracy: 0.9904\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9971\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9971\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9974\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.8294\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8412\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8718\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8553\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.8808\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3026 - accuracy: 0.8702\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.8753\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8658\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.8776\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8861\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9065\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.8856\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9026\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9065\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2230 - accuracy: 0.9157\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9103\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.9191\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9288\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9207\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9075\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9316\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.9365\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.1887 - accuracy: 0.9247\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9320\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9286\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9458\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.9429\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9456\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.9450\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9378\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9447\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9628\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.1140 - accuracy: 0.9524\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.1261 - accuracy: 0.9550\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.1352 - accuracy: 0.9452\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.1215 - accuracy: 0.9542\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.1352 - accuracy: 0.9372\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.1248 - accuracy: 0.9522\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.1214 - accuracy: 0.9537\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.1041 - accuracy: 0.9620\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.1052 - accuracy: 0.9592\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1073 - accuracy: 0.9662\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0892 - accuracy: 0.9664\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0858 - accuracy: 0.9673\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9689\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9686\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0952 - accuracy: 0.9600\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0722 - accuracy: 0.9792\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0839 - accuracy: 0.9715\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0863 - accuracy: 0.9691\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0728 - accuracy: 0.9784\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0813 - accuracy: 0.9687\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0645 - accuracy: 0.9761\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0775 - accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0671 - accuracy: 0.9732\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0625 - accuracy: 0.9845\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0692 - accuracy: 0.9752\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0586 - accuracy: 0.9830\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0671 - accuracy: 0.9760\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0673 - accuracy: 0.9757\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0713 - accuracy: 0.9723\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0637 - accuracy: 0.9799\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0640 - accuracy: 0.9756\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0619 - accuracy: 0.9835\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0972 - accuracy: 0.9545\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0473 - accuracy: 0.9850\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0564 - accuracy: 0.9832\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9805\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0568 - accuracy: 0.9854\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0578 - accuracy: 0.9878\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0386 - accuracy: 0.9955\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0444 - accuracy: 0.9877\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0460 - accuracy: 0.9839\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0513 - accuracy: 0.9834\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0318 - accuracy: 0.9932\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0470 - accuracy: 0.9872\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0529 - accuracy: 0.9831\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0400 - accuracy: 0.9919\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9736\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9909\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9867\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9870\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0444 - accuracy: 0.9832\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0407 - accuracy: 0.9918\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9966\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9918\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9904\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9974\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9946\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9868\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9884\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9872\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9944\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9930\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0425 - accuracy: 0.9849\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9926\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9951\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9856\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9939\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9887\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9976\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9994\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9962\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0300 - accuracy: 0.9883\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0260 - accuracy: 0.9946\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0347 - accuracy: 0.9876\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0265 - accuracy: 0.9979\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9850\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0301 - accuracy: 0.9882\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9900\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9923\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0238 - accuracy: 0.9919\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0226 - accuracy: 0.9966\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0210 - accuracy: 0.9985\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0185 - accuracy: 0.9951\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0186 - accuracy: 0.9987\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0171 - accuracy: 0.9946\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0190 - accuracy: 0.9975\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0210 - accuracy: 0.9963\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0172 - accuracy: 0.9954\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0266 - accuracy: 0.9896\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0165 - accuracy: 0.9992\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0234 - accuracy: 0.9942\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0219 - accuracy: 0.9935\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9942\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9954\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9969\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.9956\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9867\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9955\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9891\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9915\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9899\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9943\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9894\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9973\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0199 - accuracy: 0.9939\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0161 - accuracy: 0.9954\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0087 - accuracy: 0.9999\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0136 - accuracy: 0.9967\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0227 - accuracy: 0.9923\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9990\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0265 - accuracy: 0.9886\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0150 - accuracy: 0.9933\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0189 - accuracy: 0.9958\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0186 - accuracy: 0.9931\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0177 - accuracy: 0.9997\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0170 - accuracy: 0.9957\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9890\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0202 - accuracy: 0.9940\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0352 - accuracy: 0.9896\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0158 - accuracy: 0.9915\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0235 - accuracy: 0.9954\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0139 - accuracy: 0.9967\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0241 - accuracy: 0.9925\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0263 - accuracy: 0.9883\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0150 - accuracy: 0.9991\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 945us/step - loss: 0.0131 - accuracy: 0.9967\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0191 - accuracy: 0.9920\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0114 - accuracy: 0.9968\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9903\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9880\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0184 - accuracy: 0.9954\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0134 - accuracy: 0.9972\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0128 - accuracy: 0.9965\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0267 - accuracy: 0.9907\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0247 - accuracy: 0.9906\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0249 - accuracy: 0.9935\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.0098 - accuracy: 0.9987\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 0.9946\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9967\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 0.9975\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0150 - accuracy: 0.9960\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0241 - accuracy: 0.9901\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0137 - accuracy: 0.9971\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9992\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9925\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0166 - accuracy: 0.9943\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0217 - accuracy: 0.9910\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0242 - accuracy: 0.9886\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0208 - accuracy: 0.9915\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0138 - accuracy: 0.9942\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0195 - accuracy: 0.9956\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0155 - accuracy: 0.9964\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0142 - accuracy: 0.9939\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0371 - accuracy: 0.9925\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0129 - accuracy: 0.9980\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0093 - accuracy: 0.9979\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9945\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0229 - accuracy: 0.9916\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 0.9992\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0225 - accuracy: 0.9850\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0137 - accuracy: 0.9966\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 838us/step - loss: 0.6337 - accuracy: 0.7251\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.4153 - accuracy: 0.8303\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.3780 - accuracy: 0.8581\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8451\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8462\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.3159 - accuracy: 0.8609\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8629\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8744\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.2726 - accuracy: 0.8815\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.2741 - accuracy: 0.8991\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.2819 - accuracy: 0.8787\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.2669 - accuracy: 0.8754\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.8866\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.8790\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.2348 - accuracy: 0.8931\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.2395 - accuracy: 0.8865\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.2172 - accuracy: 0.9061\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.2023 - accuracy: 0.9119\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.2307 - accuracy: 0.8952\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.1963 - accuracy: 0.9144\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.1738 - accuracy: 0.9241\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.2011 - accuracy: 0.8984\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2044 - accuracy: 0.9071\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.1751 - accuracy: 0.9234\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.9263\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.1690 - accuracy: 0.9303\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.1653 - accuracy: 0.9349\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.1600 - accuracy: 0.9303\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.1569 - accuracy: 0.9408\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1514 - accuracy: 0.9376\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.1652 - accuracy: 0.9377\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.9362\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.1731 - accuracy: 0.9333\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.1340 - accuracy: 0.9494\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.1363 - accuracy: 0.9447\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.1158 - accuracy: 0.9543\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.1148 - accuracy: 0.9573\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.9502\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.1228 - accuracy: 0.9539\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.1025 - accuracy: 0.9604\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0935 - accuracy: 0.9727\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0957 - accuracy: 0.9683\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0984 - accuracy: 0.9681\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.1132 - accuracy: 0.9494\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9565\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9614\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0835 - accuracy: 0.9720\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9616\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0948 - accuracy: 0.9583\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9436\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.1076 - accuracy: 0.9593\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0915 - accuracy: 0.9646\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0852 - accuracy: 0.9671\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0721 - accuracy: 0.9815\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9781\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0679 - accuracy: 0.9793\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0749 - accuracy: 0.9726\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0704 - accuracy: 0.9714\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0740 - accuracy: 0.9795\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9715\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0721 - accuracy: 0.9728\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9863\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9863\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0536 - accuracy: 0.9849\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0549 - accuracy: 0.9852\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0835 - accuracy: 0.9661\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0493 - accuracy: 0.9861\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9801\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9794\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0579 - accuracy: 0.9870\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0547 - accuracy: 0.9848\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0547 - accuracy: 0.9767\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0454 - accuracy: 0.9849\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0522 - accuracy: 0.9895\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0703 - accuracy: 0.9804\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0755 - accuracy: 0.9646\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0597 - accuracy: 0.9758\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0323 - accuracy: 0.9904\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0502 - accuracy: 0.9824\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0554 - accuracy: 0.9836\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 963us/step - loss: 0.0554 - accuracy: 0.9846\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0586 - accuracy: 0.9721\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0653 - accuracy: 0.9798\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9757\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9791\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0481 - accuracy: 0.9841\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9787\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9954\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.0516 - accuracy: 0.9789\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0496 - accuracy: 0.9863\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0459 - accuracy: 0.9830\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0497 - accuracy: 0.9818\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0557 - accuracy: 0.9821\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0310 - accuracy: 0.9922\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9867\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0482 - accuracy: 0.9871\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0528 - accuracy: 0.9840\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0661 - accuracy: 0.9773\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0432 - accuracy: 0.9858\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0524 - accuracy: 0.9767\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9875\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9895\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0369 - accuracy: 0.9851\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0199 - accuracy: 0.9968\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0394 - accuracy: 0.9889\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9821\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9821\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0399 - accuracy: 0.9890\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0301 - accuracy: 0.9913\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0321 - accuracy: 0.9938\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0254 - accuracy: 0.9942\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0346 - accuracy: 0.9859\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9924\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0292 - accuracy: 0.9881\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9888\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0368 - accuracy: 0.9869\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0327 - accuracy: 0.9857\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9885\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9840\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0356 - accuracy: 0.9868\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0279 - accuracy: 0.9899\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0192 - accuracy: 0.9938\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0353 - accuracy: 0.9908\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9862\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.0485 - accuracy: 0.9833\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0267 - accuracy: 0.9901\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0258 - accuracy: 0.9917\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.0313 - accuracy: 0.9912\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0329 - accuracy: 0.9853\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0205 - accuracy: 0.9946\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0173 - accuracy: 0.9970\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0209 - accuracy: 0.9938\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0254 - accuracy: 0.9956\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0268 - accuracy: 0.9921\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0236 - accuracy: 0.9959\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0498 - accuracy: 0.9763\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0410 - accuracy: 0.9831\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0427 - accuracy: 0.9801\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0248 - accuracy: 0.9894\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0328 - accuracy: 0.9867\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0290 - accuracy: 0.9919\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0310 - accuracy: 0.9932\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0319 - accuracy: 0.9887\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9881\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9921\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0323 - accuracy: 0.9906\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9932\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9904\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9878\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9860\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9917\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0305 - accuracy: 0.9867\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0179 - accuracy: 0.9991\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0147 - accuracy: 0.9963\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0199 - accuracy: 0.9948\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0241 - accuracy: 0.9934\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0393 - accuracy: 0.9836\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0356 - accuracy: 0.9879\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0211 - accuracy: 0.9912\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 933us/step - loss: 0.0234 - accuracy: 0.9919\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0263 - accuracy: 0.9922\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9941\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0293 - accuracy: 0.9863\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9931\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0284 - accuracy: 0.9873\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0215 - accuracy: 0.9915\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0148 - accuracy: 0.9984\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0280 - accuracy: 0.9879\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0164 - accuracy: 0.9953\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0220 - accuracy: 0.9940\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9953\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0142 - accuracy: 0.9961\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0233 - accuracy: 0.9911\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0206 - accuracy: 0.9933\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0253 - accuracy: 0.9921\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0350 - accuracy: 0.9884\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0263 - accuracy: 0.9884\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0152 - accuracy: 0.9960\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9882\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0255 - accuracy: 0.9938\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0292 - accuracy: 0.9857\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9881\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0254 - accuracy: 0.9876\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9912\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0142 - accuracy: 0.9988\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9913\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9938\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9944\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.9962\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9932\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9942\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0178 - accuracy: 0.9974\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0171 - accuracy: 0.9967\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 0.9976\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0240 - accuracy: 0.9881\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0368 - accuracy: 0.9844\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0145 - accuracy: 0.9970\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 995us/step - loss: 0.6678 - accuracy: 0.7188\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.3933 - accuracy: 0.8447\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8454\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8563\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8791\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8611\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.8690\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8610\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.2857 - accuracy: 0.8881\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.2957 - accuracy: 0.8650\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.2931 - accuracy: 0.8786\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.2922 - accuracy: 0.8883\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.2710 - accuracy: 0.8856\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.2512 - accuracy: 0.8987\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.2568 - accuracy: 0.8967\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.2259 - accuracy: 0.9071\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.2465 - accuracy: 0.9111\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.2533 - accuracy: 0.8746\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.2363 - accuracy: 0.8949\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.2055 - accuracy: 0.9060\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.2077 - accuracy: 0.9161\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.1921 - accuracy: 0.9309\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.1937 - accuracy: 0.9181\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.2014 - accuracy: 0.9107\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.2029 - accuracy: 0.9070\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.1569 - accuracy: 0.9434\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9499\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.1651 - accuracy: 0.9227\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.1609 - accuracy: 0.9285\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.1549 - accuracy: 0.9395\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.1548 - accuracy: 0.9425\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1493 - accuracy: 0.9385\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.1507 - accuracy: 0.9322\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.1240 - accuracy: 0.9476\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1270 - accuracy: 0.9642\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.1483 - accuracy: 0.9311\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.1400 - accuracy: 0.9389\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.1046 - accuracy: 0.9580\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.1270 - accuracy: 0.9549\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.1225 - accuracy: 0.9497\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.1268 - accuracy: 0.9578\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.1159 - accuracy: 0.9579\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9614\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9591\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.1157 - accuracy: 0.9588\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0841 - accuracy: 0.9714\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0902 - accuracy: 0.9761\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9671\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0879 - accuracy: 0.9669\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0853 - accuracy: 0.9785\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.1055 - accuracy: 0.9556\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9655\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0823 - accuracy: 0.9681\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0979 - accuracy: 0.9674\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9714\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0792 - accuracy: 0.9768\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0785 - accuracy: 0.9684\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0960 - accuracy: 0.9625\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0866 - accuracy: 0.9631\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0718 - accuracy: 0.9835\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0761 - accuracy: 0.9799\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0649 - accuracy: 0.9779\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0731 - accuracy: 0.9776\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0703 - accuracy: 0.9781\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0669 - accuracy: 0.9818\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0554 - accuracy: 0.9869\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0675 - accuracy: 0.9817\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0582 - accuracy: 0.9814\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0670 - accuracy: 0.9774\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0646 - accuracy: 0.9817\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0511 - accuracy: 0.9904\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0564 - accuracy: 0.9876\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0767 - accuracy: 0.9758\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0468 - accuracy: 0.9860\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0706 - accuracy: 0.9746\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0479 - accuracy: 0.9881\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0557 - accuracy: 0.9782\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0581 - accuracy: 0.9857\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0635 - accuracy: 0.9790\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0644 - accuracy: 0.9777\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 972us/step - loss: 0.0472 - accuracy: 0.9839\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0516 - accuracy: 0.9813\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0585 - accuracy: 0.9725\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.0717 - accuracy: 0.9673\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0543 - accuracy: 0.9814\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0422 - accuracy: 0.9883\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9897\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9872\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0456 - accuracy: 0.9933\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0305 - accuracy: 0.9941\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9876\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0476 - accuracy: 0.9790\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0446 - accuracy: 0.9862\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0493 - accuracy: 0.9834\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0590 - accuracy: 0.9801\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9881\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9840\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0387 - accuracy: 0.9905\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9845\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9847\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9865\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0338 - accuracy: 0.9920\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0360 - accuracy: 0.9906\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0267 - accuracy: 0.9967\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9859\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9907\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9915\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0337 - accuracy: 0.9923\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0479 - accuracy: 0.9817\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9859\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0593 - accuracy: 0.9792\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0370 - accuracy: 0.9906\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0313 - accuracy: 0.9936\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9900\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0430 - accuracy: 0.9772\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0215 - accuracy: 0.9937\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0319 - accuracy: 0.9866\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0371 - accuracy: 0.9927\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0210 - accuracy: 0.9945\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0288 - accuracy: 0.9945\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0333 - accuracy: 0.9921\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0244 - accuracy: 0.9942\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0324 - accuracy: 0.9897\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0381 - accuracy: 0.9860\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0308 - accuracy: 0.9914\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0401 - accuracy: 0.9806\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0213 - accuracy: 0.9931\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0324 - accuracy: 0.9869\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0279 - accuracy: 0.9891\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0277 - accuracy: 0.9905\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0286 - accuracy: 0.9892\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9910\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9872\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9968\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0288 - accuracy: 0.9913\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0233 - accuracy: 0.9911\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0208 - accuracy: 0.9919\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0215 - accuracy: 0.9944\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0434 - accuracy: 0.9868\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0370 - accuracy: 0.9920\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0334 - accuracy: 0.9878\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0315 - accuracy: 0.9913\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0354 - accuracy: 0.9854\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0348 - accuracy: 0.9861\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0263 - accuracy: 0.9924\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9869\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0387 - accuracy: 0.9889\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0352 - accuracy: 0.9871\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0246 - accuracy: 0.9943\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0229 - accuracy: 0.9922\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9945\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9825\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0258 - accuracy: 0.9910\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0339 - accuracy: 0.9911\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0301 - accuracy: 0.9913\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0367 - accuracy: 0.9811\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0175 - accuracy: 0.9964\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0169 - accuracy: 0.9966\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0138 - accuracy: 0.9961\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0175 - accuracy: 0.9962\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0246 - accuracy: 0.9880\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9960\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9957\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9974\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0267 - accuracy: 0.9920\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9865\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9928\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9976\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0123 - accuracy: 0.9963\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0168 - accuracy: 0.9978\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9957\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0223 - accuracy: 0.9967\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0301 - accuracy: 0.9908\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9909\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0212 - accuracy: 0.9918\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9883\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0378 - accuracy: 0.9858\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0280 - accuracy: 0.9934\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0372 - accuracy: 0.9844\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0215 - accuracy: 0.9962\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0306 - accuracy: 0.9886\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0207 - accuracy: 0.9942\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9987\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9964\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9944\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9905\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9969\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9934\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9909\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0194 - accuracy: 0.9949\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9891\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9953\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 0.9960\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9947\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 0.9987\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9947\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9894\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6057 - accuracy: 0.7649\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8218\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8639\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.3657 - accuracy: 0.8410\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.3605 - accuracy: 0.8427\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.3027 - accuracy: 0.8711\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.3297 - accuracy: 0.8493\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.2928 - accuracy: 0.8841\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.8795\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.2539 - accuracy: 0.8978\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.2362 - accuracy: 0.9079\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.2332 - accuracy: 0.9077\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.2721 - accuracy: 0.8895\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.2392 - accuracy: 0.8932\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.2408 - accuracy: 0.9023\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.2390 - accuracy: 0.9069\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.2047 - accuracy: 0.9164\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2263 - accuracy: 0.9052\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.2214 - accuracy: 0.9049\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.2155 - accuracy: 0.9127\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.2209 - accuracy: 0.8991\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.1795 - accuracy: 0.9269\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.1808 - accuracy: 0.9294\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.1538 - accuracy: 0.9422\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.1706 - accuracy: 0.9342\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.1688 - accuracy: 0.9335\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.1688 - accuracy: 0.9255\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1569 - accuracy: 0.9325\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.1553 - accuracy: 0.9414\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.1632 - accuracy: 0.9373\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.1514 - accuracy: 0.9402\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9531\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9661\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1277 - accuracy: 0.9510\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9417\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.9504\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9669\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9680\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9608\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.1121 - accuracy: 0.9540\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0978 - accuracy: 0.9611\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0983 - accuracy: 0.9685\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.1066 - accuracy: 0.9629\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0915 - accuracy: 0.9613\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0804 - accuracy: 0.9775\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0831 - accuracy: 0.9774\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0899 - accuracy: 0.9679\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0785 - accuracy: 0.9710\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0597 - accuracy: 0.9844\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0872 - accuracy: 0.9719\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0685 - accuracy: 0.9808\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0768 - accuracy: 0.9685\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0747 - accuracy: 0.9810\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0613 - accuracy: 0.9854\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0675 - accuracy: 0.9781\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0681 - accuracy: 0.9777\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0791 - accuracy: 0.9683\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9914\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9837\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0610 - accuracy: 0.9796\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0542 - accuracy: 0.9829\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9837\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0537 - accuracy: 0.9770\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0506 - accuracy: 0.9858\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0532 - accuracy: 0.9796\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9823\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0421 - accuracy: 0.9909\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0461 - accuracy: 0.9903\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0481 - accuracy: 0.9836\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0812 - accuracy: 0.9644\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0504 - accuracy: 0.9907\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0319 - accuracy: 0.9903\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0324 - accuracy: 0.9924\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0389 - accuracy: 0.9877\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0312 - accuracy: 0.9961\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9870\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0461 - accuracy: 0.9841\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9953\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0519 - accuracy: 0.9790\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0372 - accuracy: 0.9915\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 916us/step - loss: 0.0317 - accuracy: 0.9928\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0455 - accuracy: 0.9926\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0395 - accuracy: 0.9872\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0287 - accuracy: 0.9949\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9911\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0326 - accuracy: 0.9953\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0363 - accuracy: 0.9903\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0270 - accuracy: 0.9977\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9908\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9910\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9863\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9937\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9885\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9893\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0252 - accuracy: 0.9958\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9961\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9912\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9905\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9891\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9900\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9947\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9985\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0361 - accuracy: 0.9912\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0281 - accuracy: 0.9939\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9961\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 0.9950\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9905\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0194 - accuracy: 0.9974\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9923\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0214 - accuracy: 0.9934\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0182 - accuracy: 0.9927\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0281 - accuracy: 0.9945\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0330 - accuracy: 0.9922\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0310 - accuracy: 0.9931\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0270 - accuracy: 0.9929\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0298 - accuracy: 0.9907\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0168 - accuracy: 0.9993\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0227 - accuracy: 0.9945\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0463 - accuracy: 0.9845\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0168 - accuracy: 0.9947\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0202 - accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0222 - accuracy: 0.9919\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0158 - accuracy: 0.9944\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9932\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9989\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0131 - accuracy: 0.9979\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0098 - accuracy: 0.9962\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0234 - accuracy: 0.9936\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9931\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0243 - accuracy: 0.9945\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0382 - accuracy: 0.9898\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0165 - accuracy: 0.9970\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0174 - accuracy: 0.9949\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0235 - accuracy: 0.9895\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0217 - accuracy: 0.9945\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0158 - accuracy: 0.9996\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0194 - accuracy: 0.9949\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0193 - accuracy: 0.9935\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0188 - accuracy: 0.9940\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0164 - accuracy: 0.9957\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0130 - accuracy: 0.9985\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0165 - accuracy: 0.9959\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0126 - accuracy: 0.9970\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9975\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9902\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0130 - accuracy: 0.9991\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0128 - accuracy: 0.9985\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 968us/step - loss: 0.0154 - accuracy: 0.9940\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0260 - accuracy: 0.9926\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0216 - accuracy: 0.9915\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0295 - accuracy: 0.9930\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0165 - accuracy: 0.9956\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0151 - accuracy: 0.9989\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0123 - accuracy: 0.9975\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0272 - accuracy: 0.9889\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0207 - accuracy: 0.9936\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 940us/step - loss: 0.0177 - accuracy: 0.9945\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0093 - accuracy: 0.9997\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0238 - accuracy: 0.9886\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0101 - accuracy: 0.9965\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0301 - accuracy: 0.9918\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0217 - accuracy: 0.9869\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0141 - accuracy: 0.9945\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0088 - accuracy: 0.9985\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0092 - accuracy: 0.9995\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0181 - accuracy: 0.9954\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0163 - accuracy: 0.9967\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0194 - accuracy: 0.9937\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0158 - accuracy: 0.9971\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0087 - accuracy: 0.9985\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0203 - accuracy: 0.9905\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0178 - accuracy: 0.9948\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0162 - accuracy: 0.9940\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0150 - accuracy: 0.9952\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0183 - accuracy: 0.9967\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0045 - accuracy: 0.9982\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0079 - accuracy: 0.9992\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0049 - accuracy: 0.9996\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0096 - accuracy: 0.9978\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0122 - accuracy: 0.9983\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0083 - accuracy: 0.9985\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0100 - accuracy: 0.9999\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0089 - accuracy: 0.9980\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0220 - accuracy: 0.9929\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0114 - accuracy: 0.9986\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0129 - accuracy: 0.9985\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0093 - accuracy: 0.9977\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0069 - accuracy: 0.9989\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0099 - accuracy: 0.9953\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0260 - accuracy: 0.9915\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 960us/step - loss: 0.6503 - accuracy: 0.7114\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.4339 - accuracy: 0.8249\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.4094 - accuracy: 0.8253\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.3225 - accuracy: 0.8662\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.3269 - accuracy: 0.8574\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.3334 - accuracy: 0.8542\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2972 - accuracy: 0.8796\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.2733 - accuracy: 0.8724\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.2700 - accuracy: 0.8899\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.2956 - accuracy: 0.8614\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.2715 - accuracy: 0.8831\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.2490 - accuracy: 0.8977\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.2454 - accuracy: 0.8996\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.2695 - accuracy: 0.8855\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.2292 - accuracy: 0.9008\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.2336 - accuracy: 0.8936\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.2335 - accuracy: 0.9048\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.2233 - accuracy: 0.9062\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.2090 - accuracy: 0.9156\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.2043 - accuracy: 0.9061\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.1966 - accuracy: 0.9118\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.2033 - accuracy: 0.9115\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9317\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9312\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9307\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9326\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9200\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9375\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.9229\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9527\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9407\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9527\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9459\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9497\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9565\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1195 - accuracy: 0.9572\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9503\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.1101 - accuracy: 0.9706\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9531\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9530\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9473\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9570\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9692\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9550\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.1110 - accuracy: 0.9578\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9667\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0915 - accuracy: 0.9734\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0711 - accuracy: 0.9797\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0787 - accuracy: 0.9792\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.1057 - accuracy: 0.9605\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0851 - accuracy: 0.9736\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0822 - accuracy: 0.9718\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0632 - accuracy: 0.9826\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0739 - accuracy: 0.9762\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0855 - accuracy: 0.9697\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0669 - accuracy: 0.9725\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0652 - accuracy: 0.9810\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0549 - accuracy: 0.9834\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0744 - accuracy: 0.9787\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0756 - accuracy: 0.9728\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0565 - accuracy: 0.9821\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0517 - accuracy: 0.9893\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0555 - accuracy: 0.9875\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0612 - accuracy: 0.9799\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0484 - accuracy: 0.9874\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0560 - accuracy: 0.9841\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0431 - accuracy: 0.9888\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0435 - accuracy: 0.9912\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0561 - accuracy: 0.9760\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0473 - accuracy: 0.9879\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0666 - accuracy: 0.9819\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0530 - accuracy: 0.9840\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0509 - accuracy: 0.9789\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0496 - accuracy: 0.9828\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0372 - accuracy: 0.9965\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0616 - accuracy: 0.9798\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0485 - accuracy: 0.9899\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0361 - accuracy: 0.9968\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0372 - accuracy: 0.9892\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0455 - accuracy: 0.9803\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0395 - accuracy: 0.9916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0305 - accuracy: 0.9958\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0398 - accuracy: 0.9874\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0446 - accuracy: 0.9881\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9956\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0467 - accuracy: 0.9861\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9934\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9909\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9809\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9951\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0372 - accuracy: 0.9903\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9942\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 0.9849\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9907\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9935\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9894\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9890\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9888\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9923\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9840\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9875\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9824\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0298 - accuracy: 0.9935\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0214 - accuracy: 0.9941\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9923\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0276 - accuracy: 0.9946\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9953\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9930\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9923\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9894\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0215 - accuracy: 0.9959\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9954\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0265 - accuracy: 0.9930\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0362 - accuracy: 0.9866\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0207 - accuracy: 0.9971\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0146 - accuracy: 0.9987\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0293 - accuracy: 0.9917\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0413 - accuracy: 0.9863\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0354 - accuracy: 0.9831\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0308 - accuracy: 0.9887\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0277 - accuracy: 0.9887\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 805us/step - loss: 0.0228 - accuracy: 0.9963\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0340 - accuracy: 0.9869\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0163 - accuracy: 0.9991\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0219 - accuracy: 0.9948\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0330 - accuracy: 0.9889\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0168 - accuracy: 0.9982\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0229 - accuracy: 0.9950\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0231 - accuracy: 0.9955\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0247 - accuracy: 0.9980\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0310 - accuracy: 0.9872\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0230 - accuracy: 0.9914\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0134 - accuracy: 0.9973\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0134 - accuracy: 0.9990\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 791us/step - loss: 0.0138 - accuracy: 0.9980\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0198 - accuracy: 0.9966\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0187 - accuracy: 0.9956\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0197 - accuracy: 0.9973\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.0254 - accuracy: 0.9893\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0143 - accuracy: 0.9971\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0214 - accuracy: 0.9915\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0262 - accuracy: 0.9894\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0152 - accuracy: 0.9959\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0218 - accuracy: 0.9943\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0138 - accuracy: 0.9973\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 815us/step - loss: 0.0197 - accuracy: 0.9946\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0185 - accuracy: 0.9939\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0151 - accuracy: 0.9956\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0180 - accuracy: 0.9975\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0309 - accuracy: 0.9895\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0157 - accuracy: 0.9957\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0214 - accuracy: 0.9948\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0188 - accuracy: 0.9949\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0144 - accuracy: 0.9957\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0141 - accuracy: 0.9998\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0183 - accuracy: 0.9938\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0121 - accuracy: 0.9983\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.0185 - accuracy: 0.9964\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0279 - accuracy: 0.9910\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 821us/step - loss: 0.0180 - accuracy: 0.9937\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0142 - accuracy: 0.9953\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0165 - accuracy: 0.9938\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0318 - accuracy: 0.9874\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 810us/step - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0193 - accuracy: 0.9965\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0228 - accuracy: 0.9946\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0189 - accuracy: 0.9966\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0132 - accuracy: 0.9981\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0263 - accuracy: 0.9889\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0205 - accuracy: 0.9949\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 804us/step - loss: 0.0173 - accuracy: 0.9970\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0280 - accuracy: 0.9926\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 811us/step - loss: 0.0403 - accuracy: 0.9821\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0210 - accuracy: 0.9921\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 797us/step - loss: 0.0132 - accuracy: 0.9986\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0115 - accuracy: 0.9984\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 805us/step - loss: 0.0149 - accuracy: 0.9960\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0151 - accuracy: 0.9979\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.0128 - accuracy: 0.9964\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0125 - accuracy: 0.9981\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0154 - accuracy: 0.9960\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 815us/step - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0079 - accuracy: 0.9989\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.0113 - accuracy: 0.9947\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0305 - accuracy: 0.9859\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0194 - accuracy: 0.9938\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0133 - accuracy: 0.9950\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0187 - accuracy: 0.9949\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0192 - accuracy: 0.9942\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0232 - accuracy: 0.9911\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0099 - accuracy: 0.9995\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.0211 - accuracy: 0.9963\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0169 - accuracy: 0.9996\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0123 - accuracy: 0.9969\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0202 - accuracy: 0.9913\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 889us/step - loss: 0.7336 - accuracy: 0.6773\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.4381 - accuracy: 0.8138\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.3963 - accuracy: 0.8295\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.3425 - accuracy: 0.8545\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.3272 - accuracy: 0.8486\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.2947 - accuracy: 0.8760\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.3000 - accuracy: 0.8652\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.2803 - accuracy: 0.8750\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 799us/step - loss: 0.2575 - accuracy: 0.8922\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.2484 - accuracy: 0.8926\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.2395 - accuracy: 0.8920\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.2568 - accuracy: 0.8789\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.2219 - accuracy: 0.8979\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.2486 - accuracy: 0.8784\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 795us/step - loss: 0.2017 - accuracy: 0.9165\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.1961 - accuracy: 0.9251\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 810us/step - loss: 0.2094 - accuracy: 0.9157\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.1887 - accuracy: 0.9276\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 808us/step - loss: 0.2061 - accuracy: 0.9207\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.1954 - accuracy: 0.9172\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.1918 - accuracy: 0.9229\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.1867 - accuracy: 0.9278\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.1749 - accuracy: 0.9268\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.1400 - accuracy: 0.9448\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 812us/step - loss: 0.1998 - accuracy: 0.9150\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.1751 - accuracy: 0.9252\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 807us/step - loss: 0.1642 - accuracy: 0.9387\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.1483 - accuracy: 0.9310\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.1572 - accuracy: 0.9346\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.1535 - accuracy: 0.9407\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.1297 - accuracy: 0.9422\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.1434 - accuracy: 0.9506\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.1229 - accuracy: 0.9536\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.1329 - accuracy: 0.9440\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0998 - accuracy: 0.9708\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 815us/step - loss: 0.1349 - accuracy: 0.9394\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.1142 - accuracy: 0.9593\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.1106 - accuracy: 0.9541\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.1401 - accuracy: 0.9446\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.0996 - accuracy: 0.9683\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.1099 - accuracy: 0.9644\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.1229 - accuracy: 0.9541\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0952 - accuracy: 0.9735\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0995 - accuracy: 0.9607\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0953 - accuracy: 0.9662\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0994 - accuracy: 0.9672\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0932 - accuracy: 0.9700\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0961 - accuracy: 0.9657\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0974 - accuracy: 0.9678\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0925 - accuracy: 0.9689\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0815 - accuracy: 0.9725\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0870 - accuracy: 0.9764\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.1065 - accuracy: 0.9578\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.1041 - accuracy: 0.9491\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 812us/step - loss: 0.0784 - accuracy: 0.9696\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 807us/step - loss: 0.0755 - accuracy: 0.9720\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0886 - accuracy: 0.9744\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0934 - accuracy: 0.9657\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0924 - accuracy: 0.9652\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.0595 - accuracy: 0.9789\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0729 - accuracy: 0.9767\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0702 - accuracy: 0.9782\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0620 - accuracy: 0.9861\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0605 - accuracy: 0.9839\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0594 - accuracy: 0.9769\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0582 - accuracy: 0.9771\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 815us/step - loss: 0.0733 - accuracy: 0.9654\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0524 - accuracy: 0.9865\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0750 - accuracy: 0.9660\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0667 - accuracy: 0.9856\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0501 - accuracy: 0.9848\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0429 - accuracy: 0.9921\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0592 - accuracy: 0.9816\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0649 - accuracy: 0.9834\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0538 - accuracy: 0.9831\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0497 - accuracy: 0.9900\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0555 - accuracy: 0.9844\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0470 - accuracy: 0.9845\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0501 - accuracy: 0.9871\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0502 - accuracy: 0.9848\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 813us/step - loss: 0.0456 - accuracy: 0.9879\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0629 - accuracy: 0.9743\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0509 - accuracy: 0.9833\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0459 - accuracy: 0.9839\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0444 - accuracy: 0.9855\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0500 - accuracy: 0.9897\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0390 - accuracy: 0.9905\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0336 - accuracy: 0.9911\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0476 - accuracy: 0.9878\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0350 - accuracy: 0.9891\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0386 - accuracy: 0.9893\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0336 - accuracy: 0.9894\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0329 - accuracy: 0.9931\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 805us/step - loss: 0.0475 - accuracy: 0.9856\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0415 - accuracy: 0.9922\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0307 - accuracy: 0.9945\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0393 - accuracy: 0.9875\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0349 - accuracy: 0.9879\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0331 - accuracy: 0.9938\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0282 - accuracy: 0.9901\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0353 - accuracy: 0.9899\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 797us/step - loss: 0.0296 - accuracy: 0.9915\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0319 - accuracy: 0.9891\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0398 - accuracy: 0.9865\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0353 - accuracy: 0.9863\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0352 - accuracy: 0.9862\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0423 - accuracy: 0.9809\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0343 - accuracy: 0.9902\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0289 - accuracy: 0.9877\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0316 - accuracy: 0.9879\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0329 - accuracy: 0.9927\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0431 - accuracy: 0.9850\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 808us/step - loss: 0.0429 - accuracy: 0.9841\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.0264 - accuracy: 0.9948\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0280 - accuracy: 0.9885\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.0229 - accuracy: 0.9942\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0203 - accuracy: 0.9970\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0393 - accuracy: 0.9892\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 811us/step - loss: 0.0225 - accuracy: 0.9919\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0299 - accuracy: 0.9902\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0255 - accuracy: 0.9872\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0344 - accuracy: 0.9938\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0340 - accuracy: 0.9848\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0410 - accuracy: 0.9848\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0378 - accuracy: 0.9839\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 810us/step - loss: 0.0263 - accuracy: 0.9919\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0289 - accuracy: 0.9912\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0330 - accuracy: 0.9897\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0163 - accuracy: 0.9970\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0284 - accuracy: 0.9899\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0240 - accuracy: 0.9902\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0273 - accuracy: 0.9885\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0157 - accuracy: 0.9993\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0244 - accuracy: 0.9894\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0186 - accuracy: 0.9979\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0173 - accuracy: 0.9992\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0273 - accuracy: 0.9916\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0213 - accuracy: 0.9938\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0275 - accuracy: 0.9908\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0162 - accuracy: 0.9950\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0208 - accuracy: 0.9975\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0259 - accuracy: 0.9902\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0182 - accuracy: 0.9974\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0202 - accuracy: 0.9996\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0359 - accuracy: 0.9868\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.0278 - accuracy: 0.9887\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0164 - accuracy: 0.9974\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0238 - accuracy: 0.9906\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0158 - accuracy: 0.9962\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0176 - accuracy: 0.9932\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0272 - accuracy: 0.9904\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 810us/step - loss: 0.0174 - accuracy: 0.9941\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0178 - accuracy: 0.9973\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 811us/step - loss: 0.0238 - accuracy: 0.9926\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0139 - accuracy: 0.9985\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0210 - accuracy: 0.9928\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0227 - accuracy: 0.9939\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0184 - accuracy: 0.9949\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0088 - accuracy: 0.9998\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 812us/step - loss: 0.0325 - accuracy: 0.9908\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0299 - accuracy: 0.9904\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0278 - accuracy: 0.9877\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0189 - accuracy: 0.9943\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 806us/step - loss: 0.0215 - accuracy: 0.9944\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0221 - accuracy: 0.9962\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0217 - accuracy: 0.9937\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0191 - accuracy: 0.9944\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0183 - accuracy: 0.9913\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0129 - accuracy: 0.9995\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0140 - accuracy: 0.9978\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0115 - accuracy: 0.9988\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0096 - accuracy: 0.9980\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0208 - accuracy: 0.9942\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0295 - accuracy: 0.9885\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.0171 - accuracy: 0.9963\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0372 - accuracy: 0.9829\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 802us/step - loss: 0.0335 - accuracy: 0.9873\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0266 - accuracy: 0.9914\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 798us/step - loss: 0.0180 - accuracy: 0.9953\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0218 - accuracy: 0.9929\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 808us/step - loss: 0.0158 - accuracy: 0.9983\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0152 - accuracy: 0.9936\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0176 - accuracy: 0.9958\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0214 - accuracy: 0.9914\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0229 - accuracy: 0.9910\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0370 - accuracy: 0.9880\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 810us/step - loss: 0.0212 - accuracy: 0.9913\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0181 - accuracy: 0.9931\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0119 - accuracy: 0.9973\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0135 - accuracy: 0.9990\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0183 - accuracy: 0.9932\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0117 - accuracy: 0.9975\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0144 - accuracy: 0.9972\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 808us/step - loss: 0.0259 - accuracy: 0.9923\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0253 - accuracy: 0.9910\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0223 - accuracy: 0.9916\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0124 - accuracy: 0.9940\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0180 - accuracy: 0.9951\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0088 - accuracy: 0.9968\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 956us/step - loss: 0.6098 - accuracy: 0.7350\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8411\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.3207 - accuracy: 0.8687\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.3389 - accuracy: 0.8673\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.2848 - accuracy: 0.8836\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.2841 - accuracy: 0.8697\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.2995 - accuracy: 0.8792\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.3100 - accuracy: 0.8765\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.2707 - accuracy: 0.8894\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.2384 - accuracy: 0.8956\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.2534 - accuracy: 0.8927\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.2416 - accuracy: 0.9013\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.2279 - accuracy: 0.9075\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2601 - accuracy: 0.8979\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.2281 - accuracy: 0.9006\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.1905 - accuracy: 0.9271\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.2283 - accuracy: 0.8975\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.2093 - accuracy: 0.9119\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.1923 - accuracy: 0.9223\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.1880 - accuracy: 0.9164\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.1674 - accuracy: 0.9392\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9298\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1722 - accuracy: 0.9388\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9360\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9430\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9481\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.9542\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1558 - accuracy: 0.9454\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9350\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9405\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.1173 - accuracy: 0.9538\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9588\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9459\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9636\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.1035 - accuracy: 0.9686\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9472\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9777\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0928 - accuracy: 0.9684\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.9646\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9827\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9695\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9724\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9677\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9700\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9684\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0701 - accuracy: 0.9804\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9703\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0762 - accuracy: 0.9829\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0721 - accuracy: 0.9791\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9795\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0603 - accuracy: 0.9841\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9854\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9837\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9813\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9726\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9920\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9827\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0520 - accuracy: 0.9817\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0619 - accuracy: 0.9786\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0483 - accuracy: 0.9911\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0513 - accuracy: 0.9930\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0526 - accuracy: 0.9820\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0451 - accuracy: 0.9862\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0474 - accuracy: 0.9886\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0587 - accuracy: 0.9753\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0495 - accuracy: 0.9881\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0424 - accuracy: 0.9838\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0405 - accuracy: 0.9887\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0422 - accuracy: 0.9860\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0367 - accuracy: 0.9878\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0386 - accuracy: 0.9900\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0380 - accuracy: 0.9877\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 790us/step - loss: 0.0411 - accuracy: 0.9840\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 815us/step - loss: 0.0400 - accuracy: 0.9893\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 799us/step - loss: 0.0401 - accuracy: 0.9922\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.0375 - accuracy: 0.9944\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 795us/step - loss: 0.0345 - accuracy: 0.9914\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 800us/step - loss: 0.0265 - accuracy: 0.9935\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0286 - accuracy: 0.9956\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0275 - accuracy: 0.9982\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0231 - accuracy: 0.9943\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 805us/step - loss: 0.0331 - accuracy: 0.9884\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 802us/step - loss: 0.0578 - accuracy: 0.9788\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 804us/step - loss: 0.0388 - accuracy: 0.9875\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0251 - accuracy: 0.9975\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0352 - accuracy: 0.9946\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.0399 - accuracy: 0.9956\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0332 - accuracy: 0.9877\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0289 - accuracy: 0.9905\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0349 - accuracy: 0.9914\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0313 - accuracy: 0.9893\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0243 - accuracy: 0.9939\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0383 - accuracy: 0.9852\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0247 - accuracy: 0.9968\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0290 - accuracy: 0.9896\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0247 - accuracy: 0.9958\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 810us/step - loss: 0.0295 - accuracy: 0.9889\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0201 - accuracy: 0.9973\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 812us/step - loss: 0.0273 - accuracy: 0.9927\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0212 - accuracy: 0.9921\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0161 - accuracy: 0.9989\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9905\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9952\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9949\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9960\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9948\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9967\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9949\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0134 - accuracy: 0.9982\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9992\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9965\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0218 - accuracy: 0.9919\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0189 - accuracy: 0.9973\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 0.9988\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9891\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0188 - accuracy: 0.9982\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9966\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9970\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0375 - accuracy: 0.9889\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0201 - accuracy: 0.9941\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0195 - accuracy: 0.9950\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0352 - accuracy: 0.9870\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0184 - accuracy: 0.9948\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0200 - accuracy: 0.9892\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0187 - accuracy: 0.9953\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0190 - accuracy: 0.9976\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 808us/step - loss: 0.0202 - accuracy: 0.9932\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0116 - accuracy: 0.9965\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0135 - accuracy: 0.9974\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9912\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9939\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9945\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9990\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9998\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0189 - accuracy: 0.9930\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9974\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9977\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0181 - accuracy: 0.9947\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0107 - accuracy: 0.9987\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0139 - accuracy: 0.9958\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0297 - accuracy: 0.9862\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0144 - accuracy: 0.9977\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0181 - accuracy: 0.9945\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0212 - accuracy: 0.9911\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 793us/step - loss: 0.0194 - accuracy: 0.9932\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0181 - accuracy: 0.9925\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0238 - accuracy: 0.9893\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0168 - accuracy: 0.9952\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 983us/step - loss: 0.0272 - accuracy: 0.9933\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9925\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9957\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0524 - accuracy: 0.9801\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 0.9969\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9888\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9904\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9933\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9963\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 999us/step - loss: 0.0183 - accuracy: 0.9912\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9933\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.9997\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 0.9987\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 0.9968\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 0.9994\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 0.9980\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9919\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9979\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 0.9967\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9990\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0140 - accuracy: 0.9932\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0081 - accuracy: 0.9992\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9950\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0380 - accuracy: 0.9875\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0258 - accuracy: 0.9908\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0239 - accuracy: 0.9888\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0177 - accuracy: 0.9981\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0097 - accuracy: 0.9995\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0091 - accuracy: 0.9958\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0079 - accuracy: 0.9980\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0316 - accuracy: 0.9919\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0119 - accuracy: 0.9963\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0216 - accuracy: 0.9933\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0160 - accuracy: 0.9929\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0108 - accuracy: 0.9954\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0096 - accuracy: 0.9973\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0059 - accuracy: 0.9987\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0078 - accuracy: 0.9988\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0076 - accuracy: 0.9973\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0169 - accuracy: 0.9936\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0207 - accuracy: 0.9921\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0098 - accuracy: 0.9993\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0089 - accuracy: 0.9968\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 807us/step - loss: 0.0078 - accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.6026 - accuracy: 0.7742\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.3807 - accuracy: 0.8751\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.3297 - accuracy: 0.8869\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.3293 - accuracy: 0.8778\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.3629 - accuracy: 0.8658\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.3019 - accuracy: 0.8820\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.2687 - accuracy: 0.9131\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.2661 - accuracy: 0.9026\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.2439 - accuracy: 0.9144\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.2349 - accuracy: 0.9072\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.2441 - accuracy: 0.9114\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.2333 - accuracy: 0.9144\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.2214 - accuracy: 0.9179\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.2014 - accuracy: 0.9233\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.2088 - accuracy: 0.9286\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 804us/step - loss: 0.1927 - accuracy: 0.9333\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.1833 - accuracy: 0.9271\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.2067 - accuracy: 0.9286\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.1659 - accuracy: 0.9443\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.1598 - accuracy: 0.9444\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.1640 - accuracy: 0.9456\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.1553 - accuracy: 0.9487\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.1580 - accuracy: 0.9496\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 823us/step - loss: 0.1677 - accuracy: 0.9313\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.1609 - accuracy: 0.9458\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.1448 - accuracy: 0.9341\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.1635 - accuracy: 0.9398\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.1438 - accuracy: 0.9435\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.1350 - accuracy: 0.9585\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.1084 - accuracy: 0.9639\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.1207 - accuracy: 0.9532\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.1171 - accuracy: 0.9608\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.1097 - accuracy: 0.9676\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.1117 - accuracy: 0.9681\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0927 - accuracy: 0.9704\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.1186 - accuracy: 0.9557\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.1051 - accuracy: 0.9685\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0895 - accuracy: 0.9744\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0968 - accuracy: 0.9634\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.1027 - accuracy: 0.9596\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0970 - accuracy: 0.9666\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0899 - accuracy: 0.9692\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0991 - accuracy: 0.9710\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0697 - accuracy: 0.9854\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0878 - accuracy: 0.9668\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0888 - accuracy: 0.9744\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0841 - accuracy: 0.9691\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 833us/step - loss: 0.1025 - accuracy: 0.9619\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0898 - accuracy: 0.9710\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.0889 - accuracy: 0.9649\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0805 - accuracy: 0.9693\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0732 - accuracy: 0.9750\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0736 - accuracy: 0.9726\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0592 - accuracy: 0.9799\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0500 - accuracy: 0.9841\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0610 - accuracy: 0.9783\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0544 - accuracy: 0.9812\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0453 - accuracy: 0.9858\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 814us/step - loss: 0.0488 - accuracy: 0.9877\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0395 - accuracy: 0.9886\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0502 - accuracy: 0.9865\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0428 - accuracy: 0.9890\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0603 - accuracy: 0.9843\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0607 - accuracy: 0.9818\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0455 - accuracy: 0.9859\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0519 - accuracy: 0.9875\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 803us/step - loss: 0.0471 - accuracy: 0.9844\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.0451 - accuracy: 0.9891\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0356 - accuracy: 0.9899\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0572 - accuracy: 0.9837\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0491 - accuracy: 0.9818\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0342 - accuracy: 0.9917\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0482 - accuracy: 0.9850\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0512 - accuracy: 0.9844\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0397 - accuracy: 0.9884\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0446 - accuracy: 0.9871\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0441 - accuracy: 0.9884\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0363 - accuracy: 0.9855\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 818us/step - loss: 0.0349 - accuracy: 0.9876\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0534 - accuracy: 0.9830\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 825us/step - loss: 0.0486 - accuracy: 0.9786\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0453 - accuracy: 0.9862\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0257 - accuracy: 0.9927\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0276 - accuracy: 0.9941\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0305 - accuracy: 0.9905\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0332 - accuracy: 0.9888\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0361 - accuracy: 0.9885\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0337 - accuracy: 0.9944\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0327 - accuracy: 0.9918\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0365 - accuracy: 0.9893\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0421 - accuracy: 0.9853\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0381 - accuracy: 0.9882\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0412 - accuracy: 0.9857\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0346 - accuracy: 0.9842\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0233 - accuracy: 0.9980\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0318 - accuracy: 0.9900\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0253 - accuracy: 0.9939\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0199 - accuracy: 0.9952\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0338 - accuracy: 0.9900\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0263 - accuracy: 0.9951\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0269 - accuracy: 0.9904\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0253 - accuracy: 0.9953\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0293 - accuracy: 0.9880\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.0217 - accuracy: 0.9978\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0247 - accuracy: 0.9924\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0154 - accuracy: 0.9982\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0166 - accuracy: 0.9964\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0257 - accuracy: 0.9923\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0430 - accuracy: 0.9834\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0286 - accuracy: 0.9902\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0334 - accuracy: 0.9906\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0287 - accuracy: 0.9900\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0323 - accuracy: 0.9954\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0251 - accuracy: 0.9917\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0203 - accuracy: 0.9946\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0244 - accuracy: 0.9904\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9951\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9884\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9901\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9949\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9928\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9929\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9958\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9940\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9907\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9970\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9914\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9904\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9856\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9863\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9901\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9930\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9886\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9840\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9922\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9987\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9920\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.0198 - accuracy: 0.9898\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.9923\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 0.9985\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0256 - accuracy: 0.9924\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9942\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0135 - accuracy: 0.9966\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0195 - accuracy: 0.9934\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0171 - accuracy: 0.9957\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0146 - accuracy: 0.9976\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0153 - accuracy: 0.9972\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0276 - accuracy: 0.9901\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0279 - accuracy: 0.9906\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0217 - accuracy: 0.9914\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0130 - accuracy: 0.9952\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0149 - accuracy: 0.9979\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0239 - accuracy: 0.9920\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0190 - accuracy: 0.9973\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0196 - accuracy: 0.9948\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0268 - accuracy: 0.9928\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 882us/step - loss: 0.0095 - accuracy: 0.9994\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0349 - accuracy: 0.9907\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0224 - accuracy: 0.9934\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0208 - accuracy: 0.9954\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0211 - accuracy: 0.9923\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0285 - accuracy: 0.9885\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0197 - accuracy: 0.9922\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0203 - accuracy: 0.9937\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0171 - accuracy: 0.9919\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0378 - accuracy: 0.9834\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0211 - accuracy: 0.9957\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0184 - accuracy: 0.9907\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0197 - accuracy: 0.9901\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0220 - accuracy: 0.9941\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0194 - accuracy: 0.9927\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0127 - accuracy: 0.9968\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0163 - accuracy: 0.9990\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0177 - accuracy: 0.9981\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0282 - accuracy: 0.9864\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0276 - accuracy: 0.9899\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0139 - accuracy: 0.9975\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0148 - accuracy: 0.9965\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0101 - accuracy: 0.9984\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0153 - accuracy: 0.9966\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0119 - accuracy: 0.9977\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0211 - accuracy: 0.9955\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0080 - accuracy: 0.9985\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0183 - accuracy: 0.9947\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0143 - accuracy: 0.9961\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0177 - accuracy: 0.9942\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0129 - accuracy: 0.9960\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0148 - accuracy: 0.9960\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0148 - accuracy: 0.9965\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0084 - accuracy: 0.9970\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0105 - accuracy: 0.9974\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0147 - accuracy: 0.9969\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9994\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 827us/step - loss: 0.5579 - accuracy: 0.7783\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.3504 - accuracy: 0.8791\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.3251 - accuracy: 0.8940\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.3322 - accuracy: 0.8781\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.3007 - accuracy: 0.8782\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.3147 - accuracy: 0.8798\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.2662 - accuracy: 0.8911\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8958\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2687 - accuracy: 0.8928\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.2364 - accuracy: 0.9047\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.2490 - accuracy: 0.8957\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.2491 - accuracy: 0.8917\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.9059\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.2322 - accuracy: 0.9061\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 813us/step - loss: 0.1943 - accuracy: 0.9297\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.2166 - accuracy: 0.9107\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.2077 - accuracy: 0.9112\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.1766 - accuracy: 0.9391\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.1916 - accuracy: 0.9266\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.9339\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1782 - accuracy: 0.9361\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.2045 - accuracy: 0.9274\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.1704 - accuracy: 0.9360\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.1641 - accuracy: 0.9337\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9421\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1562 - accuracy: 0.9385\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9367\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.9268\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9472\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.1615 - accuracy: 0.9240\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.1630 - accuracy: 0.9380\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.1342 - accuracy: 0.9465\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9371\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.1473 - accuracy: 0.9506\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9522\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0965 - accuracy: 0.9728\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.9621\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.1237 - accuracy: 0.9579\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9609\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.1102 - accuracy: 0.9516\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.0933 - accuracy: 0.9659\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9617\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0885 - accuracy: 0.9674\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9645\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0849 - accuracy: 0.9690\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9750\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9702\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0784 - accuracy: 0.9644\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0923 - accuracy: 0.9633\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0835 - accuracy: 0.9762\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0790 - accuracy: 0.9710\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0748 - accuracy: 0.9701\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0951 - accuracy: 0.9679\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0626 - accuracy: 0.9782\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0747 - accuracy: 0.9705\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0595 - accuracy: 0.9879\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0632 - accuracy: 0.9726\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0776 - accuracy: 0.9684\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0703 - accuracy: 0.9812\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0712 - accuracy: 0.9751\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0556 - accuracy: 0.9829\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0518 - accuracy: 0.9866\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0646 - accuracy: 0.9713\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0591 - accuracy: 0.9756\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0570 - accuracy: 0.9804\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0581 - accuracy: 0.9829\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 963us/step - loss: 0.0588 - accuracy: 0.9804\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0527 - accuracy: 0.9843\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0532 - accuracy: 0.9861\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9818\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0467 - accuracy: 0.9854\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0506 - accuracy: 0.9866\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0546 - accuracy: 0.9803\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0400 - accuracy: 0.9891\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0516 - accuracy: 0.9864\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0426 - accuracy: 0.9884\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0459 - accuracy: 0.9849\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0511 - accuracy: 0.9795\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0337 - accuracy: 0.9925\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 851us/step - loss: 0.0519 - accuracy: 0.9829\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0483 - accuracy: 0.9849\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0452 - accuracy: 0.9857\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0378 - accuracy: 0.9876\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0390 - accuracy: 0.9896\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0405 - accuracy: 0.9864\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0380 - accuracy: 0.9856\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0331 - accuracy: 0.9912\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0419 - accuracy: 0.9903\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0329 - accuracy: 0.9906\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0444 - accuracy: 0.9890\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0406 - accuracy: 0.9864\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0411 - accuracy: 0.9885\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0371 - accuracy: 0.9940\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0307 - accuracy: 0.9936\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0317 - accuracy: 0.9964\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0262 - accuracy: 0.9939\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0176 - accuracy: 0.9984\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0247 - accuracy: 0.9941\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0463 - accuracy: 0.9870\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0380 - accuracy: 0.9887\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0290 - accuracy: 0.9917\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0337 - accuracy: 0.9878\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0376 - accuracy: 0.9901\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0303 - accuracy: 0.9882\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0282 - accuracy: 0.9938\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0288 - accuracy: 0.9904\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0242 - accuracy: 0.9938\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0275 - accuracy: 0.9946\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0184 - accuracy: 0.9981\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0309 - accuracy: 0.9964\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0170 - accuracy: 0.9975\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0199 - accuracy: 0.9975\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0282 - accuracy: 0.9924\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9941\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9957\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9951\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9928\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9881\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0243 - accuracy: 0.9935\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9952\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9942\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9883\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9963\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9962\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0282 - accuracy: 0.9933\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0126 - accuracy: 0.9994\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0210 - accuracy: 0.9945\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9969\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0315 - accuracy: 0.9880\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0305 - accuracy: 0.9913\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0249 - accuracy: 0.9912\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0151 - accuracy: 0.9970\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0164 - accuracy: 0.9961\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0215 - accuracy: 0.9949\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0232 - accuracy: 0.9977\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0414 - accuracy: 0.9844\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 815us/step - loss: 0.0143 - accuracy: 0.9956\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0301 - accuracy: 0.9882\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0206 - accuracy: 0.9948\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0177 - accuracy: 0.9953\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9962\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9888\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9982\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9928\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9958\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9942\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9996\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9961\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9945\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9920\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9968\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9949\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9843\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9950\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9960\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9897\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9968\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9925\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9990\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9948\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9939\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9899\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 0.9952\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9899\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9962\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9966\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9997\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9906\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9941\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9928\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 0.9975\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9958\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 0.9962\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9984\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9863\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9957\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9951\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9992\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.9995\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0177 - accuracy: 0.9920\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9893\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0199 - accuracy: 0.9938\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0281 - accuracy: 0.9899\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0151 - accuracy: 0.9920\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0139 - accuracy: 0.9974\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0167 - accuracy: 0.9919\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0105 - accuracy: 0.9981\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0140 - accuracy: 0.9943\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0142 - accuracy: 0.9964\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9981\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9974\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9950\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.8547 - accuracy: 0.6824\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.8628\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8884\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.8789\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.3069 - accuracy: 0.8854\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.9019\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.2555 - accuracy: 0.9009\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.9151\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9140\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2612 - accuracy: 0.9063\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9182\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.9250\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.9270\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9203\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9150\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9493\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9379\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9443\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9457\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.9349\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9294\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9395\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9576\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9401\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.1523 - accuracy: 0.9491\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.9715\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9540\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9656\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9494\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9597\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9676\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9530\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9564\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.1091 - accuracy: 0.9579\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.1049 - accuracy: 0.9601\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9545\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9618\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1017 - accuracy: 0.9649\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9688\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9688\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9663\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.9766\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9765\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9681\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9660\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9702\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9808\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9762\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9857\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9677\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9791\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9794\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9808\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9819\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.9806\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9763\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0529 - accuracy: 0.9895\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9818\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9756\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9886\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9840\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0504 - accuracy: 0.9909\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.0592 - accuracy: 0.9809\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0453 - accuracy: 0.9868\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9807\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9850\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0353 - accuracy: 0.9920\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0489 - accuracy: 0.9873\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0404 - accuracy: 0.9905\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0472 - accuracy: 0.9859\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0471 - accuracy: 0.9814\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0527 - accuracy: 0.9798\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0510 - accuracy: 0.9808\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0297 - accuracy: 0.9916\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0561 - accuracy: 0.9790\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0381 - accuracy: 0.9889\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0323 - accuracy: 0.9906\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0340 - accuracy: 0.9901\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0391 - accuracy: 0.9858\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0400 - accuracy: 0.9844\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0275 - accuracy: 0.9949\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 897us/step - loss: 0.0309 - accuracy: 0.9885\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0343 - accuracy: 0.9896\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0327 - accuracy: 0.9895\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0305 - accuracy: 0.9874\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0301 - accuracy: 0.9929\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0453 - accuracy: 0.9855\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0297 - accuracy: 0.9862\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0334 - accuracy: 0.9885\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0349 - accuracy: 0.9895\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0322 - accuracy: 0.9903\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0350 - accuracy: 0.9904\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0365 - accuracy: 0.9788\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0364 - accuracy: 0.9879\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0249 - accuracy: 0.9967\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0401 - accuracy: 0.9876\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0236 - accuracy: 0.9920\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0268 - accuracy: 0.9953\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0307 - accuracy: 0.9930\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0260 - accuracy: 0.9929\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.0289 - accuracy: 0.9933\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0312 - accuracy: 0.9849\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0399 - accuracy: 0.9819\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0283 - accuracy: 0.9942\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0184 - accuracy: 0.9987\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0515 - accuracy: 0.9734\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0292 - accuracy: 0.9937\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9944\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0184 - accuracy: 0.9965\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0386 - accuracy: 0.9830\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0244 - accuracy: 0.9876\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0260 - accuracy: 0.9905\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0170 - accuracy: 0.9979\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0171 - accuracy: 0.9974\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0200 - accuracy: 0.9971\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0201 - accuracy: 0.9976\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9972\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9938\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9919\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9982\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9954\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9974\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0184 - accuracy: 0.9955\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0191 - accuracy: 0.9979\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0139 - accuracy: 0.9967\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0180 - accuracy: 0.9930\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0162 - accuracy: 0.9968\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0166 - accuracy: 0.9935\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0134 - accuracy: 0.9977\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0371 - accuracy: 0.9861\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9892\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9963\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9981\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 0.9978\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.9993\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9988\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9968\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0153 - accuracy: 0.9938\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0374 - accuracy: 0.9866\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0210 - accuracy: 0.9954\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0169 - accuracy: 0.9953\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.0339 - accuracy: 0.9837\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 0.9960\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 0.9988\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9955\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9887\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9963\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0098 - accuracy: 0.9989\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0206 - accuracy: 0.9950\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 976us/step - loss: 0.0171 - accuracy: 0.9948\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0146 - accuracy: 0.9980\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0074 - accuracy: 0.9969\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0164 - accuracy: 0.9935\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0189 - accuracy: 0.9918\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 0.9980\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0085 - accuracy: 0.9982\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0248 - accuracy: 0.9905\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 998us/step - loss: 0.0223 - accuracy: 0.9937\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0118 - accuracy: 0.9988\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9941\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9945\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9963\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9989\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0177 - accuracy: 0.9894\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0190 - accuracy: 0.9919\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9916\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0095 - accuracy: 0.9976\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0098 - accuracy: 0.9976\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0201 - accuracy: 0.9938\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0154 - accuracy: 0.9917\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0208 - accuracy: 0.9879\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0124 - accuracy: 0.9968\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0120 - accuracy: 0.9945\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0069 - accuracy: 0.9995\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0125 - accuracy: 0.9976\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0376 - accuracy: 0.9867\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0141 - accuracy: 0.9984\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0134 - accuracy: 0.9966\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0113 - accuracy: 0.9954\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0118 - accuracy: 0.9935\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0161 - accuracy: 0.9970\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9971\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0215 - accuracy: 0.9935\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0138 - accuracy: 0.9936\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0211 - accuracy: 0.9903\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0239 - accuracy: 0.9912\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0100 - accuracy: 0.9977\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0208 - accuracy: 0.9911\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0256 - accuracy: 0.9888\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0133 - accuracy: 0.9971\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0092 - accuracy: 0.9974\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0231 - accuracy: 0.9882\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0111 - accuracy: 0.9960\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0074 - accuracy: 0.9981\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0110 - accuracy: 0.9971\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 782us/step - loss: 0.7853 - accuracy: 0.7093\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.3918 - accuracy: 0.8656\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.3577 - accuracy: 0.8726\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.3731 - accuracy: 0.8644\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.3552 - accuracy: 0.8728\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.2863 - accuracy: 0.8955\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.3482 - accuracy: 0.8677\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.3073 - accuracy: 0.8865\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.2653 - accuracy: 0.8977\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.2895 - accuracy: 0.8860\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.2896 - accuracy: 0.8941\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.2824 - accuracy: 0.8835\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.2801 - accuracy: 0.8888\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.2761 - accuracy: 0.8833\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.2619 - accuracy: 0.8904\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.2535 - accuracy: 0.9041\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.2474 - accuracy: 0.9160\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.2430 - accuracy: 0.8924\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.2546 - accuracy: 0.9020\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.2604 - accuracy: 0.8935\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.2561 - accuracy: 0.8971\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.2601 - accuracy: 0.8993\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.2037 - accuracy: 0.9083\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.2203 - accuracy: 0.9011\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 975us/step - loss: 0.2351 - accuracy: 0.9084\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.2035 - accuracy: 0.9216\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.2057 - accuracy: 0.9136\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.9099\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.1919 - accuracy: 0.9360\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2022 - accuracy: 0.9210\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.2031 - accuracy: 0.9194\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.1799 - accuracy: 0.9274\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.1876 - accuracy: 0.9249\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.2099 - accuracy: 0.9217\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1940 - accuracy: 0.9165\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.1769 - accuracy: 0.9214\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.1776 - accuracy: 0.9233\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.1473 - accuracy: 0.9458\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.1840 - accuracy: 0.9277\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.1590 - accuracy: 0.9402\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.1485 - accuracy: 0.9466\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.1598 - accuracy: 0.9330\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.1903 - accuracy: 0.9434\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.1609 - accuracy: 0.9447\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.1576 - accuracy: 0.9428\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.1384 - accuracy: 0.9558\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.1374 - accuracy: 0.9511\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1318 - accuracy: 0.9397\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.1332 - accuracy: 0.9461\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.1262 - accuracy: 0.9529\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.1099 - accuracy: 0.9627\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9480\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.1469 - accuracy: 0.9433\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1263 - accuracy: 0.9408\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.1288 - accuracy: 0.9502\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.1596 - accuracy: 0.9331\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.1078 - accuracy: 0.9554\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.1169 - accuracy: 0.9584\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.1332 - accuracy: 0.9353\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1365 - accuracy: 0.9404\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.1203 - accuracy: 0.9538\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.1169 - accuracy: 0.9641\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.1114 - accuracy: 0.9582\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0978 - accuracy: 0.9593\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.1059 - accuracy: 0.9535\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.1055 - accuracy: 0.9599\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1266 - accuracy: 0.9540\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.1043 - accuracy: 0.9670\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0874 - accuracy: 0.9620\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.1060 - accuracy: 0.9670\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0903 - accuracy: 0.9712\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0923 - accuracy: 0.9672\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0972 - accuracy: 0.9642\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0686 - accuracy: 0.9761\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0941 - accuracy: 0.9664\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0930 - accuracy: 0.9625\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0914 - accuracy: 0.9625\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0834 - accuracy: 0.9646\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0893 - accuracy: 0.9749\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1109 - accuracy: 0.9568\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 882us/step - loss: 0.0957 - accuracy: 0.9570\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0824 - accuracy: 0.9686\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0845 - accuracy: 0.9652\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0654 - accuracy: 0.9771\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0720 - accuracy: 0.9691\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0706 - accuracy: 0.9693\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0649 - accuracy: 0.9820\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0611 - accuracy: 0.9863\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0923 - accuracy: 0.9665\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0944 - accuracy: 0.9578\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0647 - accuracy: 0.9756\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0730 - accuracy: 0.9694\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0643 - accuracy: 0.9774\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0704 - accuracy: 0.9679\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0756 - accuracy: 0.9698\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0643 - accuracy: 0.9774\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0725 - accuracy: 0.9723\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0718 - accuracy: 0.9697\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0686 - accuracy: 0.9792\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0561 - accuracy: 0.9758\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0705 - accuracy: 0.9742\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0637 - accuracy: 0.9733\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0613 - accuracy: 0.9801\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9760\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0535 - accuracy: 0.9765\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0767 - accuracy: 0.9765\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0660 - accuracy: 0.9722\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0663 - accuracy: 0.9732\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0448 - accuracy: 0.9910\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0460 - accuracy: 0.9886\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0758 - accuracy: 0.9709\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0561 - accuracy: 0.9804\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0559 - accuracy: 0.9794\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0536 - accuracy: 0.9745\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0708 - accuracy: 0.9788\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0699 - accuracy: 0.9768\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0524 - accuracy: 0.9847\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0868 - accuracy: 0.9679\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0454 - accuracy: 0.9897\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0652 - accuracy: 0.9736\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0753 - accuracy: 0.9709\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0647 - accuracy: 0.9786\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0465 - accuracy: 0.9877\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0642 - accuracy: 0.9791\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0533 - accuracy: 0.9815\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0534 - accuracy: 0.9820\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0641 - accuracy: 0.9751\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0555 - accuracy: 0.9781\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0552 - accuracy: 0.9795\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0560 - accuracy: 0.9798\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0566 - accuracy: 0.9760\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0544 - accuracy: 0.9802\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0396 - accuracy: 0.9841\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0383 - accuracy: 0.9897\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0397 - accuracy: 0.9901\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0452 - accuracy: 0.9868\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0573 - accuracy: 0.9726\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9794\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9829\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9829\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 994us/step - loss: 0.0446 - accuracy: 0.9876\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9914\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0408 - accuracy: 0.9853\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0534 - accuracy: 0.9875\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0387 - accuracy: 0.9874\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0439 - accuracy: 0.9836\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0413 - accuracy: 0.9868\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0476 - accuracy: 0.9843\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0476 - accuracy: 0.9815\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0453 - accuracy: 0.9774\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9926\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0418 - accuracy: 0.9837\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0427 - accuracy: 0.9891\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0508 - accuracy: 0.9802\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9875\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9889\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0469 - accuracy: 0.9818\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0572 - accuracy: 0.9750\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0354 - accuracy: 0.9846\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9884\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9926\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0301 - accuracy: 0.9917\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0409 - accuracy: 0.9863\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0484 - accuracy: 0.9880\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0327 - accuracy: 0.9883\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0294 - accuracy: 0.9892\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0423 - accuracy: 0.9878\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0267 - accuracy: 0.9955\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0533 - accuracy: 0.9825\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0312 - accuracy: 0.9922\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0455 - accuracy: 0.9803\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0226 - accuracy: 0.9897\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0373 - accuracy: 0.9904\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0423 - accuracy: 0.9849\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0431 - accuracy: 0.9845\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0376 - accuracy: 0.9924\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0319 - accuracy: 0.9891\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0440 - accuracy: 0.9891\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0353 - accuracy: 0.9840\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0326 - accuracy: 0.9831\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0331 - accuracy: 0.9890\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.0388 - accuracy: 0.9882\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0306 - accuracy: 0.9898\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0384 - accuracy: 0.9833\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0312 - accuracy: 0.9881\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0350 - accuracy: 0.9881\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0496 - accuracy: 0.9797\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0337 - accuracy: 0.9914\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0292 - accuracy: 0.9903\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0291 - accuracy: 0.9889\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0298 - accuracy: 0.9921\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0298 - accuracy: 0.9919\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0571 - accuracy: 0.9747\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0435 - accuracy: 0.9865\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0282 - accuracy: 0.9883\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0386 - accuracy: 0.9846\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0488 - accuracy: 0.9743\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0353 - accuracy: 0.9840\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0362 - accuracy: 0.9842\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 849us/step - loss: 0.5387 - accuracy: 0.8268\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.3531 - accuracy: 0.8861\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.3112 - accuracy: 0.8934\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.3053 - accuracy: 0.8851\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.2960 - accuracy: 0.8874\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.3210 - accuracy: 0.8655\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.2859 - accuracy: 0.8878\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.2908 - accuracy: 0.8817\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.2797 - accuracy: 0.8860\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.2772 - accuracy: 0.8873\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.2627 - accuracy: 0.8840\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.2761 - accuracy: 0.8909\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.2290 - accuracy: 0.9190\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.2363 - accuracy: 0.9009\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.2343 - accuracy: 0.9105\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.2341 - accuracy: 0.9109\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.2038 - accuracy: 0.9316\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.1983 - accuracy: 0.9310\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.2048 - accuracy: 0.9161\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.1996 - accuracy: 0.9307\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.1908 - accuracy: 0.9239\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.1965 - accuracy: 0.9315\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.1845 - accuracy: 0.9218\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.1858 - accuracy: 0.9376\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.2065 - accuracy: 0.9346\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.1702 - accuracy: 0.9365\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.1528 - accuracy: 0.9577\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.1586 - accuracy: 0.9368\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.1632 - accuracy: 0.9309\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.1749 - accuracy: 0.9278\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.1516 - accuracy: 0.9415\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.1465 - accuracy: 0.9395\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.1427 - accuracy: 0.9557\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.1487 - accuracy: 0.9445\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.1303 - accuracy: 0.9646\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.1132 - accuracy: 0.9519\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.1223 - accuracy: 0.9624\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.1215 - accuracy: 0.9627\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.1099 - accuracy: 0.9644\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.1294 - accuracy: 0.9494\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.1122 - accuracy: 0.9677\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.1033 - accuracy: 0.9637\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0839 - accuracy: 0.9742\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.1092 - accuracy: 0.9664\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0911 - accuracy: 0.9830\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.1154 - accuracy: 0.9602\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.1005 - accuracy: 0.9717\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.1245 - accuracy: 0.9497\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.1012 - accuracy: 0.9571\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0867 - accuracy: 0.9696\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0947 - accuracy: 0.9673\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0824 - accuracy: 0.9658\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0782 - accuracy: 0.9746\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0811 - accuracy: 0.9762\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0785 - accuracy: 0.9790\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0754 - accuracy: 0.9736\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0921 - accuracy: 0.9756\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0821 - accuracy: 0.9706\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0659 - accuracy: 0.9756\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0735 - accuracy: 0.9627\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0612 - accuracy: 0.9828\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0798 - accuracy: 0.9738\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0673 - accuracy: 0.9751\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0714 - accuracy: 0.9743\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 819us/step - loss: 0.0763 - accuracy: 0.9732\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0672 - accuracy: 0.9776\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0603 - accuracy: 0.9821\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0778 - accuracy: 0.9640\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0548 - accuracy: 0.9782\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0461 - accuracy: 0.9889\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0580 - accuracy: 0.9773\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0556 - accuracy: 0.9831\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0481 - accuracy: 0.9880\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0546 - accuracy: 0.9872\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0468 - accuracy: 0.9891\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0535 - accuracy: 0.9853\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0589 - accuracy: 0.9770\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0522 - accuracy: 0.9804\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0469 - accuracy: 0.9883\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0670 - accuracy: 0.9652\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 845us/step - loss: 0.0543 - accuracy: 0.9825\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0461 - accuracy: 0.9849\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0545 - accuracy: 0.9817\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0490 - accuracy: 0.9895\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0478 - accuracy: 0.9808\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0691 - accuracy: 0.9818\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0440 - accuracy: 0.9865\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0648 - accuracy: 0.9741\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0443 - accuracy: 0.9889\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0523 - accuracy: 0.9879\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0474 - accuracy: 0.9894\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0368 - accuracy: 0.9899\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0501 - accuracy: 0.9817\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0531 - accuracy: 0.9848\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0479 - accuracy: 0.9820\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0462 - accuracy: 0.9889\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0534 - accuracy: 0.9863\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0342 - accuracy: 0.9876\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0503 - accuracy: 0.9847\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0435 - accuracy: 0.9860\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0361 - accuracy: 0.9915\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0366 - accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0361 - accuracy: 0.9933\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0323 - accuracy: 0.9935\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0320 - accuracy: 0.9912\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0422 - accuracy: 0.9896\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0378 - accuracy: 0.9909\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0407 - accuracy: 0.9862\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0608 - accuracy: 0.9736\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0305 - accuracy: 0.9919\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0314 - accuracy: 0.9934\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0368 - accuracy: 0.9928\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0302 - accuracy: 0.9862\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0318 - accuracy: 0.9904\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0393 - accuracy: 0.9864\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0284 - accuracy: 0.9943\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0351 - accuracy: 0.9899\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0360 - accuracy: 0.9873\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0357 - accuracy: 0.9904\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0377 - accuracy: 0.9907\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0387 - accuracy: 0.9933\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0264 - accuracy: 0.9951\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0366 - accuracy: 0.9930\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0298 - accuracy: 0.9901\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0399 - accuracy: 0.9907\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0242 - accuracy: 0.9952\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0508 - accuracy: 0.9799\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0304 - accuracy: 0.9932\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0510 - accuracy: 0.9796\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0238 - accuracy: 0.9930\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0235 - accuracy: 0.9935\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0312 - accuracy: 0.9921\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0269 - accuracy: 0.9918\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0240 - accuracy: 0.9954\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0237 - accuracy: 0.9978\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0224 - accuracy: 0.9967\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0401 - accuracy: 0.9857\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0491 - accuracy: 0.9818\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0270 - accuracy: 0.9943\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0326 - accuracy: 0.9875\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0285 - accuracy: 0.9941\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0311 - accuracy: 0.9902\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0324 - accuracy: 0.9910\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0233 - accuracy: 0.9945\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0281 - accuracy: 0.9881\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0230 - accuracy: 0.9950\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0245 - accuracy: 0.9922\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0186 - accuracy: 0.9942\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0171 - accuracy: 0.9964\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0239 - accuracy: 0.9914\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0362 - accuracy: 0.9873\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0301 - accuracy: 0.9891\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0312 - accuracy: 0.9833\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0176 - accuracy: 0.9989\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0262 - accuracy: 0.9966\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0256 - accuracy: 0.9885\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0279 - accuracy: 0.9939\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0591 - accuracy: 0.9816\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 887us/step - loss: 0.0282 - accuracy: 0.9934\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0205 - accuracy: 0.9973\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0203 - accuracy: 0.9945\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0267 - accuracy: 0.9909\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0220 - accuracy: 0.9946\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0290 - accuracy: 0.9895\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0159 - accuracy: 0.9970\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0307 - accuracy: 0.9915\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0214 - accuracy: 0.9973\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0168 - accuracy: 0.9966\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0158 - accuracy: 0.9981\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0180 - accuracy: 0.9980\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0173 - accuracy: 0.9904\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0318 - accuracy: 0.9907\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0177 - accuracy: 0.9960\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0347 - accuracy: 0.9851\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0246 - accuracy: 0.9898\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0165 - accuracy: 0.9911\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0204 - accuracy: 0.9944\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.0144 - accuracy: 0.9986\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0160 - accuracy: 0.9945\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0190 - accuracy: 0.9975\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0148 - accuracy: 0.9981\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0353 - accuracy: 0.9840\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0385 - accuracy: 0.9923\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0159 - accuracy: 0.9961\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0413 - accuracy: 0.9821\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0430 - accuracy: 0.9830\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0244 - accuracy: 0.9936\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0220 - accuracy: 0.9944\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0222 - accuracy: 0.9922\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0180 - accuracy: 0.9957\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0194 - accuracy: 0.9926\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0196 - accuracy: 0.9938\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0135 - accuracy: 0.9982\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0266 - accuracy: 0.9915\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0175 - accuracy: 0.9951\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0183 - accuracy: 0.9955\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0373 - accuracy: 0.9781\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0148 - accuracy: 0.9986\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 826us/step - loss: 0.3930 - accuracy: 0.8850\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.3272 - accuracy: 0.8880\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.3250 - accuracy: 0.8846\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.3023 - accuracy: 0.8881\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.2732 - accuracy: 0.9009\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.2930 - accuracy: 0.8818\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.2671 - accuracy: 0.8947\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.2613 - accuracy: 0.9104\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.2573 - accuracy: 0.9015\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.9122\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.2269 - accuracy: 0.9095\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.2221 - accuracy: 0.9227\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.2566 - accuracy: 0.9139\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.2014 - accuracy: 0.9213\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1920 - accuracy: 0.9323\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.1755 - accuracy: 0.9324\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.1893 - accuracy: 0.9243\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1793 - accuracy: 0.9305\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1577 - accuracy: 0.9523\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.1718 - accuracy: 0.9384\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.1591 - accuracy: 0.9438\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.1353 - accuracy: 0.9527\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1446 - accuracy: 0.9412\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1245 - accuracy: 0.9568\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.1795 - accuracy: 0.9372\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.1315 - accuracy: 0.9493\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.1703 - accuracy: 0.9352\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1289 - accuracy: 0.9478\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.1122 - accuracy: 0.9668\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.1145 - accuracy: 0.9609\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.1161 - accuracy: 0.9617\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0911 - accuracy: 0.9671\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0977 - accuracy: 0.9560\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0850 - accuracy: 0.9681\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0852 - accuracy: 0.9775\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0940 - accuracy: 0.9562\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0830 - accuracy: 0.9757\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9767\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0843 - accuracy: 0.9733\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0697 - accuracy: 0.9762\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0771 - accuracy: 0.9840\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0650 - accuracy: 0.9716\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0846 - accuracy: 0.9728\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0584 - accuracy: 0.9755\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0567 - accuracy: 0.9857\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0614 - accuracy: 0.9772\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0550 - accuracy: 0.9851\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0520 - accuracy: 0.9794\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0516 - accuracy: 0.9872\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0716 - accuracy: 0.9698\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0551 - accuracy: 0.9841\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0612 - accuracy: 0.9760\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0484 - accuracy: 0.9871\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0569 - accuracy: 0.9828\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0550 - accuracy: 0.9848\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0507 - accuracy: 0.9837\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0390 - accuracy: 0.9879\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0363 - accuracy: 0.9829\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0349 - accuracy: 0.9846\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0382 - accuracy: 0.9859\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0462 - accuracy: 0.9885\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0456 - accuracy: 0.9801\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0367 - accuracy: 0.9858\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0444 - accuracy: 0.9897\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0463 - accuracy: 0.9852\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0421 - accuracy: 0.9889\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0661 - accuracy: 0.9744\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0395 - accuracy: 0.9842\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0379 - accuracy: 0.9909\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0406 - accuracy: 0.9824\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0323 - accuracy: 0.9940\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0278 - accuracy: 0.9973\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0279 - accuracy: 0.9901\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0331 - accuracy: 0.9910\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0202 - accuracy: 0.9966\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0194 - accuracy: 0.9938\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0283 - accuracy: 0.9931\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0302 - accuracy: 0.9897\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0259 - accuracy: 0.9901\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0165 - accuracy: 0.9978\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 819us/step - loss: 0.0200 - accuracy: 0.9937\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0309 - accuracy: 0.9903\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0244 - accuracy: 0.9900\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0338 - accuracy: 0.9903\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0216 - accuracy: 0.9957\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0162 - accuracy: 0.9984\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0200 - accuracy: 0.9944\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0213 - accuracy: 0.9955\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0215 - accuracy: 0.9955\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0228 - accuracy: 0.9948\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0255 - accuracy: 0.9893\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0255 - accuracy: 0.9921\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0242 - accuracy: 0.9883\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0300 - accuracy: 0.9935\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0241 - accuracy: 0.9957\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0214 - accuracy: 0.9946\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0173 - accuracy: 0.9964\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0207 - accuracy: 0.9953\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0189 - accuracy: 0.9947\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0201 - accuracy: 0.9919\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0153 - accuracy: 0.9970\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9999\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0238 - accuracy: 0.9916\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0283 - accuracy: 0.9955\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0226 - accuracy: 0.9926\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0231 - accuracy: 0.9916\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0153 - accuracy: 0.9985\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0172 - accuracy: 0.9948\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0203 - accuracy: 0.9947\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0140 - accuracy: 0.9986\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0202 - accuracy: 0.9977\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0161 - accuracy: 0.9949\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0102 - accuracy: 0.9991\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0156 - accuracy: 0.9974\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0225 - accuracy: 0.9922\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0258 - accuracy: 0.9913\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0292 - accuracy: 0.9931\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 820us/step - loss: 0.0210 - accuracy: 0.9944\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0127 - accuracy: 0.9991\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0192 - accuracy: 0.9899\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0179 - accuracy: 0.9959\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0128 - accuracy: 0.9965\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0119 - accuracy: 0.9980\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0116 - accuracy: 0.9987\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0126 - accuracy: 0.9992\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0130 - accuracy: 0.9992\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0224 - accuracy: 0.9890\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.0130 - accuracy: 0.9985\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0169 - accuracy: 0.9953\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0088 - accuracy: 0.9992\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0088 - accuracy: 0.9996\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0100 - accuracy: 0.9985\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0192 - accuracy: 0.9963\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0195 - accuracy: 0.9910\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0185 - accuracy: 0.9960\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0273 - accuracy: 0.9950\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0185 - accuracy: 0.9969\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0191 - accuracy: 0.9917\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0154 - accuracy: 0.9962\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0241 - accuracy: 0.9948\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0134 - accuracy: 0.9971\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0116 - accuracy: 0.9975\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0311 - accuracy: 0.9890\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0111 - accuracy: 0.9993\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0060 - accuracy: 0.9998\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 834us/step - loss: 0.0118 - accuracy: 0.9950\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0132 - accuracy: 0.9965\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0217 - accuracy: 0.9943\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.0184 - accuracy: 0.9964\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0147 - accuracy: 0.9943\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0117 - accuracy: 0.9979\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0158 - accuracy: 0.9938\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0132 - accuracy: 0.9994\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0070 - accuracy: 0.9995\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 853us/step - loss: 0.0099 - accuracy: 0.9997\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 824us/step - loss: 0.0099 - accuracy: 0.9985\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0096 - accuracy: 0.9941\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0092 - accuracy: 0.9966\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0117 - accuracy: 0.9942\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0094 - accuracy: 0.9959\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0084 - accuracy: 0.9988\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0106 - accuracy: 0.9982\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0108 - accuracy: 0.9960\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0066 - accuracy: 0.9998\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0087 - accuracy: 0.9984\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0088 - accuracy: 0.9975\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0128 - accuracy: 0.9928\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.0067 - accuracy: 0.9996\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0094 - accuracy: 0.9958\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0144 - accuracy: 0.9938\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0063 - accuracy: 0.9998\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0091 - accuracy: 0.9979\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0191 - accuracy: 0.9961\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0116 - accuracy: 0.9961\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 991us/step - loss: 0.0168 - accuracy: 0.9908\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0103 - accuracy: 0.9956\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0093 - accuracy: 0.9954\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0091 - accuracy: 0.9986\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0066 - accuracy: 0.9996\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9965\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0207 - accuracy: 0.9902\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0072 - accuracy: 0.9981\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0106 - accuracy: 0.9968\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0063 - accuracy: 0.9991\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0096 - accuracy: 0.9997\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 959us/step - loss: 0.0053 - accuracy: 0.9990\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0090 - accuracy: 0.9945\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0111 - accuracy: 0.9940\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 783us/step - loss: 0.4982 - accuracy: 0.8299\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.3448 - accuracy: 0.8839\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.3185 - accuracy: 0.8787\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.3117 - accuracy: 0.8737\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.3114 - accuracy: 0.8858\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.2831 - accuracy: 0.9023\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.2558 - accuracy: 0.8969\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.2488 - accuracy: 0.9123\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.2456 - accuracy: 0.9077\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.2554 - accuracy: 0.9114\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.2140 - accuracy: 0.9296\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.2624 - accuracy: 0.8933\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.2204 - accuracy: 0.9228\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.1988 - accuracy: 0.9293\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.2008 - accuracy: 0.9200\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.1888 - accuracy: 0.9302\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.2048 - accuracy: 0.9258\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.1876 - accuracy: 0.9370\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.2063 - accuracy: 0.9200\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1694 - accuracy: 0.9355\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.1601 - accuracy: 0.9478\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.1940 - accuracy: 0.9277\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.1509 - accuracy: 0.9475\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.1520 - accuracy: 0.9490\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1539 - accuracy: 0.9467\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1532 - accuracy: 0.9414\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.1350 - accuracy: 0.9564\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.1358 - accuracy: 0.9503\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.1333 - accuracy: 0.9510\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.1370 - accuracy: 0.9436\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 989us/step - loss: 0.1376 - accuracy: 0.9466\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.1190 - accuracy: 0.9549\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.1252 - accuracy: 0.9476\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.1207 - accuracy: 0.9605\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.1172 - accuracy: 0.9598\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.1117 - accuracy: 0.9528\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.0855 - accuracy: 0.9716\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.1001 - accuracy: 0.9717\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0887 - accuracy: 0.9686\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0962 - accuracy: 0.9675\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0880 - accuracy: 0.9643\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.1018 - accuracy: 0.9559\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0971 - accuracy: 0.9685\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0795 - accuracy: 0.9799\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0981 - accuracy: 0.9544\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0868 - accuracy: 0.9684\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0744 - accuracy: 0.9808\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0717 - accuracy: 0.9783\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0597 - accuracy: 0.9739\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0611 - accuracy: 0.9779\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0625 - accuracy: 0.9740\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0636 - accuracy: 0.9830\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0629 - accuracy: 0.9836\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0591 - accuracy: 0.9789\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0657 - accuracy: 0.9773\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0418 - accuracy: 0.9861\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0504 - accuracy: 0.9868\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0555 - accuracy: 0.9825\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0530 - accuracy: 0.9806\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0516 - accuracy: 0.9889\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0531 - accuracy: 0.9812\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9880\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0501 - accuracy: 0.9873\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0443 - accuracy: 0.9919\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0461 - accuracy: 0.9832\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0314 - accuracy: 0.9955\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0340 - accuracy: 0.9934\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9967\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9931\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0296 - accuracy: 0.9931\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0326 - accuracy: 0.9914\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9949\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 992us/step - loss: 0.0415 - accuracy: 0.9829\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0279 - accuracy: 0.9974\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0279 - accuracy: 0.9967\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9897\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0210 - accuracy: 0.9965\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9943\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0257 - accuracy: 0.9915\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0258 - accuracy: 0.9951\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 922us/step - loss: 0.0344 - accuracy: 0.9873\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0268 - accuracy: 0.9905\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0221 - accuracy: 0.9943\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9886\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9942\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9977\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9941\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.0198 - accuracy: 0.9969\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9933\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0224 - accuracy: 0.9961\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0324 - accuracy: 0.9888\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0339 - accuracy: 0.9901\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0296 - accuracy: 0.9924\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0271 - accuracy: 0.9901\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0134 - accuracy: 0.9983\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0155 - accuracy: 0.9969\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0247 - accuracy: 0.9883\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0129 - accuracy: 0.9979\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0138 - accuracy: 0.9980\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0205 - accuracy: 0.9968\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0223 - accuracy: 0.9945\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0166 - accuracy: 0.9997\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0193 - accuracy: 0.9929\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0249 - accuracy: 0.9904\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0106 - accuracy: 0.9990\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0176 - accuracy: 0.9980\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0252 - accuracy: 0.9945\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0462 - accuracy: 0.9812\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0344 - accuracy: 0.9904\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0239 - accuracy: 0.9964\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0242 - accuracy: 0.9925\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0178 - accuracy: 0.9955\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0167 - accuracy: 0.9968\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.0229 - accuracy: 0.9915\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0154 - accuracy: 0.9971\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0176 - accuracy: 0.9958\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0170 - accuracy: 0.9954\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0147 - accuracy: 0.9951\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0137 - accuracy: 0.9971\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0143 - accuracy: 0.9961\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0246 - accuracy: 0.9884\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0181 - accuracy: 0.9939\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0200 - accuracy: 0.9924\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0204 - accuracy: 0.9896\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0170 - accuracy: 0.9956\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0187 - accuracy: 0.9957\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0109 - accuracy: 0.9993\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0135 - accuracy: 0.9969\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0125 - accuracy: 0.9989\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 835us/step - loss: 0.0187 - accuracy: 0.9944\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0131 - accuracy: 0.9980\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0216 - accuracy: 0.9932\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0179 - accuracy: 0.9961\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0104 - accuracy: 0.9985\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0156 - accuracy: 0.9951\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0201 - accuracy: 0.9925\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0150 - accuracy: 0.9955\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0201 - accuracy: 0.9899\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0180 - accuracy: 0.9956\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0171 - accuracy: 0.9895\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0079 - accuracy: 0.9988\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0126 - accuracy: 0.9950\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0095 - accuracy: 0.9992\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0110 - accuracy: 0.9934\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0122 - accuracy: 0.9972\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0072 - accuracy: 0.9988\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0138 - accuracy: 0.9971\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0062 - accuracy: 0.9997\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0098 - accuracy: 0.9976\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0077 - accuracy: 0.9983\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0157 - accuracy: 0.9928\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0134 - accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0086 - accuracy: 0.9987\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0126 - accuracy: 0.9958\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 972us/step - loss: 0.0183 - accuracy: 0.9962\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 908us/step - loss: 0.0185 - accuracy: 0.9954\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0204 - accuracy: 0.9935\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0221 - accuracy: 0.9942\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0099 - accuracy: 0.9965\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0144 - accuracy: 0.9949\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0139 - accuracy: 0.9969\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0054 - accuracy: 0.9994\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0102 - accuracy: 0.9953\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0121 - accuracy: 0.9973\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0141 - accuracy: 0.9917\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0102 - accuracy: 0.9981\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0101 - accuracy: 0.9966\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0203 - accuracy: 0.9921\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0058 - accuracy: 0.9994\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0180 - accuracy: 0.9921\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0116 - accuracy: 0.9968\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0090 - accuracy: 0.9987\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0060 - accuracy: 0.9990\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0080 - accuracy: 0.9983\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0157 - accuracy: 0.9937\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0149 - accuracy: 0.9964\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0185 - accuracy: 0.9956\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0135 - accuracy: 0.9958\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0081 - accuracy: 0.9971\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 970us/step - loss: 0.0252 - accuracy: 0.9894\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0118 - accuracy: 0.9971\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 941us/step - loss: 0.0110 - accuracy: 0.9957\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0066 - accuracy: 0.9992\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0175 - accuracy: 0.9954\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0250 - accuracy: 0.9892\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 830us/step - loss: 0.5842 - accuracy: 0.7699\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 816us/step - loss: 0.3582 - accuracy: 0.8840\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.3403 - accuracy: 0.8859\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.3254 - accuracy: 0.8857\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 916us/step - loss: 0.3472 - accuracy: 0.8743\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.3079 - accuracy: 0.8874\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 996us/step - loss: 0.2814 - accuracy: 0.8914\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.3252 - accuracy: 0.8861\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.2900 - accuracy: 0.8874\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.2630 - accuracy: 0.8963\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.2671 - accuracy: 0.8979\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.2313 - accuracy: 0.9166\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.2354 - accuracy: 0.9074\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.2644 - accuracy: 0.9057\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.2191 - accuracy: 0.9198\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.2191 - accuracy: 0.9145\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.2178 - accuracy: 0.9168\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.1867 - accuracy: 0.9233\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.2130 - accuracy: 0.9208\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.1849 - accuracy: 0.9371\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.1670 - accuracy: 0.9507\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.1921 - accuracy: 0.9275\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1591 - accuracy: 0.9428\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.1642 - accuracy: 0.9432\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.1439 - accuracy: 0.9434\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1492 - accuracy: 0.9582\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.1591 - accuracy: 0.9463\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.1604 - accuracy: 0.9459\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.1174 - accuracy: 0.9575\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 977us/step - loss: 0.1260 - accuracy: 0.9576\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.1229 - accuracy: 0.9554\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.1248 - accuracy: 0.9516\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.1321 - accuracy: 0.9578\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.1205 - accuracy: 0.9545\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.1129 - accuracy: 0.9642\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.1145 - accuracy: 0.9589\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 846us/step - loss: 0.1003 - accuracy: 0.9562\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.1114 - accuracy: 0.9604\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.1060 - accuracy: 0.9672\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.1121 - accuracy: 0.9615\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.1064 - accuracy: 0.9594\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0934 - accuracy: 0.9753\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.1108 - accuracy: 0.9629\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.1051 - accuracy: 0.9638\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0954 - accuracy: 0.9739\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0859 - accuracy: 0.9744\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0733 - accuracy: 0.9833\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0834 - accuracy: 0.9639\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0881 - accuracy: 0.9734\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0676 - accuracy: 0.9737\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0905 - accuracy: 0.9769\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0714 - accuracy: 0.9734\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0799 - accuracy: 0.9737\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.1092 - accuracy: 0.9605\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0758 - accuracy: 0.9706\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0771 - accuracy: 0.9680\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0784 - accuracy: 0.9737\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0567 - accuracy: 0.9834\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0661 - accuracy: 0.9798\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0660 - accuracy: 0.9793\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0656 - accuracy: 0.9785\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0775 - accuracy: 0.9705\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0629 - accuracy: 0.9765\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0658 - accuracy: 0.9742\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0647 - accuracy: 0.9857\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0603 - accuracy: 0.9796\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0714 - accuracy: 0.9826\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0690 - accuracy: 0.9726\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0835 - accuracy: 0.9631\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0560 - accuracy: 0.9771\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0779 - accuracy: 0.9711\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0534 - accuracy: 0.9784\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0481 - accuracy: 0.9850\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0515 - accuracy: 0.9844\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0634 - accuracy: 0.9879\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0558 - accuracy: 0.9744\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0700 - accuracy: 0.9729\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0639 - accuracy: 0.9762\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0520 - accuracy: 0.9853\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0487 - accuracy: 0.9776\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 872us/step - loss: 0.0473 - accuracy: 0.9843\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0472 - accuracy: 0.9789\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0437 - accuracy: 0.9813\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0344 - accuracy: 0.9911\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0488 - accuracy: 0.9755\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0521 - accuracy: 0.9792\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0481 - accuracy: 0.9759\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0379 - accuracy: 0.9900\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0399 - accuracy: 0.9875\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0383 - accuracy: 0.9872\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0478 - accuracy: 0.9740\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0253 - accuracy: 0.9964\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0515 - accuracy: 0.9800\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0382 - accuracy: 0.9912\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0439 - accuracy: 0.9832\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0496 - accuracy: 0.9791\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0327 - accuracy: 0.9865\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0551 - accuracy: 0.9782\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0455 - accuracy: 0.9801\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0352 - accuracy: 0.9880\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0486 - accuracy: 0.9785\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 925us/step - loss: 0.0304 - accuracy: 0.9882\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0383 - accuracy: 0.9812\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0250 - accuracy: 0.9920\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 964us/step - loss: 0.0335 - accuracy: 0.9884\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0375 - accuracy: 0.9829\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0409 - accuracy: 0.9784\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0338 - accuracy: 0.9882\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0244 - accuracy: 0.9896\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0284 - accuracy: 0.9876\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0387 - accuracy: 0.9864\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0408 - accuracy: 0.9821\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0333 - accuracy: 0.9937\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0351 - accuracy: 0.9862\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0230 - accuracy: 0.9942\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0250 - accuracy: 0.9937\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0237 - accuracy: 0.9949\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0240 - accuracy: 0.9924\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9780\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0412 - accuracy: 0.9837\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0356 - accuracy: 0.9888\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0327 - accuracy: 0.9919\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0342 - accuracy: 0.9899\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0362 - accuracy: 0.9866\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0240 - accuracy: 0.9924\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0344 - accuracy: 0.9796\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0556 - accuracy: 0.9863\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0364 - accuracy: 0.9852\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0191 - accuracy: 0.9943\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0289 - accuracy: 0.9882\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0242 - accuracy: 0.9934\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0371 - accuracy: 0.9781\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9872\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9831\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9866\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9990\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9891\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9803\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9806\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0221 - accuracy: 0.9921\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0216 - accuracy: 0.9906\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0331 - accuracy: 0.9854\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 978us/step - loss: 0.0193 - accuracy: 0.9944\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9867\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0202 - accuracy: 0.9956\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0307 - accuracy: 0.9871\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0235 - accuracy: 0.9905\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.0248 - accuracy: 0.9887\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0273 - accuracy: 0.9863\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0186 - accuracy: 0.9976\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0229 - accuracy: 0.9915\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0278 - accuracy: 0.9839\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0310 - accuracy: 0.9940\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0175 - accuracy: 0.9978\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0301 - accuracy: 0.9869\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0220 - accuracy: 0.9899\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0245 - accuracy: 0.9903\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0234 - accuracy: 0.9935\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0162 - accuracy: 0.9955\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 827us/step - loss: 0.0290 - accuracy: 0.9908\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 820us/step - loss: 0.0384 - accuracy: 0.9856\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.0247 - accuracy: 0.9942\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0203 - accuracy: 0.9924\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0175 - accuracy: 0.9931\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0285 - accuracy: 0.9949\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0186 - accuracy: 0.9916\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 817us/step - loss: 0.0308 - accuracy: 0.9853\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0255 - accuracy: 0.9873\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 811us/step - loss: 0.0181 - accuracy: 0.9888\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0106 - accuracy: 0.9961\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0193 - accuracy: 0.9914\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.0171 - accuracy: 0.9954\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0227 - accuracy: 0.9948\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0181 - accuracy: 0.9947\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 821us/step - loss: 0.0211 - accuracy: 0.9909\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0154 - accuracy: 0.9971\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 830us/step - loss: 0.0158 - accuracy: 0.9960\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0157 - accuracy: 0.9985\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0148 - accuracy: 0.9971\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0269 - accuracy: 0.9905\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0151 - accuracy: 0.9947\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0394 - accuracy: 0.9847\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0270 - accuracy: 0.9869\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0216 - accuracy: 0.9936\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0414 - accuracy: 0.9871\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9927\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.0206 - accuracy: 0.9918\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0391 - accuracy: 0.9830\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0246 - accuracy: 0.9897\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0255 - accuracy: 0.9911\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0147 - accuracy: 0.9949\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0176 - accuracy: 0.9949\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0287 - accuracy: 0.9885\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0113 - accuracy: 0.9956\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0272 - accuracy: 0.9912\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0123 - accuracy: 0.9968\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0133 - accuracy: 0.9966\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 832us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0225 - accuracy: 0.9916\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0225 - accuracy: 0.9906\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 856us/step - loss: 0.7598 - accuracy: 0.7226\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 840us/step - loss: 0.3676 - accuracy: 0.8616\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.3284 - accuracy: 0.8923\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.3051 - accuracy: 0.8908\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.2817 - accuracy: 0.8819\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.2816 - accuracy: 0.8837\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.2998 - accuracy: 0.8923\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.2882 - accuracy: 0.8863\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.2527 - accuracy: 0.8960\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 924us/step - loss: 0.2477 - accuracy: 0.9052\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.2228 - accuracy: 0.9259\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.2078 - accuracy: 0.9208\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.2197 - accuracy: 0.9134\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 953us/step - loss: 0.2075 - accuracy: 0.9220\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.1999 - accuracy: 0.9175\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.2066 - accuracy: 0.9288\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.2106 - accuracy: 0.9244\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.2170 - accuracy: 0.9261\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.2208 - accuracy: 0.9199\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.1906 - accuracy: 0.9212\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 853us/step - loss: 0.1945 - accuracy: 0.9271\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.1697 - accuracy: 0.9335\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.1571 - accuracy: 0.9484\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.1462 - accuracy: 0.9391\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.1446 - accuracy: 0.9512\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.1367 - accuracy: 0.9462\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 956us/step - loss: 0.1418 - accuracy: 0.9547\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.1551 - accuracy: 0.9337\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.1234 - accuracy: 0.9588\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.1221 - accuracy: 0.9617\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.1009 - accuracy: 0.9671\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.1531 - accuracy: 0.9516\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.1271 - accuracy: 0.9621\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 869us/step - loss: 0.1239 - accuracy: 0.9525\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 826us/step - loss: 0.1280 - accuracy: 0.9495\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.1176 - accuracy: 0.9676\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.1200 - accuracy: 0.9685\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.1019 - accuracy: 0.9703\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.1189 - accuracy: 0.9581\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.1192 - accuracy: 0.9589\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0975 - accuracy: 0.9642\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.1040 - accuracy: 0.9638\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 943us/step - loss: 0.0949 - accuracy: 0.9605\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1004 - accuracy: 0.9704\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0973 - accuracy: 0.9672\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0595 - accuracy: 0.9831\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0734 - accuracy: 0.9802\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 905us/step - loss: 0.0715 - accuracy: 0.9783\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0809 - accuracy: 0.9755\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0818 - accuracy: 0.9745\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0578 - accuracy: 0.9861\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0744 - accuracy: 0.9733\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0698 - accuracy: 0.9743\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.0761 - accuracy: 0.9764\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0636 - accuracy: 0.9818\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0479 - accuracy: 0.9852\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0536 - accuracy: 0.9846\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0660 - accuracy: 0.9773\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0576 - accuracy: 0.9915\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0555 - accuracy: 0.9856\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0592 - accuracy: 0.9855\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0498 - accuracy: 0.9879\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.0651 - accuracy: 0.9787\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0434 - accuracy: 0.9929\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0509 - accuracy: 0.9843\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0444 - accuracy: 0.9924\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0402 - accuracy: 0.9900\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0453 - accuracy: 0.9879\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0634 - accuracy: 0.9845\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0402 - accuracy: 0.9915\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 836us/step - loss: 0.0418 - accuracy: 0.9914\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0412 - accuracy: 0.9898\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 825us/step - loss: 0.0447 - accuracy: 0.9853\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0505 - accuracy: 0.9909\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0332 - accuracy: 0.9889\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 946us/step - loss: 0.0428 - accuracy: 0.9827\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0544 - accuracy: 0.9827\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0375 - accuracy: 0.9928\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0466 - accuracy: 0.9917\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0317 - accuracy: 0.9907\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 861us/step - loss: 0.0407 - accuracy: 0.9867\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0296 - accuracy: 0.9926\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0255 - accuracy: 0.9951\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0293 - accuracy: 0.9990\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0317 - accuracy: 0.9964\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 918us/step - loss: 0.0345 - accuracy: 0.9912\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0370 - accuracy: 0.9867\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.0388 - accuracy: 0.9933\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0325 - accuracy: 0.9958\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.0343 - accuracy: 0.9935\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0345 - accuracy: 0.9922\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9925\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 998us/step - loss: 0.0285 - accuracy: 0.9945\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 966us/step - loss: 0.0309 - accuracy: 0.9952\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0307 - accuracy: 0.9891\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9925\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9867\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0293 - accuracy: 0.9863\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0223 - accuracy: 0.9957\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 984us/step - loss: 0.0197 - accuracy: 0.9979\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 913us/step - loss: 0.0276 - accuracy: 0.9923\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0269 - accuracy: 0.9925\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.0439 - accuracy: 0.9850\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9899\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9895\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 950us/step - loss: 0.0303 - accuracy: 0.9910\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0360 - accuracy: 0.9885\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9925\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 1000us/step - loss: 0.0259 - accuracy: 0.9946\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0259 - accuracy: 0.9973\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0293 - accuracy: 0.9959\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0265 - accuracy: 0.9943\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0207 - accuracy: 0.9943\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0198 - accuracy: 0.9947\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0221 - accuracy: 0.9965\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 935us/step - loss: 0.0329 - accuracy: 0.9834\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0214 - accuracy: 0.9925\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0218 - accuracy: 0.9920\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0218 - accuracy: 0.9936\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 985us/step - loss: 0.0214 - accuracy: 0.9977\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 952us/step - loss: 0.0205 - accuracy: 0.9987\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 0.9985\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0144 - accuracy: 0.9990\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0159 - accuracy: 0.9962\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0113 - accuracy: 0.9996\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 960us/step - loss: 0.0118 - accuracy: 0.9992\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0131 - accuracy: 0.9950\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 898us/step - loss: 0.0175 - accuracy: 0.9968\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0228 - accuracy: 0.9955\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 973us/step - loss: 0.0177 - accuracy: 0.9994\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0158 - accuracy: 0.9949\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0208 - accuracy: 0.9960\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0229 - accuracy: 0.9941\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0164 - accuracy: 0.9957\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0121 - accuracy: 0.9984\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0239 - accuracy: 0.9920\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0221 - accuracy: 0.9948\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0127 - accuracy: 0.9970\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0194 - accuracy: 0.9961\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0144 - accuracy: 0.9977\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 986us/step - loss: 0.0247 - accuracy: 0.9920\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0115 - accuracy: 0.9996\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0103 - accuracy: 0.9993\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.0150 - accuracy: 0.9951\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 990us/step - loss: 0.0121 - accuracy: 0.9994\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0133 - accuracy: 0.9980\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0182 - accuracy: 0.9935\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0109 - accuracy: 0.9977\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 969us/step - loss: 0.0212 - accuracy: 0.9955\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 822us/step - loss: 0.0341 - accuracy: 0.9850\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0402 - accuracy: 0.9818\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0282 - accuracy: 0.9930\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0166 - accuracy: 0.9972\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 847us/step - loss: 0.0132 - accuracy: 0.9971\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 829us/step - loss: 0.0133 - accuracy: 0.9996\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0103 - accuracy: 0.9985\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 886us/step - loss: 0.0270 - accuracy: 0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0121 - accuracy: 0.9977\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0138 - accuracy: 0.9973\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0162 - accuracy: 0.9948\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 982us/step - loss: 0.0158 - accuracy: 0.9977\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9926\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 860us/step - loss: 0.0157 - accuracy: 0.9975\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0223 - accuracy: 0.9924\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0190 - accuracy: 0.9969\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0219 - accuracy: 0.9904\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 828us/step - loss: 0.0119 - accuracy: 0.9957\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0177 - accuracy: 0.9896\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0140 - accuracy: 0.9989\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 897us/step - loss: 0.0147 - accuracy: 0.9975\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0214 - accuracy: 0.9934\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0182 - accuracy: 0.9942\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0227 - accuracy: 0.9965\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0309 - accuracy: 0.9890\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0167 - accuracy: 0.9955\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0130 - accuracy: 0.9948\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0259 - accuracy: 0.9916\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0113 - accuracy: 0.9969\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 879us/step - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 894us/step - loss: 0.0059 - accuracy: 0.9998\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0094 - accuracy: 0.9983\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0128 - accuracy: 0.9971\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0362 - accuracy: 0.9896\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 888us/step - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0193 - accuracy: 0.9946\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 927us/step - loss: 0.0172 - accuracy: 0.9960\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 929us/step - loss: 0.0142 - accuracy: 0.9946\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 997us/step - loss: 0.0179 - accuracy: 0.9980\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 891us/step - loss: 0.0119 - accuracy: 0.9976\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0127 - accuracy: 0.9998\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0124 - accuracy: 0.9972\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 896us/step - loss: 0.7339 - accuracy: 0.7221\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.4231 - accuracy: 0.8594\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 987us/step - loss: 0.3399 - accuracy: 0.8834\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.3445 - accuracy: 0.8663\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.3071 - accuracy: 0.8857\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8834\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2952 - accuracy: 0.8880\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8698\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8861\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.2724 - accuracy: 0.9062\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.2395 - accuracy: 0.9147\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 981us/step - loss: 0.2614 - accuracy: 0.8945\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.2411 - accuracy: 0.9042\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.2568 - accuracy: 0.9130\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 974us/step - loss: 0.2193 - accuracy: 0.9172\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9227\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.9291\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.9291\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.9401\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9379\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1687 - accuracy: 0.9373\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1651 - accuracy: 0.9286\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1690 - accuracy: 0.9381\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9345\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9317\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9435\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9330\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1432 - accuracy: 0.9346\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9468\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.9585\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 945us/step - loss: 0.1368 - accuracy: 0.9496\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.1241 - accuracy: 0.9581\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9563\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 915us/step - loss: 0.1110 - accuracy: 0.9620\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.1173 - accuracy: 0.9611\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.1043 - accuracy: 0.9563\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 871us/step - loss: 0.1116 - accuracy: 0.9591\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 868us/step - loss: 0.0960 - accuracy: 0.9724\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.1086 - accuracy: 0.9611\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0946 - accuracy: 0.9696\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0944 - accuracy: 0.9682\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 980us/step - loss: 0.0869 - accuracy: 0.9701\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 858us/step - loss: 0.0894 - accuracy: 0.9655\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 922us/step - loss: 0.1277 - accuracy: 0.9529\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.1037 - accuracy: 0.9645\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 911us/step - loss: 0.0878 - accuracy: 0.9608\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0898 - accuracy: 0.9656\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 948us/step - loss: 0.0718 - accuracy: 0.9736\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 837us/step - loss: 0.0786 - accuracy: 0.9785\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 933us/step - loss: 0.0662 - accuracy: 0.9791\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 852us/step - loss: 0.0970 - accuracy: 0.9583\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 919us/step - loss: 0.0900 - accuracy: 0.9671\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0846 - accuracy: 0.9724\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 958us/step - loss: 0.0804 - accuracy: 0.9735\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 861us/step - loss: 0.0648 - accuracy: 0.9744\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0837 - accuracy: 0.9589\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 849us/step - loss: 0.0697 - accuracy: 0.9736\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0641 - accuracy: 0.9718\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 909us/step - loss: 0.0554 - accuracy: 0.9830\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0673 - accuracy: 0.9786\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0660 - accuracy: 0.9756\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0607 - accuracy: 0.9697\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 887us/step - loss: 0.0667 - accuracy: 0.9682\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 962us/step - loss: 0.0683 - accuracy: 0.9760\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 947us/step - loss: 0.0730 - accuracy: 0.9644\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0543 - accuracy: 0.9829\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 892us/step - loss: 0.0697 - accuracy: 0.9732\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0822 - accuracy: 0.9702\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 936us/step - loss: 0.0837 - accuracy: 0.9663\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 910us/step - loss: 0.0541 - accuracy: 0.9803\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0517 - accuracy: 0.9782\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0533 - accuracy: 0.9809\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 942us/step - loss: 0.0664 - accuracy: 0.9787\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0466 - accuracy: 0.9830\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 951us/step - loss: 0.0511 - accuracy: 0.9804\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0405 - accuracy: 0.9854\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0511 - accuracy: 0.9814\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0419 - accuracy: 0.9907\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 967us/step - loss: 0.0477 - accuracy: 0.9819\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0486 - accuracy: 0.9810\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 887us/step - loss: 0.0409 - accuracy: 0.9793\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0435 - accuracy: 0.9877\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 901us/step - loss: 0.0415 - accuracy: 0.9854\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 971us/step - loss: 0.0424 - accuracy: 0.9782\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 995us/step - loss: 0.0385 - accuracy: 0.9887\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 965us/step - loss: 0.0370 - accuracy: 0.9864\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 930us/step - loss: 0.0448 - accuracy: 0.9891\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9851\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 979us/step - loss: 0.0285 - accuracy: 0.9859\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 993us/step - loss: 0.0333 - accuracy: 0.9913\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 0.9888\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 937us/step - loss: 0.0407 - accuracy: 0.9853\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 923us/step - loss: 0.0502 - accuracy: 0.9809\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0453 - accuracy: 0.9799\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 931us/step - loss: 0.0543 - accuracy: 0.9748\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0430 - accuracy: 0.9854\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 988us/step - loss: 0.0412 - accuracy: 0.9857\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0426 - accuracy: 0.9898\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 921us/step - loss: 0.0398 - accuracy: 0.9900\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 842us/step - loss: 0.0505 - accuracy: 0.9867\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0376 - accuracy: 0.9893\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 912us/step - loss: 0.0208 - accuracy: 0.9952\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0298 - accuracy: 0.9895\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 928us/step - loss: 0.0342 - accuracy: 0.9936\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0446 - accuracy: 0.9813\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 954us/step - loss: 0.0427 - accuracy: 0.9862\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0313 - accuracy: 0.9889\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 961us/step - loss: 0.0364 - accuracy: 0.9879\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0211 - accuracy: 0.9945\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 907us/step - loss: 0.0300 - accuracy: 0.9869\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0284 - accuracy: 0.9884\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 999us/step - loss: 0.0408 - accuracy: 0.9832\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0380 - accuracy: 0.9772\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 944us/step - loss: 0.0269 - accuracy: 0.9949\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0322 - accuracy: 0.9915\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0345 - accuracy: 0.9905\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 904us/step - loss: 0.0272 - accuracy: 0.9944\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 934us/step - loss: 0.0257 - accuracy: 0.9933\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 938us/step - loss: 0.0241 - accuracy: 0.9917\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 895us/step - loss: 0.0213 - accuracy: 0.9940\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0325 - accuracy: 0.9897\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0353 - accuracy: 0.9889\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 863us/step - loss: 0.0316 - accuracy: 0.9874\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0301 - accuracy: 0.9902\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 862us/step - loss: 0.0307 - accuracy: 0.9905\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0293 - accuracy: 0.9881\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 881us/step - loss: 0.0244 - accuracy: 0.9944\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0363 - accuracy: 0.9833\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 949us/step - loss: 0.0275 - accuracy: 0.9912\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0281 - accuracy: 0.9932\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 939us/step - loss: 0.0270 - accuracy: 0.9928\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0332 - accuracy: 0.9852\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 865us/step - loss: 0.0237 - accuracy: 0.9940\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 893us/step - loss: 0.0365 - accuracy: 0.9834\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 859us/step - loss: 0.0228 - accuracy: 0.9944\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0294 - accuracy: 0.9870\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 851us/step - loss: 0.0258 - accuracy: 0.9872\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 831us/step - loss: 0.0242 - accuracy: 0.9869\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 906us/step - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0283 - accuracy: 0.9883\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 874us/step - loss: 0.0103 - accuracy: 0.9992\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 843us/step - loss: 0.0273 - accuracy: 0.9826\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0266 - accuracy: 0.9933\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 850us/step - loss: 0.0327 - accuracy: 0.9875\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 809us/step - loss: 0.0197 - accuracy: 0.9920\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0280 - accuracy: 0.9951\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 875us/step - loss: 0.0200 - accuracy: 0.9954\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 845us/step - loss: 0.0256 - accuracy: 0.9941\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 926us/step - loss: 0.0339 - accuracy: 0.9907\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 855us/step - loss: 0.0229 - accuracy: 0.9896\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0276 - accuracy: 0.9928\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 940us/step - loss: 0.0210 - accuracy: 0.9963\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 844us/step - loss: 0.0442 - accuracy: 0.9782\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0253 - accuracy: 0.9902\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 899us/step - loss: 0.0233 - accuracy: 0.9903\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 854us/step - loss: 0.0243 - accuracy: 0.9926\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0208 - accuracy: 0.9969\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0210 - accuracy: 0.9922\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 883us/step - loss: 0.0340 - accuracy: 0.9866\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 848us/step - loss: 0.0302 - accuracy: 0.9878\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0226 - accuracy: 0.9945\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 932us/step - loss: 0.0245 - accuracy: 0.9937\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 920us/step - loss: 0.0281 - accuracy: 0.9891\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 914us/step - loss: 0.0341 - accuracy: 0.9867\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 877us/step - loss: 0.0285 - accuracy: 0.9932\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 884us/step - loss: 0.0188 - accuracy: 0.9924\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0220 - accuracy: 0.9914\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0359 - accuracy: 0.9843\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0149 - accuracy: 0.9946\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 883us/step - loss: 0.0218 - accuracy: 0.9912\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0316 - accuracy: 0.9883\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 903us/step - loss: 0.0140 - accuracy: 0.9952\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 857us/step - loss: 0.0172 - accuracy: 0.9914\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0132 - accuracy: 0.9989\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0224 - accuracy: 0.9918\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 856us/step - loss: 0.0256 - accuracy: 0.9894\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 917us/step - loss: 0.0148 - accuracy: 0.9963\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 841us/step - loss: 0.0324 - accuracy: 0.9885\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 902us/step - loss: 0.0203 - accuracy: 0.9911\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 870us/step - loss: 0.0148 - accuracy: 0.9986\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 864us/step - loss: 0.0172 - accuracy: 0.9902\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 885us/step - loss: 0.0241 - accuracy: 0.9953\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 838us/step - loss: 0.0185 - accuracy: 0.9969\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 876us/step - loss: 0.0112 - accuracy: 0.9974\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 955us/step - loss: 0.0446 - accuracy: 0.9805\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 880us/step - loss: 0.0208 - accuracy: 0.9915\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0154 - accuracy: 0.9948\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 900us/step - loss: 0.0216 - accuracy: 0.9905\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 866us/step - loss: 0.0274 - accuracy: 0.9914\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 878us/step - loss: 0.0208 - accuracy: 0.9954\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 873us/step - loss: 0.0104 - accuracy: 0.9989\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 957us/step - loss: 0.0261 - accuracy: 0.9911\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 867us/step - loss: 0.0108 - accuracy: 0.9995\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 882us/step - loss: 0.0096 - accuracy: 0.9977\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 889us/step - loss: 0.0252 - accuracy: 0.9878\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 890us/step - loss: 0.0215 - accuracy: 0.9908\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 896us/step - loss: 0.0146 - accuracy: 0.9947\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 872us/step - loss: 0.0190 - accuracy: 0.9929\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 839us/step - loss: 0.0201 - accuracy: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/Users/bassler/opt/anaconda3/envs/Scientific_computing/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# with calibration (using stratified KFold for calibrator)\n",
    "probs = dict()\n",
    "for i in range(n_classes):\n",
    "#    clf_calib = CalibratedClassifierCV(clf.estimators_[i], cv=skf, method='isotonic')\n",
    "    clf_calib = CalibratedClassifierCV(clf, cv=skf, method='isotonic')\n",
    "    probs[i] = clf_calib.fit(X_onehot, y[:,i]).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bicyclomycin_Sds', 'Carbenicillin_Cholate', 'Cecropinb_Sds',\n",
       "       'Ceftazidime_Dibucaine', 'Ceftazidime_Sds',\n",
       "       'Chlorpromazine_Taurocholate', 'Chlorpromazine_Tetracycline',\n",
       "       'Deoxycholate_Sds', 'Nigericin_Sds', 'Norfloxacin_Sds',\n",
       "       'Sds_Tetracycline', 'Sds_Tunicamycin'], dtype='<U31')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# antagonisms based on calibrated probabilities\n",
    "combs_test[probs[1][:,1] > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Actinomycin D_Ethanol', 'Ampicillin_Cefoxitin',\n",
       "       'Azidothymidine_Ethanol', 'Cefoxitin_Ceftazidime',\n",
       "       'Ceftazidime_Taurocholate', 'Chir090_Uv',\n",
       "       'Chlorpromazine_Vancomycin', 'Deoxycholate_Taurocholate',\n",
       "       'Nalidixicacid_Streptonigrin', 'Norfloxacin_Taurocholate',\n",
       "       'Taurocholate_Vancomycin', 'Tritonx_Vancomycin'], dtype='<U31')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synergies based on calibrated probabilities\n",
    "combs_test[probs[2][:,1] > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df = pd.DataFrame(dict(antag=probs[1][:,1], synergy=probs[2][:,1], none=probs[0][:,1]))\\ndf.index = combs_test\\nnp.all(df.idxmax(axis=1).values == 'none')\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df = pd.DataFrame(dict(antag=probs[1][:,1], synergy=probs[2][:,1], none=probs[0][:,1]))\n",
    "df.index = combs_test\n",
    "np.all(df.idxmax(axis=1).values == 'none')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
