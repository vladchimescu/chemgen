{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antagonism and Synergy prediction in Salmonella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "sys.path.append('..')\n",
    "import base.chemgen_utils as utl\n",
    "import MLmod.predictor as prd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugleg_fname = \"../data/chemicals/legend_gramnegpos.txt\"\n",
    "gene_subset = '../data/interaction-genes-Salmonella'\n",
    "gene_subset = pd.read_csv(gene_subset, header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chemgen = pd.read_csv('../data/chemgenetics/salmonella_binarized.csv', index_col=0)\n",
    "X_chemgen = X_chemgen.iloc[:,np.where(np.isin(X_chemgen.columns, gene_subset))[0]]\n",
    "targets = pd.read_csv(\"../data/chemgenetics/salmonella_y.csv\")\n",
    "combs = targets['comb'].values\n",
    "y = targets['type'].values\n",
    "\n",
    "X_df = pd.DataFrame([utl.get_comb_feat(X_chemgen, c) for c in combs])\n",
    "\n",
    "drugclasses = pd.read_csv(drugleg_fname, sep='\\t')\n",
    "druglegend = drugclasses.loc[:,['Drug', 'Class']]\n",
    "\n",
    "comb_drugs = pd.DataFrame(np.array([utl.split_vec(i) for i in combs]),\n",
    "                          columns=['d1', 'd2'])\n",
    "comb_drugs = utl.add_class(strain=comb_drugs,\n",
    "                           druglegend=druglegend)\n",
    "# an array with all drug class labels\n",
    "class_arr = np.unique(np.union1d(pd.unique(comb_drugs.class1),\n",
    "                                 pd.unique(comb_drugs.class2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_drugs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs rest classification\n",
    "y[y=='none'] = 0\n",
    "y[y=='antagonism']=1\n",
    "y[y=='synergy']=2\n",
    "\n",
    "y=y.astype('int')\n",
    "y = label_binarize(y, classes=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'n_estimators': 200,\n",
    " 'min_samples_split': 7,\n",
    " 'min_samples_leaf': 3,\n",
    " 'max_depth': None,\n",
    " 'class_weight': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = prd.MultiClassPredictions(X=X_df.to_numpy(), y=y,\n",
    "                                   combs=combs,\n",
    "                                  **param_dict,\n",
    "                                   clf='randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.crossval_drugclass(class_arr=class_arr, leg_class=comb_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.save_topfeat(outdir='../data/', fname=\"topfeat-multiclass-Salmonella\",\n",
    "                    featname=X_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df = (pd.concat({k: pd.DataFrame(v.values(),\n",
    "                                   index=['AUCROC_none',\n",
    "                                          'AUCROC_antag',\n",
    "                                          'AUCROC_syn']).T \\\n",
    "                   for k,v in pr.auc.items()}).\n",
    "         reset_index().rename(columns={\"level_0\": \"cvfold\"}).\n",
    "         drop(columns=[\"level_1\"]))\n",
    "\n",
    "ap_df = (pd.concat({k: pd.DataFrame(v.values(),\n",
    "                           index=['AP_none',\n",
    "                                  'AP_antag',\n",
    "                                  'AP_syn']).T \\\n",
    "           for k,v in pr.avprec.items()}).\n",
    " reset_index().rename(columns={\"level_0\": \"cvfold\"}).\n",
    " drop(columns=[\"level_1\"]))\n",
    "\n",
    "metrics = pd.merge(auc_df, ap_df, on='cvfold', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics.\n",
    " sort_values('AP_antag', ascending=False).\n",
    " reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metrics.\n",
    " sort_values('AP_syn', ascending=False).\n",
    " reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvars = (pd.concat(pr.topfeat).\n",
    "                   reset_index().\n",
    "                   rename(columns={\"level_0\": \"cvfold\"}).\n",
    "                   drop(columns=['level_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featname=X_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topvars = (topvars.assign(feature=featname[topvars.feat]).\n",
    "           drop(columns=['feat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top genes for antagonism prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(topvars[topvars.type == 'antagonism'].\n",
    " groupby('feature').agg('count').\n",
    " query('cvfold > 1').\n",
    " sort_values('cvfold', ascending=False).iloc[:20,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top genes for synergy prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(topvars[topvars.type == 'synergy'].\n",
    " groupby('feature').agg('count').\n",
    " query('cvfold > 1').\n",
    " sort_values('cvfold', ascending=False).iloc[:20,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_df = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in pr.predicted.keys():\n",
    "    #print(cl)\n",
    "    ycl = y[np.isin(combs, pr.predicted[cl]['comb'].values)]\n",
    "    gt = pd.DataFrame(ycl, columns=['none', 'antagonism', 'synergy'])\n",
    "    gt['comb'] = combs[np.isin(combs, pr.predicted[cl]['comb'].values)]\n",
    "    pred_df = pd.merge(left=pr.predicted[cl], right=gt, how='inner', on='comb')\n",
    "    \n",
    "    precision, recall, thresh = precision_recall_curve(pred_df['antagonism'].values,\n",
    "                                                        pred_df['prob_ant'].values)\n",
    "    if not np.any(np.isnan(precision)) and not np.any(np.isnan(recall)) and len(thresh) > 1:\n",
    "        q3 = np.quantile(recall, 0.75)\n",
    "        if np.any(recall == q3):\n",
    "            pmax = np.max(precision[recall == q3])\n",
    "        else:\n",
    "            ind = np.floor(np.quantile(range(len(recall)),0.75)).astype(int)\n",
    "            q3 = recall[ind]\n",
    "            pmax = precision[ind]\n",
    "        antag_thresh = thresh[np.where(np.logical_and(precision == pmax, recall == q3))[0]+1][0]\n",
    "        antag_tp = pred_df[(pred_df.prob_ant > antag_thresh) == pred_df.antagonism]\n",
    "        antag_tp = antag_tp[antag_tp.antagonism == 1]\n",
    "        antag_tp['thresh'] = antag_thresh\n",
    "        antag_tp['precision'] = pmax\n",
    "        antag_tp['recall'] = q3\n",
    "        antag_tp['cvfold'] = cl\n",
    "        TP_df.append(antag_tp)\n",
    "    \n",
    "    precision, recall, thresh = precision_recall_curve(pred_df['synergy'].values,\n",
    "                                                        pred_df['prob_syn'].values)\n",
    "    if not np.any(np.isnan(precision)) and not np.any(np.isnan(recall)) and len(thresh) > 1:\n",
    "        q3 = np.quantile(recall, 0.75)\n",
    "        if np.any(recall == q3):\n",
    "            pmax = np.max(precision[recall == q3])\n",
    "        else:\n",
    "            ind = np.floor(np.quantile(range(len(recall)),0.75)).astype(int)\n",
    "            q3 = recall[ind]\n",
    "            pmax = precision[ind]\n",
    "        syn_thresh = thresh[np.where(np.logical_and(precision == pmax, recall == q3))[0]][0]\n",
    "\n",
    "        syn_tp = pred_df[(pred_df.prob_syn > syn_thresh) == pred_df.synergy]\n",
    "        syn_tp = syn_tp[syn_tp.synergy == 1]\n",
    "        syn_tp['thresh'] = syn_thresh\n",
    "        syn_tp['precision'] = pmax\n",
    "        syn_tp['recall'] = q3\n",
    "        syn_tp['cvfold'] = cl\n",
    "        TP_df.append(syn_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_df = pd.concat(TP_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_df.to_csv('Salmonella-true-positives-CVfold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Classifier with Cross-Validated Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X_df\n",
    "ytrain = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RandomForestClassifier(bootstrap=True,\n",
    "                                                max_features='sqrt',\n",
    "                                                **param_dict,\n",
    "                                                random_state=2305,\n",
    "                                              n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(Xtrain, ytrain, test_size=0.3,\n",
    "                                                    random_state=2305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_ = clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot precision-recall for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "thresh = dict()\n",
    "average_precision = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val[:, i], probas_[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    precision[i], recall[i], thresh[i] = precision_recall_curve(y_val[:, i],\n",
    "                                                        probas_[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val[:, i], probas_[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "class_names = ['none', 'antagonism', 'synergy']\n",
    "colors = cycle(['#808080','#FFCC33', '#009999'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y_ = f_score * x / (2 * x - f_score)\n",
    "    plt.plot(x[y_ >= 0], y_[y_ >= 0], color='gray', alpha=0.2,\n",
    "             label='iso-F1 curves')\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y_[45] + 0.02))\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label='Precision-recall of class {0} (area = {1:0.2f})'\n",
    "             ''.format(class_names[i], average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "fraction_of_positives = dict()\n",
    "mean_predicted_value = dict()\n",
    "for i in range(n_classes):\n",
    "    proba_val = clf.predict_proba(X_val)[:, i]\n",
    "    fraction_of_positives[i], mean_predicted_value[i] = calibration_curve(y_val[:,i],\n",
    "                                                                proba_val,\n",
    "                                                                n_bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "plt.plot(mean_predicted_value[0], fraction_of_positives[0], 's-', label='none')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot(mean_predicted_value[1], fraction_of_positives[1], 's-', label='antagonism')\n",
    "plt.plot(mean_predicted_value[2], fraction_of_positives[2], 's-', label='synergy')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Uncalibrated probabilities')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_of_positives = dict()\n",
    "mean_predicted_value = dict()\n",
    "for i in range(n_classes):\n",
    "    #proba_val = clf.predict_proba(X_val)[:, i]\n",
    "    clf_calib = CalibratedClassifierCV(clf.estimators_[i], cv=5, method='sigmoid')\n",
    "    proba_val = clf_calib.fit(X_train, y_train[:,i]).predict_proba(X_val)[:,1]\n",
    "    fraction_of_positives[i], mean_predicted_value[i] = calibration_curve(y_val[:,i],\n",
    "                                                                proba_val,\n",
    "                                                                n_bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "plt.plot(mean_predicted_value[0], fraction_of_positives[0], 's-', label='none')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.plot(mean_predicted_value[1], fraction_of_positives[1], 's-', label='antagonism')\n",
    "plt.plot(mean_predicted_value[2], fraction_of_positives[2], 's-', label='synergy')\n",
    "plt.title('Calibrated probabilities')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow calibrated probabilities are worse than the \"uncalibrated\" ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs = pd.read_csv('../data/chemgenetics/salmonella_testset_binarized.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs = X_drugs.iloc[:,np.where(np.isin(X_drugs.columns, gene_subset))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drugs = X_drugs.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "combs_test = list(itertools.combinations(test_drugs, 2))\n",
    "combs_test = np.array([i[0]+\"_\"+i[1] for i in combs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame([utl.get_comb_feat(X_drugs, c) for c in combs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(X_test.columns == Xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without probability calibration\n",
    "y_test_proba = clf.fit(Xtrain, ytrain).predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antag = combs_test[y_test_proba[:,1] > 0.24]\n",
    "syn = combs_test[y_test_proba[:,2] > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr = pd.DataFrame(y_test_proba, index=combs_test,\n",
    "             columns=['none', 'antag', 'synergy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr.to_csv('salmonella_test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr.sort_values('antag', ascending=False).iloc[:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_uncalibr.sort_values('synergy', ascending=False).iloc[:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with calibration\n",
    "probs = dict()\n",
    "for i in range(n_classes):\n",
    "    clf_calib = CalibratedClassifierCV(clf.estimators_[i], cv=skf, method='isotonic')\n",
    "    probs[i] = clf_calib.fit(Xtrain, ytrain[:,i]).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antag = combs_test[probs[1][:,1] > 0.2]\n",
    "syn = combs_test[probs[2][:,1] > 0.2]\n",
    "not_none = combs_test[probs[0][:,1] < 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setdiff1d(antag, syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.setdiff1d(syn, antag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.intersect1d(antag, syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
